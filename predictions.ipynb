{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import cache\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import requests\n",
    "import heapq\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from math import floor\n",
    "from torch import nn\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch rows from the database. Run once and only when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8240287\n"
     ]
    }
   ],
   "source": [
    "df: pd.DataFrame = pd.read_pickle('bikeshare_data.pkl')\n",
    "print(df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fetch station_information, which will be used in later functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIKE_BASE_ENDPOINT = \"https://tor.publicbikesystem.net/ube/gbfs/v1/en/\" \n",
    "ENDPOINTS = {\n",
    "        \"station_status\": BIKE_BASE_ENDPOINT + \"station_status\",\n",
    "        \"station_information\": BIKE_BASE_ENDPOINT + \"station_information\",\n",
    "}\n",
    "\n",
    "\n",
    "def _fetch_station_status(endpoints: dict[str, str]) -> list[dict]:\n",
    "    \"\"\"Return a sorted list (by station_id) containing station status for all stations.\"\"\"\n",
    "    response = requests.get(endpoints[\"station_status\"])\n",
    "    response_data: dict = response.json()\n",
    "    return response_data[\"data\"][\"stations\"]\n",
    "\n",
    "def _fetch_station_information(endpoints: dict[str, str]) -> list[dict]:\n",
    "    \"\"\"Return a sorted list (by station_id) containing station information for all stations.\"\"\"\n",
    "    response = requests.get(endpoints[\"station_information\"])\n",
    "    response_data: dict = response.json()\n",
    "    return response_data[\"data\"][\"stations\"]\n",
    "\n",
    "station_status = _fetch_station_status(ENDPOINTS)\n",
    "station_information = _fetch_station_information(ENDPOINTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the working station IDS, discarding EOL stations and other define ID related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_IDs() -> list[str]:\n",
    "    \"\"\"Return a sorted list with all the stationIDs.\"\"\"\n",
    "    ids = []\n",
    "    status_i = 0\n",
    "    information_i = 0\n",
    "    while status_i < len(station_status) and information_i < len(station_information):\n",
    "        status_station_id = int(station_status[status_i][\"station_id\"])\n",
    "        information_station_id = int(station_information[information_i][\"station_id\"])\n",
    "        if status_station_id < information_station_id:\n",
    "            status_i += 1\n",
    "        elif information_station_id < status_station_id:\n",
    "            information_i += 1\n",
    "        else:\n",
    "            ids.append(station_status[status_i][\"station_id\"])\n",
    "            status_i += 1\n",
    "            information_i += 1\n",
    "    \n",
    "    return ids\n",
    "\n",
    "original_station_ids = get_all_IDs()\n",
    "NUM_STATIONS_ORIGINAL = len(original_station_ids)\n",
    "\n",
    "\n",
    "# to be used for testing\n",
    "def id_to_original_ID(id: int) -> int:\n",
    "    \"\"\"Convert the id (internal) to the original ID in the data.\"\"\"\n",
    "    return original_station_ids[id]\n",
    "\n",
    "@cache\n",
    "def station_encoding(station_id: int) -> list[int]:\n",
    "    \"\"\"Return a one hot encoding of the original station ID, station_id, based on its index in original_station_ids.\"\"\"\n",
    "    one_hot_encoding = [0] * NUM_STATIONS_ORIGINAL\n",
    "    index = original_station_ids.index(station_id)\n",
    "    one_hot_encoding[index] = 1\n",
    "    return tuple(one_hot_encoding)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather related code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all weather status, taking from the open weather map website\n",
    "WEATHER_STATUSES = [\n",
    "        200, 201, 202, 210, 211, 212, 221, 230, 231, 232,\n",
    "        300, 301, 302, 310, 311, 312, 313, 314, 321,\n",
    "        500, 501, 502, 503, 504, 511, 520, 521, 522, 531,\n",
    "        600, 601, 602, 611, 612, 613, 615, 616, 620, 621, 622,\n",
    "        701, 711, 721, 731, 741, 751, 761, 762, 771, 781,\n",
    "        800,\n",
    "        801, 802, 803, 804\n",
    "]\n",
    "NUM_STATUSES =  len(WEATHER_STATUSES)\n",
    "\n",
    "@cache\n",
    "def weather_encoding(weather_status: int) -> tuple[int]:\n",
    "    \"\"\"Return a one hot encoding of weather_status based on its index in WEATHER_STATUSES.\"\"\"\n",
    "    one_hot_encoding = [0] * NUM_STATUSES\n",
    "    index = WEATHER_STATUSES.index(weather_status)\n",
    "    one_hot_encoding[index] = 1\n",
    "    return tuple(one_hot_encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain stations are turned of for a day or some period of time, we ignore those stations in our analysis\n",
    "\n",
    "group_sizes = df.groupby(\"StationID\").size()\n",
    "size_to_groups: dict = group_sizes.groupby(group_sizes).apply(lambda x: list(x.index)).to_dict()\n",
    "\n",
    "station_ids = size_to_groups[max(size_to_groups.keys())]\n",
    "NUM_STATIONS = len(station_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StationID', 'Time', 'NumBikes', 'NumDocks', 'Latitude', 'Longitude',\n",
      "       'Temperature', 'WeatherStatus'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "station_ids_set = set(station_ids)\n",
    "\n",
    "def nearest_k_stations(K: int) -> dict[int, list[int]]:\n",
    "    \"\"\"Compute the K nearest stations to all stations, not including itself.\n",
    "    \n",
    "    The returned dict is a mapping from (transformed) stationID to a list containing the \n",
    "    (transformed) station IDs of the nearest K stations.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    coordinates = []\n",
    "    status_i = 0\n",
    "    information_i = 0\n",
    "    while status_i < len(station_status) and information_i < len(station_information):\n",
    "        status_station_id = int(station_status[status_i][\"station_id\"])\n",
    "        information_station_id = int(station_information[information_i][\"station_id\"])\n",
    "        if status_station_id < information_station_id:\n",
    "            status_i += 1\n",
    "        elif information_station_id < status_station_id:\n",
    "            information_i += 1\n",
    "        else:\n",
    "            if station_status[status_i][\"station_id\"] in station_ids_set:\n",
    "                # the tranformed stationID is the stationID used internally\n",
    "                # it is simply the index of the stationID in the original_station_ids list\n",
    "                transformed_station_id = len(ids)\n",
    "                ids.append(transformed_station_id)\n",
    "                coordinates.append((station_information[information_i][\"lat\"], station_information[information_i][\"lon\"]))\n",
    "            status_i += 1\n",
    "            information_i += 1\n",
    "    \n",
    "    k_nearest = {}\n",
    "    for i, id in enumerate(ids):\n",
    "        coordinate = coordinates[i]\n",
    "        distances = [(distance.euclidean(x, coordinate), j) for j, x in enumerate(coordinates)]\n",
    "        closest = heapq.nsmallest(K + 1, distances)\n",
    "        k_nearest[id] = [ids[j] for _, j in closest[1:]]\n",
    "    return k_nearest\n",
    "\n",
    "\n",
    "def nearest_k_stations_inclusive(K: int) -> dict[int, list[int]]:\n",
    "    \"\"\"Compute the K nearest stations to all stations, including itself.\n",
    "    \n",
    "    The returned dict is a mapping from (transformed) stationID to a list containing the \n",
    "    (transformed) station IDs of the nearest K stations.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    coordinates = []\n",
    "    status_i = 0\n",
    "    information_i = 0\n",
    "    while status_i < len(station_status) and information_i < len(station_information):\n",
    "        status_station_id = int(station_status[status_i][\"station_id\"])\n",
    "        information_station_id = int(station_information[information_i][\"station_id\"])\n",
    "        if status_station_id < information_station_id:\n",
    "            status_i += 1\n",
    "        elif information_station_id < status_station_id:\n",
    "            information_i += 1\n",
    "        else:\n",
    "            if station_status[status_i][\"station_id\"] in station_ids_set:\n",
    "                # the tranformed stationID is the stationID used internally\n",
    "                # it is simply the index of the stationID in the original_station_ids list\n",
    "                transformed_station_id = len(ids)\n",
    "                ids.append(transformed_station_id)\n",
    "                coordinates.append((station_information[information_i][\"lat\"], station_information[information_i][\"lon\"]))\n",
    "            status_i += 1\n",
    "            information_i += 1\n",
    "    \n",
    "    k_nearest = {}\n",
    "    for i, id in enumerate(ids):\n",
    "        coordinate = coordinates[i]\n",
    "        distances = [(distance.euclidean(x, coordinate), j) for j, x in enumerate(coordinates)]\n",
    "        closest = heapq.nsmallest(K + 1, distances)\n",
    "        k_nearest[id] = [ids[j] for _, j in closest]\n",
    "    return k_nearest\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data in the data frame. Further preprocessing will be done later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove station ids that are now removed from the endpoints, but were present when data collection started (1 station was problematic)\n",
    "df = df[df[\"StationID\"].isin(station_ids_set)]\n",
    "\n",
    "df = df.sort_values(by=[\"Time\", \"StationID\"])\n",
    "\n",
    "# df['StationID'] = df['StationID'].apply(station_encoding)\n",
    "# df['WeatherStatus'] = df['WeatherStatus'].apply(weather_encoding)\n",
    "\n",
    "# turn categorical variables into a one-hot encoding\n",
    "# df = pd.get_dummies(df, columns=[\"WeatherStatus\", \"StationID\"], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=[\"WeatherStatus\",], drop_first=True)\n",
    "df = df.drop('StationID', axis=1)\n",
    "\n",
    "# Extract year, month, day of the year, hours, and minutes\n",
    "df['year'] = df['Time'].dt.year\n",
    "df['month'] = df['Time'].dt.month\n",
    "df['dayoftheyear'] = df['Time'].dt.dayofyear\n",
    "df['hours'] = df['Time'].dt.hour + (df['Time'].dt.minute / 60)\n",
    "df['weekday'] = df['Time'].dt.weekday \n",
    "df = df.drop('Time', axis=1)\n",
    "\n",
    "\n",
    "# TODO: consider normalizing other quantities later\n",
    "\n",
    "# CHECK: do the boolean columns cause issues in training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check why this is different\n",
    "# df.head(820)\n",
    "# df.iloc[820][\"StationID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8175265\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for splitting\n",
    "TRAIN_RATIO = 0.70\n",
    "VALIDATION_RATIO = 0.15\n",
    "TEST_RATIO = 1 - TRAIN_RATIO - VALIDATION_RATIO\n",
    "\n",
    "# Ensure the ratios sum to 1\n",
    "assert TRAIN_RATIO + VALIDATION_RATIO + TEST_RATIO == 1.0\n",
    "\n",
    "# Calculate the indices for the splits\n",
    "n = len(df) // NUM_STATIONS\n",
    "train_end = floor(TRAIN_RATIO * n) * NUM_STATIONS  # First half for training\n",
    "val_end = floor((TRAIN_RATIO + VALIDATION_RATIO) * n) * NUM_STATIONS  # Next quarter for validation\n",
    "\n",
    "# Perform the split\n",
    "df_train = df.iloc[:train_end]\n",
    "df_val = df.iloc[train_end:val_end]\n",
    "df_test = df.iloc[val_end:]\n",
    "\n",
    "assert df_train.shape[0] + df_val.shape[0] + df_test.shape[0] == df.shape[0]\n",
    "assert df_train.shape[0] % NUM_STATIONS == 0\n",
    "assert df_val.shape[0] % NUM_STATIONS == 0 \n",
    "assert df_test.shape[0] % NUM_STATIONS == 0 \n",
    "# df_train, df_val, and df_test are your resulting splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NumBikes', 'NumDocks', 'Latitude', 'Longitude', 'Temperature',\n",
      "       'WeatherStatus_701', 'WeatherStatus_741', 'WeatherStatus_800',\n",
      "       'WeatherStatus_801', 'WeatherStatus_802', 'WeatherStatus_803',\n",
      "       'WeatherStatus_804', 'year', 'month', 'dayoftheyear', 'hours',\n",
      "       'weekday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the torch Dataset to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeShareDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, lookback: int, lookback_size: int, horizon: int, k: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): DataFrame containing time series data.\n",
    "            lookback (int): Number of time steps to look back.\n",
    "            lookback_size (int): Length of time to jump over each lookback\n",
    "            horizon (int): Number of time steps to predict.\n",
    "            k (int):: Number of nearest stations information to consider in predictions.\n",
    "        \"\"\"\n",
    "        self.FLAT_NUM_FEATURES = data.shape[1] * (k + 1)\n",
    "        self.data = data.to_numpy()\n",
    "        self.lookback = lookback\n",
    "        self.lookback_size = lookback_size\n",
    "        self.horizon = horizon\n",
    "        self.k = k\n",
    "        self.k_nearest_dict = nearest_k_stations(k)\n",
    "        self.k_nearest_differences = self._compute_k_nearest_differences()\n",
    "\n",
    "    def _compute_k_nearest_differences(self) -> dict[int, list[int]]:\n",
    "        \"\"\"Return the differences between the indices of neighbours in the pandas dataframe.\"\"\"\n",
    "        k_nearest_differences = defaultdict(list)\n",
    "        for station in self.k_nearest_dict:\n",
    "            for near_station in self.k_nearest_dict[station]:\n",
    "                diff = near_station - station\n",
    "                k_nearest_differences[station].append(diff) \n",
    "        return k_nearest_differences\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        FIRST_MINUTES_SKIPPED = self.lookback * self.lookback_size\n",
    "        padded_length = len(self.data) - (NUM_STATIONS * (self.horizon + FIRST_MINUTES_SKIPPED))\n",
    "        padded_length = max(padded_length, 0)\n",
    "        return padded_length\n",
    "            \n",
    "    def __getitem__(self, idx: int):\n",
    "        FIRST_MINUTES_SKIPPED = self.lookback * self.lookback_size\n",
    "        start_i = NUM_STATIONS * FIRST_MINUTES_SKIPPED\n",
    "        idx = idx + start_i     \n",
    "        current_station = idx % NUM_STATIONS\n",
    "        x = np.ndarray((self.lookback, self.k + 1, self.data.shape[1]))\n",
    "        for steps_behind in range(self.lookback):\n",
    "            for k in range(self.k + 1):\n",
    "                if k == 0:\n",
    "                    x[steps_behind][k] = self.data[idx - (steps_behind * self.lookback_size * NUM_STATIONS)]\n",
    "                else: \n",
    "                    x[steps_behind][k] = self.data[idx - (steps_behind * self.lookback_size * NUM_STATIONS) + self.k_nearest_differences[current_station][k - 1]]\n",
    "        x = x.reshape(self.lookback, self.FLAT_NUM_FEATURES)\n",
    "\n",
    "        y = np.ndarray((self.horizon))\n",
    "        for minutes_ahead in range(1, self.horizon + 1):\n",
    "            y[minutes_ahead - 1] = self.data[idx + (NUM_STATIONS * minutes_ahead)][0]  # index 0 is NumBikes\n",
    "        return x, y\n",
    "        \n",
    "\n",
    "class BikeShareDatasetOptimized(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, lookback: int, lookback_size: int, horizon: int, k: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): DataFrame containing time series data.\n",
    "            lookback (int): Number of time steps to look back.\n",
    "            lookback_size (int): Length of time to jump over each lookback\n",
    "            horizon (int): Number of time steps to predict.\n",
    "            k (int):: Number of nearest stations information to consider in predictions.\n",
    "        \"\"\"\n",
    "        self.FLAT_NUM_FEATURES = data.shape[1] * (k + 1)\n",
    "        self.data = data.to_numpy(dtype=float)\n",
    "        self.lookback = lookback\n",
    "        self.lookback_size = lookback_size\n",
    "        self.horizon = horizon\n",
    "        self.k = k\n",
    "        self.k_nearest_dict = nearest_k_stations_inclusive(k)\n",
    "        self.k_nearest_differences = self._compute_k_nearest_differences()\n",
    "\n",
    "    def _compute_k_nearest_differences(self) -> dict[int, list[int]]:\n",
    "        \"\"\"Return the differences between the indices of neighbours in the pandas dataframe.\"\"\"\n",
    "        k_nearest_differences = defaultdict(np.array)\n",
    "        for station in self.k_nearest_dict:\n",
    "            near_stations =  np.array(self.k_nearest_dict[station])\n",
    "            diff = near_stations - station\n",
    "            k_nearest_differences[station] = diff\n",
    "            \n",
    "        return k_nearest_differences\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        FIRST_MINUTES_SKIPPED = self.lookback * self.lookback_size\n",
    "        padded_length = len(self.data) - (NUM_STATIONS * (self.horizon + FIRST_MINUTES_SKIPPED))\n",
    "        padded_length = max(padded_length, 0)\n",
    "        return padded_length\n",
    "            \n",
    "    def __getitem__(self, idx: int):\n",
    "        FIRST_MINUTES_SKIPPED = self.lookback * self.lookback_size\n",
    "        start_i = NUM_STATIONS * FIRST_MINUTES_SKIPPED\n",
    "        idx = idx + start_i     \n",
    "        current_station = idx % NUM_STATIONS\n",
    "        \n",
    "        indices = np.arange(idx, idx - (self.lookback - 1) * self.lookback_size * NUM_STATIONS - 1, -(self.lookback_size * NUM_STATIONS))\n",
    "        neighbour_diffs = self.k_nearest_differences[current_station]\n",
    "        x = self.data[indices[:, None] + neighbour_diffs[None, :]]\n",
    "        x = x.reshape(self.lookback, self.FLAT_NUM_FEATURES)\n",
    "\n",
    "        y_indices = idx + np.arange(1, self.horizon + 1) * NUM_STATIONS\n",
    "        y = self.data[y_indices, 0]  # index 0 is NumBikes\n",
    "        return x, y\n",
    "        \n",
    "\n",
    "class TrivialDataSet(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, lookback: int, lookback_size: int, horizon: int, k: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): DataFrame containing time series data.\n",
    "            lookback (int): Number of time steps to look back.\n",
    "            lookback_size (int): Length of time to jump over each lookback\n",
    "            horizon (int): Number of time steps to predict.\n",
    "            k (int):: Number of nearest stations information to consider in predictions.\n",
    "        \"\"\"\n",
    "        self.FLAT_NUM_FEATURES = data.shape[1] * (k + 1)\n",
    "        self.data = data.to_numpy(dtype=float)\n",
    "        self.lookback = lookback\n",
    "        self.lookback_size = lookback_size\n",
    "        self.horizon = horizon\n",
    "        self.k = k\n",
    "        self.k_nearest_dict = nearest_k_stations_inclusive(k)\n",
    "        self.k_nearest_differences = self._compute_k_nearest_differences()\n",
    "\n",
    "    def _compute_k_nearest_differences(self) -> dict[int, list[int]]:\n",
    "        \"\"\"Return the differences between the indices of neighbours in the pandas dataframe.\"\"\"\n",
    "        k_nearest_differences = defaultdict(np.array)\n",
    "        for station in self.k_nearest_dict:\n",
    "            near_stations =  np.array(self.k_nearest_dict[station])\n",
    "            diff = near_stations - station\n",
    "            k_nearest_differences[station] = diff\n",
    "            \n",
    "        return k_nearest_differences\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        FIRST_MINUTES_SKIPPED = self.lookback * self.lookback_size\n",
    "        padded_length = len(self.data) - (NUM_STATIONS * (self.horizon + FIRST_MINUTES_SKIPPED))\n",
    "        padded_length = max(padded_length, 0)\n",
    "        return padded_length\n",
    "            \n",
    "    def __getitem__(self, idx: int):\n",
    "        FIRST_MINUTES_SKIPPED = self.lookback * self.lookback_size\n",
    "        start_i = NUM_STATIONS * FIRST_MINUTES_SKIPPED\n",
    "        idx = idx + start_i     \n",
    "        #current_station = idx % NUM_STATIONS\n",
    "        x = np.ndarray((1))\n",
    "        x[0] = self.data[idx][0]\n",
    "        y = np.ndarray((1))\n",
    "        y[0] = self.data[idx + NUM_STATIONS][0] \n",
    "\n",
    "        #y_indices = idx + np.arange(1, self.horizon + 1) * NUM_STATIONS\n",
    "        #y = self.data[y_indices, 0]  # index 0 is NumBikes\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 6\n",
    "lookback_size = 5\n",
    "horizon = 120\n",
    "k = 5\n",
    "train_data = BikeShareDatasetOptimized(df_train, lookback, lookback_size, horizon, k)\n",
    "validation_data = BikeShareDatasetOptimized(df_val, lookback, lookback_size, horizon, k)\n",
    "test_data = BikeShareDatasetOptimized(df_test, lookback, lookback_size, horizon, k)\n",
    "\n",
    "batch_size = 124\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Experiments on the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = BikeShareDataset(df_train, lookback, lookback_size, horizon, k)\n",
    "# optimized_data = BikeShareDatasetOptimized(df_train, lookback, lookback_size, horizon, k)\n",
    "\n",
    "# def compare_get_item(indices: np.ndarray) -> None:\n",
    "#     total_time = 0\n",
    "#     total_time_optimized = 0\n",
    "\n",
    "#     for idx in indices:\n",
    "#         start = time.perf_counter()  # Use perf_counter for high-resolution timing\n",
    "#         X, y = data[idx]\n",
    "#         end = time.perf_counter()\n",
    "#         total_time += end - start\n",
    "\n",
    "#         start = time.perf_counter()  # Use perf_counter for high-resolution timing\n",
    "#         Xo, yo = optimized_data[idx]\n",
    "#         end = time.perf_counter()\n",
    "#         total_time_optimized += end - start\n",
    "\n",
    "#     print(f\"BikeShareDataset's __getitem took {total_time} seconds in total\")\n",
    "#     print(f\"BikeShareDatasetOptimized's __getitem took {total_time_optimized} seconds in total\")\n",
    "\n",
    "\n",
    "# random_indices = np.random.randint(low=0, high=len(data), size=10_000)\n",
    "# compare_get_item(random_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAT_NUM_FEATURES = df.shape[1] * (k + 1)\n",
    "\n",
    "class BikeShareLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size: int, horizon: int, lookback: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.lookback = lookback\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lstm = nn.LSTM(input_size=FLAT_NUM_FEATURES, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.linear = nn.Linear((hidden_size * self.lookback), horizon)\n",
    "        self.linear = nn.Linear(hidden_size, horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        # x is of shape (batch_size, lookbacks, hidden_size)\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        # x = x.reshape(batch_size, sequence_length * self.hidden_size)\n",
    "        # x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class BikeShareNN(nn.Module):\n",
    "    def __init__(self, hidden_size: int, horizon: int, lookback: int):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lookback = lookback\n",
    "        self.horizon = horizon\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(FLAT_NUM_FEATURES * lookback, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, self.horizon),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] * x.shape[2] == FLAT_NUM_FEATURES * self.lookback\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class TrivialNN(nn.Module):\n",
    "    def __init__(self, horizon: int, lookback: int):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lookback = lookback\n",
    "        self.horizon = horizon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        result = torch.zeros((batch_size, self.horizon))\n",
    "        for i in range(batch_size):\n",
    "            current_occupancy = x[i, 0, 0]  # Assuming current occupancy is in the first column of features\n",
    "            result[i] = torch.zeros((self.horizon)) + current_occupancy\n",
    "        return result\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BikeShareNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=612, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=120, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 50\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "# model = BikeShareLSTM(HIDDEN_SIZE, horizon, lookback, NUM_LAYERS).to(device)\n",
    "model = BikeShareNN(HIDDEN_SIZE, horizon, lookback) \n",
    "# model = TrivialNN(horizon, lookback)  \n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        assert pred.shape == y.shape\n",
    "        # total_loss_by_time = torch.zeros((horizon), dtype=float)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # total_loss_by_time += torch.sum(torch.abs(pred - y), dim=0)\n",
    "\n",
    "        total_delta_from_current_occupancy = torch.zeros((horizon), dtype=float)\n",
    "        for i in range(X.shape[0]):\n",
    "            current_occupancy = X[i, 0, 0]  # Assuming current occupancy is in the first column of features\n",
    "            delta = pred[i] - current_occupancy  # Compute delta from current occupancy for each time step\n",
    "            total_delta_from_current_occupancy += torch.abs(delta)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            # average_loss_by_time = total_loss_by_time / (batch_size)\n",
    "            average_delta_from_current_occupancy = total_delta_from_current_occupancy / batch_size\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            # print(f\"average loss by time {average_loss_by_time}\")\n",
    "            print(f\"average delta from current occupancy {average_delta_from_current_occupancy}\")\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss =  0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 17.257336  [  124/5599865]\n",
      "average delta from current occupancy tensor([11.9448, 14.4050, 36.0386,  5.2461, 10.7995, 13.0852, 31.3708,  8.4317,\n",
      "        18.3779,  6.2954, 26.4700, 21.6317, 20.3962, 48.5272,  7.0801,  7.4867,\n",
      "        28.0024, 11.4552, 14.0233, 28.0560, 17.9458,  5.4053, 19.4396,  8.7588,\n",
      "         7.8032, 10.6401,  5.6818, 10.1108, 35.3561, 12.6630, 12.1494, 16.2521,\n",
      "         8.9894,  9.6224,  5.8342, 12.3440,  7.1557, 63.9073, 26.1489,  8.6496,\n",
      "        38.7340,  6.4310, 18.7940,  9.1772, 12.9744,  8.7339, 11.1877, 11.9587,\n",
      "         6.0498, 15.0643, 37.1960,  5.2776, 16.6764, 34.6784, 10.0308,  5.3564,\n",
      "        35.6766,  6.1861,  8.4484, 36.3182, 27.4193,  7.7520, 14.4815,  5.5804,\n",
      "         7.2863, 10.5216,  9.7077, 17.3043, 17.3555,  5.5301, 39.7794, 20.8819,\n",
      "         5.4583, 33.4244, 17.3754, 17.5353, 23.7443, 24.3034,  9.1744, 38.3422,\n",
      "         5.3351,  8.6803, 16.0248, 25.7972, 14.4939,  7.7936,  9.6158, 15.5818,\n",
      "         6.0666, 21.7280, 12.2018, 38.7088, 21.7886, 11.0006, 13.3519, 32.8896,\n",
      "        22.3603,  5.6310,  6.7234, 20.3309, 38.9555,  9.5948, 42.1388, 16.4480,\n",
      "        33.7382,  6.0223, 28.0183, 17.3100,  8.6588, 26.3453, 33.5651, 12.3242,\n",
      "         6.3477, 27.3654, 16.6657, 11.3514,  5.4193, 10.1321, 32.8261, 10.6529],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.440616  [12524/5599865]\n",
      "average delta from current occupancy tensor([6.4332, 6.4593, 6.3948, 6.5131, 6.5879, 6.4592, 6.4066, 6.4794, 6.4116,\n",
      "        6.4123, 6.4390, 6.4837, 6.5102, 6.6630, 6.4380, 6.4459, 6.4770, 6.5032,\n",
      "        6.4297, 6.4073, 6.5159, 6.5752, 6.4191, 6.3934, 6.4165, 6.4807, 6.5975,\n",
      "        6.4258, 6.5313, 6.5488, 6.5641, 6.5597, 6.4942, 6.5763, 6.4075, 6.5802,\n",
      "        6.4643, 6.5281, 6.4509, 6.6325, 6.4174, 6.5859, 6.4709, 6.4332, 6.4814,\n",
      "        6.4544, 6.4632, 6.4211, 6.6032, 6.3791, 6.5247, 6.4252, 6.4188, 6.3967,\n",
      "        6.5170, 6.6008, 6.4571, 6.3953, 6.4632, 6.5458, 6.4174, 6.4920, 6.4471,\n",
      "        6.4709, 6.4948, 6.4538, 6.3811, 6.6331, 6.5676, 6.4302, 6.5958, 6.4469,\n",
      "        6.5642, 6.5468, 6.5358, 6.5093, 6.5381, 6.5294, 6.5077, 6.4931, 6.5519,\n",
      "        6.5146, 6.5691, 6.4191, 6.4203, 6.4036, 6.3990, 6.4333, 6.4059, 6.5607,\n",
      "        6.3985, 6.4641, 6.4446, 6.4226, 6.4145, 6.4189, 6.4338, 6.4793, 6.5012,\n",
      "        6.4054, 6.4049, 6.5056, 6.5747, 6.4169, 6.3823, 6.4543, 6.5067, 6.5767,\n",
      "        6.5385, 6.4637, 6.4197, 6.4970, 6.5897, 6.5567, 6.4198, 6.5344, 6.4574,\n",
      "        6.5408, 6.3713, 6.4213], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.805924  [24924/5599865]\n",
      "average delta from current occupancy tensor([6.5002, 6.5297, 6.4625, 6.5730, 6.6508, 6.5308, 6.4741, 6.5444, 6.4796,\n",
      "        6.4791, 6.5080, 6.5505, 6.5735, 6.7303, 6.5062, 6.5128, 6.5426, 6.5648,\n",
      "        6.4988, 6.4739, 6.5792, 6.6404, 6.4875, 6.4645, 6.4860, 6.5450, 6.6573,\n",
      "        6.4916, 6.5899, 6.6109, 6.6246, 6.6228, 6.5543, 6.6387, 6.4728, 6.6351,\n",
      "        6.5338, 6.5927, 6.5230, 6.6921, 6.4877, 6.6458, 6.5389, 6.4982, 6.5495,\n",
      "        6.5203, 6.5296, 6.4882, 6.6693, 6.4454, 6.5859, 6.4927, 6.4858, 6.4641,\n",
      "        6.5800, 6.6615, 6.5251, 6.4629, 6.5316, 6.6076, 6.4891, 6.5547, 6.5122,\n",
      "        6.5365, 6.5571, 6.5205, 6.4467, 6.6949, 6.6321, 6.4980, 6.6544, 6.5138,\n",
      "        6.6261, 6.6125, 6.5978, 6.5671, 6.5957, 6.5871, 6.5737, 6.5555, 6.6104,\n",
      "        6.5782, 6.6321, 6.4851, 6.4857, 6.4720, 6.4672, 6.5014, 6.4747, 6.6196,\n",
      "        6.4652, 6.5329, 6.5107, 6.4885, 6.4794, 6.4898, 6.4998, 6.5437, 6.5610,\n",
      "        6.4713, 6.4714, 6.5686, 6.6357, 6.4823, 6.4477, 6.5241, 6.5744, 6.6381,\n",
      "        6.6039, 6.5305, 6.4879, 6.5595, 6.6493, 6.6217, 6.4881, 6.5941, 6.5233,\n",
      "        6.6042, 6.4382, 6.4909], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.035559  [37324/5599865]\n",
      "average delta from current occupancy tensor([6.0733, 6.1031, 6.0397, 6.1333, 6.2138, 6.1048, 6.0499, 6.1116, 6.0555,\n",
      "        6.0539, 6.0817, 6.1183, 6.1362, 6.2976, 6.0801, 6.0845, 6.1102, 6.1277,\n",
      "        6.0736, 6.0492, 6.1419, 6.2052, 6.0630, 6.0445, 6.0625, 6.1110, 6.2170,\n",
      "        6.0644, 6.1484, 6.1727, 6.1850, 6.1854, 6.1203, 6.2009, 6.0472, 6.1899,\n",
      "        6.1057, 6.1572, 6.0985, 6.2516, 6.0647, 6.2056, 6.1093, 6.0697, 6.1187,\n",
      "        6.0906, 6.0996, 6.0624, 6.2350, 6.0232, 6.1471, 6.0670, 6.0601, 6.0410,\n",
      "        6.1429, 6.2221, 6.0964, 6.0401, 6.1026, 6.1694, 6.0675, 6.1224, 6.0824,\n",
      "        6.1047, 6.1250, 6.0914, 6.0237, 6.2566, 6.1962, 6.0721, 6.2127, 6.0854,\n",
      "        6.1878, 6.1781, 6.1598, 6.1267, 6.1535, 6.1449, 6.1395, 6.1236, 6.1684,\n",
      "        6.1421, 6.1945, 6.0586, 6.0590, 6.0491, 6.0447, 6.0754, 6.0518, 6.1785,\n",
      "        6.0415, 6.1047, 6.0819, 6.0616, 6.0524, 6.0673, 6.0721, 6.1099, 6.1252,\n",
      "        6.0462, 6.0470, 6.1312, 6.1967, 6.0555, 6.0245, 6.0973, 6.1421, 6.1997,\n",
      "        6.1693, 6.1006, 6.0634, 6.1259, 6.2086, 6.1864, 6.0634, 6.1538, 6.0931,\n",
      "        6.1675, 6.0172, 6.0672], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.107619  [49724/5599865]\n",
      "average delta from current occupancy tensor([6.0195, 6.0571, 5.9818, 6.0845, 6.1644, 6.0600, 5.9927, 6.0615, 6.0003,\n",
      "        5.9971, 6.0305, 6.0701, 6.0870, 6.2525, 6.0294, 6.0322, 6.0601, 6.0818,\n",
      "        6.0216, 5.9917, 6.0911, 6.1569, 6.0089, 5.9907, 6.0093, 6.0592, 6.1637,\n",
      "        6.0081, 6.0936, 6.1212, 6.1319, 6.1349, 6.0707, 6.1500, 5.9885, 6.1315,\n",
      "        6.0585, 6.1086, 6.0536, 6.1984, 6.0129, 6.1521, 6.0618, 6.0133, 6.0723,\n",
      "        6.0383, 6.0492, 6.0069, 6.1877, 5.9620, 6.0949, 6.0132, 6.0043, 5.9833,\n",
      "        6.0923, 6.1698, 6.0467, 5.9822, 6.0540, 6.1184, 6.0181, 6.0750, 6.0281,\n",
      "        6.0535, 6.0794, 6.0401, 5.9618, 6.2056, 6.1470, 6.0193, 6.1579, 6.0332,\n",
      "        6.1361, 6.1309, 6.1091, 6.0779, 6.0983, 6.0899, 6.0920, 6.0771, 6.1133,\n",
      "        6.0929, 6.1437, 6.0016, 6.0023, 5.9937, 5.9885, 6.0232, 5.9969, 6.1241,\n",
      "        5.9831, 6.0578, 6.0282, 6.0051, 5.9934, 6.0169, 6.0175, 6.0579, 6.0781,\n",
      "        5.9877, 5.9895, 6.0847, 6.1448, 5.9976, 5.9625, 6.0498, 6.0965, 6.1487,\n",
      "        6.1219, 6.0508, 6.0100, 6.0805, 6.1549, 6.1379, 6.0097, 6.1003, 6.0410,\n",
      "        6.1175, 5.9558, 6.0156], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.404946  [62124/5599865]\n",
      "average delta from current occupancy tensor([6.5664, 6.6100, 6.5276, 6.6339, 6.7120, 6.6136, 6.5373, 6.6091, 6.5470,\n",
      "        6.5422, 6.5792, 6.6184, 6.6382, 6.8041, 6.5789, 6.5797, 6.6077, 6.6319,\n",
      "        6.5704, 6.5367, 6.6404, 6.7053, 6.5563, 6.5398, 6.5578, 6.6040, 6.7071,\n",
      "        6.5527, 6.6395, 6.6661, 6.6755, 6.6806, 6.6175, 6.6959, 6.5327, 6.6697,\n",
      "        6.6090, 6.6568, 6.6083, 6.7413, 6.5620, 6.6950, 6.6124, 6.5573, 6.6229,\n",
      "        6.5855, 6.5974, 6.5526, 6.7367, 6.5054, 6.6420, 6.5611, 6.5495, 6.5287,\n",
      "        6.6417, 6.7141, 6.5957, 6.5274, 6.6031, 6.6647, 6.5706, 6.6238, 6.5731,\n",
      "        6.5996, 6.6304, 6.5878, 6.5044, 6.7517, 6.6938, 6.5671, 6.6994, 6.5807,\n",
      "        6.6804, 6.6802, 6.6547, 6.6251, 6.6418, 6.6377, 6.6433, 6.6273, 6.6551,\n",
      "        6.6426, 6.6893, 6.5463, 6.5472, 6.5410, 6.5357, 6.5715, 6.5446, 6.6663,\n",
      "        6.5278, 6.6098, 6.5740, 6.5503, 6.5365, 6.5682, 6.5636, 6.6029, 6.6279,\n",
      "        6.5321, 6.5348, 6.6356, 6.6900, 6.5419, 6.5048, 6.6017, 6.6470, 6.6944,\n",
      "        6.6713, 6.5990, 6.5586, 6.6318, 6.6971, 6.6861, 6.5573, 6.6439, 6.5878,\n",
      "        6.6643, 6.4994, 6.5653], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.157548  [74524/5599865]\n",
      "average delta from current occupancy tensor([6.1301, 6.1702, 6.0977, 6.1864, 6.2595, 6.1737, 6.1041, 6.1648, 6.1143,\n",
      "        6.1089, 6.1417, 6.1728, 6.1913, 6.3558, 6.1425, 6.1412, 6.1637, 6.1851,\n",
      "        6.1346, 6.1043, 6.1923, 6.2534, 6.1223, 6.1105, 6.1245, 6.1580, 6.2501,\n",
      "        6.1169, 6.1898, 6.2106, 6.2185, 6.2256, 6.1706, 6.2415, 6.1009, 6.2074,\n",
      "        6.1674, 6.2047, 6.1706, 6.2837, 6.1284, 6.2372, 6.1702, 6.1200, 6.1785,\n",
      "        6.1457, 6.1562, 6.1179, 6.2850, 6.0781, 6.1937, 6.1267, 6.1148, 6.0985,\n",
      "        6.1942, 6.2581, 6.1553, 6.0973, 6.1611, 6.2108, 6.1385, 6.1777, 6.1335,\n",
      "        6.1558, 6.1851, 6.1478, 6.0765, 6.2976, 6.2403, 6.1313, 6.2402, 6.1419,\n",
      "        6.2244, 6.2294, 6.2008, 6.1770, 6.1915, 6.1886, 6.1973, 6.1816, 6.1991,\n",
      "        6.1958, 6.2345, 6.1118, 6.1131, 6.1100, 6.1058, 6.1353, 6.1131, 6.2080,\n",
      "        6.0969, 6.1693, 6.1351, 6.1155, 6.1024, 6.1354, 6.1271, 6.1571, 6.1818,\n",
      "        6.1002, 6.1034, 6.1888, 6.2350, 6.1082, 6.0767, 6.1626, 6.2003, 6.2399,\n",
      "        6.2207, 6.1574, 6.1254, 6.1864, 6.2387, 6.2341, 6.1234, 6.1941, 6.1469,\n",
      "        6.2110, 6.0732, 6.1316], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.794793  [86924/5599865]\n",
      "average delta from current occupancy tensor([5.6126, 5.6583, 5.5784, 5.6712, 5.7426, 5.6627, 5.5832, 5.6481, 5.5961,\n",
      "        5.5893, 5.6255, 5.6563, 5.6775, 5.8427, 5.6276, 5.6241, 5.6467, 5.6703,\n",
      "        5.6186, 5.5843, 5.6780, 5.7366, 5.6049, 5.5947, 5.6080, 5.6379, 5.7280,\n",
      "        5.5965, 5.6734, 5.6916, 5.6963, 5.7058, 5.6523, 5.7222, 5.5809, 5.6863,\n",
      "        5.6531, 5.6912, 5.6609, 5.7611, 5.6127, 5.7141, 5.6562, 5.5990, 5.6643,\n",
      "        5.6282, 5.6398, 5.5988, 5.7685, 5.5567, 5.6793, 5.6100, 5.5951, 5.5791,\n",
      "        5.6806, 5.7374, 5.6396, 5.5778, 5.6450, 5.6929, 5.6265, 5.6618, 5.6138,\n",
      "        5.6369, 5.6717, 5.6311, 5.5541, 5.7789, 5.7223, 5.6143, 5.7161, 5.6247,\n",
      "        5.7034, 5.7137, 5.6877, 5.6591, 5.6751, 5.6725, 5.6859, 5.6669, 5.6833,\n",
      "        5.6834, 5.7149, 5.5915, 5.5935, 5.5927, 5.5886, 5.6191, 5.5960, 5.6889,\n",
      "        5.5767, 5.6571, 5.6160, 5.5961, 5.5804, 5.6222, 5.6083, 5.6365, 5.6670,\n",
      "        5.5800, 5.5840, 5.6751, 5.7152, 5.5878, 5.5544, 5.6497, 5.6904, 5.7206,\n",
      "        5.7056, 5.6411, 5.6092, 5.6731, 5.7154, 5.7173, 5.6065, 5.6785, 5.6287,\n",
      "        5.6931, 5.5517, 5.6165], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.572006  [99324/5599865]\n",
      "average delta from current occupancy tensor([6.6103, 6.6622, 6.5741, 6.6711, 6.7417, 6.6676, 6.5773, 6.6467, 6.5931,\n",
      "        6.5847, 6.6246, 6.6547, 6.6787, 6.8457, 6.6283, 6.6223, 6.6448, 6.6704,\n",
      "        6.6179, 6.5793, 6.6788, 6.7356, 6.6027, 6.5945, 6.6069, 6.6325, 6.7213,\n",
      "        6.5912, 6.6719, 6.6930, 6.6954, 6.7018, 6.6487, 6.7186, 6.5761, 6.6830,\n",
      "        6.6543, 6.6953, 6.6674, 6.7540, 6.6125, 6.7063, 6.6579, 6.5926, 6.6656,\n",
      "        6.6259, 6.6386, 6.5947, 6.7679, 6.5503, 6.6797, 6.6087, 6.5904, 6.5750,\n",
      "        6.6822, 6.7324, 6.6390, 6.5735, 6.6441, 6.6958, 6.6307, 6.6608, 6.6090,\n",
      "        6.6329, 6.6738, 6.6299, 6.5465, 6.7760, 6.7201, 6.6126, 6.7077, 6.6227,\n",
      "        6.6997, 6.7138, 6.6903, 6.6559, 6.6736, 6.6716, 6.6901, 6.6676, 6.6825,\n",
      "        6.6865, 6.7108, 6.5864, 6.5891, 6.5907, 6.5868, 6.6187, 6.5942, 6.6884,\n",
      "        6.5717, 6.6609, 6.6118, 6.5917, 6.5728, 6.6249, 6.6044, 6.6302, 6.6674,\n",
      "        6.5749, 6.5798, 6.6769, 6.7111, 6.5824, 6.5468, 6.6524, 6.6961, 6.7169,\n",
      "        6.7065, 6.6399, 6.6083, 6.6752, 6.7072, 6.7161, 6.6049, 6.6779, 6.6253,\n",
      "        6.6963, 6.5449, 6.6169], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 7.193357  [111724/5599865]\n",
      "average delta from current occupancy tensor([6.9022, 6.9583, 6.8656, 6.9622, 7.0314, 6.9643, 6.8667, 6.9380, 6.8850,\n",
      "        6.8752, 6.9171, 6.9447, 6.9703, 7.1390, 6.9226, 6.9139, 6.9353, 6.9615,\n",
      "        6.9110, 6.8697, 6.9703, 7.0243, 6.8946, 6.8889, 6.8996, 6.9197, 7.0038,\n",
      "        6.8806, 6.9613, 6.9844, 6.9860, 6.9939, 6.9368, 7.0045, 6.8670, 6.9699,\n",
      "        6.9474, 6.9896, 6.9660, 7.0369, 6.9066, 6.9935, 6.9514, 6.8807, 6.9579,\n",
      "        6.9167, 6.9298, 6.8851, 7.0574, 6.8406, 6.9706, 6.9019, 6.8802, 6.8668,\n",
      "        6.9743, 7.0173, 6.9310, 6.8648, 6.9358, 6.9887, 6.9285, 6.9514, 6.8983,\n",
      "        6.9212, 6.9671, 6.9220, 6.8358, 7.0630, 7.0077, 6.9051, 6.9940, 6.9143,\n",
      "        6.9910, 7.0037, 6.9834, 6.9441, 6.9630, 6.9617, 6.9846, 6.9594, 6.9722,\n",
      "        6.9799, 6.9980, 6.8762, 6.8795, 6.8841, 6.8802, 6.9122, 6.8873, 6.9782,\n",
      "        6.8631, 6.9571, 6.9016, 6.8823, 6.8608, 6.9214, 6.8946, 6.9162, 6.9594,\n",
      "        6.8656, 6.8710, 6.9700, 6.9983, 6.8721, 6.8360, 6.9473, 6.9921, 7.0028,\n",
      "        6.9989, 6.9315, 6.9017, 6.9682, 6.9940, 7.0045, 6.8980, 6.9678, 6.9152,\n",
      "        6.9897, 6.8354, 6.9115], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.853039  [124124/5599865]\n",
      "average delta from current occupancy tensor([6.7472, 6.8046, 6.7120, 6.8037, 6.8695, 6.8109, 6.7108, 6.7812, 6.7309,\n",
      "        6.7203, 6.7621, 6.7861, 6.8115, 6.9808, 6.7690, 6.7582, 6.7776, 6.8029,\n",
      "        6.7569, 6.7150, 6.8116, 6.8606, 6.7397, 6.7370, 6.7453, 6.7595, 6.8402,\n",
      "        6.7243, 6.8011, 6.8250, 6.8257, 6.8351, 6.7764, 6.8425, 6.7131, 6.8070,\n",
      "        6.7913, 6.8327, 6.8147, 6.8677, 6.7536, 6.8319, 6.7955, 6.7226, 6.8004,\n",
      "        6.7597, 6.7726, 6.7293, 6.8947, 6.6870, 6.8112, 6.7483, 6.7241, 6.7137,\n",
      "        6.8157, 6.8500, 6.7746, 6.7109, 6.7790, 6.8305, 6.7780, 6.7928, 6.7412,\n",
      "        6.7617, 6.8104, 6.7665, 6.6815, 6.8978, 6.8448, 6.7506, 6.8323, 6.7587,\n",
      "        6.8311, 6.8444, 6.8259, 6.7836, 6.8026, 6.8024, 6.8281, 6.8013, 6.8122,\n",
      "        6.8227, 6.8385, 6.7204, 6.7244, 6.7314, 6.7278, 6.7585, 6.7342, 6.8175,\n",
      "        6.7096, 6.8042, 6.7444, 6.7273, 6.7040, 6.7702, 6.7384, 6.7545, 6.8020,\n",
      "        6.7114, 6.7172, 6.8132, 6.8391, 6.7165, 6.6815, 6.7930, 6.8370, 6.8418,\n",
      "        6.8432, 6.7750, 6.7485, 6.8112, 6.8325, 6.8439, 6.7446, 6.8078, 6.7580,\n",
      "        6.8320, 6.6826, 6.7590], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.583092  [136524/5599865]\n",
      "average delta from current occupancy tensor([6.3210, 6.3824, 6.2850, 6.3766, 6.4412, 6.3897, 6.2813, 6.3549, 6.3046,\n",
      "        6.2927, 6.3365, 6.3579, 6.3846, 6.5561, 6.3453, 6.3317, 6.3503, 6.3757,\n",
      "        6.3320, 6.2872, 6.3848, 6.4301, 6.3130, 6.3130, 6.3195, 6.3283, 6.4119,\n",
      "        6.2955, 6.3721, 6.3980, 6.3978, 6.4093, 6.3457, 6.4169, 6.2861, 6.3758,\n",
      "        6.3661, 6.4090, 6.3958, 6.4314, 6.3296, 6.4033, 6.3707, 6.2920, 6.3742,\n",
      "        6.3321, 6.3455, 6.3009, 6.4654, 6.2588, 6.3837, 6.3234, 6.2952, 6.2875,\n",
      "        6.3894, 6.4218, 6.3484, 6.2840, 6.3523, 6.4051, 6.3578, 6.3650, 6.3122,\n",
      "        6.3314, 6.3856, 6.3407, 6.2523, 6.4663, 6.4201, 6.3250, 6.4036, 6.3323,\n",
      "        6.4041, 6.4214, 6.4013, 6.3534, 6.3737, 6.3746, 6.4044, 6.3746, 6.3839,\n",
      "        6.3978, 6.4121, 6.2916, 6.2967, 6.3067, 6.3031, 6.3338, 6.3090, 6.3889,\n",
      "        6.2828, 6.3829, 6.3157, 6.2999, 6.2732, 6.3488, 6.3102, 6.3215, 6.3760,\n",
      "        6.2839, 6.2902, 6.3885, 6.4131, 6.2879, 6.2520, 6.3699, 6.4153, 6.4162,\n",
      "        6.4211, 6.3486, 6.3240, 6.3862, 6.4040, 6.4196, 6.3199, 6.3793, 6.3298,\n",
      "        6.4075, 6.2550, 6.3357], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 7.305614  [148924/5599865]\n",
      "average delta from current occupancy tensor([7.5565, 7.6357, 7.5121, 7.6225, 7.6979, 7.6458, 7.5044, 7.5975, 7.5364,\n",
      "        7.5206, 7.5761, 7.5984, 7.6322, 7.8164, 7.5890, 7.5690, 7.5905, 7.6210,\n",
      "        7.5715, 7.5139, 7.6325, 7.6884, 7.5462, 7.5497, 7.5551, 7.5589, 7.6634,\n",
      "        7.5223, 7.6147, 7.6481, 7.6469, 7.6635, 7.5805, 7.6728, 7.5136, 7.6163,\n",
      "        7.6122, 7.6659, 7.6560, 7.6849, 7.5695, 7.6525, 7.6183, 7.5160, 7.6207,\n",
      "        7.5679, 7.5849, 7.5294, 7.7209, 7.4790, 7.6303, 7.5610, 7.5220, 7.5161,\n",
      "        7.6386, 7.6781, 7.5894, 7.5111, 7.5936, 7.6590, 7.6086, 7.6074, 7.5423,\n",
      "        7.5639, 7.6362, 7.5809, 7.4698, 7.7195, 7.6780, 7.5622, 7.6530, 7.5699,\n",
      "        7.6556, 7.6818, 7.6554, 7.5906, 7.6166, 7.6191, 7.6601, 7.6206, 7.6296,\n",
      "        7.6509, 7.6661, 7.5180, 7.5253, 7.5413, 7.5369, 7.5742, 7.5432, 7.6354,\n",
      "        7.5095, 7.6374, 7.5470, 7.5298, 7.4930, 7.5962, 7.5410, 7.5484, 7.6232,\n",
      "        7.5102, 7.5184, 7.6399, 7.6679, 7.5135, 7.4693, 7.6193, 7.6759, 7.6719,\n",
      "        7.6826, 7.5896, 7.5624, 7.6365, 7.6537, 7.6779, 7.5569, 7.6238, 7.5645,\n",
      "        7.6629, 7.4752, 7.5779], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.780696  [161324/5599865]\n",
      "average delta from current occupancy tensor([6.5583, 6.6412, 6.5137, 6.6217, 6.6989, 6.6525, 6.5026, 6.5985, 6.5381,\n",
      "        6.5212, 6.5782, 6.5965, 6.6312, 6.8182, 6.5935, 6.5700, 6.5902, 6.6199,\n",
      "        6.5746, 6.5145, 6.6316, 6.6899, 6.5472, 6.5543, 6.5572, 6.5537, 6.6601,\n",
      "        6.5210, 6.6115, 6.6466, 6.6442, 6.6634, 6.5755, 6.6729, 6.5152, 6.6100,\n",
      "        6.6141, 6.6688, 6.6654, 6.6818, 6.5737, 6.6488, 6.6207, 6.5128, 6.6212,\n",
      "        6.5675, 6.5850, 6.5288, 6.7176, 6.4796, 6.6285, 6.5646, 6.5209, 6.5187,\n",
      "        6.6382, 6.6775, 6.5905, 6.5129, 6.5939, 6.6599, 6.6173, 6.6058, 6.5406,\n",
      "        6.5601, 6.6381, 6.5829, 6.4693, 6.7138, 6.6794, 6.5647, 6.6496, 6.5712,\n",
      "        6.6543, 6.6855, 6.6574, 6.5864, 6.6137, 6.6175, 6.6628, 6.6204, 6.6271,\n",
      "        6.6525, 6.6653, 6.5172, 6.5258, 6.5455, 6.5413, 6.5779, 6.5465, 6.6322,\n",
      "        6.5113, 6.6442, 6.5456, 6.5308, 6.4897, 6.6036, 6.5404, 6.5410, 6.6242,\n",
      "        6.5113, 6.5200, 6.6421, 6.6677, 6.5128, 6.4687, 6.6237, 6.6810, 6.6720,\n",
      "        6.6874, 6.5905, 6.5664, 6.6382, 6.6502, 6.6796, 6.5605, 6.6210, 6.5634,\n",
      "        6.6648, 6.4767, 6.5831], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.246538  [173724/5599865]\n",
      "average delta from current occupancy tensor([6.1532, 6.2418, 6.1072, 6.2152, 6.2990, 6.2548, 6.0921, 6.1934, 6.1322,\n",
      "        6.1137, 6.1737, 6.1882, 6.2245, 6.4164, 6.1922, 6.1641, 6.1834, 6.2130,\n",
      "        6.1712, 6.1068, 6.2251, 6.2874, 6.1409, 6.1520, 6.1521, 6.1409, 6.2519,\n",
      "        6.1117, 6.2021, 6.2398, 6.2362, 6.2587, 6.1633, 6.2685, 6.1089, 6.1975,\n",
      "        6.2101, 6.2675, 6.2708, 6.2743, 6.1713, 6.2397, 6.2176, 6.1011, 6.2161,\n",
      "        6.1601, 6.1786, 6.1201, 6.3100, 6.0713, 6.2210, 6.1613, 6.1117, 6.1134,\n",
      "        6.2323, 6.2725, 6.1852, 6.1067, 6.1878, 6.2560, 6.2207, 6.1978, 6.1313,\n",
      "        6.1488, 6.2348, 6.1785, 6.0593, 6.3047, 6.2766, 6.1604, 6.2409, 6.1658,\n",
      "        6.2480, 6.2852, 6.2549, 6.1754, 6.2048, 6.2100, 6.2609, 6.2145, 6.2189,\n",
      "        6.2494, 6.2598, 6.1082, 6.1185, 6.1427, 6.1384, 6.1752, 6.1426, 6.2234,\n",
      "        6.1050, 6.2464, 6.1368, 6.1242, 6.0775, 6.2053, 6.1321, 6.1255, 6.2196,\n",
      "        6.1043, 6.1136, 6.2392, 6.2628, 6.1039, 6.0589, 6.2226, 6.2822, 6.2677,\n",
      "        6.2885, 6.1850, 6.1636, 6.2348, 6.2414, 6.2770, 6.1573, 6.2124, 6.1551,\n",
      "        6.2621, 6.0692, 6.1822], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.150620  [186124/5599865]\n",
      "average delta from current occupancy tensor([6.2641, 6.3631, 6.2146, 6.3273, 6.4223, 6.3787, 6.1944, 6.3064, 6.2413,\n",
      "        6.2205, 6.2863, 6.2972, 6.3369, 6.5380, 6.3092, 6.2749, 6.2941, 6.3246,\n",
      "        6.2851, 6.2132, 6.3379, 6.4073, 6.2500, 6.2661, 6.2632, 6.2428, 6.3639,\n",
      "        6.2166, 6.3105, 6.3528, 6.3478, 6.3748, 6.2668, 6.3857, 6.2168, 6.3024,\n",
      "        6.3250, 6.3878, 6.3989, 6.3882, 6.2862, 6.3503, 6.3340, 6.2029, 6.3303,\n",
      "        6.2691, 6.2893, 6.2258, 6.4300, 6.1753, 6.3321, 6.2750, 6.2164, 6.2225,\n",
      "        6.3461, 6.3891, 6.2977, 6.2146, 6.2992, 6.3730, 6.3441, 6.3075, 6.2366,\n",
      "        6.2528, 6.3515, 6.2915, 6.1607, 6.4249, 6.3958, 6.2726, 6.3520, 6.2771,\n",
      "        6.3617, 6.4075, 6.3734, 6.2809, 6.3138, 6.3210, 6.3803, 6.3274, 6.3292,\n",
      "        6.3669, 6.3748, 6.2131, 6.2255, 6.2556, 6.2514, 6.2899, 6.2545, 6.3334,\n",
      "        6.2124, 6.3696, 6.2427, 6.2324, 6.1771, 6.3263, 6.2385, 6.2235, 6.3343,\n",
      "        6.2112, 6.2215, 6.3568, 6.3788, 6.2083, 6.1604, 6.3415, 6.4058, 6.3848,\n",
      "        6.4125, 6.2970, 6.2775, 6.3512, 6.3522, 6.3963, 6.2705, 6.3219, 6.2627,\n",
      "        6.3807, 6.1741, 6.2991], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.889766  [198524/5599865]\n",
      "average delta from current occupancy tensor([5.9395, 6.0302, 5.8958, 5.9920, 6.0804, 6.0455, 5.8744, 5.9759, 5.9192,\n",
      "        5.9000, 5.9592, 5.9644, 6.0001, 6.1909, 5.9822, 5.9482, 5.9637, 5.9892,\n",
      "        5.9595, 5.8936, 6.0014, 6.0648, 5.9261, 5.9442, 5.9389, 5.9133, 6.0216,\n",
      "        5.8948, 5.9746, 6.0137, 6.0082, 6.0347, 5.9342, 6.0445, 5.8980, 5.9646,\n",
      "        5.9928, 6.0493, 6.0661, 6.0433, 5.9614, 6.0092, 6.0018, 5.8807, 5.9964,\n",
      "        5.9416, 5.9596, 5.9032, 6.0855, 5.8605, 5.9948, 5.9512, 5.8946, 5.9039,\n",
      "        6.0089, 6.0468, 5.9684, 5.8964, 5.9685, 6.0341, 6.0169, 5.9734, 5.9117,\n",
      "        5.9235, 6.0162, 5.9640, 5.8460, 6.0794, 6.0548, 5.9476, 6.0111, 5.9506,\n",
      "        6.0217, 6.0672, 6.0359, 5.9477, 5.9782, 5.9858, 6.0422, 5.9930, 5.9918,\n",
      "        6.0297, 6.0337, 5.8922, 5.9042, 5.9346, 5.9312, 5.9642, 5.9327, 5.9950,\n",
      "        5.8941, 6.0375, 5.9173, 5.9111, 5.8576, 5.9999, 5.9142, 5.8938, 6.0004,\n",
      "        5.8925, 5.9018, 6.0214, 6.0377, 5.8877, 5.8461, 6.0100, 6.0672, 6.0437,\n",
      "        6.0731, 5.9673, 5.9533, 6.0157, 6.0109, 6.0551, 5.9468, 5.9851, 5.9349,\n",
      "        6.0418, 5.8602, 5.9739], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.647558  [210924/5599865]\n",
      "average delta from current occupancy tensor([6.5317, 6.6435, 6.4798, 6.5900, 6.7003, 6.6634, 6.4498, 6.5737, 6.5072,\n",
      "        6.4837, 6.5552, 6.5559, 6.5991, 6.8104, 6.5858, 6.5410, 6.5575, 6.5861,\n",
      "        6.5571, 6.4758, 6.6012, 6.6789, 6.5146, 6.5405, 6.5311, 6.4914, 6.6217,\n",
      "        6.4750, 6.5661, 6.6146, 6.6068, 6.6414, 6.5160, 6.6533, 6.4827, 6.5508,\n",
      "        6.5944, 6.6627, 6.6910, 6.6477, 6.5603, 6.6064, 6.6062, 6.4558, 6.5973,\n",
      "        6.5311, 6.5529, 6.4855, 6.7043, 6.4369, 6.5914, 6.5480, 6.4749, 6.4906,\n",
      "        6.6102, 6.6552, 6.5650, 6.4813, 6.5636, 6.6421, 6.6318, 6.5664, 6.4944,\n",
      "        6.5052, 6.6223, 6.5611, 6.4179, 6.6952, 6.6673, 6.5422, 6.6094, 6.5444,\n",
      "        6.6244, 6.6846, 6.6461, 6.5331, 6.5712, 6.5818, 6.6536, 6.5921, 6.5874,\n",
      "        6.6380, 6.6390, 6.4726, 6.4882, 6.5289, 6.5254, 6.5634, 6.5254, 6.5904,\n",
      "        6.4779, 6.6538, 6.5011, 6.4974, 6.4280, 6.6098, 6.4981, 6.4652, 6.6026,\n",
      "        6.4756, 6.4868, 6.6291, 6.6446, 6.4669, 6.4184, 6.6180, 6.6865, 6.6523,\n",
      "        6.6934, 6.5631, 6.5503, 6.6212, 6.6086, 6.6676, 6.5423, 6.5790, 6.5221,\n",
      "        6.6524, 6.4376, 6.5765], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.468575  [223324/5599865]\n",
      "average delta from current occupancy tensor([6.3206, 6.4281, 6.2724, 6.3708, 6.4784, 6.4484, 6.2403, 6.3585, 6.2976,\n",
      "        6.2751, 6.3426, 6.3381, 6.3789, 6.5814, 6.3742, 6.3284, 6.3419, 6.3668,\n",
      "        6.3459, 6.2677, 6.3814, 6.4558, 6.3038, 6.3320, 6.3203, 6.2746, 6.3971,\n",
      "        6.2649, 6.3458, 6.3928, 6.3843, 6.4194, 6.2971, 6.4306, 6.2756, 6.3284,\n",
      "        6.3783, 6.4429, 6.4772, 6.4215, 6.3498, 6.3824, 6.3905, 6.2447, 6.3798,\n",
      "        6.3174, 6.3378, 6.2749, 6.4801, 6.2319, 6.3704, 6.3382, 6.2647, 6.2837,\n",
      "        6.3899, 6.4317, 6.3506, 6.2747, 6.3478, 6.4213, 6.4213, 6.3477, 6.2820,\n",
      "        6.2891, 6.4044, 6.3483, 6.2126, 6.4700, 6.4454, 6.3312, 6.3858, 6.3322,\n",
      "        6.4021, 6.4637, 6.4268, 6.3141, 6.3514, 6.3626, 6.4338, 6.3739, 6.3663,\n",
      "        6.4187, 6.4160, 6.2633, 6.2790, 6.3210, 6.3183, 6.3524, 6.3165, 6.3685,\n",
      "        6.2710, 6.4396, 6.2884, 6.2883, 6.2184, 6.3993, 6.2862, 6.2474, 6.3852,\n",
      "        6.2684, 6.2790, 6.4111, 6.4219, 6.2575, 6.2134, 6.4032, 6.4673, 6.4297,\n",
      "        6.4737, 6.3484, 6.3401, 6.4029, 6.3846, 6.4455, 6.3324, 6.3581, 6.3078,\n",
      "        6.4320, 6.2335, 6.3662], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 7.225011  [235724/5599865]\n",
      "average delta from current occupancy tensor([7.2404, 7.3702, 7.1841, 7.2941, 7.4256, 7.3958, 7.1415, 7.2831, 7.2130,\n",
      "        7.1861, 7.2658, 7.2547, 7.3029, 7.5280, 7.3068, 7.2483, 7.2618, 7.2889,\n",
      "        7.2717, 7.1774, 7.3068, 7.3961, 7.2195, 7.2571, 7.2400, 7.1764, 7.3209,\n",
      "        7.1715, 7.2613, 7.3185, 7.3072, 7.3517, 7.2023, 7.3651, 7.1884, 7.2374,\n",
      "        7.3070, 7.3836, 7.4331, 7.3497, 7.2773, 7.3033, 7.3225, 7.1453, 7.3072,\n",
      "        7.2333, 7.2574, 7.1838, 7.4253, 7.1360, 7.2913, 7.2637, 7.1713, 7.1986,\n",
      "        7.3166, 7.3653, 7.2741, 7.1878, 7.2689, 7.3553, 7.3667, 7.2654, 7.1905,\n",
      "        7.1950, 7.3375, 7.2730, 7.1113, 7.4113, 7.3843, 7.2535, 7.3079, 7.2535,\n",
      "        7.3297, 7.4082, 7.3638, 7.2231, 7.2690, 7.2836, 7.3721, 7.2991, 7.2863,\n",
      "        7.3539, 7.3463, 7.1703, 7.1902, 7.2442, 7.2419, 7.2802, 7.2375, 7.2881,\n",
      "        7.1827, 7.3856, 7.1981, 7.2021, 7.1140, 7.3393, 7.1963, 7.1411, 7.3141,\n",
      "        7.1794, 7.1919, 7.3460, 7.3541, 7.1632, 7.1132, 7.3395, 7.4149, 7.3640,\n",
      "        7.4225, 7.2710, 7.2656, 7.3352, 7.3060, 7.3842, 7.2562, 7.2763, 7.2206,\n",
      "        7.3692, 7.1391, 7.2980], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.024880  [248124/5599865]\n",
      "average delta from current occupancy tensor([6.3644, 6.4780, 6.3170, 6.4058, 6.5220, 6.5011, 6.2764, 6.3992, 6.3409,\n",
      "        6.3175, 6.3856, 6.3713, 6.4127, 6.6093, 6.4240, 6.3702, 6.3797, 6.4008,\n",
      "        6.3924, 6.3101, 6.4168, 6.4942, 6.3456, 6.3814, 6.3642, 6.3015, 6.4250,\n",
      "        6.3029, 6.3749, 6.4255, 6.4147, 6.4553, 6.3230, 6.4667, 6.3211, 6.3517,\n",
      "        6.4202, 6.4860, 6.5360, 6.4498, 6.3982, 6.4098, 6.4347, 6.2788, 6.4193,\n",
      "        6.3558, 6.3762, 6.3139, 6.5200, 6.2759, 6.4015, 6.3869, 6.3030, 6.3304,\n",
      "        6.4251, 6.4662, 6.3922, 6.3210, 6.3860, 6.4598, 6.4789, 6.3801, 6.3186,\n",
      "        6.3189, 6.4461, 6.3925, 6.2529, 6.5063, 6.4848, 6.3764, 6.4142, 6.3755,\n",
      "        6.4351, 6.5071, 6.4686, 6.3418, 6.3828, 6.3964, 6.4758, 6.4113, 6.3972,\n",
      "        6.4600, 6.4496, 6.3028, 6.3210, 6.3705, 6.3695, 6.4007, 6.3639, 6.3980,\n",
      "        6.3161, 6.4929, 6.3248, 6.3318, 6.2518, 6.4542, 6.3238, 6.2688, 6.4257,\n",
      "        6.3132, 6.3238, 6.4538, 6.4568, 6.2963, 6.2553, 6.4505, 6.5147, 6.4658,\n",
      "        6.5215, 6.3888, 6.3879, 6.4438, 6.4121, 6.4845, 6.3796, 6.3882, 6.3437,\n",
      "        6.4725, 6.2792, 6.4172], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.050615  [260524/5599865]\n",
      "average delta from current occupancy tensor([6.0310, 6.1771, 5.9723, 6.0770, 6.2280, 6.2078, 5.9158, 6.0724, 6.0010,\n",
      "        5.9713, 6.0568, 6.0328, 6.0849, 6.3164, 6.1095, 6.0370, 6.0462, 6.0701,\n",
      "        6.0676, 5.9621, 6.0912, 6.1899, 6.0061, 6.0556, 6.0306, 5.9412, 6.0966,\n",
      "        5.9502, 6.0345, 6.1003, 6.0852, 6.1395, 5.9675, 6.1540, 5.9777, 6.0018,\n",
      "        6.0995, 6.1827, 6.2553, 6.1277, 6.0760, 6.0772, 6.1193, 5.9176, 6.0969,\n",
      "        6.0167, 6.0422, 5.9647, 6.2233, 5.9203, 6.0690, 6.0623, 5.9505, 5.9901,\n",
      "        6.1012, 6.1523, 6.0644, 5.9783, 6.0542, 6.1471, 6.1829, 6.0431, 5.9689,\n",
      "        5.9649, 6.1318, 6.0664, 5.8890, 6.2037, 6.1788, 6.0466, 6.0832, 6.0445,\n",
      "        6.1125, 6.2090, 6.1600, 5.9921, 6.0460, 6.0645, 6.1691, 6.0854, 6.0637,\n",
      "        6.1490, 6.1309, 5.9510, 5.9755, 6.0421, 6.0421, 6.0792, 6.0325, 6.0638,\n",
      "        5.9712, 6.1979, 5.9767, 5.9900, 5.8833, 6.1504, 5.9760, 5.8968, 6.1057,\n",
      "        5.9676, 5.9810, 6.1422, 6.1410, 5.9425, 5.8935, 6.1409, 6.2215, 6.1529,\n",
      "        6.2304, 6.0595, 6.0629, 6.1285, 6.0803, 6.1782, 6.0521, 6.0520, 6.0000,\n",
      "        6.1642, 5.9257, 6.1016], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 7.402375  [272924/5599865]\n",
      "average delta from current occupancy tensor([7.5563, 7.7230, 7.4917, 7.6006, 7.7745, 7.7589, 7.4226, 7.5998, 7.5224,\n",
      "        7.4891, 7.5841, 7.5504, 7.6086, 7.8580, 7.6479, 7.5616, 7.5687, 7.5921,\n",
      "        7.5986, 7.4787, 7.6170, 7.7284, 7.5271, 7.5873, 7.5559, 7.4442, 7.6172,\n",
      "        7.4622, 7.5491, 7.6248, 7.6065, 7.6705, 7.4723, 7.6867, 7.4982, 7.5087,\n",
      "        7.6307, 7.7239, 7.8160, 7.6519, 7.6092, 7.5953, 7.6546, 7.4233, 7.6261,\n",
      "        7.5362, 7.5645, 7.4792, 7.7668, 7.4335, 7.5888, 7.5947, 7.4629, 7.5127,\n",
      "        7.6276, 7.6839, 7.5916, 7.4998, 7.5775, 7.6811, 7.7346, 7.5611, 7.4821,\n",
      "        7.4724, 7.6667, 7.5958, 7.3959, 7.7421, 7.7171, 7.5744, 7.6026, 7.5710,\n",
      "        7.6388, 7.7531, 7.6978, 7.5009, 7.5639, 7.5860, 7.7080, 7.6120, 7.5829,\n",
      "        7.6855, 7.6595, 7.4643, 7.4933, 7.5723, 7.5741, 7.6130, 7.5602, 7.5822,\n",
      "        7.4907, 7.7483, 7.4905, 7.5104, 7.3846, 7.6966, 7.4903, 7.3907, 7.6367,\n",
      "        7.4866, 7.5015, 7.6787, 7.6717, 7.4541, 7.4024, 7.6805, 7.7702, 7.6856,\n",
      "        7.7806, 7.5853, 7.5942, 7.6622, 7.5988, 7.7159, 7.5818, 7.5693, 7.5157,\n",
      "        7.7015, 7.4407, 7.6396], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.770188  [285324/5599865]\n",
      "average delta from current occupancy tensor([4.6801, 4.8476, 4.6176, 4.7169, 4.8931, 4.8848, 4.5435, 4.7202, 4.6463,\n",
      "        4.6134, 4.7063, 4.6665, 4.7237, 4.9720, 4.7742, 4.6840, 4.6877, 4.7076,\n",
      "        4.7231, 4.6032, 4.7334, 4.8444, 4.6501, 4.7141, 4.6796, 4.5577, 4.7276,\n",
      "        4.5836, 4.6617, 4.7388, 4.7191, 4.7856, 4.5844, 4.8016, 4.6243, 4.6183,\n",
      "        4.7514, 4.8433, 4.9449, 4.7617, 4.7348, 4.7060, 4.7766, 4.5430, 4.7451,\n",
      "        4.6564, 4.6838, 4.6013, 4.8831, 4.5603, 4.7023, 4.7213, 4.5848, 4.6394,\n",
      "        4.7431, 4.7977, 4.7130, 4.6269, 4.6962, 4.7982, 4.8641, 4.6760, 4.6022,\n",
      "        4.5875, 4.7867, 4.7190, 4.5207, 4.8560, 4.8341, 4.6986, 4.7137, 4.6944,\n",
      "        4.7529, 4.8718, 4.8168, 4.6136, 4.6785, 4.7015, 4.8271, 4.7300, 4.6965,\n",
      "        4.8049, 4.7734, 4.5871, 4.6173, 4.6995, 4.7031, 4.7390, 4.6863, 4.6949,\n",
      "        4.6168, 4.8749, 4.6105, 4.6349, 4.5046, 4.8254, 4.6109, 4.5016, 4.7564,\n",
      "        4.6129, 4.6277, 4.7989, 4.7865, 4.5761, 4.5285, 4.8037, 4.8920, 4.8005,\n",
      "        4.9025, 4.7059, 4.7197, 4.7814, 4.7095, 4.8327, 4.7072, 4.6826, 4.6343,\n",
      "        4.8197, 4.5688, 4.7668], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.478579  [297724/5599865]\n",
      "average delta from current occupancy tensor([6.6513, 6.8451, 6.5817, 6.6851, 6.8905, 6.8890, 6.4908, 6.6937, 6.6126,\n",
      "        6.5752, 6.6797, 6.6271, 6.6917, 6.9786, 6.7624, 6.6542, 6.6546, 6.6735,\n",
      "        6.7015, 6.5636, 6.7045, 6.8317, 6.6161, 6.6939, 6.6510, 6.4992, 6.6912,\n",
      "        6.5378, 6.6178, 6.7081, 6.6838, 6.7630, 6.5281, 6.7812, 6.5898, 6.5642,\n",
      "        6.7298, 6.8342, 6.9617, 6.7294, 6.7162, 6.6664, 6.7604, 6.4889, 6.7207,\n",
      "        6.6200, 6.6507, 6.5588, 6.8765, 6.5167, 6.6653, 6.7020, 6.5396, 6.6075,\n",
      "        6.7145, 6.7753, 6.6863, 6.5939, 6.6641, 6.7798, 6.8694, 6.6368, 6.5575,\n",
      "        6.5350, 6.7699, 6.6954, 6.4690, 6.8426, 6.8209, 6.6731, 6.6756, 6.6673,\n",
      "        6.7241, 6.8661, 6.8032, 6.5622, 6.6392, 6.6667, 6.8152, 6.7023, 6.6587,\n",
      "        6.7901, 6.7478, 6.5432, 6.5793, 6.6775, 6.6839, 6.7216, 6.6610, 6.6561,\n",
      "        6.5811, 6.8786, 6.5671, 6.6001, 6.4450, 6.8240, 6.5681, 6.4317, 6.7344,\n",
      "        6.5769, 6.5937, 6.7840, 6.7637, 6.5296, 6.4797, 6.7931, 6.8930, 6.7800,\n",
      "        6.9054, 6.6777, 6.6989, 6.7629, 6.6706, 6.8192, 6.6844, 6.6427, 6.5928,\n",
      "        6.8058, 6.5282, 6.7550], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.155557  [310124/5599865]\n",
      "average delta from current occupancy tensor([6.1224, 6.3192, 6.0541, 6.1479, 6.3580, 6.3649, 5.9567, 6.1613, 6.0832,\n",
      "        6.0461, 6.1492, 6.0891, 6.1532, 6.4444, 6.2374, 6.1236, 6.1201, 6.1352,\n",
      "        6.1738, 6.0345, 6.1679, 6.2961, 6.0859, 6.1688, 6.1223, 5.9572, 6.1477,\n",
      "        6.0051, 6.0760, 6.1689, 6.1428, 6.2255, 5.9847, 6.2437, 6.0629, 6.0185,\n",
      "        6.1984, 6.3025, 6.4420, 6.1855, 6.1900, 6.1230, 6.2308, 5.9536, 6.1871,\n",
      "        6.0865, 6.1167, 6.0271, 6.3415, 5.9895, 6.1249, 6.1768, 6.0074, 6.0812,\n",
      "        6.1770, 6.2365, 6.1549, 6.0683, 6.1294, 6.2447, 6.3492, 6.0978, 6.0233,\n",
      "        5.9951, 6.2384, 6.1663, 5.9393, 6.3047, 6.2864, 6.1449, 6.1325, 6.1382,\n",
      "        6.1852, 6.3337, 6.2705, 6.0195, 6.0999, 6.1286, 6.2828, 6.1675, 6.1183,\n",
      "        6.2579, 6.2089, 6.0120, 6.0497, 6.1527, 6.1613, 6.1960, 6.1345, 6.1148,\n",
      "        6.0540, 6.3551, 6.0330, 6.0712, 5.9092, 6.3024, 6.0345, 5.8858, 6.2015,\n",
      "        6.0498, 6.0667, 6.2524, 6.2256, 5.9970, 5.9515, 6.2649, 6.3646, 6.2422,\n",
      "        6.3772, 6.1455, 6.1722, 6.2300, 6.1272, 6.2843, 6.1575, 6.1018, 6.0572,\n",
      "        6.2723, 6.0028, 6.2310], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.571284  [322524/5599865]\n",
      "average delta from current occupancy tensor([5.6898, 5.9225, 5.6121, 5.7100, 5.9598, 5.9778, 5.4910, 5.7312, 5.6438,\n",
      "        5.6010, 5.7192, 5.6406, 5.7144, 6.0583, 5.8282, 5.6894, 5.6807, 5.6938,\n",
      "        5.7510, 5.5873, 5.7339, 5.8840, 5.6461, 5.7482, 5.6901, 5.4823, 5.7020,\n",
      "        5.5489, 5.6204, 5.7316, 5.6993, 5.7995, 5.5125, 5.8208, 5.6231, 5.5492,\n",
      "        5.7754, 5.8960, 6.0724, 5.7456, 5.7716, 5.6735, 5.8152, 5.4861, 5.7597,\n",
      "        5.6428, 5.6774, 5.5759, 5.9377, 5.5371, 5.6792, 5.7574, 5.5522, 5.6448,\n",
      "        5.7431, 5.8108, 5.7246, 5.6309, 5.6911, 5.8249, 5.9639, 5.6494, 5.5684,\n",
      "        5.5288, 5.8218, 5.7407, 5.4758, 5.8911, 5.8739, 5.7170, 5.6850, 5.7081,\n",
      "        5.7510, 5.9314, 5.8577, 5.5537, 5.6514, 5.6861, 5.8724, 5.7354, 5.6714,\n",
      "        5.8436, 5.7786, 5.5587, 5.6045, 5.7298, 5.7427, 5.7792, 5.7066, 5.6666,\n",
      "        5.6124, 5.9670, 5.5799, 5.6304, 5.4379, 5.9077, 5.5820, 5.4161, 5.7771,\n",
      "        5.6076, 5.6271, 5.8379, 5.7992, 5.5395, 5.4920, 5.8567, 5.9722, 5.8190,\n",
      "        5.9871, 5.7129, 5.7505, 5.8104, 5.6783, 5.8710, 5.7328, 5.6517, 5.6061,\n",
      "        5.8588, 5.5547, 5.8217], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.462050  [334924/5599865]\n",
      "average delta from current occupancy tensor([6.3613, 6.6147, 6.2794, 6.3729, 6.6457, 6.6756, 6.1599, 6.4017, 6.3117,\n",
      "        6.2652, 6.3911, 6.2971, 6.3754, 6.7492, 6.5139, 6.3580, 6.3442, 6.3530,\n",
      "        6.4277, 6.2504, 6.3984, 6.5606, 6.3129, 6.4288, 6.3611, 6.1464, 6.3553,\n",
      "        6.2050, 6.2700, 6.3923, 6.3561, 6.4678, 6.1670, 6.4900, 6.2916, 6.1925,\n",
      "        6.4501, 6.5782, 6.7823, 6.4015, 6.4523, 6.3247, 6.4938, 6.1554, 6.4304,\n",
      "        6.3045, 6.3409, 6.2361, 6.6189, 6.1994, 6.3349, 6.4380, 6.2089, 6.3157,\n",
      "        6.4070, 6.4779, 6.3952, 6.3019, 6.3551, 6.4979, 6.6653, 6.3046, 6.2237,\n",
      "        6.1822, 6.4992, 6.4152, 6.1524, 6.5641, 6.5505, 6.3913, 6.3372, 6.3801,\n",
      "        6.4136, 6.6154, 6.5355, 6.1990, 6.3065, 6.3445, 6.5521, 6.4020, 6.3255,\n",
      "        6.5217, 6.4431, 6.2174, 6.2689, 6.4087, 6.4252, 6.4603, 6.3812, 6.3204,\n",
      "        6.2801, 6.6643, 6.2370, 6.2973, 6.1165, 6.6036, 6.2395, 6.0780, 6.4488,\n",
      "        6.2753, 6.2959, 6.5159, 6.4668, 6.1967, 6.1663, 6.5401, 6.6640, 6.4878,\n",
      "        6.6810, 6.3819, 6.4287, 6.4846, 6.3297, 6.5473, 6.4092, 6.3046, 6.2629,\n",
      "        6.5366, 6.2200, 6.5088], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.042753  [347324/5599865]\n",
      "average delta from current occupancy tensor([5.8384, 6.1360, 5.7564, 5.8410, 6.1623, 6.2080, 5.6597, 5.8807, 5.7803,\n",
      "        5.7456, 5.8703, 5.7600, 5.8409, 6.2806, 6.0191, 5.8300, 5.8098, 5.8142,\n",
      "        5.9151, 5.7359, 5.8692, 6.0595, 5.7806, 5.9216, 5.8365, 5.6392, 5.8102,\n",
      "        5.7037, 5.7383, 5.8588, 5.8155, 5.9495, 5.6583, 5.9744, 5.7653, 5.6813,\n",
      "        5.9378, 6.0843, 6.3384, 5.8628, 5.9474, 5.7743, 5.9893, 5.6543, 5.9118,\n",
      "        5.7685, 5.8061, 5.7255, 6.1272, 5.7035, 5.7915, 5.9318, 5.7064, 5.7883,\n",
      "        5.8788, 5.9597, 5.8741, 5.7734, 5.8234, 5.9880, 6.2018, 5.7641, 5.7143,\n",
      "        5.6766, 5.9946, 5.9001, 5.6559, 6.0590, 6.0483, 5.8744, 5.7893, 5.8586,\n",
      "        5.8842, 6.1278, 6.0331, 5.6908, 5.7654, 5.8044, 6.0540, 5.8767, 5.7789,\n",
      "        6.0201, 5.9182, 5.7128, 5.7487, 5.8987, 5.9199, 5.9562, 5.8631, 5.7740,\n",
      "        5.7577, 6.1955, 5.7244, 5.7677, 5.6155, 6.1288, 5.7259, 5.5688, 5.9321,\n",
      "        5.7543, 5.7678, 6.0124, 5.9478, 5.6970, 5.6723, 6.0445, 6.1886, 5.9715,\n",
      "        6.2103, 5.8579, 5.9183, 5.9740, 5.7797, 6.0441, 5.8955, 5.7626, 5.7394,\n",
      "        6.0351, 5.7194, 6.0167], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.140954  [359724/5599865]\n",
      "average delta from current occupancy tensor([6.2375, 6.5787, 6.1651, 6.2309, 6.6006, 6.6683, 6.0232, 6.2666, 6.1925,\n",
      "        6.1480, 6.2598, 6.1590, 6.2289, 6.7425, 6.4374, 6.2275, 6.2081, 6.2077,\n",
      "        6.3062, 6.1347, 6.2522, 6.4699, 6.1916, 6.3190, 6.2349, 5.9864, 6.1991,\n",
      "        6.0867, 6.1239, 6.2413, 6.2059, 6.3336, 6.0113, 6.3641, 6.1787, 6.0407,\n",
      "        6.3294, 6.5067, 6.8349, 6.2399, 6.3490, 6.1704, 6.3936, 6.0149, 6.2942,\n",
      "        6.1750, 6.2064, 6.1187, 6.5527, 6.0920, 6.1887, 6.3312, 6.0906, 6.2010,\n",
      "        6.2593, 6.3448, 6.2618, 6.1894, 6.2190, 6.3852, 6.6679, 6.1628, 6.0992,\n",
      "        6.0410, 6.3992, 6.2871, 6.0229, 6.4654, 6.4575, 6.2660, 6.1823, 6.2520,\n",
      "        6.2620, 6.5597, 6.4412, 6.0582, 6.1646, 6.2003, 6.4677, 6.2602, 6.1769,\n",
      "        6.4288, 6.2927, 6.1002, 6.1532, 6.2918, 6.3208, 6.3589, 6.2571, 6.1735,\n",
      "        6.1675, 6.6538, 6.1146, 6.1797, 5.9604, 6.5768, 6.1170, 5.8844, 6.3189,\n",
      "        6.1626, 6.1812, 6.4186, 6.3321, 6.0775, 6.0486, 6.4627, 6.6392, 6.3605,\n",
      "        6.6667, 6.2492, 6.3131, 6.3708, 6.1747, 6.4530, 6.2850, 6.1589, 6.1328,\n",
      "        6.4449, 6.1157, 6.4369], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.636381  [372124/5599865]\n",
      "average delta from current occupancy tensor([5.5281, 5.7500, 5.4834, 5.5185, 5.7616, 5.8332, 5.3907, 5.5435, 5.5001,\n",
      "        5.4716, 5.5406, 5.4735, 5.5168, 5.8894, 5.6217, 5.5196, 5.5058, 5.5030,\n",
      "        5.5641, 5.4634, 5.5314, 5.6378, 5.4987, 5.5709, 5.5254, 5.3632, 5.4948,\n",
      "        5.4316, 5.4490, 5.5232, 5.5006, 5.5692, 5.3780, 5.5809, 5.4929, 5.3949,\n",
      "        5.5712, 5.6774, 5.9925, 5.5199, 5.5820, 5.4766, 5.5963, 5.3853, 5.5563,\n",
      "        5.4861, 5.5053, 5.4526, 5.7144, 5.4382, 5.4906, 5.5756, 5.4343, 5.5069,\n",
      "        5.5358, 5.5728, 5.5414, 5.4997, 5.5130, 5.5908, 5.8391, 5.4748, 5.4381,\n",
      "        5.3987, 5.5981, 5.5562, 5.3932, 5.6307, 5.6279, 5.5458, 5.4838, 5.5360,\n",
      "        5.5363, 5.7260, 5.6152, 5.4082, 5.4761, 5.4990, 5.6404, 5.5375, 5.4824,\n",
      "        5.6096, 5.5520, 5.4406, 5.4753, 5.5612, 5.5730, 5.5851, 5.5408, 5.4803,\n",
      "        5.4853, 5.8216, 5.4485, 5.4925, 5.3512, 5.7548, 5.4506, 5.3069, 5.5660,\n",
      "        5.4824, 5.4940, 5.6052, 5.5688, 5.4262, 5.4111, 5.6409, 5.8022, 5.5793,\n",
      "        5.8286, 5.5335, 5.5680, 5.5860, 5.4794, 5.6240, 5.5571, 5.4717, 5.4588,\n",
      "        5.6191, 5.4535, 5.6240], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.586937  [384524/5599865]\n",
      "average delta from current occupancy tensor([5.6318, 5.8854, 5.5521, 5.6064, 5.8905, 6.0042, 5.4008, 5.6564, 5.5814,\n",
      "        5.5298, 5.6519, 5.5245, 5.6014, 6.0673, 5.7906, 5.6137, 5.5858, 5.5766,\n",
      "        5.6965, 5.5151, 5.6284, 5.7920, 5.5774, 5.7116, 5.6254, 5.3659, 5.5569,\n",
      "        5.4557, 5.4771, 5.6115, 5.5706, 5.6967, 5.3813, 5.7179, 5.5722, 5.3995,\n",
      "        5.7062, 5.8259, 6.2354, 5.6018, 5.7311, 5.5243, 5.7522, 5.3944, 5.6773,\n",
      "        5.5524, 5.5855, 5.4942, 5.8495, 5.4725, 5.5536, 5.7207, 5.4609, 5.5967,\n",
      "        5.6368, 5.7022, 5.6532, 5.5839, 5.5988, 5.7382, 6.0199, 5.5261, 5.4652,\n",
      "        5.4069, 5.7543, 5.6822, 5.4072, 5.7858, 5.7863, 5.6648, 5.5377, 5.6450,\n",
      "        5.6359, 5.8619, 5.7788, 5.4157, 5.5287, 5.5706, 5.7981, 5.6420, 5.5377,\n",
      "        5.7727, 5.6636, 5.4730, 5.5382, 5.6957, 5.7184, 5.7360, 5.6564, 5.5338,\n",
      "        5.5572, 5.9907, 5.4846, 5.5690, 5.3574, 5.9002, 5.4893, 5.2913, 5.6948,\n",
      "        5.5523, 5.5725, 5.7657, 5.6957, 5.4459, 5.4278, 5.8027, 5.9538, 5.7145,\n",
      "        5.9929, 5.6386, 5.7051, 5.7302, 5.5295, 5.7827, 5.6852, 5.5186, 5.5014,\n",
      "        5.7807, 5.5010, 5.7945], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.212146  [396924/5599865]\n",
      "average delta from current occupancy tensor([5.2161, 5.5611, 5.1385, 5.1740, 5.5586, 5.6478, 5.0019, 5.2469, 5.1602,\n",
      "        5.1207, 5.2410, 5.1097, 5.1681, 5.6817, 5.4367, 5.1879, 5.1588, 5.1492,\n",
      "        5.3057, 5.1092, 5.1994, 5.4249, 5.1564, 5.3297, 5.2059, 4.9516, 5.1311,\n",
      "        5.0622, 5.0712, 5.1760, 5.1429, 5.2933, 4.9699, 5.3227, 5.1548, 4.9923,\n",
      "        5.3137, 5.4749, 5.8942, 5.1644, 5.3548, 5.1054, 5.3777, 4.9935, 5.2719,\n",
      "        5.1350, 5.1595, 5.0915, 5.5011, 5.0791, 5.1311, 5.3404, 5.0661, 5.1735,\n",
      "        5.2126, 5.3003, 5.2415, 5.1637, 5.1693, 5.3540, 5.6620, 5.1105, 5.0676,\n",
      "        5.0058, 5.3791, 5.2856, 5.0142, 5.4143, 5.4188, 5.2623, 5.1164, 5.2327,\n",
      "        5.2096, 5.5263, 5.4115, 5.0156, 5.1125, 5.1457, 5.4375, 5.2226, 5.1185,\n",
      "        5.4035, 5.2463, 5.0755, 5.1275, 5.3093, 5.3416, 5.3622, 5.2528, 5.1151,\n",
      "        5.1432, 5.6397, 5.0833, 5.1523, 4.9459, 5.5804, 5.0873, 4.8544, 5.2977,\n",
      "        5.1398, 5.1549, 5.3960, 5.2939, 5.0551, 5.0418, 5.4497, 5.6077, 5.3194,\n",
      "        5.6347, 5.2231, 5.3198, 5.3455, 5.1102, 5.4134, 5.2935, 5.1049, 5.0955,\n",
      "        5.4126, 5.1022, 5.4446], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.112135  [409324/5599865]\n",
      "average delta from current occupancy tensor([5.0925, 5.3337, 5.0496, 5.0707, 5.3266, 5.4199, 4.9426, 5.1040, 5.0656,\n",
      "        5.0352, 5.1016, 5.0226, 5.0661, 5.4444, 5.2169, 5.0801, 5.0613, 5.0528,\n",
      "        5.1299, 5.0267, 5.0817, 5.1941, 5.0624, 5.1405, 5.0885, 4.9333, 5.0369,\n",
      "        4.9894, 4.9923, 5.0716, 5.0464, 5.1204, 4.9341, 5.1325, 5.0626, 4.9351,\n",
      "        5.1312, 5.2454, 5.5751, 5.0612, 5.1496, 5.0164, 5.1574, 4.9359, 5.1132,\n",
      "        5.0447, 5.0627, 5.0118, 5.2657, 5.0051, 5.0382, 5.1435, 4.9928, 5.0755,\n",
      "        5.0873, 5.1225, 5.1013, 5.0689, 5.0690, 5.1458, 5.4369, 5.0232, 4.9933,\n",
      "        4.9438, 5.1569, 5.1215, 4.9548, 5.1802, 5.1878, 5.1120, 5.0255, 5.0989,\n",
      "        5.0861, 5.2955, 5.1827, 4.9510, 5.0251, 5.0510, 5.2079, 5.0925, 5.0291,\n",
      "        5.1758, 5.1009, 4.9997, 5.0407, 5.1323, 5.1457, 5.1526, 5.1086, 5.0256,\n",
      "        5.0531, 5.4119, 5.0051, 5.0605, 4.9332, 5.3578, 5.0087, 4.9285, 5.1241,\n",
      "        5.0508, 5.0624, 5.1697, 5.1214, 4.9848, 4.9770, 5.2234, 5.3760, 5.1308,\n",
      "        5.4013, 5.0946, 5.1358, 5.1427, 5.0206, 5.1818, 5.1254, 5.0188, 5.0141,\n",
      "        5.1823, 5.0233, 5.2240], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.894444  [421724/5599865]\n",
      "average delta from current occupancy tensor([4.9582, 5.1454, 4.9007, 4.9252, 5.1392, 5.2353, 4.8277, 4.9740, 4.9230,\n",
      "        4.8810, 4.9706, 4.8704, 4.9181, 5.2537, 5.0827, 4.9410, 4.9138, 4.9005,\n",
      "        5.0107, 4.8747, 4.9396, 5.0644, 4.9182, 5.0267, 4.9531, 4.8032, 4.8779,\n",
      "        4.8538, 4.8535, 4.9260, 4.8905, 4.9927, 4.8098, 5.0096, 4.9205, 4.8187,\n",
      "        5.0104, 5.0947, 5.4071, 4.9096, 5.0380, 4.8658, 5.0457, 4.8240, 4.9853,\n",
      "        4.8930, 4.9169, 4.8658, 5.1039, 4.8632, 4.8794, 5.0297, 4.8556, 4.9370,\n",
      "        4.9477, 4.9957, 4.9695, 4.9283, 4.9241, 5.0287, 5.2600, 4.8707, 4.8555,\n",
      "        4.8272, 5.0434, 4.9992, 4.8353, 5.0569, 5.0619, 4.9861, 4.8710, 4.9669,\n",
      "        4.9452, 5.1230, 5.0605, 4.8307, 4.8717, 4.8986, 5.0740, 4.9558, 4.8738,\n",
      "        5.0565, 4.9651, 4.8592, 4.8885, 5.0155, 5.0340, 5.0416, 4.9821, 4.8716,\n",
      "        4.9059, 5.2275, 4.8619, 4.9166, 4.8039, 5.1717, 4.8639, 4.7594, 5.0000,\n",
      "        4.9033, 4.9188, 5.0537, 4.9947, 4.8514, 4.8480, 5.0847, 5.1840, 5.0070,\n",
      "        5.2124, 4.9610, 5.0193, 5.0249, 4.8681, 5.0576, 5.0052, 4.8679, 4.8663,\n",
      "        5.0589, 4.8735, 5.0875], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.070231  [434124/5599865]\n",
      "average delta from current occupancy tensor([4.8275, 5.0519, 4.7911, 4.8038, 5.0418, 5.1173, 4.6911, 4.8365, 4.8052,\n",
      "        4.7777, 4.8345, 4.7610, 4.7988, 5.1256, 4.9711, 4.8162, 4.7973, 4.7881,\n",
      "        4.8706, 4.7707, 4.8131, 4.9385, 4.8019, 4.8935, 4.8239, 4.6547, 4.7713,\n",
      "        4.7354, 4.7322, 4.8039, 4.7799, 4.8470, 4.6601, 4.8633, 4.8045, 4.6733,\n",
      "        4.8673, 4.9827, 5.2797, 4.7919, 4.9082, 4.7514, 4.9167, 4.6852, 4.8432,\n",
      "        4.7847, 4.7999, 4.7551, 4.9923, 4.7534, 4.7739, 4.8964, 4.7388, 4.8149,\n",
      "        4.8187, 4.8492, 4.8335, 4.8095, 4.8042, 4.8914, 5.1361, 4.7616, 4.7381,\n",
      "        4.6898, 4.9122, 4.8546, 4.7063, 4.9277, 4.9361, 4.8457, 4.7606, 4.8326,\n",
      "        4.8165, 5.0221, 4.9356, 4.6950, 4.7633, 4.7870, 4.9529, 4.8239, 4.7658,\n",
      "        4.9292, 4.8286, 4.7446, 4.7831, 4.8786, 4.9041, 4.9128, 4.8429, 4.7617,\n",
      "        4.7939, 5.1121, 4.7483, 4.8009, 4.6559, 5.0772, 4.7521, 4.6176, 4.8541,\n",
      "        4.7926, 4.8028, 4.9265, 4.8490, 4.7320, 4.7274, 4.9708, 5.0801, 4.8600,\n",
      "        5.0994, 4.8283, 4.8831, 4.8872, 4.7554, 4.9296, 4.8637, 4.7567, 4.7555,\n",
      "        4.9316, 4.7701, 4.9767], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.825626  [446524/5599865]\n",
      "average delta from current occupancy tensor([5.7247, 5.8819, 5.6861, 5.6974, 5.8694, 5.9536, 5.6064, 5.7341, 5.7011,\n",
      "        5.6712, 5.7316, 5.6508, 5.6915, 5.9584, 5.8048, 5.7114, 5.6907, 5.6799,\n",
      "        5.7598, 5.6633, 5.7067, 5.7887, 5.6967, 5.7704, 5.7202, 5.5905, 5.6603,\n",
      "        5.6241, 5.6202, 5.6963, 5.6699, 5.7424, 5.5941, 5.7534, 5.7001, 5.5988,\n",
      "        5.7565, 5.8092, 6.0749, 5.6827, 5.7759, 5.6383, 5.7787, 5.6038, 5.7389,\n",
      "        5.6769, 5.6930, 5.6452, 5.8135, 5.6445, 5.6637, 5.7710, 5.6277, 5.7106,\n",
      "        5.7121, 5.7441, 5.7291, 5.7045, 5.6971, 5.7670, 5.9739, 5.6505, 5.6270,\n",
      "        5.6054, 5.7765, 5.7511, 5.6120, 5.7834, 5.7873, 5.7434, 5.6487, 5.7292,\n",
      "        5.7099, 5.8467, 5.7880, 5.6073, 5.6524, 5.6785, 5.7950, 5.7183, 5.6550,\n",
      "        5.7848, 5.7223, 5.6334, 5.6757, 5.7634, 5.7746, 5.7784, 5.7405, 5.6501,\n",
      "        5.6873, 5.9463, 5.6370, 5.6954, 5.5918, 5.9099, 5.6415, 5.5616, 5.7492,\n",
      "        5.6864, 5.6971, 5.7838, 5.7442, 5.6208, 5.6191, 5.8037, 5.9088, 5.7513,\n",
      "        5.9307, 5.7239, 5.7655, 5.7651, 5.6425, 5.7845, 5.7555, 5.6452, 5.6451,\n",
      "        5.7854, 5.6623, 5.8075], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.295877  [458924/5599865]\n",
      "average delta from current occupancy tensor([5.2657, 5.3976, 5.2213, 5.2330, 5.3909, 5.4357, 5.1825, 5.2761, 5.2389,\n",
      "        5.2137, 5.2727, 5.2066, 5.2255, 5.4367, 5.3571, 5.2495, 5.2247, 5.2158,\n",
      "        5.3057, 5.2113, 5.2435, 5.3381, 5.2338, 5.3190, 5.2605, 5.1654, 5.2096,\n",
      "        5.1985, 5.1963, 5.2316, 5.2126, 5.2850, 5.1693, 5.2974, 5.2388, 5.1741,\n",
      "        5.3019, 5.3609, 5.5541, 5.2168, 5.3254, 5.2024, 5.3280, 5.1799, 5.2815,\n",
      "        5.2155, 5.2293, 5.2055, 5.3640, 5.2056, 5.2111, 5.3199, 5.2000, 5.2507,\n",
      "        5.2506, 5.2876, 5.2714, 5.2440, 5.2339, 5.3138, 5.4581, 5.2069, 5.1995,\n",
      "        5.1816, 5.3246, 5.2963, 5.1893, 5.3313, 5.3360, 5.2870, 5.2058, 5.2706,\n",
      "        5.2469, 5.3806, 5.3378, 5.1832, 5.2074, 5.2155, 5.3448, 5.2572, 5.2080,\n",
      "        5.3339, 5.2610, 5.2018, 5.2151, 5.3111, 5.3242, 5.3281, 5.2846, 5.2064,\n",
      "        5.2233, 5.4299, 5.2027, 5.2327, 5.1672, 5.4106, 5.2041, 5.1384, 5.2933,\n",
      "        5.2220, 5.2344, 5.3330, 5.2867, 5.1975, 5.1961, 5.3563, 5.4094, 5.2953,\n",
      "        5.4200, 5.2651, 5.3138, 5.3122, 5.2038, 5.3339, 5.3028, 5.2050, 5.2053,\n",
      "        5.3350, 5.2112, 5.3612], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.471966  [471324/5599865]\n",
      "average delta from current occupancy tensor([4.4876, 4.5331, 4.5029, 4.4994, 4.5303, 4.5457, 4.5549, 4.4842, 4.4963,\n",
      "        4.5092, 4.4852, 4.5200, 4.5021, 4.5456, 4.5172, 4.4935, 4.5023, 4.5069,\n",
      "        4.4963, 4.5128, 4.4957, 4.5087, 4.4987, 4.5017, 4.4895, 4.5803, 4.5158,\n",
      "        4.5314, 4.5352, 4.5000, 4.5118, 4.4877, 4.5745, 4.4926, 4.4963, 4.5680,\n",
      "        4.4945, 4.5182, 4.5823, 4.5061, 4.5042, 4.5266, 4.5051, 4.5589, 4.4862,\n",
      "        4.5070, 4.5004, 4.5215, 4.5192, 4.5206, 4.5137, 4.5019, 4.5289, 4.4928,\n",
      "        4.4936, 4.4882, 4.4860, 4.4952, 4.4994, 4.4990, 4.5495, 4.5194, 4.5299,\n",
      "        4.5565, 4.5036, 4.4924, 4.5449, 4.5058, 4.5077, 4.4885, 4.5220, 4.4860,\n",
      "        4.4950, 4.5259, 4.5086, 4.5545, 4.5190, 4.5074, 4.5115, 4.4910, 4.5180,\n",
      "        4.5071, 4.4897, 4.5268, 4.5073, 4.4986, 4.5038, 4.5050, 4.4874, 4.5207,\n",
      "        4.5023, 4.5446, 4.5256, 4.4987, 4.5772, 4.5383, 4.5231, 4.6228, 4.4910,\n",
      "        4.5022, 4.4977, 4.5068, 4.4883, 4.5324, 4.5341, 4.5166, 4.5376, 4.4918,\n",
      "        4.5415, 4.4879, 4.4997, 4.4986, 4.5244, 4.5071, 4.4952, 4.5224, 4.5219,\n",
      "        4.5073, 4.5125, 4.5185], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.280446  [483724/5599865]\n",
      "average delta from current occupancy tensor([5.2643, 5.3201, 5.2621, 5.2625, 5.3150, 5.3406, 5.2544, 5.2646, 5.2630,\n",
      "        5.2611, 5.2645, 5.2596, 5.2622, 5.3405, 5.2945, 5.2635, 5.2622, 5.2615,\n",
      "        5.2658, 5.2607, 5.2631, 5.2796, 5.2627, 5.2685, 5.2641, 5.2508, 5.2601,\n",
      "        5.2579, 5.2573, 5.2624, 5.2607, 5.2650, 5.2516, 5.2656, 5.2630, 5.2524,\n",
      "        5.2658, 5.2956, 5.3734, 5.2615, 5.2727, 5.2585, 5.2741, 5.2538, 5.2648,\n",
      "        5.2614, 5.2623, 5.2593, 5.2967, 5.2594, 5.2604, 5.2688, 5.2582, 5.2635,\n",
      "        5.2633, 5.2650, 5.2644, 5.2631, 5.2625, 5.2660, 5.3470, 5.2595, 5.2580,\n",
      "        5.2541, 5.2711, 5.2655, 5.2558, 5.2744, 5.2778, 5.2651, 5.2591, 5.2644,\n",
      "        5.2631, 5.3079, 5.2790, 5.2544, 5.2596, 5.2613, 5.2834, 5.2637, 5.2597,\n",
      "        5.2766, 5.2639, 5.2585, 5.2614, 5.2659, 5.2716, 5.2733, 5.2649, 5.2594,\n",
      "        5.2621, 5.3377, 5.2587, 5.2626, 5.2512, 5.3277, 5.2591, 5.2717, 5.2654,\n",
      "        5.2621, 5.2628, 5.2761, 5.2651, 5.2578, 5.2576, 5.2921, 5.3268, 5.2654,\n",
      "        5.3332, 5.2642, 5.2660, 5.2659, 5.2588, 5.2768, 5.2657, 5.2592, 5.2592,\n",
      "        5.2773, 5.2606, 5.2961], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.840221  [496124/5599865]\n",
      "average delta from current occupancy tensor([5.9588, 6.0092, 5.9475, 5.9495, 6.0025, 6.0355, 5.9082, 5.9604, 5.9525,\n",
      "        5.9427, 5.9597, 5.9344, 5.9478, 6.0348, 5.9767, 5.9546, 5.9478, 5.9442,\n",
      "        5.9666, 5.9402, 5.9523, 5.9703, 5.9506, 5.9675, 5.9574, 5.8941, 5.9368,\n",
      "        5.9257, 5.9226, 5.9488, 5.9399, 5.9618, 5.8945, 5.9646, 5.9521, 5.8972,\n",
      "        5.9656, 5.9768, 6.0768, 5.9437, 5.9685, 5.9281, 5.9689, 5.9046, 5.9610,\n",
      "        5.9438, 5.9486, 5.9333, 5.9783, 5.9340, 5.9384, 5.9676, 5.9277, 5.9547,\n",
      "        5.9534, 5.9620, 5.9587, 5.9526, 5.9489, 5.9668, 6.0435, 5.9339, 5.9266,\n",
      "        5.9065, 5.9680, 5.9646, 5.9154, 5.9691, 5.9700, 5.9625, 5.9317, 5.9590,\n",
      "        5.9521, 5.9931, 5.9705, 5.9080, 5.9346, 5.9435, 5.9715, 5.9555, 5.9353,\n",
      "        5.9699, 5.9560, 5.9288, 5.9437, 5.9665, 5.9686, 5.9692, 5.9618, 5.9330,\n",
      "        5.9471, 6.0309, 5.9297, 5.9503, 5.8943, 6.0185, 5.9319, 5.8870, 5.9641,\n",
      "        5.9477, 5.9512, 5.9696, 5.9627, 5.9253, 5.9243, 5.9749, 6.0175, 5.9639,\n",
      "        6.0259, 5.9579, 5.9667, 5.9661, 5.9302, 5.9697, 5.9657, 5.9320, 5.9323,\n",
      "        5.9699, 5.9396, 5.9786], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.591735  [508524/5599865]\n",
      "average delta from current occupancy tensor([5.6054, 5.6305, 5.5964, 5.5980, 5.6227, 5.6591, 5.5647, 5.6068, 5.6003,\n",
      "        5.5924, 5.6063, 5.5858, 5.5966, 5.6576, 5.6186, 5.6022, 5.5966, 5.5938,\n",
      "        5.6119, 5.5907, 5.6004, 5.6149, 5.5990, 5.6126, 5.6044, 5.5568, 5.5876,\n",
      "        5.5787, 5.5761, 5.5972, 5.5902, 5.6079, 5.5568, 5.6102, 5.6002, 5.5567,\n",
      "        5.6109, 5.6184, 5.7049, 5.5933, 5.6132, 5.5808, 5.6137, 5.5618, 5.6073,\n",
      "        5.5935, 5.5972, 5.5850, 5.6185, 5.5853, 5.5887, 5.6123, 5.5801, 5.6018,\n",
      "        5.6009, 5.6079, 5.6052, 5.6003, 5.5973, 5.6119, 5.6671, 5.5852, 5.5793,\n",
      "        5.5630, 5.6127, 5.6099, 5.5703, 5.6136, 5.6142, 5.6082, 5.5835, 5.6055,\n",
      "        5.5998, 5.6192, 5.6149, 5.5644, 5.5859, 5.5931, 5.6157, 5.6026, 5.5864,\n",
      "        5.6142, 5.6030, 5.5812, 5.5931, 5.6114, 5.6131, 5.6137, 5.6078, 5.5845,\n",
      "        5.5959, 5.6540, 5.5817, 5.5984, 5.5568, 5.6409, 5.5837, 5.5595, 5.6097,\n",
      "        5.5965, 5.5992, 5.6141, 5.6085, 5.5783, 5.5775, 5.6182, 5.6393, 5.6097,\n",
      "        5.6488, 5.6048, 5.6121, 5.6116, 5.5826, 5.6145, 5.6113, 5.5841, 5.5845,\n",
      "        5.6148, 5.5904, 5.6188], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.316905  [520924/5599865]\n",
      "average delta from current occupancy tensor([5.2847, 5.2890, 5.2824, 5.2828, 5.2886, 5.2902, 5.2744, 5.2851, 5.2835,\n",
      "        5.2815, 5.2850, 5.2798, 5.2825, 5.2900, 5.2881, 5.2839, 5.2825, 5.2817,\n",
      "        5.2864, 5.2810, 5.2834, 5.2871, 5.2831, 5.2866, 5.2845, 5.2766, 5.2801,\n",
      "        5.2780, 5.2773, 5.2826, 5.2808, 5.2853, 5.2766, 5.2859, 5.2834, 5.2765,\n",
      "        5.2861, 5.2880, 5.3349, 5.2816, 5.2866, 5.2784, 5.2868, 5.2769, 5.2852,\n",
      "        5.2817, 5.2827, 5.2796, 5.2880, 5.2796, 5.2805, 5.2865, 5.2783, 5.2838,\n",
      "        5.2836, 5.2854, 5.2847, 5.2835, 5.2827, 5.2864, 5.2974, 5.2796, 5.2781,\n",
      "        5.2755, 5.2866, 5.2860, 5.2759, 5.2869, 5.2870, 5.2856, 5.2792, 5.2849,\n",
      "        5.2834, 5.2883, 5.2872, 5.2743, 5.2798, 5.2816, 5.2874, 5.2841, 5.2800,\n",
      "        5.2871, 5.2842, 5.2787, 5.2818, 5.2864, 5.2869, 5.2870, 5.2855, 5.2795,\n",
      "        5.2825, 5.2899, 5.2788, 5.2831, 5.2764, 5.2895, 5.2793, 5.2854, 5.2860,\n",
      "        5.2827, 5.2833, 5.2871, 5.2857, 5.2780, 5.2778, 5.2881, 5.2894, 5.2859,\n",
      "        5.2896, 5.2847, 5.2866, 5.2865, 5.2791, 5.2872, 5.2864, 5.2795, 5.2796,\n",
      "        5.2873, 5.2811, 5.2883], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.554033  [533324/5599865]\n",
      "average delta from current occupancy tensor([4.6440, 4.6612, 4.6347, 4.6363, 4.6596, 4.6655, 4.6054, 4.6457, 4.6389,\n",
      "        4.6309, 4.6449, 4.6240, 4.6350, 4.6650, 4.6575, 4.6407, 4.6349, 4.6320,\n",
      "        4.6508, 4.6289, 4.6386, 4.6535, 4.6372, 4.6512, 4.6428, 4.6048, 4.6252,\n",
      "        4.6165, 4.6138, 4.6353, 4.6281, 4.6463, 4.6049, 4.6487, 4.6387, 4.6048,\n",
      "        4.6496, 4.6574, 4.6782, 4.6310, 4.6515, 4.6182, 4.6523, 4.6048, 4.6457,\n",
      "        4.6316, 4.6355, 4.6230, 4.6569, 4.6231, 4.6264, 4.6510, 4.6180, 4.6402,\n",
      "        4.6391, 4.6463, 4.6437, 4.6388, 4.6356, 4.6507, 4.6671, 4.6235, 4.6176,\n",
      "        4.6051, 4.6518, 4.6491, 4.6086, 4.6526, 4.6533, 4.6476, 4.6216, 4.6446,\n",
      "        4.6387, 4.6586, 4.6542, 4.6054, 4.6244, 4.6319, 4.6551, 4.6419, 4.6253,\n",
      "        4.6538, 4.6423, 4.6202, 4.6326, 4.6514, 4.6530, 4.6535, 4.6475, 4.6235,\n",
      "        4.6352, 4.6651, 4.6206, 4.6378, 4.6052, 4.6635, 4.6227, 4.6048, 4.6495,\n",
      "        4.6362, 4.6387, 4.6540, 4.6481, 4.6172, 4.6164, 4.6580, 4.6631, 4.6493,\n",
      "        4.6640, 4.6445, 4.6521, 4.6514, 4.6216, 4.6546, 4.6516, 4.6236, 4.6243,\n",
      "        4.6549, 4.6302, 4.6594], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.416424  [545724/5599865]\n",
      "average delta from current occupancy tensor([5.2783, 5.2912, 5.2712, 5.2725, 5.2899, 5.2944, 5.2504, 5.2794, 5.2742,\n",
      "        5.2681, 5.2787, 5.2629, 5.2713, 5.2939, 5.2882, 5.2755, 5.2712, 5.2689,\n",
      "        5.2829, 5.2665, 5.2738, 5.2851, 5.2730, 5.2836, 5.2772, 5.2505, 5.2638,\n",
      "        5.2572, 5.2551, 5.2714, 5.2659, 5.2797, 5.2505, 5.2815, 5.2740, 5.2505,\n",
      "        5.2822, 5.2880, 5.2971, 5.2682, 5.2836, 5.2585, 5.2842, 5.2505, 5.2792,\n",
      "        5.2686, 5.2715, 5.2621, 5.2875, 5.2620, 5.2645, 5.2830, 5.2583, 5.2751,\n",
      "        5.2742, 5.2796, 5.2776, 5.2740, 5.2716, 5.2829, 5.2954, 5.2625, 5.2581,\n",
      "        5.2505, 5.2838, 5.2818, 5.2512, 5.2843, 5.2848, 5.2806, 5.2610, 5.2783,\n",
      "        5.2739, 5.2889, 5.2856, 5.2506, 5.2632, 5.2689, 5.2864, 5.2765, 5.2639,\n",
      "        5.2854, 5.2767, 5.2601, 5.2694, 5.2835, 5.2847, 5.2851, 5.2805, 5.2624,\n",
      "        5.2712, 5.2938, 5.2602, 5.2732, 5.2505, 5.2927, 5.2620, 5.2505, 5.2822,\n",
      "        5.2722, 5.2740, 5.2856, 5.2811, 5.2578, 5.2573, 5.2886, 5.2924, 5.2820,\n",
      "        5.2932, 5.2786, 5.2844, 5.2837, 5.2612, 5.2862, 5.2840, 5.2628, 5.2634,\n",
      "        5.2864, 5.2679, 5.2899], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.280321  [558124/5599865]\n",
      "average delta from current occupancy tensor([5.0155, 5.0111, 5.0178, 5.0174, 5.0116, 5.0101, 5.0249, 5.0151, 5.0168,\n",
      "        5.0188, 5.0153, 5.0206, 5.0178, 5.0102, 5.0121, 5.0164, 5.0178, 5.0186,\n",
      "        5.0139, 5.0194, 5.0170, 5.0132, 5.0172, 5.0137, 5.0158, 5.0253, 5.0203,\n",
      "        5.0225, 5.0232, 5.0178, 5.0196, 5.0150, 5.0252, 5.0144, 5.0169, 5.0253,\n",
      "        5.0142, 5.0122, 5.0091, 5.0188, 5.0136, 5.0221, 5.0135, 5.0253, 5.0152,\n",
      "        5.0187, 5.0178, 5.0209, 5.0124, 5.0210, 5.0202, 5.0140, 5.0223, 5.0166,\n",
      "        5.0169, 5.0150, 5.0157, 5.0169, 5.0177, 5.0139, 5.0097, 5.0208, 5.0222,\n",
      "        5.0254, 5.0136, 5.0143, 5.0254, 5.0135, 5.0133, 5.0147, 5.0213, 5.0154,\n",
      "        5.0169, 5.0119, 5.0130, 5.0255, 5.0205, 5.0186, 5.0127, 5.0161, 5.0203,\n",
      "        5.0131, 5.0160, 5.0216, 5.0185, 5.0138, 5.0134, 5.0132, 5.0148, 5.0209,\n",
      "        5.0180, 5.0104, 5.0216, 5.0172, 5.0256, 5.0107, 5.0210, 5.0256, 5.0142,\n",
      "        5.0175, 5.0169, 5.0131, 5.0146, 5.0224, 5.0226, 5.0121, 5.0108, 5.0143,\n",
      "        5.0106, 5.0155, 5.0135, 5.0137, 5.0213, 5.0130, 5.0137, 5.0208, 5.0206,\n",
      "        5.0128, 5.0191, 5.0117], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.471617  [570524/5599865]\n",
      "average delta from current occupancy tensor([5.6208, 5.6032, 5.6302, 5.6287, 5.6049, 5.5987, 5.6524, 5.6189, 5.6260,\n",
      "        5.6341, 5.6201, 5.6413, 5.6300, 5.5996, 5.6072, 5.6243, 5.6301, 5.6333,\n",
      "        5.6143, 5.6365, 5.6268, 5.6114, 5.6277, 5.6134, 5.6222, 5.6526, 5.6404,\n",
      "        5.6490, 5.6520, 5.6300, 5.6375, 5.6189, 5.6526, 5.6165, 5.6267, 5.6526,\n",
      "        5.6157, 5.6077, 5.5953, 5.6345, 5.6138, 5.6481, 5.6134, 5.6527, 5.6201,\n",
      "        5.6344, 5.6304, 5.6432, 5.6092, 5.6435, 5.6403, 5.6152, 5.6486, 5.6259,\n",
      "        5.6272, 5.6196, 5.6222, 5.6270, 5.6303, 5.6150, 5.5981, 5.6429, 5.6486,\n",
      "        5.6528, 5.6139, 5.6165, 5.6530, 5.6132, 5.6125, 5.6179, 5.6445, 5.6209,\n",
      "        5.6271, 5.6067, 5.6111, 5.6529, 5.6416, 5.6339, 5.6103, 5.6240, 5.6410,\n",
      "        5.6120, 5.6237, 5.6461, 5.6336, 5.6142, 5.6128, 5.6120, 5.6183, 5.6428,\n",
      "        5.6308, 5.6003, 5.6456, 5.6279, 5.6528, 5.6017, 5.6433, 5.6529, 5.6160,\n",
      "        5.6293, 5.6269, 5.6113, 5.6175, 5.6490, 5.6498, 5.6074, 5.6022, 5.6163,\n",
      "        5.6013, 5.6207, 5.6127, 5.6137, 5.6443, 5.6106, 5.6133, 5.6421, 5.6412,\n",
      "        5.6103, 5.6353, 5.6054], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.688194  [582924/5599865]\n",
      "average delta from current occupancy tensor([4.9289, 4.9245, 4.9313, 4.9309, 4.9249, 4.9233, 4.9361, 4.9285, 4.9303,\n",
      "        4.9323, 4.9287, 4.9341, 4.9313, 4.9235, 4.9254, 4.9298, 4.9313, 4.9321,\n",
      "        4.9272, 4.9329, 4.9305, 4.9266, 4.9307, 4.9270, 4.9292, 4.9360, 4.9339,\n",
      "        4.9362, 4.9359, 4.9312, 4.9332, 4.9284, 4.9360, 4.9279, 4.9304, 4.9362,\n",
      "        4.9277, 4.9257, 4.9225, 4.9325, 4.9272, 4.9363, 4.9271, 4.9361, 4.9288,\n",
      "        4.9324, 4.9314, 4.9346, 4.9260, 4.9347, 4.9339, 4.9275, 4.9363, 4.9303,\n",
      "        4.9306, 4.9287, 4.9293, 4.9305, 4.9314, 4.9275, 4.9232, 4.9346, 4.9364,\n",
      "        4.9361, 4.9272, 4.9279, 4.9360, 4.9271, 4.9269, 4.9282, 4.9350, 4.9290,\n",
      "        4.9306, 4.9254, 4.9265, 4.9359, 4.9342, 4.9323, 4.9263, 4.9297, 4.9341,\n",
      "        4.9267, 4.9297, 4.9354, 4.9322, 4.9273, 4.9269, 4.9267, 4.9283, 4.9345,\n",
      "        4.9315, 4.9238, 4.9352, 4.9307, 4.9359, 4.9241, 4.9346, 4.9357, 4.9277,\n",
      "        4.9311, 4.9305, 4.9266, 4.9282, 4.9360, 4.9360, 4.9256, 4.9242, 4.9278,\n",
      "        4.9240, 4.9289, 4.9269, 4.9272, 4.9349, 4.9264, 4.9270, 4.9343, 4.9341,\n",
      "        4.9263, 4.9326, 4.9250], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.549611  [595324/5599865]\n",
      "average delta from current occupancy tensor([4.1905, 4.1414, 4.2171, 4.2126, 4.1462, 4.1287, 4.2567, 4.1858, 4.2050,\n",
      "        4.2276, 4.1883, 4.2473, 4.2159, 4.1305, 4.1512, 4.1993, 4.2162, 4.2246,\n",
      "        4.1716, 4.2339, 4.2071, 4.1641, 4.2090, 4.1687, 4.1936, 4.2568, 4.2453,\n",
      "        4.2568, 4.2567, 4.2161, 4.2379, 4.1854, 4.2567, 4.1791, 4.2067, 4.2567,\n",
      "        4.1772, 4.1550, 4.1202, 4.2301, 4.1717, 4.2569, 4.1707, 4.2566, 4.1880,\n",
      "        4.2277, 4.2168, 4.2525, 4.1577, 4.2529, 4.2451, 4.1741, 4.2568, 4.2037,\n",
      "        4.2080, 4.1870, 4.1937, 4.2071, 4.2158, 4.1729, 4.1252, 4.2514, 4.2574,\n",
      "        4.2574, 4.1704, 4.1769, 4.2577, 4.1689, 4.1669, 4.1809, 4.2563, 4.1898,\n",
      "        4.2076, 4.1500, 4.1627, 4.2574, 4.2474, 4.2258, 4.1601, 4.1981, 4.2460,\n",
      "        4.1645, 4.1979, 4.2565, 4.2253, 4.1703, 4.1665, 4.1641, 4.1816, 4.2503,\n",
      "        4.2169, 4.1321, 4.2573, 4.2090, 4.2570, 4.1352, 4.2514, 4.2569, 4.1756,\n",
      "        4.2127, 4.2062, 4.1629, 4.1809, 4.2568, 4.2571, 4.1513, 4.1366, 4.1760,\n",
      "        4.1342, 4.1887, 4.1660, 4.1693, 4.2548, 4.1604, 4.1674, 4.2482, 4.2465,\n",
      "        4.1605, 4.2303, 4.1463], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.700986  [607724/5599865]\n",
      "average delta from current occupancy tensor([5.7858, 5.7947, 5.7809, 5.7816, 5.7938, 5.7970, 5.7743, 5.7866, 5.7831,\n",
      "        5.7790, 5.7861, 5.7754, 5.7811, 5.7967, 5.7930, 5.7842, 5.7810, 5.7794,\n",
      "        5.7891, 5.7777, 5.7826, 5.7905, 5.7823, 5.7897, 5.7851, 5.7743, 5.7757,\n",
      "        5.7743, 5.7743, 5.7810, 5.7770, 5.7865, 5.7743, 5.7877, 5.7827, 5.7743,\n",
      "        5.7879, 5.7920, 5.7983, 5.7783, 5.7890, 5.7743, 5.7891, 5.7743, 5.7860,\n",
      "        5.7788, 5.7808, 5.7743, 5.7915, 5.7742, 5.7756, 5.7885, 5.7743, 5.7831,\n",
      "        5.7823, 5.7862, 5.7850, 5.7825, 5.7809, 5.7887, 5.7975, 5.7745, 5.7743,\n",
      "        5.7742, 5.7893, 5.7881, 5.7743, 5.7896, 5.7900, 5.7875, 5.7742, 5.7859,\n",
      "        5.7825, 5.7931, 5.7908, 5.7742, 5.7753, 5.7793, 5.7913, 5.7843, 5.7755,\n",
      "        5.7904, 5.7843, 5.7742, 5.7793, 5.7893, 5.7900, 5.7904, 5.7872, 5.7746,\n",
      "        5.7808, 5.7962, 5.7743, 5.7821, 5.7743, 5.7956, 5.7744, 5.7743, 5.7883,\n",
      "        5.7815, 5.7827, 5.7906, 5.7874, 5.7743, 5.7742, 5.7928, 5.7955, 5.7883,\n",
      "        5.7960, 5.7861, 5.7903, 5.7896, 5.7742, 5.7912, 5.7900, 5.7752, 5.7755,\n",
      "        5.7912, 5.7785, 5.7939], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.613720  [620124/5599865]\n",
      "average delta from current occupancy tensor([4.6209, 4.6072, 4.6281, 4.6270, 4.6086, 4.6039, 4.6370, 4.6195, 4.6247,\n",
      "        4.6310, 4.6202, 4.6365, 4.6278, 4.6044, 4.6099, 4.6233, 4.6280, 4.6304,\n",
      "        4.6158, 4.6330, 4.6256, 4.6138, 4.6261, 4.6149, 4.6218, 4.6369, 4.6358,\n",
      "        4.6371, 4.6371, 4.6279, 4.6340, 4.6196, 4.6370, 4.6180, 4.6254, 4.6374,\n",
      "        4.6175, 4.6114, 4.6018, 4.6320, 4.6158, 4.6371, 4.6158, 4.6370, 4.6204,\n",
      "        4.6312, 4.6282, 4.6371, 4.6121, 4.6371, 4.6360, 4.6166, 4.6370, 4.6247,\n",
      "        4.6259, 4.6201, 4.6219, 4.6257, 4.6281, 4.6164, 4.6030, 4.6369, 4.6370,\n",
      "        4.6371, 4.6155, 4.6173, 4.6372, 4.6151, 4.6145, 4.6182, 4.6370, 4.6207,\n",
      "        4.6257, 4.6098, 4.6133, 4.6368, 4.6365, 4.6306, 4.6125, 4.6231, 4.6362,\n",
      "        4.6138, 4.6230, 4.6370, 4.6305, 4.6155, 4.6145, 4.6138, 4.6187, 4.6370,\n",
      "        4.6283, 4.6052, 4.6370, 4.6264, 4.6369, 4.6061, 4.6371, 4.6369, 4.6171,\n",
      "        4.6273, 4.6254, 4.6135, 4.6184, 4.6369, 4.6369, 4.6102, 4.6063, 4.6170,\n",
      "        4.6054, 4.6202, 4.6139, 4.6149, 4.6370, 4.6126, 4.6145, 4.6367, 4.6364,\n",
      "        4.6127, 4.6318, 4.6086], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.939204  [632524/5599865]\n",
      "average delta from current occupancy tensor([4.7664, 4.7259, 4.7886, 4.7851, 4.7299, 4.7155, 4.8139, 4.7626, 4.7783,\n",
      "        4.7969, 4.7649, 4.8136, 4.7873, 4.7169, 4.7336, 4.7734, 4.7876, 4.7946,\n",
      "        4.7510, 4.8026, 4.7804, 4.7450, 4.7821, 4.7486, 4.7691, 4.8135, 4.8119,\n",
      "        4.8139, 4.8140, 4.7883, 4.8065, 4.7634, 4.8143, 4.7587, 4.7807, 4.8144,\n",
      "        4.7572, 4.7390, 4.7101, 4.8005, 4.7522, 4.8141, 4.7518, 4.8144, 4.7661,\n",
      "        4.7983, 4.7894, 4.8142, 4.7409, 4.8141, 4.8125, 4.7543, 4.8142, 4.7787,\n",
      "        4.7826, 4.7654, 4.7710, 4.7821, 4.7893, 4.7543, 4.7140, 4.8145, 4.8145,\n",
      "        4.8146, 4.7509, 4.7563, 4.8144, 4.7498, 4.7479, 4.7590, 4.8142, 4.7665,\n",
      "        4.7818, 4.7341, 4.7445, 4.8144, 4.8142, 4.7965, 4.7425, 4.7744, 4.8138,\n",
      "        4.7465, 4.7741, 4.8145, 4.7967, 4.7514, 4.7485, 4.7465, 4.7613, 4.8145,\n",
      "        4.7903, 4.7210, 4.8145, 4.7847, 4.8144, 4.7238, 4.8145, 4.8145, 4.7564,\n",
      "        4.7871, 4.7816, 4.7457, 4.7601, 4.8144, 4.8145, 4.7362, 4.7244, 4.7565,\n",
      "        4.7217, 4.7663, 4.7472, 4.7507, 4.8145, 4.7436, 4.7496, 4.8143, 4.8143,\n",
      "        4.7443, 4.8018, 4.7320], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.578345  [644924/5599865]\n",
      "average delta from current occupancy tensor([5.1707, 5.1797, 5.1657, 5.1664, 5.1788, 5.1820, 5.1615, 5.1715, 5.1680,\n",
      "        5.1639, 5.1711, 5.1615, 5.1660, 5.1817, 5.1780, 5.1690, 5.1658, 5.1642,\n",
      "        5.1740, 5.1625, 5.1674, 5.1753, 5.1670, 5.1745, 5.1699, 5.1615, 5.1615,\n",
      "        5.1615, 5.1615, 5.1657, 5.1616, 5.1712, 5.1616, 5.1722, 5.1674, 5.1615,\n",
      "        5.1727, 5.1767, 5.1831, 5.1630, 5.1738, 5.1616, 5.1739, 5.1616, 5.1707,\n",
      "        5.1635, 5.1655, 5.1616, 5.1763, 5.1616, 5.1616, 5.1733, 5.1616, 5.1678,\n",
      "        5.1669, 5.1707, 5.1694, 5.1669, 5.1654, 5.1732, 5.1822, 5.1616, 5.1616,\n",
      "        5.1616, 5.1739, 5.1727, 5.1615, 5.1741, 5.1746, 5.1722, 5.1615, 5.1705,\n",
      "        5.1670, 5.1777, 5.1753, 5.1616, 5.1616, 5.1637, 5.1757, 5.1686, 5.1617,\n",
      "        5.1748, 5.1686, 5.1616, 5.1636, 5.1738, 5.1744, 5.1748, 5.1716, 5.1616,\n",
      "        5.1651, 5.1806, 5.1616, 5.1664, 5.1615, 5.1800, 5.1615, 5.1616, 5.1727,\n",
      "        5.1659, 5.1672, 5.1752, 5.1719, 5.1615, 5.1616, 5.1772, 5.1798, 5.1726,\n",
      "        5.1804, 5.1704, 5.1748, 5.1740, 5.1615, 5.1756, 5.1742, 5.1615, 5.1616,\n",
      "        5.1753, 5.1625, 5.1780], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.079884  [657324/5599865]\n",
      "average delta from current occupancy tensor([5.8258, 5.8840, 5.7923, 5.7978, 5.8776, 5.8986, 5.7711, 5.8303, 5.8073,\n",
      "        5.7807, 5.8274, 5.7711, 5.7940, 5.8961, 5.8721, 5.8139, 5.7923, 5.7821,\n",
      "        5.8454, 5.7709, 5.8031, 5.8540, 5.8003, 5.8485, 5.8187, 5.7708, 5.7709,\n",
      "        5.7708, 5.7710, 5.7918, 5.7712, 5.8282, 5.7713, 5.8347, 5.8035, 5.7714,\n",
      "        5.8375, 5.8641, 5.9058, 5.7747, 5.8455, 5.7714, 5.8456, 5.7712, 5.8248,\n",
      "        5.7778, 5.7908, 5.7719, 5.8617, 5.7713, 5.7715, 5.8419, 5.7711, 5.8057,\n",
      "        5.7995, 5.8245, 5.8161, 5.8001, 5.7902, 5.8407, 5.8996, 5.7714, 5.7714,\n",
      "        5.7714, 5.8454, 5.8374, 5.7714, 5.8463, 5.8490, 5.8341, 5.7713, 5.8224,\n",
      "        5.7997, 5.8692, 5.8533, 5.7705, 5.7708, 5.7785, 5.8565, 5.8107, 5.7710,\n",
      "        5.8508, 5.8111, 5.7715, 5.7790, 5.8445, 5.8486, 5.8513, 5.8294, 5.7716,\n",
      "        5.7874, 5.8878, 5.7718, 5.7957, 5.7713, 5.8848, 5.7716, 5.7713, 5.8376,\n",
      "        5.7929, 5.8014, 5.8528, 5.8316, 5.7710, 5.7708, 5.8657, 5.8833, 5.8364,\n",
      "        5.8872, 5.8223, 5.8504, 5.8450, 5.7709, 5.8553, 5.8468, 5.7711, 5.7710,\n",
      "        5.8539, 5.7707, 5.8722], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.694507  [669724/5599865]\n",
      "average delta from current occupancy tensor([4.9598, 4.9194, 4.9833, 4.9798, 4.9241, 4.9094, 4.9928, 4.9571, 4.9731,\n",
      "        4.9914, 4.9589, 4.9929, 4.9826, 4.9114, 4.9278, 4.9684, 4.9834, 4.9901,\n",
      "        4.9459, 4.9926, 4.9760, 4.9404, 4.9773, 4.9438, 4.9648, 4.9928, 4.9929,\n",
      "        4.9928, 4.9928, 4.9836, 4.9928, 4.9586, 4.9931, 4.9541, 4.9757, 4.9930,\n",
      "        4.9521, 4.9333, 4.9043, 4.9930, 4.9463, 4.9929, 4.9464, 4.9927, 4.9606,\n",
      "        4.9927, 4.9845, 4.9925, 4.9350, 4.9925, 4.9924, 4.9483, 4.9924, 4.9735,\n",
      "        4.9782, 4.9610, 4.9669, 4.9780, 4.9848, 4.9495, 4.9078, 4.9927, 4.9926,\n",
      "        4.9925, 4.9456, 4.9511, 4.9926, 4.9453, 4.9434, 4.9534, 4.9927, 4.9617,\n",
      "        4.9777, 4.9293, 4.9405, 4.9928, 4.9927, 4.9924, 4.9383, 4.9700, 4.9929,\n",
      "        4.9421, 4.9700, 4.9927, 4.9919, 4.9461, 4.9434, 4.9415, 4.9565, 4.9929,\n",
      "        4.9857, 4.9156, 4.9925, 4.9799, 4.9926, 4.9178, 4.9926, 4.9923, 4.9503,\n",
      "        4.9816, 4.9757, 4.9405, 4.9555, 4.9926, 4.9927, 4.9316, 4.9193, 4.9523,\n",
      "        4.9168, 4.9623, 4.9425, 4.9463, 4.9928, 4.9393, 4.9450, 4.9926, 4.9927,\n",
      "        4.9404, 4.9925, 4.9270], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.652776  [682124/5599865]\n",
      "average delta from current occupancy tensor([4.3712, 4.3939, 4.3582, 4.3601, 4.3912, 4.3992, 4.3552, 4.3727, 4.3638,\n",
      "        4.3550, 4.3717, 4.3549, 4.3587, 4.3984, 4.3892, 4.3667, 4.3583, 4.3549,\n",
      "        4.3791, 4.3550, 4.3623, 4.3821, 4.3615, 4.3802, 4.3683, 4.3550, 4.3551,\n",
      "        4.3551, 4.3552, 4.3579, 4.3550, 4.3717, 4.3550, 4.3741, 4.3622, 4.3549,\n",
      "        4.3752, 4.3858, 4.4020, 4.3550, 4.3787, 4.3552, 4.3785, 4.3551, 4.3707,\n",
      "        4.3551, 4.3571, 4.3549, 4.3846, 4.3549, 4.3548, 4.3771, 4.3549, 4.3631,\n",
      "        4.3604, 4.3698, 4.3665, 4.3603, 4.3567, 4.3765, 4.3997, 4.3552, 4.3552,\n",
      "        4.3552, 4.3784, 4.3753, 4.3552, 4.3783, 4.3793, 4.3740, 4.3551, 4.3693,\n",
      "        4.3602, 4.3871, 4.3809, 4.3550, 4.3549, 4.3549, 4.3822, 4.3649, 4.3551,\n",
      "        4.3804, 4.3648, 4.3548, 4.3549, 4.3781, 4.3797, 4.3810, 4.3725, 4.3551,\n",
      "        4.3565, 4.3955, 4.3549, 4.3599, 4.3550, 4.3943, 4.3549, 4.3549, 4.3762,\n",
      "        4.3587, 4.3621, 4.3816, 4.3730, 4.3551, 4.3550, 4.3864, 4.3931, 4.3749,\n",
      "        4.3946, 4.3694, 4.3804, 4.3781, 4.3550, 4.3820, 4.3788, 4.3550, 4.3550,\n",
      "        4.3812, 4.3549, 4.3887], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.133462  [694524/5599865]\n",
      "average delta from current occupancy tensor([5.0596, 5.0965, 5.0413, 5.0417, 5.0917, 5.1048, 5.0414, 5.0621, 5.0481,\n",
      "        5.0413, 5.0606, 5.0413, 5.0416, 5.1036, 5.0890, 5.0524, 5.0413, 5.0414,\n",
      "        5.0723, 5.0414, 5.0453, 5.0772, 5.0440, 5.0740, 5.0550, 5.0411, 5.0411,\n",
      "        5.0412, 5.0410, 5.0409, 5.0412, 5.0597, 5.0412, 5.0638, 5.0449, 5.0411,\n",
      "        5.0654, 5.0828, 5.1088, 5.0412, 5.0715, 5.0413, 5.0713, 5.0412, 5.0586,\n",
      "        5.0414, 5.0413, 5.0414, 5.0810, 5.0415, 5.0413, 5.0690, 5.0412, 5.0461,\n",
      "        5.0418, 5.0567, 5.0516, 5.0416, 5.0413, 5.0674, 5.1047, 5.0412, 5.0413,\n",
      "        5.0411, 5.0702, 5.0651, 5.0411, 5.0698, 5.0713, 5.0631, 5.0409, 5.0559,\n",
      "        5.0412, 5.0842, 5.0742, 5.0409, 5.0410, 5.0409, 5.0762, 5.0486, 5.0410,\n",
      "        5.0737, 5.0486, 5.0410, 5.0409, 5.0700, 5.0725, 5.0746, 5.0609, 5.0408,\n",
      "        5.0408, 5.0983, 5.0409, 5.0412, 5.0408, 5.0966, 5.0410, 5.0409, 5.0674,\n",
      "        5.0415, 5.0447, 5.0761, 5.0624, 5.0411, 5.0410, 5.0837, 5.0944, 5.0651,\n",
      "        5.0964, 5.0560, 5.0739, 5.0705, 5.0409, 5.0768, 5.0718, 5.0410, 5.0410,\n",
      "        5.0753, 5.0407, 5.0874], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.882204  [706924/5599865]\n",
      "average delta from current occupancy tensor([4.9318, 4.9225, 4.9358, 4.9357, 4.9236, 4.9204, 4.9355, 4.9311, 4.9345,\n",
      "        4.9357, 4.9315, 4.9357, 4.9357, 4.9208, 4.9244, 4.9336, 4.9357, 4.9356,\n",
      "        4.9286, 4.9357, 4.9354, 4.9274, 4.9356, 4.9282, 4.9330, 4.9357, 4.9356,\n",
      "        4.9357, 4.9357, 4.9357, 4.9358, 4.9319, 4.9357, 4.9309, 4.9357, 4.9358,\n",
      "        4.9304, 4.9260, 4.9195, 4.9357, 4.9288, 4.9355, 4.9288, 4.9356, 4.9320,\n",
      "        4.9357, 4.9356, 4.9355, 4.9265, 4.9356, 4.9356, 4.9295, 4.9356, 4.9352,\n",
      "        4.9357, 4.9325, 4.9337, 4.9355, 4.9354, 4.9298, 4.9204, 4.9354, 4.9355,\n",
      "        4.9356, 4.9292, 4.9304, 4.9357, 4.9293, 4.9289, 4.9309, 4.9356, 4.9328,\n",
      "        4.9356, 4.9258, 4.9283, 4.9357, 4.9355, 4.9357, 4.9277, 4.9345, 4.9355,\n",
      "        4.9281, 4.9344, 4.9355, 4.9355, 4.9291, 4.9284, 4.9279, 4.9313, 4.9355,\n",
      "        4.9355, 4.9219, 4.9355, 4.9357, 4.9356, 4.9224, 4.9356, 4.9355, 4.9297,\n",
      "        4.9356, 4.9354, 4.9276, 4.9311, 4.9355, 4.9356, 4.9256, 4.9229, 4.9303,\n",
      "        4.9224, 4.9325, 4.9280, 4.9288, 4.9356, 4.9274, 4.9286, 4.9355, 4.9355,\n",
      "        4.9277, 4.9356, 4.9247], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.057993  [719324/5599865]\n",
      "average delta from current occupancy tensor([5.2627, 5.2767, 5.2589, 5.2589, 5.2748, 5.2796, 5.2588, 5.2636, 5.2585,\n",
      "        5.2589, 5.2631, 5.2590, 5.2589, 5.2791, 5.2737, 5.2598, 5.2589, 5.2589,\n",
      "        5.2675, 5.2589, 5.2589, 5.2693, 5.2588, 5.2680, 5.2609, 5.2588, 5.2588,\n",
      "        5.2588, 5.2588, 5.2588, 5.2588, 5.2623, 5.2587, 5.2638, 5.2588, 5.2588,\n",
      "        5.2646, 5.2712, 5.2810, 5.2588, 5.2670, 5.2589, 5.2670, 5.2588, 5.2622,\n",
      "        5.2589, 5.2588, 5.2588, 5.2706, 5.2588, 5.2589, 5.2659, 5.2589, 5.2589,\n",
      "        5.2589, 5.2615, 5.2595, 5.2588, 5.2589, 5.2655, 5.2797, 5.2589, 5.2588,\n",
      "        5.2588, 5.2666, 5.2646, 5.2588, 5.2661, 5.2668, 5.2638, 5.2588, 5.2612,\n",
      "        5.2588, 5.2716, 5.2678, 5.2588, 5.2587, 5.2588, 5.2687, 5.2585, 5.2588,\n",
      "        5.2681, 5.2586, 5.2588, 5.2588, 5.2666, 5.2675, 5.2683, 5.2631, 5.2588,\n",
      "        5.2587, 5.2774, 5.2588, 5.2587, 5.2588, 5.2767, 5.2588, 5.2588, 5.2656,\n",
      "        5.2589, 5.2589, 5.2688, 5.2635, 5.2588, 5.2588, 5.2716, 5.2758, 5.2647,\n",
      "        5.2766, 5.2614, 5.2682, 5.2672, 5.2589, 5.2692, 5.2674, 5.2590, 5.2589,\n",
      "        5.2687, 5.2590, 5.2733], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.484820  [731724/5599865]\n",
      "average delta from current occupancy tensor([4.4538, 4.4352, 4.4588, 4.4588, 4.4376, 4.4311, 4.4587, 4.4524, 4.4586,\n",
      "        4.4585, 4.4530, 4.4584, 4.4585, 4.4318, 4.4389, 4.4573, 4.4584, 4.4584,\n",
      "        4.4471, 4.4584, 4.4586, 4.4449, 4.4588, 4.4466, 4.4561, 4.4589, 4.4589,\n",
      "        4.4588, 4.4587, 4.4589, 4.4588, 4.4542, 4.4591, 4.4524, 4.4590, 4.4590,\n",
      "        4.4513, 4.4425, 4.4295, 4.4590, 4.4480, 4.4588, 4.4480, 4.4590, 4.4546,\n",
      "        4.4590, 4.4591, 4.4589, 4.4433, 4.4589, 4.4587, 4.4494, 4.4587, 4.4588,\n",
      "        4.4587, 4.4552, 4.4578, 4.4587, 4.4586, 4.4497, 4.4307, 4.4585, 4.4587,\n",
      "        4.4588, 4.4486, 4.4512, 4.4588, 4.4490, 4.4481, 4.4522, 4.4588, 4.4557,\n",
      "        4.4587, 4.4416, 4.4466, 4.4587, 4.4587, 4.4587, 4.4453, 4.4582, 4.4585,\n",
      "        4.4461, 4.4582, 4.4585, 4.4585, 4.4482, 4.4469, 4.4458, 4.4527, 4.4585,\n",
      "        4.4584, 4.4335, 4.4583, 4.4583, 4.4584, 4.4345, 4.4583, 4.4584, 4.4494,\n",
      "        4.4585, 4.4584, 4.4454, 4.4523, 4.4588, 4.4586, 4.4414, 4.4359, 4.4508,\n",
      "        4.4349, 4.4550, 4.4458, 4.4471, 4.4579, 4.4441, 4.4465, 4.4578, 4.4579,\n",
      "        4.4449, 4.4577, 4.4387], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.311743  [744124/5599865]\n",
      "average delta from current occupancy tensor([5.0117, 4.9979, 5.0151, 5.0152, 4.9998, 4.9948, 5.0151, 5.0109, 5.0151,\n",
      "        5.0151, 5.0113, 5.0152, 5.0150, 4.9955, 5.0009, 5.0146, 5.0152, 5.0153,\n",
      "        5.0070, 5.0152, 5.0151, 5.0055, 5.0151, 5.0068, 5.0140, 5.0151, 5.0151,\n",
      "        5.0152, 5.0151, 5.0150, 5.0152, 5.0124, 5.0150, 5.0109, 5.0150, 5.0152,\n",
      "        5.0101, 5.0034, 4.9937, 5.0151, 5.0075, 5.0151, 5.0076, 5.0152, 5.0125,\n",
      "        5.0153, 5.0152, 5.0153, 5.0040, 5.0153, 5.0153, 5.0085, 5.0150, 5.0152,\n",
      "        5.0152, 5.0130, 5.0149, 5.0152, 5.0152, 5.0088, 4.9944, 5.0152, 5.0151,\n",
      "        5.0150, 5.0077, 5.0098, 5.0151, 5.0081, 5.0075, 5.0105, 5.0152, 5.0133,\n",
      "        5.0151, 5.0026, 5.0064, 5.0151, 5.0151, 5.0150, 5.0054, 5.0151, 5.0151,\n",
      "        5.0061, 5.0152, 5.0151, 5.0152, 5.0075, 5.0066, 5.0057, 5.0108, 5.0153,\n",
      "        5.0153, 4.9965, 5.0153, 5.0153, 5.0153, 4.9974, 5.0153, 5.0152, 5.0086,\n",
      "        5.0152, 5.0152, 5.0057, 5.0108, 5.0151, 5.0151, 5.0026, 4.9986, 5.0096,\n",
      "        4.9977, 5.0127, 5.0058, 5.0067, 5.0148, 5.0045, 5.0064, 5.0147, 5.0149,\n",
      "        5.0051, 5.0148, 5.0005], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.052263  [756524/5599865]\n",
      "average delta from current occupancy tensor([5.2035, 5.1755, 5.2092, 5.2092, 5.1794, 5.1697, 5.2096, 5.2019, 5.2094,\n",
      "        5.2094, 5.2030, 5.2094, 5.2094, 5.1709, 5.1817, 5.2090, 5.2092, 5.2090,\n",
      "        5.1937, 5.2091, 5.2091, 5.1909, 5.2093, 5.1933, 5.2076, 5.2091, 5.2092,\n",
      "        5.2092, 5.2092, 5.2092, 5.2091, 5.2050, 5.2092, 5.2019, 5.2092, 5.2092,\n",
      "        5.2006, 5.1871, 5.1676, 5.2089, 5.1951, 5.2090, 5.1954, 5.2090, 5.2053,\n",
      "        5.2086, 5.2088, 5.2089, 5.1887, 5.2088, 5.2088, 5.1977, 5.2091, 5.2088,\n",
      "        5.2089, 5.2066, 5.2090, 5.2087, 5.2086, 5.1980, 5.1691, 5.2089, 5.2090,\n",
      "        5.2090, 5.1957, 5.1999, 5.2088, 5.1965, 5.1952, 5.2010, 5.2089, 5.2070,\n",
      "        5.2089, 5.1853, 5.1930, 5.2088, 5.2089, 5.2089, 5.1912, 5.2089, 5.2088,\n",
      "        5.1924, 5.2089, 5.2089, 5.2087, 5.1955, 5.1935, 5.1919, 5.2019, 5.2085,\n",
      "        5.2085, 5.1731, 5.2086, 5.2087, 5.2087, 5.1750, 5.2087, 5.2087, 5.1976,\n",
      "        5.2087, 5.2087, 5.1917, 5.2021, 5.2087, 5.2088, 5.1855, 5.1772, 5.1995,\n",
      "        5.1752, 5.2054, 5.1915, 5.1933, 5.2092, 5.1889, 5.1924, 5.2092, 5.2095,\n",
      "        5.1899, 5.2090, 5.1806], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.721179  [768924/5599865]\n",
      "average delta from current occupancy tensor([4.6645, 4.6831, 4.6614, 4.6613, 4.6806, 4.6871, 4.6615, 4.6657, 4.6615,\n",
      "        4.6614, 4.6647, 4.6614, 4.6615, 4.6862, 4.6789, 4.6614, 4.6613, 4.6614,\n",
      "        4.6709, 4.6614, 4.6614, 4.6727, 4.6613, 4.6711, 4.6615, 4.6614, 4.6614,\n",
      "        4.6614, 4.6614, 4.6614, 4.6613, 4.6633, 4.6613, 4.6653, 4.6613, 4.6614,\n",
      "        4.6660, 4.6750, 4.6880, 4.6614, 4.6696, 4.6613, 4.6693, 4.6614, 4.6629,\n",
      "        4.6616, 4.6615, 4.6614, 4.6740, 4.6614, 4.6614, 4.6678, 4.6613, 4.6613,\n",
      "        4.6613, 4.6620, 4.6614, 4.6614, 4.6613, 4.6677, 4.6872, 4.6614, 4.6613,\n",
      "        4.6614, 4.6694, 4.6665, 4.6613, 4.6685, 4.6694, 4.6657, 4.6613, 4.6617,\n",
      "        4.6614, 4.6763, 4.6712, 4.6613, 4.6614, 4.6614, 4.6723, 4.6613, 4.6614,\n",
      "        4.6717, 4.6614, 4.6613, 4.6613, 4.6694, 4.6707, 4.6720, 4.6653, 4.6614,\n",
      "        4.6613, 4.6845, 4.6615, 4.6614, 4.6613, 4.6830, 4.6613, 4.6614, 4.6681,\n",
      "        4.6613, 4.6613, 4.6722, 4.6653, 4.6613, 4.6613, 4.6762, 4.6817, 4.6669,\n",
      "        4.6831, 4.6629, 4.6722, 4.6710, 4.6613, 4.6739, 4.6716, 4.6613, 4.6613,\n",
      "        4.6734, 4.6613, 4.6795], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.253879  [781324/5599865]\n",
      "average delta from current occupancy tensor([5.3120, 5.2888, 5.3142, 5.3143, 5.2918, 5.2836, 5.3142, 5.3105, 5.3143,\n",
      "        5.3143, 5.3117, 5.3143, 5.3143, 5.2847, 5.2938, 5.3145, 5.3144, 5.3143,\n",
      "        5.3040, 5.3143, 5.3145, 5.3017, 5.3144, 5.3037, 5.3142, 5.3144, 5.3144,\n",
      "        5.3143, 5.3141, 5.3141, 5.3141, 5.3130, 5.3140, 5.3106, 5.3141, 5.3141,\n",
      "        5.3097, 5.2984, 5.2821, 5.3141, 5.3055, 5.3141, 5.3057, 5.3140, 5.3136,\n",
      "        5.3138, 5.3140, 5.3140, 5.2998, 5.3140, 5.3140, 5.3078, 5.3140, 5.3141,\n",
      "        5.3142, 5.3143, 5.3140, 5.3143, 5.3143, 5.3080, 5.2836, 5.3140, 5.3142,\n",
      "        5.3140, 5.3058, 5.3096, 5.3141, 5.3072, 5.3060, 5.3108, 5.3141, 5.3142,\n",
      "        5.3142, 5.2972, 5.3037, 5.3142, 5.3140, 5.3136, 5.3018, 5.3136, 5.3136,\n",
      "        5.3025, 5.3137, 5.3138, 5.3139, 5.3057, 5.3040, 5.3024, 5.3107, 5.3140,\n",
      "        5.3142, 5.2870, 5.3140, 5.3141, 5.3141, 5.2889, 5.3142, 5.3139, 5.3072,\n",
      "        5.3139, 5.3141, 5.3023, 5.3109, 5.3141, 5.3139, 5.2971, 5.2903, 5.3088,\n",
      "        5.2885, 5.3135, 5.3019, 5.3034, 5.3138, 5.2998, 5.3027, 5.3136, 5.3138,\n",
      "        5.3004, 5.3139, 5.2929], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.613847  [793724/5599865]\n",
      "average delta from current occupancy tensor([5.4552, 5.4923, 5.4524, 5.4528, 5.4878, 5.5009, 5.4527, 5.4584, 5.4527,\n",
      "        5.4531, 5.4561, 5.4527, 5.4526, 5.4993, 5.4847, 5.4530, 5.4527, 5.4521,\n",
      "        5.4687, 5.4523, 5.4523, 5.4722, 5.4524, 5.4688, 5.4525, 5.4531, 5.4532,\n",
      "        5.4530, 5.4523, 5.4522, 5.4525, 5.4540, 5.4524, 5.4578, 5.4524, 5.4527,\n",
      "        5.4595, 5.4777, 5.5038, 5.4525, 5.4663, 5.4525, 5.4658, 5.4526, 5.4531,\n",
      "        5.4528, 5.4526, 5.4530, 5.4749, 5.4527, 5.4526, 5.4623, 5.4526, 5.4531,\n",
      "        5.4533, 5.4537, 5.4531, 5.4535, 5.4534, 5.4627, 5.5014, 5.4530, 5.4531,\n",
      "        5.4535, 5.4666, 5.4605, 5.4531, 5.4640, 5.4659, 5.4582, 5.4539, 5.4541,\n",
      "        5.4540, 5.4797, 5.4695, 5.4531, 5.4529, 5.4534, 5.4723, 5.4534, 5.4534,\n",
      "        5.4713, 5.4536, 5.4534, 5.4532, 5.4663, 5.4691, 5.4719, 5.4586, 5.4533,\n",
      "        5.4533, 5.4967, 5.4534, 5.4530, 5.4531, 5.4935, 5.4535, 5.4531, 5.4640,\n",
      "        5.4531, 5.4530, 5.4718, 5.4585, 5.4531, 5.4534, 5.4802, 5.4911, 5.4616,\n",
      "        5.4939, 5.4538, 5.4727, 5.4702, 5.4536, 5.4761, 5.4713, 5.4539, 5.4537,\n",
      "        5.4752, 5.4534, 5.4871], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.487026  [806124/5599865]\n",
      "average delta from current occupancy tensor([4.4274, 4.4549, 4.4278, 4.4279, 4.4514, 4.4612, 4.4278, 4.4292, 4.4280,\n",
      "        4.4280, 4.4277, 4.4279, 4.4279, 4.4602, 4.4492, 4.4280, 4.4281, 4.4278,\n",
      "        4.4370, 4.4279, 4.4280, 4.4397, 4.4280, 4.4372, 4.4279, 4.4280, 4.4279,\n",
      "        4.4279, 4.4280, 4.4279, 4.4279, 4.4278, 4.4280, 4.4290, 4.4279, 4.4279,\n",
      "        4.4304, 4.4440, 4.4637, 4.4277, 4.4357, 4.4277, 4.4352, 4.4279, 4.4278,\n",
      "        4.4278, 4.4278, 4.4278, 4.4424, 4.4278, 4.4279, 4.4329, 4.4280, 4.4278,\n",
      "        4.4278, 4.4278, 4.4278, 4.4280, 4.4280, 4.4333, 4.4624, 4.4281, 4.4281,\n",
      "        4.4280, 4.4359, 4.4314, 4.4280, 4.4340, 4.4355, 4.4297, 4.4281, 4.4282,\n",
      "        4.4281, 4.4458, 4.4381, 4.4282, 4.4283, 4.4282, 4.4404, 4.4282, 4.4283,\n",
      "        4.4397, 4.4283, 4.4282, 4.4282, 4.4361, 4.4382, 4.4401, 4.4302, 4.4282,\n",
      "        4.4281, 4.4588, 4.4282, 4.4282, 4.4283, 4.4566, 4.4282, 4.4283, 4.4346,\n",
      "        4.4282, 4.4282, 4.4403, 4.4303, 4.4281, 4.4281, 4.4464, 4.4548, 4.4326,\n",
      "        4.4568, 4.4280, 4.4410, 4.4391, 4.4279, 4.4435, 4.4399, 4.4279, 4.4279,\n",
      "        4.4430, 4.4279, 4.4520], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.902171  [818524/5599865]\n",
      "average delta from current occupancy tensor([4.8306, 4.8233, 4.8306, 4.8306, 4.8246, 4.8213, 4.8307, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8307, 4.8306, 4.8217, 4.8254, 4.8306, 4.8306, 4.8306,\n",
      "        4.8294, 4.8306, 4.8306, 4.8284, 4.8306, 4.8292, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8268, 4.8202, 4.8306, 4.8296, 4.8306, 4.8297, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8274, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8305, 4.8206, 4.8306, 4.8306,\n",
      "        4.8306, 4.8296, 4.8306, 4.8306, 4.8302, 4.8296, 4.8306, 4.8306, 4.8305,\n",
      "        4.8305, 4.8260, 4.8286, 4.8306, 4.8306, 4.8305, 4.8278, 4.8306, 4.8306,\n",
      "        4.8280, 4.8306, 4.8306, 4.8306, 4.8293, 4.8287, 4.8280, 4.8306, 4.8306,\n",
      "        4.8306, 4.8218, 4.8306, 4.8305, 4.8306, 4.8225, 4.8306, 4.8306, 4.8300,\n",
      "        4.8305, 4.8306, 4.8281, 4.8305, 4.8305, 4.8305, 4.8260, 4.8232, 4.8306,\n",
      "        4.8226, 4.8305, 4.8279, 4.8285, 4.8305, 4.8270, 4.8281, 4.8305, 4.8305,\n",
      "        4.8270, 4.8306, 4.8240], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.554098  [830924/5599865]\n",
      "average delta from current occupancy tensor([5.4278, 5.4404, 5.4278, 5.4278, 5.4378, 5.4444, 5.4276, 5.4277, 5.4276,\n",
      "        5.4276, 5.4276, 5.4277, 5.4276, 5.4433, 5.4357, 5.4275, 5.4276, 5.4275,\n",
      "        5.4279, 5.4276, 5.4275, 5.4298, 5.4276, 5.4281, 5.4276, 5.4276, 5.4276,\n",
      "        5.4275, 5.4274, 5.4274, 5.4275, 5.4274, 5.4274, 5.4274, 5.4274, 5.4274,\n",
      "        5.4275, 5.4330, 5.4462, 5.4274, 5.4274, 5.4274, 5.4275, 5.4274, 5.4274,\n",
      "        5.4274, 5.4274, 5.4274, 5.4317, 5.4274, 5.4274, 5.4274, 5.4274, 5.4274,\n",
      "        5.4276, 5.4275, 5.4276, 5.4276, 5.4276, 5.4276, 5.4455, 5.4275, 5.4276,\n",
      "        5.4276, 5.4275, 5.4275, 5.4277, 5.4277, 5.4275, 5.4275, 5.4276, 5.4275,\n",
      "        5.4274, 5.4346, 5.4294, 5.4275, 5.4276, 5.4276, 5.4310, 5.4275, 5.4274,\n",
      "        5.4305, 5.4274, 5.4274, 5.4274, 5.4278, 5.4291, 5.4304, 5.4274, 5.4274,\n",
      "        5.4274, 5.4430, 5.4274, 5.4274, 5.4274, 5.4416, 5.4274, 5.4274, 5.4275,\n",
      "        5.4274, 5.4274, 5.4302, 5.4274, 5.4274, 5.4274, 5.4346, 5.4402, 5.4274,\n",
      "        5.4416, 5.4274, 5.4310, 5.4299, 5.4274, 5.4330, 5.4306, 5.4274, 5.4274,\n",
      "        5.4328, 5.4274, 5.4389], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.755554  [843324/5599865]\n",
      "average delta from current occupancy tensor([5.7420, 5.7541, 5.7419, 5.7420, 5.7514, 5.7580, 5.7420, 5.7421, 5.7420,\n",
      "        5.7420, 5.7420, 5.7421, 5.7421, 5.7564, 5.7489, 5.7420, 5.7420, 5.7420,\n",
      "        5.7420, 5.7420, 5.7420, 5.7431, 5.7421, 5.7421, 5.7421, 5.7423, 5.7423,\n",
      "        5.7422, 5.7422, 5.7422, 5.7421, 5.7422, 5.7420, 5.7419, 5.7421, 5.7419,\n",
      "        5.7421, 5.7464, 5.7596, 5.7419, 5.7420, 5.7421, 5.7421, 5.7420, 5.7419,\n",
      "        5.7421, 5.7420, 5.7420, 5.7451, 5.7421, 5.7421, 5.7421, 5.7420, 5.7420,\n",
      "        5.7422, 5.7421, 5.7420, 5.7420, 5.7420, 5.7419, 5.7589, 5.7420, 5.7421,\n",
      "        5.7421, 5.7420, 5.7420, 5.7419, 5.7420, 5.7420, 5.7420, 5.7421, 5.7420,\n",
      "        5.7421, 5.7482, 5.7430, 5.7423, 5.7421, 5.7421, 5.7445, 5.7421, 5.7420,\n",
      "        5.7442, 5.7421, 5.7421, 5.7419, 5.7420, 5.7426, 5.7438, 5.7420, 5.7421,\n",
      "        5.7421, 5.7560, 5.7421, 5.7421, 5.7421, 5.7548, 5.7420, 5.7420, 5.7421,\n",
      "        5.7420, 5.7421, 5.7432, 5.7421, 5.7420, 5.7420, 5.7476, 5.7533, 5.7421,\n",
      "        5.7548, 5.7421, 5.7441, 5.7429, 5.7421, 5.7459, 5.7436, 5.7421, 5.7421,\n",
      "        5.7459, 5.7421, 5.7521], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.892874  [855724/5599865]\n",
      "average delta from current occupancy tensor([5.1455, 5.1629, 5.1456, 5.1456, 5.1591, 5.1688, 5.1458, 5.1459, 5.1458,\n",
      "        5.1457, 5.1456, 5.1459, 5.1458, 5.1664, 5.1549, 5.1452, 5.1452, 5.1453,\n",
      "        5.1452, 5.1454, 5.1455, 5.1462, 5.1456, 5.1456, 5.1453, 5.1451, 5.1452,\n",
      "        5.1454, 5.1454, 5.1452, 5.1453, 5.1455, 5.1453, 5.1456, 5.1455, 5.1454,\n",
      "        5.1455, 5.1513, 5.1711, 5.1456, 5.1457, 5.1458, 5.1460, 5.1458, 5.1458,\n",
      "        5.1458, 5.1457, 5.1460, 5.1497, 5.1461, 5.1460, 5.1460, 5.1461, 5.1461,\n",
      "        5.1458, 5.1462, 5.1461, 5.1462, 5.1461, 5.1462, 5.1707, 5.1461, 5.1459,\n",
      "        5.1458, 5.1459, 5.1458, 5.1459, 5.1460, 5.1461, 5.1461, 5.1459, 5.1459,\n",
      "        5.1458, 5.1546, 5.1466, 5.1458, 5.1457, 5.1457, 5.1489, 5.1455, 5.1458,\n",
      "        5.1486, 5.1456, 5.1456, 5.1458, 5.1460, 5.1463, 5.1479, 5.1459, 5.1459,\n",
      "        5.1461, 5.1663, 5.1461, 5.1461, 5.1462, 5.1645, 5.1465, 5.1466, 5.1466,\n",
      "        5.1464, 5.1466, 5.1475, 5.1466, 5.1467, 5.1466, 5.1542, 5.1627, 5.1465,\n",
      "        5.1649, 5.1463, 5.1487, 5.1467, 5.1460, 5.1513, 5.1478, 5.1459, 5.1459,\n",
      "        5.1511, 5.1458, 5.1606], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.786432  [868124/5599865]\n",
      "average delta from current occupancy tensor([4.8393, 4.8620, 4.8391, 4.8391, 4.8555, 4.8722, 4.8392, 4.8392, 4.8393,\n",
      "        4.8394, 4.8391, 4.8395, 4.8394, 4.8678, 4.8486, 4.8397, 4.8395, 4.8394,\n",
      "        4.8397, 4.8395, 4.8395, 4.8393, 4.8395, 4.8393, 4.8394, 4.8394, 4.8395,\n",
      "        4.8395, 4.8394, 4.8394, 4.8394, 4.8392, 4.8393, 4.8393, 4.8393, 4.8391,\n",
      "        4.8393, 4.8431, 4.8763, 4.8394, 4.8392, 4.8393, 4.8390, 4.8392, 4.8391,\n",
      "        4.8391, 4.8391, 4.8392, 4.8411, 4.8394, 4.8393, 4.8392, 4.8395, 4.8393,\n",
      "        4.8393, 4.8392, 4.8394, 4.8393, 4.8394, 4.8394, 4.8765, 4.8394, 4.8392,\n",
      "        4.8394, 4.8392, 4.8394, 4.8391, 4.8394, 4.8394, 4.8393, 4.8394, 4.8392,\n",
      "        4.8393, 4.8492, 4.8392, 4.8389, 4.8391, 4.8392, 4.8395, 4.8390, 4.8389,\n",
      "        4.8391, 4.8388, 4.8387, 4.8387, 4.8387, 4.8387, 4.8388, 4.8387, 4.8387,\n",
      "        4.8387, 4.8676, 4.8387, 4.8387, 4.8389, 4.8649, 4.8388, 4.8391, 4.8392,\n",
      "        4.8392, 4.8391, 4.8393, 4.8391, 4.8391, 4.8392, 4.8489, 4.8631, 4.8392,\n",
      "        4.8665, 4.8392, 4.8398, 4.8393, 4.8394, 4.8443, 4.8387, 4.8389, 4.8393,\n",
      "        4.8440, 4.8389, 4.8595], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.199570  [880524/5599865]\n",
      "average delta from current occupancy tensor([5.2347, 5.2685, 5.2347, 5.2341, 5.2581, 5.2835, 5.2342, 5.2338, 5.2338,\n",
      "        5.2337, 5.2336, 5.2335, 5.2335, 5.2758, 5.2474, 5.2337, 5.2338, 5.2339,\n",
      "        5.2344, 5.2339, 5.2340, 5.2337, 5.2337, 5.2337, 5.2338, 5.2336, 5.2339,\n",
      "        5.2337, 5.2336, 5.2339, 5.2342, 5.2345, 5.2346, 5.2345, 5.2350, 5.2349,\n",
      "        5.2345, 5.2402, 5.2904, 5.2345, 5.2338, 5.2338, 5.2338, 5.2335, 5.2335,\n",
      "        5.2337, 5.2335, 5.2334, 5.2359, 5.2341, 5.2336, 5.2334, 5.2337, 5.2334,\n",
      "        5.2334, 5.2334, 5.2335, 5.2332, 5.2333, 5.2333, 5.2884, 5.2335, 5.2335,\n",
      "        5.2336, 5.2334, 5.2334, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2334,\n",
      "        5.2334, 5.2478, 5.2335, 5.2341, 5.2339, 5.2340, 5.2337, 5.2342, 5.2344,\n",
      "        5.2343, 5.2345, 5.2347, 5.2345, 5.2341, 5.2342, 5.2348, 5.2341, 5.2343,\n",
      "        5.2347, 5.2759, 5.2344, 5.2350, 5.2345, 5.2721, 5.2344, 5.2338, 5.2337,\n",
      "        5.2337, 5.2337, 5.2339, 5.2346, 5.2345, 5.2344, 5.2489, 5.2704, 5.2345,\n",
      "        5.2750, 5.2342, 5.2348, 5.2341, 5.2340, 5.2407, 5.2345, 5.2337, 5.2334,\n",
      "        5.2400, 5.2338, 5.2638], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.780233  [892924/5599865]\n",
      "average delta from current occupancy tensor([5.5141, 5.5285, 5.5140, 5.5139, 5.5226, 5.5361, 5.5137, 5.5138, 5.5137,\n",
      "        5.5137, 5.5137, 5.5139, 5.5138, 5.5316, 5.5164, 5.5136, 5.5137, 5.5140,\n",
      "        5.5138, 5.5137, 5.5141, 5.5142, 5.5137, 5.5137, 5.5140, 5.5141, 5.5140,\n",
      "        5.5139, 5.5141, 5.5140, 5.5141, 5.5140, 5.5140, 5.5139, 5.5136, 5.5138,\n",
      "        5.5137, 5.5133, 5.5392, 5.5137, 5.5135, 5.5136, 5.5135, 5.5137, 5.5136,\n",
      "        5.5136, 5.5135, 5.5136, 5.5137, 5.5136, 5.5137, 5.5136, 5.5135, 5.5134,\n",
      "        5.5135, 5.5136, 5.5136, 5.5137, 5.5138, 5.5139, 5.5382, 5.5137, 5.5138,\n",
      "        5.5138, 5.5139, 5.5136, 5.5135, 5.5136, 5.5137, 5.5137, 5.5140, 5.5138,\n",
      "        5.5138, 5.5161, 5.5135, 5.5138, 5.5138, 5.5138, 5.5136, 5.5137, 5.5137,\n",
      "        5.5137, 5.5138, 5.5137, 5.5138, 5.5138, 5.5137, 5.5137, 5.5135, 5.5136,\n",
      "        5.5135, 5.5308, 5.5129, 5.5130, 5.5131, 5.5289, 5.5133, 5.5134, 5.5132,\n",
      "        5.5133, 5.5133, 5.5135, 5.5135, 5.5134, 5.5133, 5.5166, 5.5283, 5.5136,\n",
      "        5.5305, 5.5134, 5.5137, 5.5135, 5.5137, 5.5127, 5.5135, 5.5137, 5.5135,\n",
      "        5.5132, 5.5135, 5.5246], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.511147  [905324/5599865]\n",
      "average delta from current occupancy tensor([4.6369, 4.6333, 4.6369, 4.6368, 4.6346, 4.6312, 4.6369, 4.6369, 4.6369,\n",
      "        4.6369, 4.6369, 4.6369, 4.6369, 4.6324, 4.6362, 4.6369, 4.6369, 4.6368,\n",
      "        4.6369, 4.6368, 4.6367, 4.6368, 4.6369, 4.6370, 4.6369, 4.6368, 4.6369,\n",
      "        4.6369, 4.6369, 4.6370, 4.6370, 4.6370, 4.6370, 4.6370, 4.6370, 4.6370,\n",
      "        4.6370, 4.6371, 4.6305, 4.6369, 4.6370, 4.6370, 4.6370, 4.6369, 4.6370,\n",
      "        4.6369, 4.6370, 4.6370, 4.6369, 4.6370, 4.6370, 4.6370, 4.6371, 4.6371,\n",
      "        4.6371, 4.6370, 4.6370, 4.6369, 4.6370, 4.6369, 4.6308, 4.6371, 4.6371,\n",
      "        4.6371, 4.6370, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371,\n",
      "        4.6371, 4.6365, 4.6371, 4.6370, 4.6370, 4.6371, 4.6371, 4.6371, 4.6371,\n",
      "        4.6370, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6370, 4.6370,\n",
      "        4.6370, 4.6330, 4.6370, 4.6370, 4.6370, 4.6334, 4.6370, 4.6371, 4.6371,\n",
      "        4.6370, 4.6371, 4.6371, 4.6371, 4.6371, 4.6370, 4.6364, 4.6335, 4.6371,\n",
      "        4.6329, 4.6371, 4.6371, 4.6371, 4.6371, 4.6370, 4.6371, 4.6370, 4.6370,\n",
      "        4.6371, 4.6371, 4.6343], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.622010  [917724/5599865]\n",
      "average delta from current occupancy tensor([5.6456, 5.6609, 5.6457, 5.6458, 5.6531, 5.6720, 5.6458, 5.6458, 5.6457,\n",
      "        5.6458, 5.6457, 5.6456, 5.6454, 5.6657, 5.6457, 5.6453, 5.6457, 5.6454,\n",
      "        5.6454, 5.6453, 5.6457, 5.6459, 5.6457, 5.6458, 5.6457, 5.6457, 5.6458,\n",
      "        5.6458, 5.6458, 5.6459, 5.6458, 5.6459, 5.6458, 5.6459, 5.6459, 5.6460,\n",
      "        5.6460, 5.6460, 5.6763, 5.6460, 5.6459, 5.6458, 5.6460, 5.6459, 5.6459,\n",
      "        5.6460, 5.6459, 5.6459, 5.6459, 5.6460, 5.6460, 5.6460, 5.6461, 5.6460,\n",
      "        5.6459, 5.6459, 5.6459, 5.6459, 5.6459, 5.6460, 5.6726, 5.6460, 5.6460,\n",
      "        5.6460, 5.6461, 5.6462, 5.6461, 5.6463, 5.6462, 5.6462, 5.6461, 5.6460,\n",
      "        5.6462, 5.6464, 5.6461, 5.6461, 5.6461, 5.6461, 5.6461, 5.6461, 5.6461,\n",
      "        5.6461, 5.6460, 5.6461, 5.6459, 5.6463, 5.6462, 5.6460, 5.6461, 5.6461,\n",
      "        5.6460, 5.6601, 5.6459, 5.6459, 5.6459, 5.6576, 5.6458, 5.6459, 5.6461,\n",
      "        5.6459, 5.6460, 5.6461, 5.6460, 5.6461, 5.6460, 5.6461, 5.6582, 5.6461,\n",
      "        5.6618, 5.6461, 5.6460, 5.6460, 5.6460, 5.6460, 5.6461, 5.6459, 5.6461,\n",
      "        5.6460, 5.6459, 5.6545], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.577070  [930124/5599865]\n",
      "average delta from current occupancy tensor([5.6585, 5.6532, 5.6586, 5.6585, 5.6568, 5.6482, 5.6584, 5.6584, 5.6586,\n",
      "        5.6586, 5.6584, 5.6584, 5.6583, 5.6510, 5.6584, 5.6584, 5.6584, 5.6585,\n",
      "        5.6585, 5.6585, 5.6585, 5.6582, 5.6586, 5.6583, 5.6583, 5.6583, 5.6584,\n",
      "        5.6583, 5.6583, 5.6583, 5.6583, 5.6583, 5.6583, 5.6585, 5.6585, 5.6585,\n",
      "        5.6585, 5.6585, 5.6464, 5.6583, 5.6589, 5.6587, 5.6590, 5.6589, 5.6588,\n",
      "        5.6589, 5.6587, 5.6588, 5.6586, 5.6586, 5.6586, 5.6587, 5.6587, 5.6587,\n",
      "        5.6584, 5.6586, 5.6587, 5.6585, 5.6584, 5.6584, 5.6481, 5.6583, 5.6583,\n",
      "        5.6584, 5.6583, 5.6583, 5.6583, 5.6581, 5.6583, 5.6582, 5.6581, 5.6582,\n",
      "        5.6581, 5.6581, 5.6582, 5.6584, 5.6583, 5.6584, 5.6582, 5.6583, 5.6583,\n",
      "        5.6583, 5.6583, 5.6582, 5.6585, 5.6582, 5.6581, 5.6583, 5.6585, 5.6583,\n",
      "        5.6584, 5.6531, 5.6585, 5.6583, 5.6583, 5.6546, 5.6585, 5.6584, 5.6585,\n",
      "        5.6584, 5.6587, 5.6586, 5.6582, 5.6586, 5.6585, 5.6586, 5.6544, 5.6585,\n",
      "        5.6526, 5.6583, 5.6586, 5.6584, 5.6588, 5.6587, 5.6586, 5.6587, 5.6584,\n",
      "        5.6587, 5.6586, 5.6558], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.907103  [942524/5599865]\n",
      "average delta from current occupancy tensor([4.9279, 4.9311, 4.9280, 4.9281, 4.9290, 4.9342, 4.9279, 4.9280, 4.9278,\n",
      "        4.9279, 4.9280, 4.9281, 4.9281, 4.9325, 4.9281, 4.9281, 4.9280, 4.9280,\n",
      "        4.9280, 4.9280, 4.9279, 4.9279, 4.9278, 4.9280, 4.9280, 4.9279, 4.9278,\n",
      "        4.9278, 4.9278, 4.9279, 4.9279, 4.9278, 4.9278, 4.9277, 4.9278, 4.9277,\n",
      "        4.9277, 4.9276, 4.9351, 4.9279, 4.9277, 4.9277, 4.9277, 4.9276, 4.9276,\n",
      "        4.9276, 4.9276, 4.9276, 4.9277, 4.9277, 4.9277, 4.9276, 4.9276, 4.9276,\n",
      "        4.9277, 4.9277, 4.9276, 4.9277, 4.9278, 4.9278, 4.9340, 4.9279, 4.9278,\n",
      "        4.9277, 4.9277, 4.9278, 4.9278, 4.9278, 4.9277, 4.9279, 4.9279, 4.9279,\n",
      "        4.9279, 4.9279, 4.9278, 4.9277, 4.9278, 4.9277, 4.9279, 4.9277, 4.9278,\n",
      "        4.9278, 4.9276, 4.9278, 4.9277, 4.9277, 4.9276, 4.9277, 4.9277, 4.9277,\n",
      "        4.9277, 4.9307, 4.9277, 4.9276, 4.9276, 4.9298, 4.9277, 4.9277, 4.9277,\n",
      "        4.9277, 4.9277, 4.9277, 4.9277, 4.9276, 4.9277, 4.9277, 4.9300, 4.9276,\n",
      "        4.9311, 4.9278, 4.9277, 4.9276, 4.9278, 4.9277, 4.9276, 4.9277, 4.9277,\n",
      "        4.9277, 4.9276, 4.9294], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.638895  [954924/5599865]\n",
      "average delta from current occupancy tensor([4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.737179  [967324/5599865]\n",
      "average delta from current occupancy tensor([4.8793, 4.8814, 4.8793, 4.8795, 4.8800, 4.8834, 4.8795, 4.8794, 4.8795,\n",
      "        4.8795, 4.8794, 4.8794, 4.8795, 4.8825, 4.8795, 4.8796, 4.8795, 4.8795,\n",
      "        4.8795, 4.8796, 4.8794, 4.8795, 4.8794, 4.8794, 4.8794, 4.8794, 4.8794,\n",
      "        4.8794, 4.8794, 4.8795, 4.8796, 4.8796, 4.8797, 4.8797, 4.8797, 4.8798,\n",
      "        4.8798, 4.8798, 4.8842, 4.8798, 4.8797, 4.8798, 4.8797, 4.8797, 4.8797,\n",
      "        4.8797, 4.8797, 4.8796, 4.8797, 4.8795, 4.8796, 4.8796, 4.8796, 4.8796,\n",
      "        4.8794, 4.8795, 4.8796, 4.8796, 4.8796, 4.8796, 4.8835, 4.8796, 4.8797,\n",
      "        4.8797, 4.8797, 4.8797, 4.8797, 4.8798, 4.8799, 4.8797, 4.8798, 4.8797,\n",
      "        4.8796, 4.8797, 4.8798, 4.8797, 4.8798, 4.8798, 4.8798, 4.8799, 4.8798,\n",
      "        4.8798, 4.8797, 4.8797, 4.8796, 4.8796, 4.8796, 4.8797, 4.8797, 4.8798,\n",
      "        4.8797, 4.8813, 4.8797, 4.8798, 4.8797, 4.8806, 4.8797, 4.8797, 4.8797,\n",
      "        4.8797, 4.8797, 4.8797, 4.8796, 4.8797, 4.8796, 4.8796, 4.8806, 4.8796,\n",
      "        4.8812, 4.8795, 4.8795, 4.8795, 4.8796, 4.8796, 4.8796, 4.8795, 4.8796,\n",
      "        4.8795, 4.8795, 4.8803], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.304213  [979724/5599865]\n",
      "average delta from current occupancy tensor([5.3669, 5.3716, 5.3668, 5.3667, 5.3671, 5.3775, 5.3667, 5.3669, 5.3669,\n",
      "        5.3668, 5.3669, 5.3668, 5.3663, 5.3750, 5.3663, 5.3663, 5.3666, 5.3667,\n",
      "        5.3666, 5.3662, 5.3667, 5.3666, 5.3667, 5.3666, 5.3668, 5.3669, 5.3668,\n",
      "        5.3667, 5.3671, 5.3672, 5.3671, 5.3670, 5.3667, 5.3663, 5.3663, 5.3666,\n",
      "        5.3667, 5.3669, 5.3801, 5.3670, 5.3668, 5.3668, 5.3664, 5.3669, 5.3666,\n",
      "        5.3673, 5.3672, 5.3671, 5.3673, 5.3675, 5.3674, 5.3672, 5.3670, 5.3671,\n",
      "        5.3672, 5.3673, 5.3673, 5.3673, 5.3670, 5.3670, 5.3782, 5.3674, 5.3672,\n",
      "        5.3672, 5.3673, 5.3670, 5.3670, 5.3669, 5.3668, 5.3664, 5.3667, 5.3667,\n",
      "        5.3670, 5.3665, 5.3664, 5.3663, 5.3667, 5.3665, 5.3666, 5.3669, 5.3668,\n",
      "        5.3668, 5.3668, 5.3672, 5.3671, 5.3670, 5.3669, 5.3670, 5.3671, 5.3669,\n",
      "        5.3671, 5.3710, 5.3670, 5.3667, 5.3669, 5.3689, 5.3672, 5.3672, 5.3671,\n",
      "        5.3672, 5.3670, 5.3671, 5.3674, 5.3673, 5.3673, 5.3673, 5.3693, 5.3672,\n",
      "        5.3710, 5.3673, 5.3673, 5.3672, 5.3673, 5.3673, 5.3673, 5.3675, 5.3672,\n",
      "        5.3673, 5.3671, 5.3680], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.611830  [992124/5599865]\n",
      "average delta from current occupancy tensor([4.5831, 4.5792, 4.5833, 4.5833, 4.5831, 4.5746, 4.5836, 4.5833, 4.5832,\n",
      "        4.5832, 4.5829, 4.5828, 4.5832, 4.5761, 4.5832, 4.5832, 4.5828, 4.5827,\n",
      "        4.5827, 4.5831, 4.5827, 4.5828, 4.5827, 4.5827, 4.5827, 4.5825, 4.5825,\n",
      "        4.5826, 4.5823, 4.5821, 4.5822, 4.5823, 4.5826, 4.5832, 4.5831, 4.5827,\n",
      "        4.5827, 4.5826, 4.5717, 4.5825, 4.5828, 4.5827, 4.5830, 4.5825, 4.5829,\n",
      "        4.5824, 4.5826, 4.5826, 4.5824, 4.5824, 4.5825, 4.5826, 4.5828, 4.5827,\n",
      "        4.5828, 4.5825, 4.5826, 4.5826, 4.5829, 4.5827, 4.5735, 4.5824, 4.5824,\n",
      "        4.5823, 4.5822, 4.5826, 4.5826, 4.5826, 4.5827, 4.5831, 4.5829, 4.5829,\n",
      "        4.5827, 4.5831, 4.5832, 4.5833, 4.5829, 4.5833, 4.5831, 4.5829, 4.5828,\n",
      "        4.5828, 4.5826, 4.5823, 4.5825, 4.5826, 4.5827, 4.5826, 4.5826, 4.5826,\n",
      "        4.5826, 4.5793, 4.5825, 4.5827, 4.5826, 4.5811, 4.5825, 4.5825, 4.5827,\n",
      "        4.5825, 4.5827, 4.5826, 4.5823, 4.5824, 4.5825, 4.5824, 4.5806, 4.5823,\n",
      "        4.5792, 4.5825, 4.5827, 4.5827, 4.5826, 4.5827, 4.5826, 4.5825, 4.5828,\n",
      "        4.5827, 4.5831, 4.5824], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.956981  [1004524/5599865]\n",
      "average delta from current occupancy tensor([4.8709, 4.8687, 4.8715, 4.8717, 4.8711, 4.8659, 4.8724, 4.8718, 4.8718,\n",
      "        4.8719, 4.8713, 4.8714, 4.8718, 4.8669, 4.8715, 4.8719, 4.8714, 4.8711,\n",
      "        4.8709, 4.8713, 4.8709, 4.8710, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8708, 4.8706, 4.8707, 4.8708, 4.8711, 4.8719, 4.8715, 4.8712,\n",
      "        4.8712, 4.8710, 4.8643, 4.8711, 4.8713, 4.8713, 4.8719, 4.8712, 4.8717,\n",
      "        4.8709, 4.8710, 4.8709, 4.8709, 4.8707, 4.8709, 4.8709, 4.8711, 4.8710,\n",
      "        4.8709, 4.8708, 4.8708, 4.8708, 4.8709, 4.8709, 4.8652, 4.8706, 4.8707,\n",
      "        4.8706, 4.8707, 4.8709, 4.8708, 4.8709, 4.8709, 4.8715, 4.8715, 4.8710,\n",
      "        4.8709, 4.8714, 4.8717, 4.8723, 4.8716, 4.8723, 4.8722, 4.8718, 4.8716,\n",
      "        4.8714, 4.8711, 4.8706, 4.8707, 4.8708, 4.8709, 4.8709, 4.8709, 4.8712,\n",
      "        4.8711, 4.8691, 4.8711, 4.8712, 4.8710, 4.8699, 4.8709, 4.8710, 4.8714,\n",
      "        4.8710, 4.8713, 4.8710, 4.8709, 4.8710, 4.8708, 4.8709, 4.8698, 4.8708,\n",
      "        4.8688, 4.8709, 4.8711, 4.8715, 4.8714, 4.8714, 4.8711, 4.8714, 4.8718,\n",
      "        4.8716, 4.8722, 4.8713], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.736629  [1016924/5599865]\n",
      "average delta from current occupancy tensor([4.7757, 4.7774, 4.7757, 4.7758, 4.7758, 4.7823, 4.7757, 4.7757, 4.7757,\n",
      "        4.7757, 4.7758, 4.7758, 4.7757, 4.7810, 4.7758, 4.7758, 4.7757, 4.7757,\n",
      "        4.7757, 4.7759, 4.7760, 4.7759, 4.7760, 4.7759, 4.7759, 4.7759, 4.7760,\n",
      "        4.7759, 4.7758, 4.7758, 4.7758, 4.7760, 4.7760, 4.7760, 4.7758, 4.7760,\n",
      "        4.7759, 4.7760, 4.7851, 4.7760, 4.7759, 4.7759, 4.7759, 4.7759, 4.7759,\n",
      "        4.7760, 4.7759, 4.7759, 4.7759, 4.7756, 4.7759, 4.7757, 4.7758, 4.7757,\n",
      "        4.7757, 4.7756, 4.7758, 4.7755, 4.7754, 4.7752, 4.7837, 4.7756, 4.7759,\n",
      "        4.7759, 4.7757, 4.7751, 4.7757, 4.7753, 4.7752, 4.7755, 4.7755, 4.7751,\n",
      "        4.7757, 4.7757, 4.7756, 4.7757, 4.7755, 4.7756, 4.7756, 4.7756, 4.7754,\n",
      "        4.7753, 4.7753, 4.7755, 4.7755, 4.7750, 4.7751, 4.7753, 4.7751, 4.7755,\n",
      "        4.7752, 4.7774, 4.7753, 4.7752, 4.7752, 4.7759, 4.7757, 4.7754, 4.7754,\n",
      "        4.7752, 4.7752, 4.7752, 4.7751, 4.7750, 4.7751, 4.7752, 4.7761, 4.7751,\n",
      "        4.7778, 4.7751, 4.7751, 4.7753, 4.7750, 4.7750, 4.7750, 4.7750, 4.7750,\n",
      "        4.7750, 4.7748, 4.7748], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.148312  [1029324/5599865]\n",
      "average delta from current occupancy tensor([5.3953, 5.3955, 5.3952, 5.3953, 5.3954, 5.3998, 5.3954, 5.3953, 5.3953,\n",
      "        5.3954, 5.3955, 5.3954, 5.3956, 5.3984, 5.3953, 5.3955, 5.3954, 5.3955,\n",
      "        5.3953, 5.3954, 5.3955, 5.3954, 5.3955, 5.3955, 5.3955, 5.3954, 5.3956,\n",
      "        5.3954, 5.3954, 5.3953, 5.3953, 5.3955, 5.3955, 5.3956, 5.3956, 5.3956,\n",
      "        5.3956, 5.3956, 5.4025, 5.3957, 5.3955, 5.3956, 5.3956, 5.3956, 5.3955,\n",
      "        5.3956, 5.3956, 5.3956, 5.3956, 5.3955, 5.3956, 5.3957, 5.3957, 5.3956,\n",
      "        5.3954, 5.3953, 5.3956, 5.3952, 5.3954, 5.3954, 5.4013, 5.3954, 5.3956,\n",
      "        5.3955, 5.3956, 5.3953, 5.3955, 5.3953, 5.3953, 5.3953, 5.3952, 5.3953,\n",
      "        5.3954, 5.3954, 5.3956, 5.3956, 5.3956, 5.3958, 5.3955, 5.3956, 5.3957,\n",
      "        5.3955, 5.3956, 5.3958, 5.3958, 5.3955, 5.3955, 5.3954, 5.3955, 5.3955,\n",
      "        5.3956, 5.3957, 5.3957, 5.3956, 5.3958, 5.3957, 5.3955, 5.3958, 5.3957,\n",
      "        5.3957, 5.3957, 5.3958, 5.3955, 5.3955, 5.3955, 5.3957, 5.3958, 5.3957,\n",
      "        5.3955, 5.3956, 5.3957, 5.3957, 5.3955, 5.3958, 5.3955, 5.3956, 5.3955,\n",
      "        5.3957, 5.3956, 5.3956], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.235104  [1041724/5599865]\n",
      "average delta from current occupancy tensor([5.2421, 5.2421, 5.2421, 5.2422, 5.2422, 5.2454, 5.2421, 5.2422, 5.2423,\n",
      "        5.2423, 5.2422, 5.2423, 5.2422, 5.2438, 5.2421, 5.2422, 5.2421, 5.2422,\n",
      "        5.2422, 5.2421, 5.2421, 5.2422, 5.2421, 5.2421, 5.2422, 5.2422, 5.2421,\n",
      "        5.2422, 5.2422, 5.2422, 5.2422, 5.2421, 5.2421, 5.2421, 5.2422, 5.2421,\n",
      "        5.2422, 5.2423, 5.2483, 5.2422, 5.2421, 5.2422, 5.2422, 5.2421, 5.2422,\n",
      "        5.2421, 5.2422, 5.2423, 5.2422, 5.2422, 5.2422, 5.2422, 5.2422, 5.2422,\n",
      "        5.2422, 5.2422, 5.2422, 5.2422, 5.2422, 5.2422, 5.2476, 5.2422, 5.2422,\n",
      "        5.2422, 5.2422, 5.2421, 5.2422, 5.2421, 5.2422, 5.2422, 5.2423, 5.2422,\n",
      "        5.2423, 5.2422, 5.2422, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423,\n",
      "        5.2424, 5.2422, 5.2423, 5.2423, 5.2422, 5.2423, 5.2423, 5.2422, 5.2422,\n",
      "        5.2422, 5.2422, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423, 5.2422,\n",
      "        5.2423, 5.2423, 5.2423, 5.2422, 5.2423, 5.2423, 5.2422, 5.2422, 5.2423,\n",
      "        5.2422, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423, 5.2423,\n",
      "        5.2422, 5.2422, 5.2422], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.476793  [1054124/5599865]\n",
      "average delta from current occupancy tensor([4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226, 4.3226,\n",
      "        4.3226, 4.3226, 4.3226], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.989469  [1066524/5599865]\n",
      "average delta from current occupancy tensor([4.7906, 4.7908, 4.7908, 4.7909, 4.7908, 4.7923, 4.7909, 4.7909, 4.7906,\n",
      "        4.7904, 4.7907, 4.7905, 4.7907, 4.7908, 4.7905, 4.7908, 4.7908, 4.7909,\n",
      "        4.7911, 4.7909, 4.7908, 4.7910, 4.7908, 4.7906, 4.7907, 4.7905, 4.7905,\n",
      "        4.7904, 4.7904, 4.7906, 4.7907, 4.7906, 4.7907, 4.7908, 4.7908, 4.7907,\n",
      "        4.7907, 4.7908, 4.7947, 4.7908, 4.7906, 4.7907, 4.7907, 4.7907, 4.7907,\n",
      "        4.7911, 4.7908, 4.7907, 4.7906, 4.7905, 4.7904, 4.7904, 4.7903, 4.7904,\n",
      "        4.7904, 4.7904, 4.7906, 4.7905, 4.7904, 4.7904, 4.7934, 4.7904, 4.7903,\n",
      "        4.7904, 4.7904, 4.7904, 4.7904, 4.7904, 4.7905, 4.7906, 4.7903, 4.7904,\n",
      "        4.7904, 4.7905, 4.7905, 4.7905, 4.7905, 4.7904, 4.7904, 4.7904, 4.7904,\n",
      "        4.7905, 4.7905, 4.7904, 4.7904, 4.7905, 4.7905, 4.7904, 4.7905, 4.7905,\n",
      "        4.7906, 4.7905, 4.7905, 4.7905, 4.7905, 4.7904, 4.7903, 4.7903, 4.7904,\n",
      "        4.7906, 4.7903, 4.7906, 4.7906, 4.7907, 4.7906, 4.7905, 4.7905, 4.7904,\n",
      "        4.7904, 4.7903, 4.7904, 4.7904, 4.7904, 4.7904, 4.7904, 4.7903, 4.7904,\n",
      "        4.7903, 4.7906, 4.7906], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.999605  [1078924/5599865]\n",
      "average delta from current occupancy tensor([5.7827, 5.7827, 5.7826, 5.7826, 5.7827, 5.7825, 5.7827, 5.7827, 5.7827,\n",
      "        5.7827, 5.7826, 5.7826, 5.7827, 5.7827, 5.7827, 5.7827, 5.7826, 5.7827,\n",
      "        5.7827, 5.7826, 5.7827, 5.7827, 5.7827, 5.7828, 5.7827, 5.7827, 5.7827,\n",
      "        5.7826, 5.7826, 5.7827, 5.7827, 5.7826, 5.7826, 5.7826, 5.7826, 5.7826,\n",
      "        5.7826, 5.7826, 5.7837, 5.7826, 5.7826, 5.7826, 5.7826, 5.7827, 5.7827,\n",
      "        5.7827, 5.7827, 5.7827, 5.7827, 5.7826, 5.7827, 5.7827, 5.7827, 5.7827,\n",
      "        5.7827, 5.7827, 5.7827, 5.7827, 5.7827, 5.7828, 5.7832, 5.7825, 5.7826,\n",
      "        5.7826, 5.7826, 5.7826, 5.7826, 5.7826, 5.7827, 5.7827, 5.7826, 5.7826,\n",
      "        5.7826, 5.7827, 5.7826, 5.7827, 5.7827, 5.7827, 5.7827, 5.7827, 5.7827,\n",
      "        5.7827, 5.7827, 5.7827, 5.7827, 5.7828, 5.7827, 5.7827, 5.7827, 5.7827,\n",
      "        5.7827, 5.7827, 5.7827, 5.7828, 5.7828, 5.7828, 5.7827, 5.7828, 5.7827,\n",
      "        5.7827, 5.7827, 5.7827, 5.7827, 5.7827, 5.7827, 5.7827, 5.7827, 5.7829,\n",
      "        5.7827, 5.7826, 5.7826, 5.7826, 5.7827, 5.7827, 5.7827, 5.7828, 5.7828,\n",
      "        5.7828, 5.7827, 5.7826], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.937191  [1091324/5599865]\n",
      "average delta from current occupancy tensor([4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6854,\n",
      "        4.6855, 4.6854, 4.6854, 4.6854, 4.6854, 4.6854, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.662308  [1103724/5599865]\n",
      "average delta from current occupancy tensor([4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6211,\n",
      "        4.6211, 4.6211, 4.6212, 4.6211, 4.6212, 4.6212, 4.6212, 4.6211, 4.6212,\n",
      "        4.6211, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212,\n",
      "        4.6212, 4.6213, 4.6212, 4.6212, 4.6212, 4.6212, 4.6213, 4.6212, 4.6213,\n",
      "        4.6212, 4.6213, 4.6212, 4.6212, 4.6211, 4.6212, 4.6212, 4.6212, 4.6212,\n",
      "        4.6213, 4.6212, 4.6212, 4.6213, 4.6212, 4.6212, 4.6213, 4.6213, 4.6213,\n",
      "        4.6213, 4.6213, 4.6213, 4.6213, 4.6213, 4.6213, 4.6213, 4.6212, 4.6212,\n",
      "        4.6212, 4.6212, 4.6212, 4.6212, 4.6213, 4.6213, 4.6212, 4.6213, 4.6213,\n",
      "        4.6213, 4.6213, 4.6212, 4.6212, 4.6212, 4.6213, 4.6212, 4.6212, 4.6212,\n",
      "        4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6211,\n",
      "        4.6211, 4.6212, 4.6211, 4.6211, 4.6212, 4.6211, 4.6211, 4.6212, 4.6212,\n",
      "        4.6211, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212,\n",
      "        4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212, 4.6212,\n",
      "        4.6212, 4.6212, 4.6212], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.185437  [1116124/5599865]\n",
      "average delta from current occupancy tensor([5.2098, 5.2100, 5.2100, 5.2101, 5.2101, 5.2098, 5.2100, 5.2097, 5.2097,\n",
      "        5.2098, 5.2098, 5.2098, 5.2097, 5.2098, 5.2097, 5.2097, 5.2099, 5.2097,\n",
      "        5.2097, 5.2098, 5.2099, 5.2099, 5.2098, 5.2097, 5.2098, 5.2099, 5.2100,\n",
      "        5.2098, 5.2099, 5.2099, 5.2098, 5.2098, 5.2097, 5.2099, 5.2099, 5.2101,\n",
      "        5.2100, 5.2101, 5.2100, 5.2099, 5.2099, 5.2098, 5.2101, 5.2099, 5.2099,\n",
      "        5.2101, 5.2097, 5.2098, 5.2100, 5.2099, 5.2097, 5.2102, 5.2100, 5.2101,\n",
      "        5.2102, 5.2103, 5.2101, 5.2101, 5.2101, 5.2101, 5.2101, 5.2097, 5.2097,\n",
      "        5.2097, 5.2097, 5.2098, 5.2099, 5.2099, 5.2098, 5.2098, 5.2101, 5.2103,\n",
      "        5.2101, 5.2101, 5.2099, 5.2099, 5.2099, 5.2099, 5.2101, 5.2097, 5.2097,\n",
      "        5.2097, 5.2099, 5.2098, 5.2098, 5.2098, 5.2097, 5.2099, 5.2097, 5.2097,\n",
      "        5.2097, 5.2097, 5.2099, 5.2100, 5.2100, 5.2099, 5.2099, 5.2098, 5.2099,\n",
      "        5.2099, 5.2099, 5.2099, 5.2098, 5.2099, 5.2098, 5.2098, 5.2098, 5.2099,\n",
      "        5.2099, 5.2098, 5.2098, 5.2097, 5.2097, 5.2097, 5.2098, 5.2097, 5.2098,\n",
      "        5.2097, 5.2098, 5.2097], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.019506  [1128524/5599865]\n",
      "average delta from current occupancy tensor([5.1124, 5.1125, 5.1122, 5.1121, 5.1120, 5.1124, 5.1122, 5.1124, 5.1124,\n",
      "        5.1124, 5.1124, 5.1125, 5.1124, 5.1124, 5.1123, 5.1124, 5.1124, 5.1124,\n",
      "        5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1123, 5.1125, 5.1125,\n",
      "        5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1125, 5.1125, 5.1125,\n",
      "        5.1125, 5.1125, 5.1125, 5.1124, 5.1124, 5.1125, 5.1124, 5.1124, 5.1124,\n",
      "        5.1124, 5.1124, 5.1125, 5.1124, 5.1124, 5.1124, 5.1125, 5.1125, 5.1124,\n",
      "        5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124,\n",
      "        5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1125, 5.1125, 5.1124,\n",
      "        5.1124, 5.1125, 5.1125, 5.1124, 5.1124, 5.1123, 5.1124, 5.1124, 5.1124,\n",
      "        5.1123, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124,\n",
      "        5.1124, 5.1124, 5.1125, 5.1124, 5.1124, 5.1125, 5.1125, 5.1124, 5.1124,\n",
      "        5.1124, 5.1124, 5.1124, 5.1123, 5.1124, 5.1124, 5.1124, 5.1125, 5.1124,\n",
      "        5.1124, 5.1125, 5.1125, 5.1124, 5.1124, 5.1124, 5.1123, 5.1124, 5.1124,\n",
      "        5.1123, 5.1124, 5.1124], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.987245  [1140924/5599865]\n",
      "average delta from current occupancy tensor([4.9433, 4.9430, 4.9433, 4.9433, 4.9433, 4.9433, 4.9432, 4.9433, 4.9432,\n",
      "        4.9433, 4.9431, 4.9432, 4.9433, 4.9429, 4.9433, 4.9432, 4.9428, 4.9432,\n",
      "        4.9432, 4.9431, 4.9428, 4.9430, 4.9433, 4.9434, 4.9434, 4.9431, 4.9434,\n",
      "        4.9434, 4.9434, 4.9432, 4.9430, 4.9430, 4.9432, 4.9431, 4.9432, 4.9430,\n",
      "        4.9431, 4.9433, 4.9430, 4.9433, 4.9433, 4.9434, 4.9433, 4.9430, 4.9433,\n",
      "        4.9429, 4.9433, 4.9433, 4.9430, 4.9429, 4.9431, 4.9430, 4.9428, 4.9429,\n",
      "        4.9433, 4.9431, 4.9430, 4.9431, 4.9426, 4.9428, 4.9431, 4.9426, 4.9428,\n",
      "        4.9429, 4.9429, 4.9432, 4.9432, 4.9431, 4.9431, 4.9433, 4.9430, 4.9430,\n",
      "        4.9428, 4.9427, 4.9431, 4.9426, 4.9426, 4.9428, 4.9425, 4.9426, 4.9426,\n",
      "        4.9427, 4.9428, 4.9428, 4.9433, 4.9428, 4.9428, 4.9429, 4.9429, 4.9429,\n",
      "        4.9427, 4.9430, 4.9430, 4.9429, 4.9427, 4.9427, 4.9427, 4.9429, 4.9427,\n",
      "        4.9430, 4.9431, 4.9431, 4.9426, 4.9428, 4.9427, 4.9426, 4.9426, 4.9427,\n",
      "        4.9424, 4.9425, 4.9426, 4.9427, 4.9425, 4.9426, 4.9428, 4.9432, 4.9432,\n",
      "        4.9432, 4.9431, 4.9433], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.544020  [1153324/5599865]\n",
      "average delta from current occupancy tensor([5.7099, 5.7099, 5.7098, 5.7097, 5.7096, 5.7100, 5.7102, 5.7101, 5.7103,\n",
      "        5.7103, 5.7104, 5.7097, 5.7097, 5.7102, 5.7101, 5.7100, 5.7104, 5.7102,\n",
      "        5.7099, 5.7103, 5.7107, 5.7107, 5.7104, 5.7099, 5.7095, 5.7103, 5.7096,\n",
      "        5.7099, 5.7096, 5.7107, 5.7104, 5.7104, 5.7100, 5.7101, 5.7102, 5.7101,\n",
      "        5.7101, 5.7101, 5.7099, 5.7101, 5.7099, 5.7099, 5.7101, 5.7098, 5.7096,\n",
      "        5.7099, 5.7102, 5.7102, 5.7101, 5.7102, 5.7105, 5.7102, 5.7096, 5.7096,\n",
      "        5.7100, 5.7102, 5.7101, 5.7100, 5.7096, 5.7099, 5.7101, 5.7096, 5.7097,\n",
      "        5.7098, 5.7098, 5.7098, 5.7100, 5.7100, 5.7101, 5.7100, 5.7102, 5.7101,\n",
      "        5.7101, 5.7101, 5.7102, 5.7102, 5.7102, 5.7100, 5.7097, 5.7100, 5.7101,\n",
      "        5.7102, 5.7102, 5.7103, 5.7097, 5.7101, 5.7105, 5.7101, 5.7102, 5.7101,\n",
      "        5.7101, 5.7101, 5.7102, 5.7104, 5.7105, 5.7106, 5.7108, 5.7107, 5.7105,\n",
      "        5.7102, 5.7099, 5.7102, 5.7103, 5.7105, 5.7105, 5.7105, 5.7104, 5.7105,\n",
      "        5.7105, 5.7106, 5.7105, 5.7105, 5.7104, 5.7104, 5.7101, 5.7103, 5.7104,\n",
      "        5.7103, 5.7103, 5.7102], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.221846  [1165724/5599865]\n",
      "average delta from current occupancy tensor([5.2988, 5.2987, 5.2988, 5.2986, 5.2986, 5.2988, 5.2988, 5.2989, 5.2989,\n",
      "        5.2989, 5.2988, 5.2989, 5.2990, 5.2989, 5.2988, 5.2988, 5.2988, 5.2988,\n",
      "        5.2988, 5.2988, 5.2987, 5.2987, 5.2988, 5.2988, 5.2987, 5.2988, 5.2987,\n",
      "        5.2990, 5.2990, 5.2987, 5.2987, 5.2987, 5.2987, 5.2987, 5.2988, 5.2991,\n",
      "        5.2987, 5.2987, 5.2986, 5.2987, 5.2988, 5.2990, 5.2990, 5.2989, 5.2987,\n",
      "        5.2987, 5.2987, 5.2986, 5.2987, 5.2987, 5.2986, 5.2987, 5.2987, 5.2987,\n",
      "        5.2987, 5.2986, 5.2988, 5.2988, 5.2984, 5.2984, 5.2988, 5.2986, 5.2988,\n",
      "        5.2987, 5.2988, 5.2986, 5.2988, 5.2987, 5.2988, 5.2987, 5.2988, 5.2987,\n",
      "        5.2987, 5.2988, 5.2989, 5.2988, 5.2987, 5.2985, 5.2986, 5.2988, 5.2988,\n",
      "        5.2989, 5.2989, 5.2989, 5.2989, 5.2989, 5.2989, 5.2987, 5.2989, 5.2989,\n",
      "        5.2989, 5.2989, 5.2989, 5.2989, 5.2989, 5.2988, 5.2989, 5.2989, 5.2990,\n",
      "        5.2990, 5.2989, 5.2988, 5.2989, 5.2989, 5.2990, 5.2988, 5.2990, 5.2989,\n",
      "        5.2989, 5.2989, 5.2988, 5.2988, 5.2990, 5.2988, 5.2989, 5.2990, 5.2989,\n",
      "        5.2989, 5.2989, 5.2990], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.939391  [1178124/5599865]\n",
      "average delta from current occupancy tensor([4.7261, 4.7262, 4.7262, 4.7262, 4.7261, 4.7262, 4.7261, 4.7261, 4.7262,\n",
      "        4.7262, 4.7261, 4.7261, 4.7261, 4.7263, 4.7263, 4.7263, 4.7264, 4.7263,\n",
      "        4.7263, 4.7262, 4.7262, 4.7263, 4.7263, 4.7262, 4.7261, 4.7263, 4.7261,\n",
      "        4.7262, 4.7262, 4.7262, 4.7261, 4.7262, 4.7261, 4.7261, 4.7261, 4.7261,\n",
      "        4.7262, 4.7262, 4.7261, 4.7260, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261,\n",
      "        4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261,\n",
      "        4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7262, 4.7263, 4.7261,\n",
      "        4.7262, 4.7262, 4.7260, 4.7261, 4.7261, 4.7260, 4.7261, 4.7262, 4.7262,\n",
      "        4.7262, 4.7260, 4.7261, 4.7261, 4.7261, 4.7262, 4.7263, 4.7263, 4.7263,\n",
      "        4.7263, 4.7263, 4.7263, 4.7264, 4.7262, 4.7262, 4.7263, 4.7263, 4.7262,\n",
      "        4.7263, 4.7263, 4.7263, 4.7263, 4.7262, 4.7263, 4.7263, 4.7263, 4.7263,\n",
      "        4.7264, 4.7263, 4.7263, 4.7263, 4.7263, 4.7263, 4.7263, 4.7263, 4.7262,\n",
      "        4.7263, 4.7262, 4.7263, 4.7262, 4.7262, 4.7262, 4.7262, 4.7262, 4.7262,\n",
      "        4.7261, 4.7262, 4.7262], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.430683  [1190524/5599865]\n",
      "average delta from current occupancy tensor([4.7799, 4.7800, 4.7794, 4.7789, 4.7795, 4.7792, 4.7796, 4.7794, 4.7797,\n",
      "        4.7793, 4.7794, 4.7789, 4.7791, 4.7788, 4.7790, 4.7792, 4.7791, 4.7791,\n",
      "        4.7787, 4.7794, 4.7796, 4.7791, 4.7786, 4.7787, 4.7792, 4.7791, 4.7792,\n",
      "        4.7799, 4.7793, 4.7793, 4.7789, 4.7793, 4.7793, 4.7791, 4.7789, 4.7789,\n",
      "        4.7791, 4.7793, 4.7792, 4.7788, 4.7790, 4.7795, 4.7794, 4.7793, 4.7794,\n",
      "        4.7790, 4.7790, 4.7791, 4.7789, 4.7788, 4.7788, 4.7786, 4.7786, 4.7788,\n",
      "        4.7784, 4.7787, 4.7783, 4.7783, 4.7783, 4.7782, 4.7792, 4.7793, 4.7789,\n",
      "        4.7798, 4.7792, 4.7787, 4.7791, 4.7788, 4.7782, 4.7783, 4.7795, 4.7793,\n",
      "        4.7787, 4.7787, 4.7787, 4.7786, 4.7790, 4.7796, 4.7792, 4.7789, 4.7791,\n",
      "        4.7792, 4.7791, 4.7791, 4.7790, 4.7795, 4.7797, 4.7790, 4.7790, 4.7795,\n",
      "        4.7793, 4.7796, 4.7795, 4.7794, 4.7795, 4.7796, 4.7799, 4.7798, 4.7803,\n",
      "        4.7799, 4.7803, 4.7804, 4.7803, 4.7808, 4.7809, 4.7800, 4.7802, 4.7795,\n",
      "        4.7797, 4.7792, 4.7794, 4.7796, 4.7790, 4.7795, 4.7799, 4.7801, 4.7795,\n",
      "        4.7800, 4.7804, 4.7798], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.309071  [1202924/5599865]\n",
      "average delta from current occupancy tensor([5.4843, 5.4843, 5.4845, 5.4846, 5.4846, 5.4846, 5.4845, 5.4845, 5.4844,\n",
      "        5.4846, 5.4846, 5.4847, 5.4846, 5.4847, 5.4846, 5.4846, 5.4848, 5.4847,\n",
      "        5.4848, 5.4846, 5.4845, 5.4846, 5.4849, 5.4848, 5.4847, 5.4846, 5.4846,\n",
      "        5.4845, 5.4846, 5.4846, 5.4847, 5.4845, 5.4845, 5.4846, 5.4846, 5.4847,\n",
      "        5.4846, 5.4845, 5.4845, 5.4846, 5.4845, 5.4843, 5.4843, 5.4844, 5.4843,\n",
      "        5.4846, 5.4846, 5.4845, 5.4846, 5.4846, 5.4846, 5.4847, 5.4847, 5.4846,\n",
      "        5.4847, 5.4846, 5.4847, 5.4847, 5.4847, 5.4846, 5.4844, 5.4843, 5.4844,\n",
      "        5.4842, 5.4843, 5.4846, 5.4845, 5.4846, 5.4847, 5.4846, 5.4842, 5.4843,\n",
      "        5.4845, 5.4846, 5.4845, 5.4844, 5.4843, 5.4841, 5.4843, 5.4844, 5.4842,\n",
      "        5.4842, 5.4841, 5.4841, 5.4841, 5.4840, 5.4840, 5.4842, 5.4842, 5.4842,\n",
      "        5.4842, 5.4841, 5.4841, 5.4842, 5.4842, 5.4841, 5.4841, 5.4841, 5.4842,\n",
      "        5.4841, 5.4842, 5.4842, 5.4841, 5.4842, 5.4842, 5.4842, 5.4842, 5.4843,\n",
      "        5.4843, 5.4844, 5.4844, 5.4844, 5.4846, 5.4844, 5.4844, 5.4842, 5.4844,\n",
      "        5.4843, 5.4841, 5.4842], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.249140  [1215324/5599865]\n",
      "average delta from current occupancy tensor([5.3870, 5.3870, 5.3869, 5.3869, 5.3870, 5.3869, 5.3870, 5.3869, 5.3870,\n",
      "        5.3870, 5.3869, 5.3870, 5.3870, 5.3870, 5.3870, 5.3870, 5.3870, 5.3870,\n",
      "        5.3870, 5.3870, 5.3870, 5.3869, 5.3870, 5.3870, 5.3870, 5.3869, 5.3868,\n",
      "        5.3868, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869,\n",
      "        5.3869, 5.3869, 5.3870, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3870,\n",
      "        5.3869, 5.3870, 5.3869, 5.3870, 5.3869, 5.3868, 5.3870, 5.3871, 5.3869,\n",
      "        5.3870, 5.3869, 5.3870, 5.3871, 5.3870, 5.3870, 5.3869, 5.3869, 5.3869,\n",
      "        5.3869, 5.3870, 5.3869, 5.3869, 5.3869, 5.3869, 5.3868, 5.3870, 5.3870,\n",
      "        5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3868, 5.3868, 5.3868,\n",
      "        5.3869, 5.3868, 5.3869, 5.3869, 5.3870, 5.3869, 5.3868, 5.3869, 5.3870,\n",
      "        5.3870, 5.3868, 5.3868, 5.3870, 5.3869, 5.3869, 5.3869, 5.3868, 5.3870,\n",
      "        5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3869, 5.3870, 5.3871,\n",
      "        5.3870, 5.3870, 5.3869, 5.3869, 5.3869, 5.3870, 5.3869, 5.3869, 5.3870,\n",
      "        5.3870, 5.3869, 5.3869], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.898862  [1227724/5599865]\n",
      "average delta from current occupancy tensor([4.8388, 4.8388, 4.8386, 4.8385, 4.8387, 4.8388, 4.8386, 4.8385, 4.8386,\n",
      "        4.8387, 4.8386, 4.8388, 4.8386, 4.8386, 4.8385, 4.8385, 4.8386, 4.8385,\n",
      "        4.8386, 4.8386, 4.8387, 4.8386, 4.8386, 4.8386, 4.8385, 4.8383, 4.8384,\n",
      "        4.8383, 4.8384, 4.8383, 4.8383, 4.8384, 4.8383, 4.8383, 4.8385, 4.8384,\n",
      "        4.8384, 4.8386, 4.8386, 4.8386, 4.8387, 4.8387, 4.8386, 4.8386, 4.8387,\n",
      "        4.8387, 4.8387, 4.8388, 4.8386, 4.8386, 4.8386, 4.8387, 4.8387, 4.8387,\n",
      "        4.8387, 4.8387, 4.8386, 4.8387, 4.8387, 4.8387, 4.8384, 4.8386, 4.8385,\n",
      "        4.8385, 4.8385, 4.8384, 4.8383, 4.8383, 4.8382, 4.8383, 4.8381, 4.8386,\n",
      "        4.8383, 4.8384, 4.8385, 4.8385, 4.8384, 4.8384, 4.8384, 4.8384, 4.8385,\n",
      "        4.8384, 4.8383, 4.8385, 4.8384, 4.8387, 4.8386, 4.8385, 4.8387, 4.8387,\n",
      "        4.8387, 4.8385, 4.8384, 4.8384, 4.8387, 4.8386, 4.8385, 4.8385, 4.8383,\n",
      "        4.8383, 4.8383, 4.8386, 4.8386, 4.8385, 4.8385, 4.8385, 4.8384, 4.8384,\n",
      "        4.8383, 4.8385, 4.8385, 4.8384, 4.8382, 4.8384, 4.8384, 4.8385, 4.8385,\n",
      "        4.8384, 4.8385, 4.8384], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.503887  [1240124/5599865]\n",
      "average delta from current occupancy tensor([5.6790, 5.6786, 5.6785, 5.6783, 5.6787, 5.6786, 5.6785, 5.6784, 5.6784,\n",
      "        5.6785, 5.6787, 5.6785, 5.6783, 5.6784, 5.6784, 5.6782, 5.6783, 5.6782,\n",
      "        5.6786, 5.6787, 5.6785, 5.6787, 5.6788, 5.6787, 5.6785, 5.6787, 5.6787,\n",
      "        5.6786, 5.6788, 5.6787, 5.6783, 5.6785, 5.6785, 5.6785, 5.6786, 5.6785,\n",
      "        5.6785, 5.6787, 5.6784, 5.6784, 5.6785, 5.6785, 5.6786, 5.6786, 5.6783,\n",
      "        5.6783, 5.6782, 5.6784, 5.6782, 5.6785, 5.6782, 5.6782, 5.6786, 5.6782,\n",
      "        5.6784, 5.6781, 5.6784, 5.6783, 5.6782, 5.6782, 5.6785, 5.6783, 5.6786,\n",
      "        5.6786, 5.6783, 5.6783, 5.6784, 5.6786, 5.6783, 5.6783, 5.6785, 5.6784,\n",
      "        5.6785, 5.6786, 5.6786, 5.6782, 5.6785, 5.6784, 5.6783, 5.6784, 5.6783,\n",
      "        5.6783, 5.6783, 5.6781, 5.6781, 5.6783, 5.6782, 5.6781, 5.6781, 5.6781,\n",
      "        5.6781, 5.6782, 5.6782, 5.6787, 5.6785, 5.6784, 5.6784, 5.6784, 5.6784,\n",
      "        5.6787, 5.6787, 5.6784, 5.6786, 5.6784, 5.6784, 5.6785, 5.6784, 5.6784,\n",
      "        5.6787, 5.6783, 5.6783, 5.6784, 5.6784, 5.6785, 5.6782, 5.6782, 5.6784,\n",
      "        5.6781, 5.6782, 5.6782], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.865713  [1252524/5599865]\n",
      "average delta from current occupancy tensor([4.7098, 4.7097, 4.7097, 4.7097, 4.7097, 4.7099, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7098, 4.7098, 4.7097, 4.7097, 4.7097, 4.7099, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7098, 4.7098, 4.7098, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7098, 4.7097, 4.7097, 4.7097, 4.7097, 4.7098, 4.7097, 4.7098, 4.7098,\n",
      "        4.7098, 4.7097, 4.7097, 4.7098, 4.7098, 4.7097, 4.7097, 4.7098, 4.7097,\n",
      "        4.7098, 4.7098, 4.7098, 4.7097, 4.7097, 4.7098, 4.7098, 4.7097, 4.7097,\n",
      "        4.7097, 4.7098, 4.7098, 4.7098, 4.7098, 4.7097, 4.7098, 4.7098, 4.7098,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7098,\n",
      "        4.7097, 4.7097, 4.7097], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.366929  [1264924/5599865]\n",
      "average delta from current occupancy tensor([4.4034, 4.4033, 4.4034, 4.4033, 4.4034, 4.4034, 4.4034, 4.4034, 4.4033,\n",
      "        4.4034, 4.4034, 4.4034, 4.4034, 4.4034, 4.4034, 4.4034, 4.4034, 4.4033,\n",
      "        4.4035, 4.4035, 4.4035, 4.4035, 4.4035, 4.4035, 4.4034, 4.4034, 4.4033,\n",
      "        4.4033, 4.4033, 4.4033, 4.4034, 4.4034, 4.4034, 4.4034, 4.4035, 4.4035,\n",
      "        4.4035, 4.4035, 4.4035, 4.4034, 4.4034, 4.4034, 4.4033, 4.4033, 4.4034,\n",
      "        4.4033, 4.4033, 4.4034, 4.4033, 4.4034, 4.4034, 4.4034, 4.4033, 4.4034,\n",
      "        4.4034, 4.4035, 4.4034, 4.4034, 4.4034, 4.4033, 4.4033, 4.4034, 4.4033,\n",
      "        4.4035, 4.4035, 4.4035, 4.4034, 4.4036, 4.4035, 4.4035, 4.4034, 4.4035,\n",
      "        4.4034, 4.4034, 4.4034, 4.4034, 4.4034, 4.4033, 4.4033, 4.4033, 4.4033,\n",
      "        4.4032, 4.4032, 4.4032, 4.4032, 4.4033, 4.4033, 4.4033, 4.4032, 4.4033,\n",
      "        4.4032, 4.4032, 4.4032, 4.4033, 4.4032, 4.4033, 4.4033, 4.4032, 4.4032,\n",
      "        4.4033, 4.4033, 4.4032, 4.4032, 4.4033, 4.4033, 4.4033, 4.4032, 4.4033,\n",
      "        4.4032, 4.4032, 4.4033, 4.4033, 4.4033, 4.4032, 4.4033, 4.4033, 4.4033,\n",
      "        4.4033, 4.4033, 4.4033], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.646792  [1277324/5599865]\n",
      "average delta from current occupancy tensor([4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5646,\n",
      "        4.5647, 4.5647, 4.5647, 4.5646, 4.5646, 4.5646, 4.5646, 4.5647, 4.5646,\n",
      "        4.5646, 4.5646, 4.5646, 4.5646, 4.5646, 4.5645, 4.5646, 4.5646, 4.5647,\n",
      "        4.5647, 4.5647, 4.5647, 4.5646, 4.5646, 4.5647, 4.5647, 4.5646, 4.5646,\n",
      "        4.5646, 4.5646, 4.5646, 4.5646, 4.5647, 4.5647, 4.5646, 4.5646, 4.5646,\n",
      "        4.5646, 4.5646, 4.5646, 4.5646, 4.5647, 4.5646, 4.5646, 4.5646, 4.5646,\n",
      "        4.5646, 4.5647, 4.5646, 4.5646, 4.5646, 4.5646, 4.5646, 4.5646, 4.5646,\n",
      "        4.5646, 4.5646, 4.5646, 4.5646, 4.5646, 4.5647, 4.5646, 4.5646, 4.5646,\n",
      "        4.5646, 4.5646, 4.5646, 4.5646, 4.5646, 4.5647, 4.5647, 4.5647, 4.5647,\n",
      "        4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647,\n",
      "        4.5647, 4.5647, 4.5647, 4.5647, 4.5646, 4.5646, 4.5647, 4.5647, 4.5647,\n",
      "        4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5646, 4.5647, 4.5647, 4.5647,\n",
      "        4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647, 4.5647,\n",
      "        4.5647, 4.5647, 4.5647], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.699380  [1289724/5599865]\n",
      "average delta from current occupancy tensor([4.7567, 4.7566, 4.7566, 4.7567, 4.7565, 4.7567, 4.7567, 4.7567, 4.7568,\n",
      "        4.7568, 4.7571, 4.7570, 4.7567, 4.7568, 4.7571, 4.7568, 4.7571, 4.7568,\n",
      "        4.7570, 4.7570, 4.7570, 4.7570, 4.7571, 4.7572, 4.7571, 4.7569, 4.7572,\n",
      "        4.7572, 4.7571, 4.7572, 4.7573, 4.7574, 4.7571, 4.7574, 4.7576, 4.7574,\n",
      "        4.7573, 4.7574, 4.7574, 4.7575, 4.7575, 4.7577, 4.7575, 4.7574, 4.7573,\n",
      "        4.7575, 4.7576, 4.7578, 4.7576, 4.7574, 4.7574, 4.7573, 4.7573, 4.7574,\n",
      "        4.7574, 4.7574, 4.7576, 4.7579, 4.7576, 4.7573, 4.7575, 4.7572, 4.7578,\n",
      "        4.7575, 4.7578, 4.7574, 4.7578, 4.7576, 4.7577, 4.7573, 4.7574, 4.7575,\n",
      "        4.7573, 4.7572, 4.7573, 4.7573, 4.7574, 4.7576, 4.7575, 4.7575, 4.7586,\n",
      "        4.7580, 4.7580, 4.7579, 4.7579, 4.7580, 4.7586, 4.7579, 4.7582, 4.7585,\n",
      "        4.7587, 4.7585, 4.7578, 4.7578, 4.7580, 4.7575, 4.7577, 4.7577, 4.7578,\n",
      "        4.7579, 4.7580, 4.7578, 4.7578, 4.7579, 4.7575, 4.7575, 4.7579, 4.7580,\n",
      "        4.7575, 4.7579, 4.7576, 4.7580, 4.7577, 4.7576, 4.7581, 4.7583, 4.7584,\n",
      "        4.7580, 4.7581, 4.7576], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.449800  [1302124/5599865]\n",
      "average delta from current occupancy tensor([5.4238, 5.4238, 5.4237, 5.4235, 5.4237, 5.4243, 5.4241, 5.4239, 5.4245,\n",
      "        5.4245, 5.4249, 5.4247, 5.4240, 5.4240, 5.4246, 5.4241, 5.4246, 5.4246,\n",
      "        5.4249, 5.4248, 5.4250, 5.4248, 5.4249, 5.4248, 5.4247, 5.4249, 5.4254,\n",
      "        5.4255, 5.4253, 5.4258, 5.4257, 5.4254, 5.4260, 5.4257, 5.4247, 5.4258,\n",
      "        5.4255, 5.4256, 5.4256, 5.4253, 5.4259, 5.4252, 5.4253, 5.4254, 5.4258,\n",
      "        5.4252, 5.4251, 5.4250, 5.4257, 5.4255, 5.4254, 5.4257, 5.4259, 5.4248,\n",
      "        5.4255, 5.4249, 5.4254, 5.4246, 5.4256, 5.4254, 5.4247, 5.4256, 5.4248,\n",
      "        5.4244, 5.4246, 5.4250, 5.4249, 5.4251, 5.4254, 5.4254, 5.4250, 5.4252,\n",
      "        5.4258, 5.4256, 5.4255, 5.4255, 5.4254, 5.4254, 5.4254, 5.4253, 5.4243,\n",
      "        5.4249, 5.4244, 5.4249, 5.4249, 5.4246, 5.4248, 5.4252, 5.4244, 5.4248,\n",
      "        5.4248, 5.4249, 5.4249, 5.4250, 5.4246, 5.4249, 5.4250, 5.4252, 5.4253,\n",
      "        5.4249, 5.4248, 5.4250, 5.4250, 5.4248, 5.4255, 5.4252, 5.4248, 5.4248,\n",
      "        5.4247, 5.4248, 5.4255, 5.4249, 5.4256, 5.4253, 5.4248, 5.4248, 5.4254,\n",
      "        5.4252, 5.4253, 5.4257], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.995781  [1314524/5599865]\n",
      "average delta from current occupancy tensor([4.9033, 4.9034, 4.9034, 4.9034, 4.9034, 4.9033, 4.9034, 4.9034, 4.9035,\n",
      "        4.9034, 4.9033, 4.9034, 4.9034, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9034, 4.9033, 4.9033, 4.9033, 4.9034,\n",
      "        4.9034, 4.9034, 4.9033, 4.9033, 4.9034, 4.9034, 4.9033, 4.9034, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9034, 4.9033, 4.9033, 4.9033, 4.9034, 4.9033,\n",
      "        4.9033, 4.9034, 4.9034, 4.9033, 4.9033, 4.9033, 4.9033, 4.9034, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9032, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9034,\n",
      "        4.9034, 4.9033, 4.9034, 4.9033, 4.9034, 4.9034, 4.9033, 4.9034, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9034, 4.9033,\n",
      "        4.9033, 4.9033, 4.9034, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9032,\n",
      "        4.9033, 4.9033, 4.9033], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.356394  [1326924/5599865]\n",
      "average delta from current occupancy tensor([4.4264, 4.4263, 4.4263, 4.4267, 4.4266, 4.4265, 4.4265, 4.4266, 4.4269,\n",
      "        4.4265, 4.4266, 4.4265, 4.4266, 4.4268, 4.4271, 4.4272, 4.4271, 4.4273,\n",
      "        4.4269, 4.4268, 4.4267, 4.4270, 4.4268, 4.4268, 4.4268, 4.4271, 4.4267,\n",
      "        4.4272, 4.4268, 4.4269, 4.4270, 4.4270, 4.4270, 4.4270, 4.4270, 4.4271,\n",
      "        4.4270, 4.4270, 4.4270, 4.4272, 4.4270, 4.4272, 4.4271, 4.4269, 4.4270,\n",
      "        4.4271, 4.4269, 4.4270, 4.4269, 4.4270, 4.4270, 4.4270, 4.4273, 4.4271,\n",
      "        4.4272, 4.4272, 4.4275, 4.4271, 4.4271, 4.4272, 4.4271, 4.4272, 4.4272,\n",
      "        4.4271, 4.4271, 4.4270, 4.4271, 4.4271, 4.4272, 4.4271, 4.4271, 4.4271,\n",
      "        4.4271, 4.4272, 4.4271, 4.4271, 4.4269, 4.4269, 4.4269, 4.4269, 4.4270,\n",
      "        4.4270, 4.4269, 4.4271, 4.4269, 4.4271, 4.4270, 4.4270, 4.4271, 4.4271,\n",
      "        4.4273, 4.4271, 4.4271, 4.4270, 4.4270, 4.4270, 4.4269, 4.4269, 4.4270,\n",
      "        4.4271, 4.4270, 4.4270, 4.4269, 4.4270, 4.4270, 4.4271, 4.4270, 4.4269,\n",
      "        4.4269, 4.4273, 4.4272, 4.4270, 4.4271, 4.4268, 4.4267, 4.4268, 4.4266,\n",
      "        4.4267, 4.4269, 4.4267], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.697748  [1339324/5599865]\n",
      "average delta from current occupancy tensor([4.3470, 4.3469, 4.3469, 4.3470, 4.3470, 4.3469, 4.3470, 4.3470, 4.3470,\n",
      "        4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3469, 4.3469,\n",
      "        4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3470, 4.3469, 4.3468, 4.3469,\n",
      "        4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3469,\n",
      "        4.3469, 4.3469, 4.3469, 4.3470, 4.3469, 4.3470, 4.3469, 4.3470, 4.3470,\n",
      "        4.3469, 4.3470, 4.3469, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3469,\n",
      "        4.3470, 4.3469, 4.3470, 4.3470, 4.3470, 4.3470, 4.3469, 4.3470, 4.3469,\n",
      "        4.3470, 4.3470, 4.3470, 4.3469, 4.3470, 4.3469, 4.3470, 4.3470, 4.3469,\n",
      "        4.3470, 4.3470, 4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3469, 4.3470,\n",
      "        4.3470, 4.3469, 4.3470, 4.3469, 4.3470, 4.3469, 4.3470, 4.3470, 4.3469,\n",
      "        4.3469, 4.3469, 4.3469, 4.3470, 4.3469, 4.3469, 4.3469, 4.3470, 4.3470,\n",
      "        4.3470, 4.3470, 4.3469, 4.3470, 4.3470, 4.3469, 4.3470, 4.3470, 4.3470,\n",
      "        4.3469, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470, 4.3470,\n",
      "        4.3470, 4.3470, 4.3470], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.547155  [1351724/5599865]\n",
      "average delta from current occupancy tensor([5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778,\n",
      "        5.6777, 5.6778, 5.6778, 5.6778, 5.6779, 5.6778, 5.6778, 5.6778, 5.6779,\n",
      "        5.6778, 5.6778, 5.6778, 5.6777, 5.6777, 5.6777, 5.6778, 5.6778, 5.6778,\n",
      "        5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778,\n",
      "        5.6776, 5.6778, 5.6778, 5.6778, 5.6777, 5.6778, 5.6778, 5.6779, 5.6778,\n",
      "        5.6778, 5.6779, 5.6778, 5.6778, 5.6779, 5.6777, 5.6778, 5.6778, 5.6777,\n",
      "        5.6778, 5.6778, 5.6778, 5.6778, 5.6779, 5.6778, 5.6779, 5.6778, 5.6778,\n",
      "        5.6778, 5.6778, 5.6778, 5.6777, 5.6778, 5.6778, 5.6778, 5.6778, 5.6777,\n",
      "        5.6778, 5.6777, 5.6777, 5.6778, 5.6778, 5.6778, 5.6777, 5.6778, 5.6778,\n",
      "        5.6777, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6778, 5.6777, 5.6778,\n",
      "        5.6778, 5.6779, 5.6777, 5.6778, 5.6779, 5.6779, 5.6778, 5.6779, 5.6779,\n",
      "        5.6777, 5.6778, 5.6778, 5.6779, 5.6779, 5.6779, 5.6778, 5.6778, 5.6779,\n",
      "        5.6780, 5.6779, 5.6779, 5.6780, 5.6779, 5.6778, 5.6779, 5.6778, 5.6779,\n",
      "        5.6781, 5.6779, 5.6778], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.051790  [1364124/5599865]\n",
      "average delta from current occupancy tensor([5.0500, 5.0501, 5.0501, 5.0501, 5.0500, 5.0498, 5.0498, 5.0497, 5.0501,\n",
      "        5.0499, 5.0499, 5.0499, 5.0497, 5.0498, 5.0495, 5.0498, 5.0496, 5.0494,\n",
      "        5.0496, 5.0494, 5.0493, 5.0493, 5.0492, 5.0492, 5.0493, 5.0492, 5.0493,\n",
      "        5.0492, 5.0492, 5.0491, 5.0492, 5.0493, 5.0492, 5.0492, 5.0493, 5.0494,\n",
      "        5.0495, 5.0493, 5.0494, 5.0495, 5.0496, 5.0494, 5.0496, 5.0495, 5.0495,\n",
      "        5.0494, 5.0497, 5.0498, 5.0497, 5.0497, 5.0498, 5.0496, 5.0498, 5.0497,\n",
      "        5.0495, 5.0494, 5.0493, 5.0494, 5.0494, 5.0492, 5.0489, 5.0489, 5.0489,\n",
      "        5.0488, 5.0488, 5.0487, 5.0486, 5.0485, 5.0486, 5.0485, 5.0488, 5.0487,\n",
      "        5.0484, 5.0486, 5.0486, 5.0489, 5.0488, 5.0487, 5.0487, 5.0486, 5.0486,\n",
      "        5.0486, 5.0487, 5.0488, 5.0488, 5.0485, 5.0484, 5.0484, 5.0484, 5.0486,\n",
      "        5.0485, 5.0484, 5.0487, 5.0486, 5.0484, 5.0484, 5.0487, 5.0486, 5.0484,\n",
      "        5.0485, 5.0486, 5.0486, 5.0486, 5.0486, 5.0486, 5.0487, 5.0486, 5.0484,\n",
      "        5.0485, 5.0485, 5.0484, 5.0484, 5.0484, 5.0485, 5.0486, 5.0487, 5.0484,\n",
      "        5.0486, 5.0484, 5.0487], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.600466  [1376524/5599865]\n",
      "average delta from current occupancy tensor([5.7098, 5.7096, 5.7097, 5.7099, 5.7100, 5.7096, 5.7099, 5.7096, 5.7102,\n",
      "        5.7101, 5.7099, 5.7099, 5.7097, 5.7097, 5.7096, 5.7097, 5.7098, 5.7097,\n",
      "        5.7097, 5.7097, 5.7096, 5.7096, 5.7097, 5.7098, 5.7097, 5.7098, 5.7097,\n",
      "        5.7098, 5.7098, 5.7096, 5.7097, 5.7097, 5.7097, 5.7096, 5.7096, 5.7098,\n",
      "        5.7098, 5.7097, 5.7096, 5.7099, 5.7097, 5.7098, 5.7098, 5.7098, 5.7096,\n",
      "        5.7096, 5.7095, 5.7096, 5.7097, 5.7097, 5.7097, 5.7097, 5.7097, 5.7097,\n",
      "        5.7097, 5.7096, 5.7098, 5.7097, 5.7097, 5.7096, 5.7097, 5.7096, 5.7096,\n",
      "        5.7097, 5.7097, 5.7098, 5.7101, 5.7100, 5.7097, 5.7101, 5.7099, 5.7099,\n",
      "        5.7101, 5.7098, 5.7099, 5.7098, 5.7098, 5.7100, 5.7097, 5.7098, 5.7099,\n",
      "        5.7097, 5.7097, 5.7098, 5.7097, 5.7098, 5.7097, 5.7097, 5.7099, 5.7099,\n",
      "        5.7098, 5.7097, 5.7096, 5.7097, 5.7095, 5.7098, 5.7097, 5.7097, 5.7098,\n",
      "        5.7097, 5.7097, 5.7098, 5.7095, 5.7096, 5.7096, 5.7097, 5.7098, 5.7097,\n",
      "        5.7099, 5.7097, 5.7097, 5.7098, 5.7099, 5.7099, 5.7098, 5.7098, 5.7100,\n",
      "        5.7096, 5.7099, 5.7097], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.165624  [1388924/5599865]\n",
      "average delta from current occupancy tensor([5.5089, 5.5084, 5.5085, 5.5087, 5.5091, 5.5086, 5.5086, 5.5083, 5.5086,\n",
      "        5.5088, 5.5089, 5.5088, 5.5084, 5.5086, 5.5083, 5.5084, 5.5085, 5.5084,\n",
      "        5.5085, 5.5087, 5.5088, 5.5086, 5.5088, 5.5090, 5.5091, 5.5090, 5.5089,\n",
      "        5.5086, 5.5090, 5.5092, 5.5093, 5.5091, 5.5091, 5.5090, 5.5092, 5.5092,\n",
      "        5.5094, 5.5091, 5.5091, 5.5089, 5.5090, 5.5093, 5.5089, 5.5090, 5.5092,\n",
      "        5.5091, 5.5090, 5.5087, 5.5085, 5.5084, 5.5086, 5.5084, 5.5084, 5.5086,\n",
      "        5.5086, 5.5087, 5.5088, 5.5087, 5.5088, 5.5090, 5.5087, 5.5087, 5.5087,\n",
      "        5.5091, 5.5090, 5.5089, 5.5090, 5.5091, 5.5091, 5.5092, 5.5092, 5.5092,\n",
      "        5.5093, 5.5094, 5.5094, 5.5092, 5.5092, 5.5093, 5.5090, 5.5092, 5.5091,\n",
      "        5.5092, 5.5092, 5.5094, 5.5093, 5.5095, 5.5094, 5.5093, 5.5093, 5.5091,\n",
      "        5.5091, 5.5092, 5.5092, 5.5091, 5.5091, 5.5091, 5.5092, 5.5090, 5.5091,\n",
      "        5.5089, 5.5088, 5.5090, 5.5091, 5.5089, 5.5087, 5.5089, 5.5090, 5.5089,\n",
      "        5.5091, 5.5089, 5.5088, 5.5089, 5.5090, 5.5090, 5.5092, 5.5092, 5.5092,\n",
      "        5.5088, 5.5087, 5.5084], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.688743  [1401324/5599865]\n",
      "average delta from current occupancy tensor([5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6372, 5.6371,\n",
      "        5.6371, 5.6372, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6372, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371, 5.6371,\n",
      "        5.6371, 5.6371, 5.6371], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.688685  [1413724/5599865]\n",
      "average delta from current occupancy tensor([4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5966, 4.5967, 4.5966, 4.5967,\n",
      "        4.5966, 4.5966, 4.5966, 4.5966, 4.5966, 4.5966, 4.5966, 4.5966, 4.5966,\n",
      "        4.5966, 4.5967, 4.5966, 4.5966, 4.5966, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5966, 4.5966, 4.5966, 4.5966, 4.5966, 4.5966, 4.5967, 4.5966,\n",
      "        4.5966, 4.5967, 4.5966, 4.5966, 4.5966, 4.5967, 4.5967, 4.5966, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967, 4.5967,\n",
      "        4.5966, 4.5967, 4.5967], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.851574  [1426124/5599865]\n",
      "average delta from current occupancy tensor([4.7420, 4.7420, 4.7419, 4.7420, 4.7420, 4.7419, 4.7420, 4.7420, 4.7420,\n",
      "        4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420,\n",
      "        4.7419, 4.7420, 4.7419, 4.7420, 4.7420, 4.7420, 4.7419, 4.7420, 4.7420,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7420, 4.7420, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7419,\n",
      "        4.7420, 4.7420, 4.7419, 4.7420, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7421, 4.7420, 4.7419, 4.7419, 4.7419, 4.7420, 4.7419, 4.7420, 4.7419,\n",
      "        4.7420, 4.7419, 4.7419, 4.7419, 4.7420, 4.7420, 4.7419, 4.7419, 4.7420,\n",
      "        4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7420, 4.7419, 4.7420, 4.7420,\n",
      "        4.7419, 4.7419, 4.7419, 4.7420, 4.7420, 4.7420, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7420, 4.7419, 4.7419, 4.7419, 4.7420, 4.7419, 4.7419, 4.7419,\n",
      "        4.7420, 4.7419, 4.7419, 4.7419, 4.7420, 4.7420, 4.7420, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7420, 4.7419, 4.7419, 4.7420, 4.7419, 4.7419, 4.7419,\n",
      "        4.7420, 4.7420, 4.7419], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.725981  [1438524/5599865]\n",
      "average delta from current occupancy tensor([5.6130, 5.6130, 5.6130, 5.6130, 5.6131, 5.6130, 5.6131, 5.6130, 5.6130,\n",
      "        5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6129, 5.6129, 5.6130, 5.6129,\n",
      "        5.6129, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130,\n",
      "        5.6129, 5.6129, 5.6129, 5.6130, 5.6130, 5.6130, 5.6130, 5.6129, 5.6130,\n",
      "        5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6130,\n",
      "        5.6130, 5.6129, 5.6130, 5.6130, 5.6130, 5.6130, 5.6129, 5.6129, 5.6129,\n",
      "        5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6129,\n",
      "        5.6129, 5.6129, 5.6129, 5.6129, 5.6129, 5.6130, 5.6129, 5.6130, 5.6130,\n",
      "        5.6129, 5.6130, 5.6129, 5.6130, 5.6130, 5.6129, 5.6129, 5.6130, 5.6131,\n",
      "        5.6130, 5.6129, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130,\n",
      "        5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6129, 5.6130, 5.6130,\n",
      "        5.6129, 5.6129, 5.6130, 5.6130, 5.6130, 5.6130, 5.6129, 5.6130, 5.6130,\n",
      "        5.6129, 5.6129, 5.6129, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130, 5.6130,\n",
      "        5.6130, 5.6129, 5.6130], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.039482  [1450924/5599865]\n",
      "average delta from current occupancy tensor([5.6855, 5.6856, 5.6855, 5.6855, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856,\n",
      "        5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856,\n",
      "        5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6855, 5.6856, 5.6855, 5.6856,\n",
      "        5.6856, 5.6856, 5.6855, 5.6855, 5.6856, 5.6855, 5.6856, 5.6855, 5.6856,\n",
      "        5.6856, 5.6855, 5.6856, 5.6856, 5.6855, 5.6856, 5.6856, 5.6856, 5.6856,\n",
      "        5.6856, 5.6855, 5.6855, 5.6855, 5.6856, 5.6856, 5.6855, 5.6856, 5.6856,\n",
      "        5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6855, 5.6856, 5.6855,\n",
      "        5.6856, 5.6855, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6856,\n",
      "        5.6856, 5.6856, 5.6855, 5.6856, 5.6856, 5.6855, 5.6855, 5.6856, 5.6856,\n",
      "        5.6855, 5.6855, 5.6855, 5.6856, 5.6855, 5.6855, 5.6855, 5.6855, 5.6855,\n",
      "        5.6855, 5.6855, 5.6855, 5.6856, 5.6855, 5.6855, 5.6855, 5.6855, 5.6856,\n",
      "        5.6856, 5.6856, 5.6856, 5.6856, 5.6856, 5.6855, 5.6855, 5.6856, 5.6856,\n",
      "        5.6855, 5.6855, 5.6855, 5.6855, 5.6856, 5.6856, 5.6856, 5.6855, 5.6855,\n",
      "        5.6856, 5.6855, 5.6855], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.780045  [1463324/5599865]\n",
      "average delta from current occupancy tensor([4.8471, 4.8470, 4.8471, 4.8471, 4.8470, 4.8470, 4.8470, 4.8470, 4.8470,\n",
      "        4.8470, 4.8470, 4.8470, 4.8470, 4.8470, 4.8471, 4.8470, 4.8470, 4.8471,\n",
      "        4.8470, 4.8470, 4.8470, 4.8470, 4.8470, 4.8471, 4.8471, 4.8471, 4.8471,\n",
      "        4.8470, 4.8470, 4.8470, 4.8471, 4.8471, 4.8471, 4.8470, 4.8471, 4.8470,\n",
      "        4.8470, 4.8470, 4.8469, 4.8470, 4.8470, 4.8470, 4.8470, 4.8470, 4.8470,\n",
      "        4.8470, 4.8470, 4.8470, 4.8471, 4.8471, 4.8470, 4.8471, 4.8470, 4.8470,\n",
      "        4.8471, 4.8471, 4.8471, 4.8470, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471,\n",
      "        4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8472, 4.8472, 4.8472, 4.8471,\n",
      "        4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8472, 4.8471, 4.8471,\n",
      "        4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8472, 4.8471, 4.8471,\n",
      "        4.8472, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471,\n",
      "        4.8470, 4.8470, 4.8470, 4.8471, 4.8471, 4.8470, 4.8470, 4.8470, 4.8470,\n",
      "        4.8471, 4.8470, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471, 4.8471,\n",
      "        4.8471, 4.8470, 4.8470], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.845516  [1475724/5599865]\n",
      "average delta from current occupancy tensor([4.8257, 4.8256, 4.8257, 4.8259, 4.8259, 4.8261, 4.8257, 4.8258, 4.8258,\n",
      "        4.8255, 4.8252, 4.8253, 4.8254, 4.8255, 4.8252, 4.8254, 4.8254, 4.8254,\n",
      "        4.8252, 4.8255, 4.8257, 4.8256, 4.8255, 4.8256, 4.8258, 4.8256, 4.8257,\n",
      "        4.8257, 4.8257, 4.8257, 4.8259, 4.8256, 4.8258, 4.8257, 4.8256, 4.8258,\n",
      "        4.8254, 4.8255, 4.8255, 4.8257, 4.8254, 4.8254, 4.8252, 4.8251, 4.8250,\n",
      "        4.8249, 4.8250, 4.8250, 4.8250, 4.8248, 4.8249, 4.8246, 4.8249, 4.8244,\n",
      "        4.8247, 4.8248, 4.8249, 4.8249, 4.8251, 4.8252, 4.8244, 4.8244, 4.8245,\n",
      "        4.8245, 4.8244, 4.8243, 4.8244, 4.8247, 4.8242, 4.8244, 4.8246, 4.8246,\n",
      "        4.8246, 4.8249, 4.8249, 4.8245, 4.8246, 4.8247, 4.8249, 4.8246, 4.8247,\n",
      "        4.8248, 4.8251, 4.8249, 4.8254, 4.8252, 4.8251, 4.8256, 4.8255, 4.8257,\n",
      "        4.8258, 4.8252, 4.8254, 4.8250, 4.8253, 4.8250, 4.8246, 4.8248, 4.8244,\n",
      "        4.8248, 4.8246, 4.8250, 4.8244, 4.8244, 4.8246, 4.8246, 4.8246, 4.8248,\n",
      "        4.8244, 4.8245, 4.8244, 4.8248, 4.8247, 4.8249, 4.8247, 4.8251, 4.8251,\n",
      "        4.8249, 4.8256, 4.8253], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.169797  [1488124/5599865]\n",
      "average delta from current occupancy tensor([5.3226, 5.3226, 5.3226, 5.3226, 5.3227, 5.3229, 5.3227, 5.3228, 5.3229,\n",
      "        5.3227, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3227,\n",
      "        5.3227, 5.3227, 5.3226, 5.3226, 5.3226, 5.3226, 5.3227, 5.3227, 5.3226,\n",
      "        5.3226, 5.3227, 5.3226, 5.3226, 5.3226, 5.3227, 5.3227, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3227,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.170910  [1500524/5599865]\n",
      "average delta from current occupancy tensor([6.1104, 6.1102, 6.1098, 6.1106, 6.1106, 6.1107, 6.1109, 6.1110, 6.1110,\n",
      "        6.1109, 6.1111, 6.1108, 6.1106, 6.1108, 6.1108, 6.1107, 6.1105, 6.1108,\n",
      "        6.1108, 6.1105, 6.1107, 6.1107, 6.1106, 6.1111, 6.1110, 6.1109, 6.1112,\n",
      "        6.1116, 6.1116, 6.1117, 6.1117, 6.1112, 6.1109, 6.1109, 6.1104, 6.1108,\n",
      "        6.1107, 6.1109, 6.1107, 6.1115, 6.1116, 6.1117, 6.1118, 6.1118, 6.1119,\n",
      "        6.1116, 6.1116, 6.1114, 6.1114, 6.1111, 6.1114, 6.1111, 6.1113, 6.1110,\n",
      "        6.1114, 6.1116, 6.1115, 6.1116, 6.1113, 6.1112, 6.1111, 6.1113, 6.1113,\n",
      "        6.1112, 6.1112, 6.1108, 6.1107, 6.1111, 6.1111, 6.1108, 6.1109, 6.1106,\n",
      "        6.1108, 6.1104, 6.1105, 6.1108, 6.1106, 6.1106, 6.1107, 6.1107, 6.1104,\n",
      "        6.1104, 6.1105, 6.1103, 6.1101, 6.1104, 6.1103, 6.1103, 6.1101, 6.1107,\n",
      "        6.1106, 6.1106, 6.1107, 6.1106, 6.1106, 6.1106, 6.1106, 6.1108, 6.1107,\n",
      "        6.1105, 6.1103, 6.1106, 6.1107, 6.1107, 6.1105, 6.1108, 6.1110, 6.1109,\n",
      "        6.1111, 6.1110, 6.1107, 6.1106, 6.1110, 6.1109, 6.1109, 6.1110, 6.1107,\n",
      "        6.1109, 6.1107, 6.1105], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.691162  [1512924/5599865]\n",
      "average delta from current occupancy tensor([4.5884, 4.5884, 4.5884, 4.5884, 4.5884, 4.5885, 4.5885, 4.5884, 4.5885,\n",
      "        4.5884, 4.5885, 4.5884, 4.5884, 4.5885, 4.5886, 4.5885, 4.5885, 4.5885,\n",
      "        4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5886, 4.5885, 4.5885, 4.5885,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5885, 4.5885, 4.5885,\n",
      "        4.5886, 4.5885, 4.5885, 4.5886, 4.5885, 4.5885, 4.5885, 4.5886, 4.5886,\n",
      "        4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5885, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5886, 4.5886, 4.5885,\n",
      "        4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5885, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5887, 4.5887, 4.5887, 4.5886, 4.5886,\n",
      "        4.5887, 4.5886, 4.5887, 4.5886, 4.5886, 4.5886, 4.5887, 4.5887, 4.5887,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5885, 4.5885, 4.5885,\n",
      "        4.5885, 4.5886, 4.5886, 4.5885, 4.5886, 4.5886, 4.5886, 4.5885, 4.5886,\n",
      "        4.5887, 4.5886, 4.5886], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.948827  [1525324/5599865]\n",
      "average delta from current occupancy tensor([4.7357, 4.7357, 4.7357, 4.7358, 4.7358, 4.7359, 4.7358, 4.7357, 4.7359,\n",
      "        4.7359, 4.7359, 4.7359, 4.7359, 4.7357, 4.7358, 4.7357, 4.7357, 4.7359,\n",
      "        4.7359, 4.7358, 4.7357, 4.7357, 4.7358, 4.7358, 4.7357, 4.7356, 4.7358,\n",
      "        4.7359, 4.7358, 4.7357, 4.7356, 4.7356, 4.7354, 4.7354, 4.7354, 4.7354,\n",
      "        4.7353, 4.7353, 4.7352, 4.7354, 4.7353, 4.7351, 4.7351, 4.7352, 4.7354,\n",
      "        4.7354, 4.7353, 4.7354, 4.7352, 4.7353, 4.7354, 4.7355, 4.7354, 4.7356,\n",
      "        4.7356, 4.7355, 4.7355, 4.7356, 4.7353, 4.7353, 4.7353, 4.7353, 4.7353,\n",
      "        4.7354, 4.7355, 4.7355, 4.7354, 4.7354, 4.7355, 4.7353, 4.7354, 4.7355,\n",
      "        4.7353, 4.7354, 4.7353, 4.7352, 4.7353, 4.7353, 4.7352, 4.7352, 4.7353,\n",
      "        4.7352, 4.7353, 4.7354, 4.7352, 4.7354, 4.7352, 4.7352, 4.7352, 4.7354,\n",
      "        4.7350, 4.7353, 4.7350, 4.7351, 4.7349, 4.7352, 4.7352, 4.7354, 4.7354,\n",
      "        4.7353, 4.7353, 4.7353, 4.7352, 4.7353, 4.7354, 4.7354, 4.7355, 4.7354,\n",
      "        4.7354, 4.7356, 4.7355, 4.7355, 4.7354, 4.7356, 4.7354, 4.7354, 4.7354,\n",
      "        4.7355, 4.7353, 4.7352], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.181864  [1537724/5599865]\n",
      "average delta from current occupancy tensor([5.3636, 5.3636, 5.3635, 5.3636, 5.3636, 5.3636, 5.3635, 5.3636, 5.3636,\n",
      "        5.3637, 5.3637, 5.3637, 5.3639, 5.3638, 5.3640, 5.3639, 5.3638, 5.3638,\n",
      "        5.3638, 5.3638, 5.3637, 5.3636, 5.3636, 5.3636, 5.3637, 5.3637, 5.3636,\n",
      "        5.3636, 5.3636, 5.3636, 5.3637, 5.3636, 5.3636, 5.3638, 5.3637, 5.3636,\n",
      "        5.3635, 5.3636, 5.3638, 5.3636, 5.3638, 5.3635, 5.3637, 5.3637, 5.3636,\n",
      "        5.3636, 5.3636, 5.3635, 5.3637, 5.3636, 5.3637, 5.3638, 5.3637, 5.3638,\n",
      "        5.3636, 5.3635, 5.3636, 5.3636, 5.3637, 5.3637, 5.3635, 5.3636, 5.3636,\n",
      "        5.3636, 5.3637, 5.3637, 5.3637, 5.3636, 5.3636, 5.3638, 5.3635, 5.3636,\n",
      "        5.3637, 5.3636, 5.3635, 5.3634, 5.3634, 5.3635, 5.3635, 5.3635, 5.3636,\n",
      "        5.3635, 5.3636, 5.3635, 5.3635, 5.3637, 5.3636, 5.3636, 5.3635, 5.3636,\n",
      "        5.3636, 5.3636, 5.3635, 5.3636, 5.3636, 5.3635, 5.3637, 5.3637, 5.3637,\n",
      "        5.3638, 5.3637, 5.3637, 5.3638, 5.3637, 5.3636, 5.3638, 5.3637, 5.3638,\n",
      "        5.3637, 5.3638, 5.3637, 5.3637, 5.3637, 5.3635, 5.3637, 5.3637, 5.3636,\n",
      "        5.3637, 5.3637, 5.3637], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.294449  [1550124/5599865]\n",
      "average delta from current occupancy tensor([5.3463, 5.3463, 5.3462, 5.3462, 5.3463, 5.3463, 5.3461, 5.3462, 5.3462,\n",
      "        5.3462, 5.3462, 5.3462, 5.3462, 5.3462, 5.3462, 5.3461, 5.3462, 5.3462,\n",
      "        5.3462, 5.3461, 5.3461, 5.3463, 5.3462, 5.3463, 5.3461, 5.3462, 5.3462,\n",
      "        5.3461, 5.3463, 5.3462, 5.3462, 5.3462, 5.3461, 5.3461, 5.3462, 5.3462,\n",
      "        5.3462, 5.3462, 5.3463, 5.3463, 5.3463, 5.3463, 5.3462, 5.3462, 5.3462,\n",
      "        5.3463, 5.3463, 5.3463, 5.3464, 5.3464, 5.3463, 5.3464, 5.3463, 5.3464,\n",
      "        5.3465, 5.3465, 5.3465, 5.3465, 5.3463, 5.3463, 5.3465, 5.3465, 5.3465,\n",
      "        5.3464, 5.3462, 5.3461, 5.3460, 5.3460, 5.3459, 5.3460, 5.3460, 5.3461,\n",
      "        5.3462, 5.3463, 5.3462, 5.3462, 5.3462, 5.3464, 5.3464, 5.3463, 5.3462,\n",
      "        5.3459, 5.3461, 5.3461, 5.3461, 5.3461, 5.3461, 5.3461, 5.3459, 5.3460,\n",
      "        5.3461, 5.3460, 5.3461, 5.3459, 5.3460, 5.3462, 5.3461, 5.3461, 5.3459,\n",
      "        5.3462, 5.3461, 5.3462, 5.3460, 5.3460, 5.3457, 5.3456, 5.3457, 5.3458,\n",
      "        5.3458, 5.3459, 5.3461, 5.3461, 5.3461, 5.3460, 5.3461, 5.3463, 5.3462,\n",
      "        5.3464, 5.3463, 5.3463], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.189952  [1562524/5599865]\n",
      "average delta from current occupancy tensor([5.1532, 5.1531, 5.1532, 5.1532, 5.1531, 5.1532, 5.1531, 5.1532, 5.1532,\n",
      "        5.1532, 5.1532, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1532, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1532, 5.1531, 5.1532, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1532, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1532, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1530,\n",
      "        5.1530, 5.1530, 5.1531, 5.1530, 5.1530, 5.1530, 5.1531, 5.1530, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531, 5.1531,\n",
      "        5.1531, 5.1531, 5.1531, 5.1530, 5.1531, 5.1531, 5.1530, 5.1531, 5.1530,\n",
      "        5.1530, 5.1530, 5.1530], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.107219  [1574924/5599865]\n",
      "average delta from current occupancy tensor([5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0001, 5.0000, 5.0000, 5.0001, 5.0001,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0001,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0001,\n",
      "        5.0000, 5.0000, 5.0000, 5.0001, 5.0000, 5.0001, 5.0000, 5.0001, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.560890  [1587324/5599865]\n",
      "average delta from current occupancy tensor([5.3973, 5.3973, 5.3973, 5.3973, 5.3974, 5.3974, 5.3973, 5.3973, 5.3973,\n",
      "        5.3972, 5.3972, 5.3973, 5.3973, 5.3973, 5.3973, 5.3973, 5.3974, 5.3974,\n",
      "        5.3973, 5.3974, 5.3975, 5.3974, 5.3973, 5.3973, 5.3973, 5.3972, 5.3974,\n",
      "        5.3973, 5.3973, 5.3973, 5.3972, 5.3973, 5.3973, 5.3974, 5.3973, 5.3973,\n",
      "        5.3973, 5.3972, 5.3970, 5.3969, 5.3973, 5.3971, 5.3974, 5.3974, 5.3971,\n",
      "        5.3972, 5.3971, 5.3975, 5.3974, 5.3973, 5.3973, 5.3974, 5.3972, 5.3972,\n",
      "        5.3974, 5.3974, 5.3974, 5.3973, 5.3974, 5.3974, 5.3975, 5.3974, 5.3975,\n",
      "        5.3973, 5.3973, 5.3973, 5.3973, 5.3975, 5.3975, 5.3974, 5.3975, 5.3974,\n",
      "        5.3973, 5.3974, 5.3974, 5.3976, 5.3975, 5.3976, 5.3976, 5.3974, 5.3976,\n",
      "        5.3974, 5.3974, 5.3974, 5.3974, 5.3974, 5.3974, 5.3975, 5.3975, 5.3976,\n",
      "        5.3974, 5.3975, 5.3975, 5.3974, 5.3975, 5.3975, 5.3975, 5.3976, 5.3976,\n",
      "        5.3976, 5.3975, 5.3975, 5.3975, 5.3975, 5.3974, 5.3974, 5.3974, 5.3975,\n",
      "        5.3973, 5.3974, 5.3974, 5.3974, 5.3974, 5.3975, 5.3975, 5.3975, 5.3976,\n",
      "        5.3976, 5.3976, 5.3975], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.156508  [1599724/5599865]\n",
      "average delta from current occupancy tensor([5.3463, 5.3463, 5.3463, 5.3463, 5.3463, 5.3464, 5.3463, 5.3463, 5.3463,\n",
      "        5.3463, 5.3463, 5.3463, 5.3463, 5.3464, 5.3464, 5.3463, 5.3463, 5.3463,\n",
      "        5.3463, 5.3463, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3464, 5.3463, 5.3464, 5.3463, 5.3463, 5.3464,\n",
      "        5.3463, 5.3463, 5.3464, 5.3463, 5.3464, 5.3463, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3463, 5.3463, 5.3463, 5.3463,\n",
      "        5.3463, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3463, 5.3464, 5.3463, 5.3463,\n",
      "        5.3463, 5.3463, 5.3463, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3463, 5.3464, 5.3464, 5.3463, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.847221  [1612124/5599865]\n",
      "average delta from current occupancy tensor([4.9268, 4.9268, 4.9268, 4.9268, 4.9266, 4.9268, 4.9269, 4.9268, 4.9268,\n",
      "        4.9269, 4.9269, 4.9270, 4.9269, 4.9268, 4.9266, 4.9269, 4.9266, 4.9268,\n",
      "        4.9268, 4.9270, 4.9267, 4.9270, 4.9270, 4.9271, 4.9270, 4.9272, 4.9271,\n",
      "        4.9272, 4.9270, 4.9270, 4.9270, 4.9270, 4.9269, 4.9270, 4.9267, 4.9268,\n",
      "        4.9272, 4.9269, 4.9270, 4.9271, 4.9270, 4.9270, 4.9270, 4.9270, 4.9269,\n",
      "        4.9271, 4.9270, 4.9269, 4.9271, 4.9270, 4.9270, 4.9270, 4.9269, 4.9272,\n",
      "        4.9272, 4.9273, 4.9272, 4.9272, 4.9273, 4.9273, 4.9272, 4.9272, 4.9271,\n",
      "        4.9272, 4.9271, 4.9271, 4.9271, 4.9270, 4.9271, 4.9271, 4.9271, 4.9270,\n",
      "        4.9270, 4.9271, 4.9271, 4.9271, 4.9271, 4.9272, 4.9271, 4.9270, 4.9271,\n",
      "        4.9272, 4.9272, 4.9271, 4.9271, 4.9271, 4.9270, 4.9270, 4.9271, 4.9269,\n",
      "        4.9269, 4.9269, 4.9269, 4.9269, 4.9269, 4.9269, 4.9269, 4.9269, 4.9269,\n",
      "        4.9269, 4.9269, 4.9269, 4.9269, 4.9268, 4.9269, 4.9269, 4.9269, 4.9269,\n",
      "        4.9268, 4.9268, 4.9266, 4.9267, 4.9266, 4.9267, 4.9267, 4.9266, 4.9268,\n",
      "        4.9269, 4.9268, 4.9268], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.127514  [1624524/5599865]\n",
      "average delta from current occupancy tensor([5.1458, 5.1458, 5.1458, 5.1458, 5.1458, 5.1458, 5.1457, 5.1457, 5.1456,\n",
      "        5.1457, 5.1457, 5.1457, 5.1458, 5.1457, 5.1458, 5.1457, 5.1458, 5.1457,\n",
      "        5.1457, 5.1457, 5.1458, 5.1456, 5.1457, 5.1456, 5.1458, 5.1456, 5.1457,\n",
      "        5.1457, 5.1457, 5.1458, 5.1459, 5.1458, 5.1459, 5.1459, 5.1459, 5.1459,\n",
      "        5.1457, 5.1458, 5.1457, 5.1458, 5.1457, 5.1456, 5.1457, 5.1457, 5.1456,\n",
      "        5.1456, 5.1455, 5.1457, 5.1457, 5.1457, 5.1457, 5.1454, 5.1455, 5.1454,\n",
      "        5.1455, 5.1454, 5.1453, 5.1455, 5.1453, 5.1453, 5.1454, 5.1454, 5.1456,\n",
      "        5.1453, 5.1453, 5.1453, 5.1454, 5.1457, 5.1454, 5.1455, 5.1455, 5.1455,\n",
      "        5.1454, 5.1456, 5.1457, 5.1457, 5.1456, 5.1457, 5.1456, 5.1456, 5.1457,\n",
      "        5.1458, 5.1458, 5.1458, 5.1455, 5.1456, 5.1457, 5.1457, 5.1455, 5.1459,\n",
      "        5.1459, 5.1458, 5.1457, 5.1457, 5.1459, 5.1459, 5.1458, 5.1459, 5.1458,\n",
      "        5.1457, 5.1457, 5.1456, 5.1457, 5.1457, 5.1457, 5.1458, 5.1457, 5.1457,\n",
      "        5.1457, 5.1457, 5.1459, 5.1458, 5.1460, 5.1460, 5.1460, 5.1461, 5.1460,\n",
      "        5.1460, 5.1461, 5.1461], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.572957  [1636924/5599865]\n",
      "average delta from current occupancy tensor([4.6448, 4.6448, 4.6448, 4.6450, 4.6449, 4.6449, 4.6449, 4.6448, 4.6448,\n",
      "        4.6448, 4.6449, 4.6449, 4.6449, 4.6448, 4.6450, 4.6450, 4.6449, 4.6449,\n",
      "        4.6448, 4.6448, 4.6448, 4.6448, 4.6449, 4.6448, 4.6450, 4.6448, 4.6449,\n",
      "        4.6449, 4.6449, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6450, 4.6450,\n",
      "        4.6450, 4.6448, 4.6451, 4.6449, 4.6450, 4.6449, 4.6450, 4.6451, 4.6449,\n",
      "        4.6451, 4.6451, 4.6449, 4.6449, 4.6450, 4.6449, 4.6451, 4.6449, 4.6450,\n",
      "        4.6449, 4.6449, 4.6449, 4.6450, 4.6449, 4.6448, 4.6449, 4.6448, 4.6450,\n",
      "        4.6448, 4.6449, 4.6449, 4.6450, 4.6449, 4.6450, 4.6451, 4.6449, 4.6450,\n",
      "        4.6449, 4.6450, 4.6448, 4.6449, 4.6450, 4.6448, 4.6449, 4.6450, 4.6448,\n",
      "        4.6449, 4.6447, 4.6449, 4.6448, 4.6448, 4.6447, 4.6447, 4.6448, 4.6448,\n",
      "        4.6448, 4.6450, 4.6450, 4.6450, 4.6448, 4.6448, 4.6448, 4.6448, 4.6447,\n",
      "        4.6449, 4.6448, 4.6447, 4.6449, 4.6447, 4.6449, 4.6446, 4.6449, 4.6447,\n",
      "        4.6448, 4.6449, 4.6447, 4.6447, 4.6448, 4.6449, 4.6446, 4.6445, 4.6447,\n",
      "        4.6445, 4.6445, 4.6446], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.549822  [1649324/5599865]\n",
      "average delta from current occupancy tensor([4.8463, 4.8461, 4.8464, 4.8461, 4.8461, 4.8461, 4.8461, 4.8461, 4.8461,\n",
      "        4.8461, 4.8463, 4.8462, 4.8461, 4.8461, 4.8462, 4.8461, 4.8462, 4.8462,\n",
      "        4.8462, 4.8463, 4.8461, 4.8462, 4.8461, 4.8461, 4.8462, 4.8460, 4.8461,\n",
      "        4.8462, 4.8461, 4.8461, 4.8461, 4.8461, 4.8462, 4.8461, 4.8462, 4.8464,\n",
      "        4.8460, 4.8461, 4.8461, 4.8463, 4.8459, 4.8461, 4.8462, 4.8463, 4.8461,\n",
      "        4.8464, 4.8463, 4.8461, 4.8461, 4.8461, 4.8461, 4.8464, 4.8462, 4.8462,\n",
      "        4.8461, 4.8460, 4.8463, 4.8462, 4.8462, 4.8461, 4.8461, 4.8463, 4.8462,\n",
      "        4.8464, 4.8463, 4.8463, 4.8463, 4.8462, 4.8463, 4.8464, 4.8463, 4.8463,\n",
      "        4.8463, 4.8464, 4.8464, 4.8463, 4.8462, 4.8462, 4.8462, 4.8462, 4.8462,\n",
      "        4.8462, 4.8462, 4.8463, 4.8463, 4.8463, 4.8462, 4.8462, 4.8462, 4.8463,\n",
      "        4.8462, 4.8462, 4.8462, 4.8462, 4.8462, 4.8461, 4.8462, 4.8461, 4.8462,\n",
      "        4.8460, 4.8461, 4.8461, 4.8460, 4.8460, 4.8460, 4.8461, 4.8461, 4.8462,\n",
      "        4.8461, 4.8462, 4.8461, 4.8461, 4.8462, 4.8462, 4.8462, 4.8461, 4.8462,\n",
      "        4.8461, 4.8461, 4.8461], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.741065  [1661724/5599865]\n",
      "average delta from current occupancy tensor([4.8219, 4.8219, 4.8220, 4.8219, 4.8218, 4.8217, 4.8220, 4.8221, 4.8222,\n",
      "        4.8220, 4.8224, 4.8225, 4.8227, 4.8231, 4.8224, 4.8222, 4.8225, 4.8224,\n",
      "        4.8225, 4.8225, 4.8222, 4.8221, 4.8220, 4.8220, 4.8223, 4.8222, 4.8223,\n",
      "        4.8224, 4.8219, 4.8222, 4.8222, 4.8221, 4.8223, 4.8223, 4.8222, 4.8224,\n",
      "        4.8223, 4.8223, 4.8224, 4.8227, 4.8222, 4.8220, 4.8224, 4.8226, 4.8221,\n",
      "        4.8226, 4.8225, 4.8223, 4.8224, 4.8225, 4.8223, 4.8228, 4.8222, 4.8226,\n",
      "        4.8223, 4.8225, 4.8222, 4.8223, 4.8223, 4.8225, 4.8223, 4.8222, 4.8223,\n",
      "        4.8221, 4.8224, 4.8222, 4.8223, 4.8220, 4.8223, 4.8225, 4.8223, 4.8222,\n",
      "        4.8222, 4.8223, 4.8221, 4.8222, 4.8224, 4.8227, 4.8222, 4.8225, 4.8224,\n",
      "        4.8224, 4.8227, 4.8225, 4.8226, 4.8229, 4.8223, 4.8226, 4.8224, 4.8224,\n",
      "        4.8228, 4.8224, 4.8222, 4.8224, 4.8224, 4.8227, 4.8226, 4.8230, 4.8227,\n",
      "        4.8230, 4.8228, 4.8231, 4.8233, 4.8232, 4.8230, 4.8233, 4.8231, 4.8233,\n",
      "        4.8231, 4.8234, 4.8233, 4.8234, 4.8233, 4.8232, 4.8230, 4.8238, 4.8230,\n",
      "        4.8231, 4.8230, 4.8231], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.069242  [1674124/5599865]\n",
      "average delta from current occupancy tensor([5.0082, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0083, 5.0083,\n",
      "        5.0082, 5.0082, 5.0082, 5.0083, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082,\n",
      "        5.0082, 5.0083, 5.0082, 5.0082, 5.0083, 5.0082, 5.0084, 5.0084, 5.0084,\n",
      "        5.0082, 5.0083, 5.0083, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082,\n",
      "        5.0083, 5.0082, 5.0081, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082, 5.0083,\n",
      "        5.0083, 5.0083, 5.0081, 5.0082, 5.0082, 5.0082, 5.0083, 5.0083, 5.0083,\n",
      "        5.0082, 5.0082, 5.0084, 5.0083, 5.0083, 5.0083, 5.0083, 5.0084, 5.0083,\n",
      "        5.0084, 5.0083, 5.0084, 5.0084, 5.0084, 5.0084, 5.0083, 5.0084, 5.0084,\n",
      "        5.0083, 5.0084, 5.0083, 5.0084, 5.0083, 5.0084, 5.0083, 5.0084, 5.0085,\n",
      "        5.0083, 5.0084, 5.0083, 5.0084, 5.0083, 5.0085, 5.0084, 5.0084, 5.0083,\n",
      "        5.0082, 5.0083, 5.0085, 5.0083, 5.0082, 5.0082, 5.0082, 5.0083, 5.0082,\n",
      "        5.0082, 5.0082, 5.0082, 5.0082, 5.0083, 5.0083, 5.0083, 5.0082, 5.0081,\n",
      "        5.0082, 5.0082, 5.0081, 5.0082, 5.0082, 5.0082, 5.0082, 5.0083, 5.0083,\n",
      "        5.0083, 5.0083, 5.0083], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.301192  [1686524/5599865]\n",
      "average delta from current occupancy tensor([5.5800, 5.5799, 5.5799, 5.5799, 5.5799, 5.5800, 5.5800, 5.5801, 5.5800,\n",
      "        5.5800, 5.5800, 5.5800, 5.5800, 5.5800, 5.5800, 5.5799, 5.5799, 5.5800,\n",
      "        5.5800, 5.5800, 5.5799, 5.5799, 5.5800, 5.5800, 5.5799, 5.5799, 5.5799,\n",
      "        5.5799, 5.5800, 5.5799, 5.5799, 5.5799, 5.5799, 5.5799, 5.5800, 5.5799,\n",
      "        5.5799, 5.5800, 5.5800, 5.5800, 5.5801, 5.5800, 5.5800, 5.5800, 5.5800,\n",
      "        5.5800, 5.5799, 5.5799, 5.5799, 5.5800, 5.5799, 5.5800, 5.5800, 5.5800,\n",
      "        5.5799, 5.5799, 5.5799, 5.5800, 5.5799, 5.5799, 5.5799, 5.5799, 5.5799,\n",
      "        5.5799, 5.5799, 5.5798, 5.5799, 5.5798, 5.5798, 5.5799, 5.5799, 5.5799,\n",
      "        5.5799, 5.5799, 5.5799, 5.5799, 5.5798, 5.5799, 5.5798, 5.5799, 5.5799,\n",
      "        5.5798, 5.5798, 5.5798, 5.5798, 5.5798, 5.5798, 5.5798, 5.5798, 5.5798,\n",
      "        5.5798, 5.5798, 5.5798, 5.5799, 5.5798, 5.5799, 5.5798, 5.5798, 5.5798,\n",
      "        5.5798, 5.5798, 5.5798, 5.5798, 5.5798, 5.5799, 5.5799, 5.5799, 5.5799,\n",
      "        5.5799, 5.5800, 5.5799, 5.5799, 5.5799, 5.5799, 5.5799, 5.5799, 5.5800,\n",
      "        5.5799, 5.5800, 5.5800], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.089990  [1698924/5599865]\n",
      "average delta from current occupancy tensor([5.2669, 5.2667, 5.2666, 5.2667, 5.2667, 5.2668, 5.2667, 5.2667, 5.2667,\n",
      "        5.2664, 5.2663, 5.2664, 5.2664, 5.2662, 5.2663, 5.2662, 5.2663, 5.2665,\n",
      "        5.2665, 5.2665, 5.2665, 5.2665, 5.2666, 5.2666, 5.2665, 5.2668, 5.2669,\n",
      "        5.2667, 5.2667, 5.2668, 5.2666, 5.2665, 5.2664, 5.2665, 5.2664, 5.2663,\n",
      "        5.2662, 5.2662, 5.2662, 5.2662, 5.2663, 5.2663, 5.2661, 5.2664, 5.2666,\n",
      "        5.2665, 5.2668, 5.2665, 5.2665, 5.2664, 5.2664, 5.2665, 5.2665, 5.2667,\n",
      "        5.2665, 5.2663, 5.2663, 5.2663, 5.2663, 5.2663, 5.2664, 5.2664, 5.2664,\n",
      "        5.2665, 5.2665, 5.2666, 5.2666, 5.2666, 5.2665, 5.2664, 5.2663, 5.2661,\n",
      "        5.2662, 5.2662, 5.2662, 5.2662, 5.2661, 5.2662, 5.2662, 5.2661, 5.2662,\n",
      "        5.2662, 5.2662, 5.2663, 5.2663, 5.2663, 5.2663, 5.2663, 5.2663, 5.2662,\n",
      "        5.2663, 5.2662, 5.2662, 5.2662, 5.2661, 5.2662, 5.2663, 5.2662, 5.2662,\n",
      "        5.2664, 5.2662, 5.2662, 5.2664, 5.2662, 5.2666, 5.2666, 5.2664, 5.2663,\n",
      "        5.2664, 5.2665, 5.2667, 5.2667, 5.2666, 5.2666, 5.2667, 5.2668, 5.2668,\n",
      "        5.2667, 5.2668, 5.2669], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.400732  [1711324/5599865]\n",
      "average delta from current occupancy tensor([5.3391, 5.3391, 5.3391, 5.3391, 5.3391, 5.3390, 5.3391, 5.3390, 5.3390,\n",
      "        5.3391, 5.3391, 5.3390, 5.3392, 5.3391, 5.3391, 5.3392, 5.3392, 5.3390,\n",
      "        5.3391, 5.3390, 5.3391, 5.3390, 5.3389, 5.3390, 5.3391, 5.3389, 5.3390,\n",
      "        5.3389, 5.3389, 5.3390, 5.3390, 5.3390, 5.3388, 5.3390, 5.3389, 5.3389,\n",
      "        5.3390, 5.3390, 5.3391, 5.3391, 5.3391, 5.3390, 5.3391, 5.3391, 5.3390,\n",
      "        5.3391, 5.3391, 5.3391, 5.3391, 5.3392, 5.3391, 5.3390, 5.3391, 5.3390,\n",
      "        5.3390, 5.3390, 5.3389, 5.3390, 5.3389, 5.3390, 5.3390, 5.3390, 5.3391,\n",
      "        5.3391, 5.3391, 5.3391, 5.3391, 5.3390, 5.3391, 5.3390, 5.3390, 5.3390,\n",
      "        5.3390, 5.3390, 5.3389, 5.3389, 5.3389, 5.3389, 5.3389, 5.3390, 5.3390,\n",
      "        5.3390, 5.3390, 5.3390, 5.3389, 5.3390, 5.3391, 5.3389, 5.3390, 5.3391,\n",
      "        5.3389, 5.3389, 5.3389, 5.3389, 5.3389, 5.3390, 5.3389, 5.3389, 5.3389,\n",
      "        5.3390, 5.3388, 5.3389, 5.3389, 5.3389, 5.3389, 5.3390, 5.3389, 5.3389,\n",
      "        5.3389, 5.3390, 5.3388, 5.3390, 5.3390, 5.3389, 5.3389, 5.3391, 5.3391,\n",
      "        5.3391, 5.3391, 5.3391], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.086136  [1723724/5599865]\n",
      "average delta from current occupancy tensor([5.0328, 5.0329, 5.0327, 5.0329, 5.0328, 5.0328, 5.0328, 5.0328, 5.0327,\n",
      "        5.0328, 5.0326, 5.0326, 5.0326, 5.0326, 5.0326, 5.0326, 5.0326, 5.0327,\n",
      "        5.0327, 5.0326, 5.0328, 5.0328, 5.0329, 5.0330, 5.0329, 5.0329, 5.0330,\n",
      "        5.0329, 5.0329, 5.0329, 5.0329, 5.0329, 5.0328, 5.0328, 5.0327, 5.0327,\n",
      "        5.0328, 5.0327, 5.0328, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327,\n",
      "        5.0328, 5.0327, 5.0327, 5.0327, 5.0328, 5.0328, 5.0328, 5.0327, 5.0328,\n",
      "        5.0326, 5.0327, 5.0327, 5.0327, 5.0327, 5.0328, 5.0327, 5.0328, 5.0328,\n",
      "        5.0328, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327, 5.0328,\n",
      "        5.0326, 5.0327, 5.0327, 5.0327, 5.0328, 5.0328, 5.0328, 5.0329, 5.0328,\n",
      "        5.0328, 5.0328, 5.0328, 5.0327, 5.0328, 5.0328, 5.0328, 5.0326, 5.0327,\n",
      "        5.0327, 5.0327, 5.0327, 5.0328, 5.0329, 5.0328, 5.0328, 5.0328, 5.0327,\n",
      "        5.0327, 5.0327, 5.0328, 5.0328, 5.0328, 5.0327, 5.0328, 5.0327, 5.0328,\n",
      "        5.0328, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327, 5.0327, 5.0328, 5.0327,\n",
      "        5.0328, 5.0327, 5.0328], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.238828  [1736124/5599865]\n",
      "average delta from current occupancy tensor([5.0974, 5.0974, 5.0974, 5.0974, 5.0974, 5.0974, 5.0974, 5.0974, 5.0974,\n",
      "        5.0974, 5.0974, 5.0975, 5.0975, 5.0975, 5.0974, 5.0975, 5.0974, 5.0974,\n",
      "        5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975,\n",
      "        5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0976, 5.0975, 5.0975, 5.0976,\n",
      "        5.0975, 5.0976, 5.0976, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975,\n",
      "        5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0974, 5.0975, 5.0974, 5.0975,\n",
      "        5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975,\n",
      "        5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0975, 5.0974, 5.0975, 5.0974,\n",
      "        5.0974, 5.0973, 5.0973, 5.0973, 5.0973, 5.0973, 5.0973, 5.0973, 5.0973,\n",
      "        5.0973, 5.0973, 5.0973, 5.0973, 5.0973, 5.0972, 5.0972, 5.0973, 5.0973,\n",
      "        5.0973, 5.0972, 5.0972, 5.0972, 5.0973, 5.0973, 5.0973, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0974, 5.0972, 5.0974, 5.0972, 5.0974, 5.0974, 5.0974,\n",
      "        5.0972, 5.0973, 5.0973, 5.0974, 5.0973, 5.0973, 5.0973, 5.0973, 5.0973,\n",
      "        5.0972, 5.0972, 5.0972], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.895968  [1748524/5599865]\n",
      "average delta from current occupancy tensor([5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163,\n",
      "        5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163,\n",
      "        5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163,\n",
      "        5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163,\n",
      "        5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0162, 5.0163,\n",
      "        5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0163, 5.0162, 5.0163,\n",
      "        5.0163, 5.0163, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0161,\n",
      "        5.0161, 5.0161, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0161, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.078494  [1760924/5599865]\n",
      "average delta from current occupancy tensor([5.9765, 5.9765, 5.9765, 5.9766, 5.9766, 5.9765, 5.9765, 5.9763, 5.9764,\n",
      "        5.9762, 5.9761, 5.9762, 5.9764, 5.9762, 5.9759, 5.9759, 5.9761, 5.9763,\n",
      "        5.9763, 5.9763, 5.9760, 5.9759, 5.9760, 5.9760, 5.9759, 5.9760, 5.9761,\n",
      "        5.9760, 5.9760, 5.9761, 5.9761, 5.9761, 5.9763, 5.9761, 5.9760, 5.9762,\n",
      "        5.9762, 5.9759, 5.9760, 5.9759, 5.9761, 5.9760, 5.9761, 5.9760, 5.9760,\n",
      "        5.9760, 5.9762, 5.9761, 5.9761, 5.9763, 5.9763, 5.9762, 5.9762, 5.9762,\n",
      "        5.9765, 5.9764, 5.9765, 5.9764, 5.9764, 5.9764, 5.9763, 5.9764, 5.9766,\n",
      "        5.9766, 5.9765, 5.9766, 5.9765, 5.9766, 5.9767, 5.9767, 5.9766, 5.9767,\n",
      "        5.9767, 5.9768, 5.9766, 5.9767, 5.9767, 5.9766, 5.9766, 5.9766, 5.9767,\n",
      "        5.9767, 5.9765, 5.9767, 5.9766, 5.9768, 5.9767, 5.9767, 5.9767, 5.9766,\n",
      "        5.9768, 5.9767, 5.9768, 5.9769, 5.9768, 5.9766, 5.9767, 5.9766, 5.9767,\n",
      "        5.9768, 5.9768, 5.9767, 5.9767, 5.9767, 5.9768, 5.9768, 5.9768, 5.9768,\n",
      "        5.9768, 5.9768, 5.9768, 5.9768, 5.9767, 5.9768, 5.9768, 5.9769, 5.9768,\n",
      "        5.9766, 5.9766, 5.9769], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.961264  [1773324/5599865]\n",
      "average delta from current occupancy tensor([5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0641, 5.0641,\n",
      "        5.0641, 5.0642, 5.0641, 5.0642, 5.0641, 5.0641, 5.0641, 5.0642, 5.0641,\n",
      "        5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0641, 5.0641, 5.0642, 5.0641, 5.0641, 5.0641, 5.0642, 5.0642, 5.0642,\n",
      "        5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642,\n",
      "        5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0642, 5.0641,\n",
      "        5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0642, 5.0641, 5.0642, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0640, 5.0640, 5.0640, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0641, 5.0641, 5.0641, 5.0641, 5.0640, 5.0641, 5.0641, 5.0641, 5.0641,\n",
      "        5.0640, 5.0641, 5.0641], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.779120  [1785724/5599865]\n",
      "average delta from current occupancy tensor([4.9289, 4.9289, 4.9289, 4.9289, 4.9290, 4.9290, 4.9290, 4.9289, 4.9289,\n",
      "        4.9290, 4.9289, 4.9289, 4.9288, 4.9289, 4.9290, 4.9288, 4.9287, 4.9286,\n",
      "        4.9287, 4.9287, 4.9288, 4.9288, 4.9288, 4.9287, 4.9288, 4.9289, 4.9289,\n",
      "        4.9289, 4.9288, 4.9288, 4.9288, 4.9289, 4.9289, 4.9290, 4.9291, 4.9290,\n",
      "        4.9290, 4.9291, 4.9290, 4.9290, 4.9290, 4.9292, 4.9290, 4.9291, 4.9291,\n",
      "        4.9290, 4.9292, 4.9291, 4.9293, 4.9293, 4.9292, 4.9290, 4.9291, 4.9290,\n",
      "        4.9291, 4.9290, 4.9290, 4.9290, 4.9289, 4.9289, 4.9289, 4.9289, 4.9287,\n",
      "        4.9288, 4.9287, 4.9287, 4.9288, 4.9287, 4.9288, 4.9288, 4.9290, 4.9291,\n",
      "        4.9291, 4.9291, 4.9292, 4.9291, 4.9292, 4.9293, 4.9291, 4.9290, 4.9289,\n",
      "        4.9288, 4.9289, 4.9288, 4.9289, 4.9288, 4.9289, 4.9289, 4.9287, 4.9287,\n",
      "        4.9290, 4.9291, 4.9291, 4.9290, 4.9288, 4.9288, 4.9288, 4.9289, 4.9290,\n",
      "        4.9290, 4.9288, 4.9289, 4.9289, 4.9289, 4.9290, 4.9289, 4.9290, 4.9290,\n",
      "        4.9288, 4.9290, 4.9289, 4.9290, 4.9291, 4.9290, 4.9290, 4.9291, 4.9291,\n",
      "        4.9292, 4.9290, 4.9289], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.362435  [1798124/5599865]\n",
      "average delta from current occupancy tensor([5.2844, 5.2838, 5.2839, 5.2836, 5.2841, 5.2842, 5.2842, 5.2841, 5.2841,\n",
      "        5.2841, 5.2841, 5.2842, 5.2840, 5.2841, 5.2839, 5.2840, 5.2842, 5.2845,\n",
      "        5.2842, 5.2841, 5.2837, 5.2839, 5.2840, 5.2839, 5.2842, 5.2841, 5.2841,\n",
      "        5.2839, 5.2841, 5.2840, 5.2838, 5.2839, 5.2837, 5.2841, 5.2844, 5.2842,\n",
      "        5.2841, 5.2843, 5.2841, 5.2842, 5.2841, 5.2846, 5.2843, 5.2846, 5.2845,\n",
      "        5.2844, 5.2842, 5.2844, 5.2845, 5.2844, 5.2847, 5.2848, 5.2848, 5.2845,\n",
      "        5.2846, 5.2844, 5.2846, 5.2845, 5.2845, 5.2845, 5.2844, 5.2848, 5.2847,\n",
      "        5.2847, 5.2847, 5.2846, 5.2846, 5.2847, 5.2850, 5.2849, 5.2849, 5.2849,\n",
      "        5.2848, 5.2852, 5.2853, 5.2851, 5.2855, 5.2853, 5.2852, 5.2852, 5.2852,\n",
      "        5.2853, 5.2848, 5.2847, 5.2849, 5.2848, 5.2850, 5.2848, 5.2846, 5.2850,\n",
      "        5.2849, 5.2848, 5.2846, 5.2846, 5.2846, 5.2845, 5.2846, 5.2846, 5.2846,\n",
      "        5.2843, 5.2843, 5.2844, 5.2843, 5.2842, 5.2843, 5.2841, 5.2841, 5.2837,\n",
      "        5.2842, 5.2841, 5.2842, 5.2845, 5.2847, 5.2849, 5.2848, 5.2847, 5.2844,\n",
      "        5.2845, 5.2849, 5.2848], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.151366  [1810524/5599865]\n",
      "average delta from current occupancy tensor([5.2508, 5.2504, 5.2505, 5.2504, 5.2506, 5.2506, 5.2507, 5.2506, 5.2506,\n",
      "        5.2506, 5.2507, 5.2508, 5.2506, 5.2508, 5.2506, 5.2507, 5.2508, 5.2508,\n",
      "        5.2508, 5.2506, 5.2507, 5.2506, 5.2506, 5.2506, 5.2506, 5.2506, 5.2507,\n",
      "        5.2505, 5.2506, 5.2507, 5.2506, 5.2506, 5.2506, 5.2506, 5.2506, 5.2507,\n",
      "        5.2506, 5.2506, 5.2505, 5.2505, 5.2506, 5.2507, 5.2507, 5.2508, 5.2508,\n",
      "        5.2506, 5.2507, 5.2507, 5.2507, 5.2507, 5.2505, 5.2504, 5.2505, 5.2506,\n",
      "        5.2506, 5.2506, 5.2506, 5.2505, 5.2505, 5.2505, 5.2505, 5.2503, 5.2505,\n",
      "        5.2506, 5.2506, 5.2506, 5.2506, 5.2505, 5.2505, 5.2504, 5.2504, 5.2504,\n",
      "        5.2505, 5.2504, 5.2503, 5.2502, 5.2502, 5.2503, 5.2504, 5.2504, 5.2504,\n",
      "        5.2505, 5.2506, 5.2505, 5.2505, 5.2506, 5.2505, 5.2505, 5.2506, 5.2506,\n",
      "        5.2505, 5.2506, 5.2506, 5.2505, 5.2505, 5.2505, 5.2506, 5.2506, 5.2505,\n",
      "        5.2503, 5.2503, 5.2506, 5.2504, 5.2504, 5.2504, 5.2504, 5.2504, 5.2505,\n",
      "        5.2504, 5.2505, 5.2504, 5.2505, 5.2506, 5.2504, 5.2505, 5.2506, 5.2506,\n",
      "        5.2505, 5.2505, 5.2505], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.352829  [1822924/5599865]\n",
      "average delta from current occupancy tensor([5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.516681  [1835324/5599865]\n",
      "average delta from current occupancy tensor([5.4933, 5.4934, 5.4931, 5.4933, 5.4932, 5.4930, 5.4932, 5.4934, 5.4933,\n",
      "        5.4936, 5.4936, 5.4937, 5.4938, 5.4936, 5.4936, 5.4936, 5.4936, 5.4935,\n",
      "        5.4937, 5.4935, 5.4935, 5.4936, 5.4935, 5.4934, 5.4933, 5.4935, 5.4935,\n",
      "        5.4935, 5.4937, 5.4935, 5.4934, 5.4934, 5.4934, 5.4934, 5.4934, 5.4936,\n",
      "        5.4934, 5.4935, 5.4933, 5.4935, 5.4932, 5.4934, 5.4933, 5.4934, 5.4934,\n",
      "        5.4933, 5.4932, 5.4931, 5.4932, 5.4930, 5.4930, 5.4929, 5.4930, 5.4929,\n",
      "        5.4929, 5.4930, 5.4928, 5.4928, 5.4929, 5.4928, 5.4929, 5.4927, 5.4927,\n",
      "        5.4927, 5.4926, 5.4927, 5.4927, 5.4927, 5.4929, 5.4928, 5.4930, 5.4930,\n",
      "        5.4931, 5.4930, 5.4929, 5.4929, 5.4929, 5.4930, 5.4930, 5.4930, 5.4931,\n",
      "        5.4931, 5.4932, 5.4930, 5.4930, 5.4931, 5.4930, 5.4931, 5.4930, 5.4930,\n",
      "        5.4931, 5.4930, 5.4928, 5.4930, 5.4929, 5.4927, 5.4929, 5.4929, 5.4928,\n",
      "        5.4928, 5.4926, 5.4926, 5.4926, 5.4926, 5.4926, 5.4926, 5.4927, 5.4926,\n",
      "        5.4926, 5.4926, 5.4928, 5.4926, 5.4928, 5.4929, 5.4927, 5.4927, 5.4927,\n",
      "        5.4928, 5.4927, 5.4929], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.143180  [1847724/5599865]\n",
      "average delta from current occupancy tensor([5.2902, 5.2901, 5.2902, 5.2901, 5.2902, 5.2902, 5.2903, 5.2901, 5.2902,\n",
      "        5.2901, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2903, 5.2902,\n",
      "        5.2903, 5.2904, 5.2902, 5.2902, 5.2902, 5.2901, 5.2901, 5.2902, 5.2901,\n",
      "        5.2901, 5.2902, 5.2901, 5.2901, 5.2901, 5.2902, 5.2903, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2903, 5.2902, 5.2902, 5.2902, 5.2902, 5.2903, 5.2904,\n",
      "        5.2903, 5.2904, 5.2904, 5.2904, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903,\n",
      "        5.2902, 5.2902, 5.2903, 5.2903, 5.2902, 5.2902, 5.2903, 5.2903, 5.2902,\n",
      "        5.2902, 5.2903, 5.2903, 5.2902, 5.2903, 5.2903, 5.2903, 5.2902, 5.2902,\n",
      "        5.2903, 5.2902, 5.2902, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903,\n",
      "        5.2903, 5.2903, 5.2902, 5.2903, 5.2903, 5.2903, 5.2904, 5.2903, 5.2903,\n",
      "        5.2903, 5.2904, 5.2903], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.123697  [1860124/5599865]\n",
      "average delta from current occupancy tensor([6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1049, 6.1049, 6.1048, 6.1048, 6.1049,\n",
      "        6.1049, 6.1048, 6.1049, 6.1049, 6.1048, 6.1049, 6.1049, 6.1050, 6.1051,\n",
      "        6.1050, 6.1049, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1049,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1049, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1049,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1049, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048,\n",
      "        6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1048, 6.1050,\n",
      "        6.1050, 6.1048, 6.1048], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.445313  [1872524/5599865]\n",
      "average delta from current occupancy tensor([5.5568, 5.5568, 5.5568, 5.5569, 5.5570, 5.5569, 5.5570, 5.5569, 5.5573,\n",
      "        5.5571, 5.5573, 5.5571, 5.5571, 5.5570, 5.5570, 5.5572, 5.5575, 5.5573,\n",
      "        5.5574, 5.5573, 5.5571, 5.5570, 5.5569, 5.5572, 5.5569, 5.5569, 5.5574,\n",
      "        5.5571, 5.5570, 5.5573, 5.5573, 5.5571, 5.5573, 5.5574, 5.5571, 5.5574,\n",
      "        5.5569, 5.5570, 5.5572, 5.5568, 5.5569, 5.5569, 5.5569, 5.5571, 5.5569,\n",
      "        5.5570, 5.5570, 5.5570, 5.5570, 5.5568, 5.5570, 5.5569, 5.5569, 5.5569,\n",
      "        5.5569, 5.5569, 5.5569, 5.5569, 5.5569, 5.5567, 5.5568, 5.5569, 5.5567,\n",
      "        5.5569, 5.5568, 5.5567, 5.5568, 5.5570, 5.5570, 5.5570, 5.5571, 5.5570,\n",
      "        5.5568, 5.5570, 5.5571, 5.5570, 5.5569, 5.5570, 5.5570, 5.5570, 5.5570,\n",
      "        5.5570, 5.5571, 5.5571, 5.5570, 5.5571, 5.5568, 5.5571, 5.5571, 5.5569,\n",
      "        5.5570, 5.5570, 5.5571, 5.5570, 5.5570, 5.5571, 5.5571, 5.5571, 5.5569,\n",
      "        5.5569, 5.5571, 5.5571, 5.5571, 5.5571, 5.5571, 5.5569, 5.5571, 5.5571,\n",
      "        5.5572, 5.5571, 5.5571, 5.5572, 5.5571, 5.5571, 5.5571, 5.5572, 5.5572,\n",
      "        5.5572, 5.5572, 5.5572], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.242160  [1884924/5599865]\n",
      "average delta from current occupancy tensor([5.2337, 5.2337, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2337, 5.2337, 5.2337, 5.2337, 5.2337, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2337, 5.2337, 5.2338, 5.2337, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2339, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2339, 5.2339, 5.2340, 5.2339, 5.2338,\n",
      "        5.2339, 5.2339, 5.2339, 5.2339, 5.2338, 5.2340, 5.2339, 5.2341, 5.2340,\n",
      "        5.2339, 5.2340, 5.2341, 5.2340, 5.2339, 5.2341, 5.2340, 5.2339, 5.2340,\n",
      "        5.2339, 5.2339, 5.2339, 5.2341, 5.2341, 5.2341, 5.2341, 5.2342, 5.2342,\n",
      "        5.2343, 5.2340, 5.2339, 5.2339, 5.2339, 5.2340, 5.2341, 5.2338, 5.2340,\n",
      "        5.2341, 5.2342, 5.2342, 5.2343, 5.2341, 5.2341, 5.2341, 5.2342, 5.2341,\n",
      "        5.2342, 5.2341, 5.2341], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.664198  [1897324/5599865]\n",
      "average delta from current occupancy tensor([4.6933, 4.6930, 4.6928, 4.6930, 4.6928, 4.6927, 4.6929, 4.6928, 4.6930,\n",
      "        4.6929, 4.6931, 4.6934, 4.6934, 4.6935, 4.6939, 4.6938, 4.6936, 4.6933,\n",
      "        4.6931, 4.6933, 4.6935, 4.6930, 4.6931, 4.6933, 4.6930, 4.6928, 4.6930,\n",
      "        4.6929, 4.6934, 4.6931, 4.6929, 4.6928, 4.6929, 4.6931, 4.6928, 4.6927,\n",
      "        4.6929, 4.6927, 4.6932, 4.6929, 4.6931, 4.6932, 4.6930, 4.6927, 4.6928,\n",
      "        4.6930, 4.6930, 4.6930, 4.6933, 4.6929, 4.6929, 4.6931, 4.6927, 4.6927,\n",
      "        4.6933, 4.6928, 4.6931, 4.6932, 4.6928, 4.6930, 4.6930, 4.6928, 4.6932,\n",
      "        4.6927, 4.6925, 4.6930, 4.6931, 4.6930, 4.6930, 4.6929, 4.6928, 4.6931,\n",
      "        4.6932, 4.6931, 4.6932, 4.6933, 4.6930, 4.6927, 4.6928, 4.6929, 4.6927,\n",
      "        4.6930, 4.6929, 4.6929, 4.6931, 4.6932, 4.6933, 4.6936, 4.6933, 4.6938,\n",
      "        4.6932, 4.6931, 4.6938, 4.6935, 4.6930, 4.6937, 4.6935, 4.6937, 4.6938,\n",
      "        4.6935, 4.6933, 4.6936, 4.6931, 4.6931, 4.6934, 4.6931, 4.6933, 4.6933,\n",
      "        4.6933, 4.6932, 4.6933, 4.6934, 4.6934, 4.6933, 4.6934, 4.6936, 4.6942,\n",
      "        4.6940, 4.6942, 4.6942], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.108810  [1909724/5599865]\n",
      "average delta from current occupancy tensor([5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6613, 5.6613, 5.6613, 5.6613,\n",
      "        5.6613, 5.6614, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613,\n",
      "        5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613,\n",
      "        5.6613, 5.6613, 5.6613, 5.6613, 5.6614, 5.6614, 5.6614, 5.6614, 5.6613,\n",
      "        5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613,\n",
      "        5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614,\n",
      "        5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6613, 5.6614, 5.6614, 5.6613,\n",
      "        5.6614, 5.6613, 5.6614, 5.6613, 5.6613, 5.6614, 5.6614, 5.6614, 5.6615,\n",
      "        5.6614, 5.6615, 5.6615, 5.6615, 5.6615, 5.6615, 5.6615, 5.6615, 5.6615,\n",
      "        5.6615, 5.6615, 5.6614, 5.6615, 5.6615, 5.6615, 5.6615, 5.6615, 5.6614,\n",
      "        5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6615, 5.6614, 5.6614, 5.6614,\n",
      "        5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6615, 5.6614, 5.6614, 5.6614,\n",
      "        5.6614, 5.6614, 5.6614, 5.6613, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614,\n",
      "        5.6614, 5.6614, 5.6614], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.517110  [1922124/5599865]\n",
      "average delta from current occupancy tensor([5.6778, 5.6779, 5.6778, 5.6777, 5.6779, 5.6778, 5.6778, 5.6778, 5.6778,\n",
      "        5.6779, 5.6777, 5.6777, 5.6777, 5.6777, 5.6777, 5.6780, 5.6776, 5.6780,\n",
      "        5.6779, 5.6779, 5.6780, 5.6778, 5.6778, 5.6776, 5.6777, 5.6777, 5.6777,\n",
      "        5.6776, 5.6777, 5.6776, 5.6777, 5.6779, 5.6779, 5.6778, 5.6777, 5.6779,\n",
      "        5.6779, 5.6777, 5.6779, 5.6778, 5.6777, 5.6779, 5.6779, 5.6779, 5.6779,\n",
      "        5.6779, 5.6780, 5.6780, 5.6780, 5.6779, 5.6779, 5.6779, 5.6779, 5.6779,\n",
      "        5.6779, 5.6778, 5.6778, 5.6779, 5.6778, 5.6779, 5.6779, 5.6780, 5.6779,\n",
      "        5.6779, 5.6779, 5.6779, 5.6779, 5.6780, 5.6779, 5.6779, 5.6780, 5.6780,\n",
      "        5.6781, 5.6781, 5.6781, 5.6780, 5.6780, 5.6780, 5.6781, 5.6781, 5.6782,\n",
      "        5.6779, 5.6782, 5.6782, 5.6782, 5.6781, 5.6781, 5.6781, 5.6781, 5.6781,\n",
      "        5.6779, 5.6780, 5.6780, 5.6779, 5.6782, 5.6779, 5.6778, 5.6780, 5.6779,\n",
      "        5.6781, 5.6777, 5.6778, 5.6779, 5.6778, 5.6778, 5.6780, 5.6780, 5.6778,\n",
      "        5.6780, 5.6779, 5.6780, 5.6779, 5.6780, 5.6780, 5.6780, 5.6780, 5.6780,\n",
      "        5.6780, 5.6780, 5.6777], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.793971  [1934524/5599865]\n",
      "average delta from current occupancy tensor([5.9129, 5.9129, 5.9130, 5.9128, 5.9127, 5.9127, 5.9129, 5.9128, 5.9125,\n",
      "        5.9126, 5.9128, 5.9128, 5.9125, 5.9125, 5.9126, 5.9128, 5.9126, 5.9127,\n",
      "        5.9125, 5.9126, 5.9126, 5.9124, 5.9127, 5.9125, 5.9126, 5.9127, 5.9125,\n",
      "        5.9127, 5.9129, 5.9127, 5.9130, 5.9128, 5.9125, 5.9126, 5.9128, 5.9125,\n",
      "        5.9128, 5.9126, 5.9125, 5.9124, 5.9126, 5.9125, 5.9124, 5.9124, 5.9124,\n",
      "        5.9126, 5.9125, 5.9124, 5.9125, 5.9125, 5.9125, 5.9124, 5.9123, 5.9123,\n",
      "        5.9123, 5.9126, 5.9126, 5.9123, 5.9124, 5.9124, 5.9122, 5.9125, 5.9122,\n",
      "        5.9124, 5.9123, 5.9123, 5.9124, 5.9124, 5.9122, 5.9124, 5.9122, 5.9123,\n",
      "        5.9124, 5.9125, 5.9123, 5.9123, 5.9123, 5.9124, 5.9126, 5.9126, 5.9125,\n",
      "        5.9123, 5.9124, 5.9124, 5.9127, 5.9124, 5.9126, 5.9127, 5.9126, 5.9127,\n",
      "        5.9125, 5.9122, 5.9125, 5.9124, 5.9126, 5.9126, 5.9126, 5.9126, 5.9126,\n",
      "        5.9125, 5.9125, 5.9126, 5.9124, 5.9123, 5.9126, 5.9126, 5.9127, 5.9125,\n",
      "        5.9126, 5.9123, 5.9127, 5.9124, 5.9128, 5.9127, 5.9129, 5.9127, 5.9131,\n",
      "        5.9131, 5.9130, 5.9126], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.037093  [1946924/5599865]\n",
      "average delta from current occupancy tensor([5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161,\n",
      "        5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0160, 5.0161, 5.0161,\n",
      "        5.0161, 5.0161, 5.0161, 5.0161, 5.0160, 5.0161, 5.0160, 5.0160, 5.0161,\n",
      "        5.0160, 5.0160, 5.0160, 5.0161, 5.0160, 5.0160, 5.0160, 5.0161, 5.0160,\n",
      "        5.0160, 5.0160, 5.0160, 5.0161, 5.0160, 5.0160, 5.0160, 5.0161, 5.0160,\n",
      "        5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0160, 5.0161,\n",
      "        5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0160, 5.0161, 5.0161, 5.0161,\n",
      "        5.0161, 5.0161, 5.0161, 5.0162, 5.0162, 5.0161, 5.0161, 5.0161, 5.0161,\n",
      "        5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0162, 5.0162, 5.0161, 5.0162,\n",
      "        5.0163, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0163, 5.0162, 5.0162,\n",
      "        5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161, 5.0161,\n",
      "        5.0161, 5.0162, 5.0161, 5.0161, 5.0162, 5.0162, 5.0161, 5.0163, 5.0161,\n",
      "        5.0161, 5.0162, 5.0162, 5.0163, 5.0162, 5.0162, 5.0161, 5.0161, 5.0161,\n",
      "        5.0161, 5.0161, 5.0161], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.315539  [1959324/5599865]\n",
      "average delta from current occupancy tensor([5.2248, 5.2248, 5.2248, 5.2247, 5.2248, 5.2249, 5.2248, 5.2248, 5.2248,\n",
      "        5.2248, 5.2248, 5.2249, 5.2248, 5.2248, 5.2249, 5.2248, 5.2249, 5.2248,\n",
      "        5.2247, 5.2247, 5.2247, 5.2247, 5.2248, 5.2248, 5.2247, 5.2248, 5.2247,\n",
      "        5.2247, 5.2247, 5.2247, 5.2246, 5.2247, 5.2246, 5.2248, 5.2248, 5.2248,\n",
      "        5.2248, 5.2248, 5.2248, 5.2249, 5.2248, 5.2249, 5.2249, 5.2249, 5.2249,\n",
      "        5.2248, 5.2247, 5.2248, 5.2248, 5.2248, 5.2247, 5.2246, 5.2247, 5.2246,\n",
      "        5.2246, 5.2246, 5.2245, 5.2245, 5.2246, 5.2246, 5.2246, 5.2246, 5.2246,\n",
      "        5.2246, 5.2246, 5.2246, 5.2246, 5.2246, 5.2245, 5.2246, 5.2246, 5.2246,\n",
      "        5.2246, 5.2246, 5.2246, 5.2246, 5.2246, 5.2246, 5.2246, 5.2245, 5.2246,\n",
      "        5.2246, 5.2246, 5.2246, 5.2246, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247,\n",
      "        5.2246, 5.2247, 5.2246, 5.2247, 5.2246, 5.2248, 5.2247, 5.2247, 5.2247,\n",
      "        5.2247, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247, 5.2248, 5.2248,\n",
      "        5.2248, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247, 5.2247,\n",
      "        5.2247, 5.2247, 5.2246], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.718630  [1971724/5599865]\n",
      "average delta from current occupancy tensor([5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0485, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.966393  [1984124/5599865]\n",
      "average delta from current occupancy tensor([5.9341, 5.9341, 5.9339, 5.9338, 5.9335, 5.9339, 5.9337, 5.9336, 5.9337,\n",
      "        5.9339, 5.9337, 5.9338, 5.9339, 5.9339, 5.9335, 5.9340, 5.9342, 5.9339,\n",
      "        5.9330, 5.9337, 5.9336, 5.9334, 5.9338, 5.9336, 5.9337, 5.9337, 5.9340,\n",
      "        5.9334, 5.9338, 5.9338, 5.9335, 5.9337, 5.9334, 5.9337, 5.9333, 5.9334,\n",
      "        5.9332, 5.9335, 5.9333, 5.9339, 5.9340, 5.9342, 5.9334, 5.9341, 5.9338,\n",
      "        5.9340, 5.9336, 5.9339, 5.9335, 5.9331, 5.9337, 5.9333, 5.9336, 5.9334,\n",
      "        5.9338, 5.9335, 5.9330, 5.9332, 5.9330, 5.9330, 5.9329, 5.9331, 5.9329,\n",
      "        5.9325, 5.9323, 5.9321, 5.9326, 5.9329, 5.9330, 5.9331, 5.9327, 5.9333,\n",
      "        5.9331, 5.9331, 5.9332, 5.9336, 5.9333, 5.9335, 5.9331, 5.9332, 5.9327,\n",
      "        5.9331, 5.9330, 5.9327, 5.9328, 5.9329, 5.9325, 5.9328, 5.9329, 5.9331,\n",
      "        5.9328, 5.9331, 5.9333, 5.9335, 5.9335, 5.9334, 5.9339, 5.9338, 5.9335,\n",
      "        5.9331, 5.9335, 5.9337, 5.9341, 5.9342, 5.9343, 5.9345, 5.9341, 5.9343,\n",
      "        5.9345, 5.9343, 5.9342, 5.9342, 5.9347, 5.9345, 5.9346, 5.9347, 5.9343,\n",
      "        5.9341, 5.9342, 5.9338], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.521104  [1996524/5599865]\n",
      "average delta from current occupancy tensor([5.5569, 5.5568, 5.5567, 5.5566, 5.5565, 5.5566, 5.5565, 5.5565, 5.5565,\n",
      "        5.5565, 5.5566, 5.5565, 5.5565, 5.5565, 5.5565, 5.5565, 5.5565, 5.5568,\n",
      "        5.5570, 5.5566, 5.5568, 5.5568, 5.5565, 5.5565, 5.5565, 5.5566, 5.5565,\n",
      "        5.5569, 5.5565, 5.5565, 5.5567, 5.5565, 5.5567, 5.5566, 5.5565, 5.5566,\n",
      "        5.5567, 5.5566, 5.5566, 5.5565, 5.5565, 5.5566, 5.5566, 5.5565, 5.5565,\n",
      "        5.5565, 5.5566, 5.5566, 5.5568, 5.5568, 5.5567, 5.5567, 5.5565, 5.5565,\n",
      "        5.5565, 5.5566, 5.5567, 5.5566, 5.5566, 5.5566, 5.5567, 5.5567, 5.5566,\n",
      "        5.5567, 5.5567, 5.5566, 5.5565, 5.5565, 5.5565, 5.5565, 5.5566, 5.5565,\n",
      "        5.5565, 5.5565, 5.5565, 5.5567, 5.5565, 5.5565, 5.5565, 5.5565, 5.5566,\n",
      "        5.5565, 5.5565, 5.5565, 5.5566, 5.5565, 5.5566, 5.5566, 5.5566, 5.5566,\n",
      "        5.5565, 5.5565, 5.5565, 5.5565, 5.5565, 5.5565, 5.5565, 5.5565, 5.5565,\n",
      "        5.5565, 5.5565, 5.5565, 5.5565, 5.5566, 5.5566, 5.5566, 5.5566, 5.5566,\n",
      "        5.5565, 5.5565, 5.5566, 5.5566, 5.5566, 5.5566, 5.5565, 5.5566, 5.5566,\n",
      "        5.5566, 5.5566, 5.5566], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.322574  [2008924/5599865]\n",
      "average delta from current occupancy tensor([5.2989, 5.2986, 5.2986, 5.2985, 5.2987, 5.2986, 5.2985, 5.2986, 5.2986,\n",
      "        5.2984, 5.2985, 5.2984, 5.2988, 5.2987, 5.2984, 5.2986, 5.2986, 5.2986,\n",
      "        5.2987, 5.2984, 5.2986, 5.2986, 5.2986, 5.2985, 5.2984, 5.2986, 5.2987,\n",
      "        5.2984, 5.2986, 5.2985, 5.2986, 5.2986, 5.2987, 5.2986, 5.2987, 5.2984,\n",
      "        5.2984, 5.2986, 5.2986, 5.2987, 5.2986, 5.2986, 5.2986, 5.2987, 5.2986,\n",
      "        5.2985, 5.2984, 5.2986, 5.2986, 5.2984, 5.2984, 5.2985, 5.2987, 5.2989,\n",
      "        5.2986, 5.2985, 5.2984, 5.2986, 5.2984, 5.2984, 5.2984, 5.2987, 5.2987,\n",
      "        5.2987, 5.2988, 5.2987, 5.2988, 5.2986, 5.2988, 5.2987, 5.2989, 5.2986,\n",
      "        5.2985, 5.2985, 5.2984, 5.2984, 5.2984, 5.2984, 5.2987, 5.2984, 5.2984,\n",
      "        5.2986, 5.2986, 5.2984, 5.2985, 5.2984, 5.2984, 5.2984, 5.2989, 5.2987,\n",
      "        5.2988, 5.2985, 5.2985, 5.2984, 5.2986, 5.2986, 5.2984, 5.2985, 5.2985,\n",
      "        5.2986, 5.2985, 5.2985, 5.2985, 5.2985, 5.2984, 5.2985, 5.2985, 5.2985,\n",
      "        5.2986, 5.2985, 5.2984, 5.2986, 5.2984, 5.2985, 5.2986, 5.2987, 5.2987,\n",
      "        5.2987, 5.2984, 5.2986], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.005101  [2021324/5599865]\n",
      "average delta from current occupancy tensor([5.1127, 5.1125, 5.1125, 5.1126, 5.1127, 5.1125, 5.1130, 5.1125, 5.1126,\n",
      "        5.1127, 5.1126, 5.1127, 5.1125, 5.1126, 5.1128, 5.1127, 5.1128, 5.1128,\n",
      "        5.1126, 5.1128, 5.1127, 5.1131, 5.1128, 5.1128, 5.1128, 5.1126, 5.1125,\n",
      "        5.1124, 5.1126, 5.1126, 5.1124, 5.1124, 5.1124, 5.1124, 5.1124, 5.1125,\n",
      "        5.1126, 5.1124, 5.1126, 5.1122, 5.1123, 5.1123, 5.1124, 5.1124, 5.1125,\n",
      "        5.1128, 5.1128, 5.1127, 5.1128, 5.1127, 5.1125, 5.1124, 5.1127, 5.1126,\n",
      "        5.1125, 5.1124, 5.1124, 5.1125, 5.1124, 5.1123, 5.1124, 5.1126, 5.1124,\n",
      "        5.1125, 5.1126, 5.1125, 5.1127, 5.1124, 5.1129, 5.1126, 5.1127, 5.1125,\n",
      "        5.1126, 5.1130, 5.1125, 5.1126, 5.1124, 5.1126, 5.1125, 5.1125, 5.1125,\n",
      "        5.1124, 5.1124, 5.1125, 5.1124, 5.1125, 5.1124, 5.1124, 5.1124, 5.1125,\n",
      "        5.1125, 5.1124, 5.1125, 5.1123, 5.1122, 5.1124, 5.1124, 5.1124, 5.1125,\n",
      "        5.1124, 5.1125, 5.1127, 5.1125, 5.1126, 5.1125, 5.1125, 5.1126, 5.1126,\n",
      "        5.1126, 5.1126, 5.1127, 5.1128, 5.1128, 5.1127, 5.1127, 5.1128, 5.1128,\n",
      "        5.1130, 5.1127, 5.1127], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.569617  [2033724/5599865]\n",
      "average delta from current occupancy tensor([5.4355, 5.4357, 5.4357, 5.4355, 5.4355, 5.4356, 5.4355, 5.4358, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4357, 5.4356, 5.4357, 5.4356, 5.4357, 5.4357,\n",
      "        5.4357, 5.4357, 5.4355, 5.4356, 5.4355, 5.4356, 5.4356, 5.4355, 5.4356,\n",
      "        5.4356, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4356, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4356, 5.4356, 5.4356, 5.4356, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4356, 5.4355,\n",
      "        5.4355, 5.4356, 5.4356, 5.4355, 5.4356, 5.4356, 5.4356, 5.4355, 5.4355,\n",
      "        5.4356, 5.4355, 5.4356, 5.4355, 5.4356, 5.4356, 5.4356, 5.4356, 5.4356,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4356, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4356, 5.4355, 5.4355, 5.4356, 5.4356, 5.4356, 5.4355,\n",
      "        5.4355, 5.4356, 5.4355, 5.4355, 5.4355, 5.4356, 5.4355, 5.4355, 5.4356,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4356, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4356, 5.4355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.082919  [2046124/5599865]\n",
      "average delta from current occupancy tensor([5.3553, 5.3554, 5.3553, 5.3552, 5.3552, 5.3551, 5.3553, 5.3552, 5.3552,\n",
      "        5.3551, 5.3553, 5.3553, 5.3553, 5.3553, 5.3553, 5.3552, 5.3552, 5.3552,\n",
      "        5.3552, 5.3552, 5.3551, 5.3552, 5.3552, 5.3550, 5.3552, 5.3552, 5.3552,\n",
      "        5.3553, 5.3552, 5.3552, 5.3552, 5.3552, 5.3552, 5.3552, 5.3553, 5.3552,\n",
      "        5.3552, 5.3552, 5.3552, 5.3551, 5.3552, 5.3552, 5.3553, 5.3553, 5.3553,\n",
      "        5.3552, 5.3553, 5.3553, 5.3553, 5.3553, 5.3553, 5.3553, 5.3554, 5.3554,\n",
      "        5.3554, 5.3553, 5.3554, 5.3553, 5.3554, 5.3553, 5.3553, 5.3552, 5.3552,\n",
      "        5.3552, 5.3553, 5.3553, 5.3552, 5.3553, 5.3552, 5.3553, 5.3554, 5.3555,\n",
      "        5.3554, 5.3556, 5.3555, 5.3555, 5.3555, 5.3554, 5.3554, 5.3554, 5.3554,\n",
      "        5.3554, 5.3553, 5.3554, 5.3555, 5.3555, 5.3554, 5.3554, 5.3554, 5.3553,\n",
      "        5.3554, 5.3554, 5.3554, 5.3555, 5.3555, 5.3554, 5.3555, 5.3555, 5.3555,\n",
      "        5.3556, 5.3555, 5.3554, 5.3555, 5.3555, 5.3554, 5.3556, 5.3555, 5.3554,\n",
      "        5.3555, 5.3555, 5.3555, 5.3554, 5.3555, 5.3555, 5.3555, 5.3555, 5.3555,\n",
      "        5.3555, 5.3555, 5.3555], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.317643  [2058524/5599865]\n",
      "average delta from current occupancy tensor([5.1288, 5.1289, 5.1288, 5.1288, 5.1288, 5.1288, 5.1288, 5.1289, 5.1288,\n",
      "        5.1288, 5.1288, 5.1288, 5.1288, 5.1288, 5.1289, 5.1288, 5.1288, 5.1290,\n",
      "        5.1289, 5.1289, 5.1289, 5.1289, 5.1290, 5.1289, 5.1288, 5.1289, 5.1288,\n",
      "        5.1289, 5.1289, 5.1289, 5.1289, 5.1289, 5.1289, 5.1288, 5.1288, 5.1289,\n",
      "        5.1289, 5.1289, 5.1289, 5.1289, 5.1288, 5.1288, 5.1288, 5.1288, 5.1289,\n",
      "        5.1289, 5.1289, 5.1289, 5.1290, 5.1289, 5.1290, 5.1288, 5.1289, 5.1289,\n",
      "        5.1289, 5.1289, 5.1289, 5.1289, 5.1292, 5.1288, 5.1290, 5.1289, 5.1290,\n",
      "        5.1289, 5.1290, 5.1290, 5.1290, 5.1291, 5.1290, 5.1290, 5.1291, 5.1289,\n",
      "        5.1291, 5.1289, 5.1290, 5.1290, 5.1289, 5.1289, 5.1289, 5.1289, 5.1290,\n",
      "        5.1290, 5.1290, 5.1290, 5.1289, 5.1289, 5.1290, 5.1289, 5.1290, 5.1290,\n",
      "        5.1289, 5.1289, 5.1290, 5.1289, 5.1289, 5.1289, 5.1289, 5.1289, 5.1289,\n",
      "        5.1289, 5.1289, 5.1289, 5.1289, 5.1289, 5.1290, 5.1289, 5.1289, 5.1289,\n",
      "        5.1289, 5.1289, 5.1289, 5.1288, 5.1288, 5.1289, 5.1289, 5.1289, 5.1289,\n",
      "        5.1289, 5.1289, 5.1289], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.095337  [2070924/5599865]\n",
      "average delta from current occupancy tensor([5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0243, 5.0243, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0242, 5.0242, 5.0242, 5.0243, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0243, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0243, 5.0242, 5.0243, 5.0243, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0243, 5.0242, 5.0242, 5.0243, 5.0242, 5.0243,\n",
      "        5.0242, 5.0242, 5.0243, 5.0242, 5.0242, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0244, 5.0244, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242,\n",
      "        5.0243, 5.0242, 5.0242, 5.0242, 5.0243, 5.0243, 5.0242, 5.0242, 5.0242,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.337999  [2083324/5599865]\n",
      "average delta from current occupancy tensor([5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302,\n",
      "        5.3302, 5.3302, 5.3302, 5.3301, 5.3301, 5.3301, 5.3302, 5.3301, 5.3301,\n",
      "        5.3301, 5.3301, 5.3301, 5.3301, 5.3301, 5.3301, 5.3301, 5.3301, 5.3301,\n",
      "        5.3301, 5.3301, 5.3301, 5.3302, 5.3301, 5.3301, 5.3301, 5.3302, 5.3302,\n",
      "        5.3301, 5.3302, 5.3302, 5.3301, 5.3302, 5.3301, 5.3302, 5.3302, 5.3301,\n",
      "        5.3302, 5.3302, 5.3301, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302,\n",
      "        5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302,\n",
      "        5.3301, 5.3301, 5.3301, 5.3302, 5.3301, 5.3302, 5.3302, 5.3302, 5.3302,\n",
      "        5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302,\n",
      "        5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302,\n",
      "        5.3302, 5.3303, 5.3302, 5.3303, 5.3302, 5.3303, 5.3301, 5.3301, 5.3302,\n",
      "        5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3302, 5.3303, 5.3303,\n",
      "        5.3303, 5.3302, 5.3302, 5.3302, 5.3303, 5.3303, 5.3303, 5.3303, 5.3302,\n",
      "        5.3302, 5.3303, 5.3302], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.216558  [2095724/5599865]\n",
      "average delta from current occupancy tensor([5.2574, 5.2574, 5.2573, 5.2573, 5.2573, 5.2573, 5.2573, 5.2572, 5.2572,\n",
      "        5.2572, 5.2572, 5.2571, 5.2569, 5.2569, 5.2570, 5.2571, 5.2571, 5.2571,\n",
      "        5.2570, 5.2570, 5.2569, 5.2569, 5.2570, 5.2570, 5.2569, 5.2570, 5.2571,\n",
      "        5.2570, 5.2570, 5.2570, 5.2570, 5.2569, 5.2570, 5.2570, 5.2571, 5.2571,\n",
      "        5.2570, 5.2571, 5.2570, 5.2570, 5.2570, 5.2569, 5.2570, 5.2570, 5.2568,\n",
      "        5.2571, 5.2569, 5.2569, 5.2570, 5.2570, 5.2569, 5.2569, 5.2569, 5.2570,\n",
      "        5.2570, 5.2571, 5.2570, 5.2570, 5.2571, 5.2570, 5.2570, 5.2570, 5.2570,\n",
      "        5.2569, 5.2569, 5.2569, 5.2569, 5.2568, 5.2569, 5.2569, 5.2568, 5.2570,\n",
      "        5.2569, 5.2569, 5.2568, 5.2568, 5.2568, 5.2569, 5.2569, 5.2568, 5.2568,\n",
      "        5.2569, 5.2569, 5.2570, 5.2569, 5.2570, 5.2570, 5.2570, 5.2570, 5.2569,\n",
      "        5.2569, 5.2571, 5.2570, 5.2570, 5.2571, 5.2571, 5.2568, 5.2568, 5.2568,\n",
      "        5.2570, 5.2569, 5.2568, 5.2569, 5.2569, 5.2569, 5.2569, 5.2571, 5.2570,\n",
      "        5.2570, 5.2569, 5.2568, 5.2570, 5.2571, 5.2571, 5.2572, 5.2571, 5.2570,\n",
      "        5.2570, 5.2571, 5.2571], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.145172  [2108124/5599865]\n",
      "average delta from current occupancy tensor([5.2906, 5.2906, 5.2905, 5.2905, 5.2906, 5.2906, 5.2906, 5.2905, 5.2905,\n",
      "        5.2906, 5.2906, 5.2906, 5.2906, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2906, 5.2905, 5.2906, 5.2905,\n",
      "        5.2906, 5.2906, 5.2906, 5.2906, 5.2905, 5.2905, 5.2906, 5.2906, 5.2905,\n",
      "        5.2906, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2906, 5.2905, 5.2906, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2906, 5.2906, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2906, 5.2905, 5.2906, 5.2905, 5.2905, 5.2906, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905,\n",
      "        5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2905, 5.2906, 5.2906, 5.2906,\n",
      "        5.2906, 5.2906, 5.2905], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.757523  [2120524/5599865]\n",
      "average delta from current occupancy tensor([4.7341, 4.7341, 4.7341, 4.7341, 4.7341, 4.7341, 4.7342, 4.7341, 4.7341,\n",
      "        4.7341, 4.7341, 4.7341, 4.7340, 4.7340, 4.7339, 4.7339, 4.7340, 4.7340,\n",
      "        4.7340, 4.7340, 4.7339, 4.7340, 4.7340, 4.7339, 4.7340, 4.7341, 4.7340,\n",
      "        4.7339, 4.7340, 4.7339, 4.7339, 4.7339, 4.7339, 4.7340, 4.7340, 4.7339,\n",
      "        4.7340, 4.7341, 4.7340, 4.7341, 4.7341, 4.7341, 4.7340, 4.7341, 4.7341,\n",
      "        4.7341, 4.7341, 4.7340, 4.7341, 4.7341, 4.7340, 4.7340, 4.7340, 4.7340,\n",
      "        4.7340, 4.7340, 4.7340, 4.7340, 4.7339, 4.7339, 4.7339, 4.7339, 4.7340,\n",
      "        4.7340, 4.7340, 4.7341, 4.7340, 4.7341, 4.7341, 4.7341, 4.7340, 4.7340,\n",
      "        4.7340, 4.7340, 4.7340, 4.7339, 4.7339, 4.7339, 4.7340, 4.7340, 4.7339,\n",
      "        4.7340, 4.7340, 4.7340, 4.7340, 4.7340, 4.7340, 4.7339, 4.7339, 4.7339,\n",
      "        4.7340, 4.7339, 4.7340, 4.7339, 4.7339, 4.7340, 4.7339, 4.7340, 4.7340,\n",
      "        4.7340, 4.7340, 4.7340, 4.7340, 4.7340, 4.7341, 4.7341, 4.7341, 4.7341,\n",
      "        4.7342, 4.7342, 4.7341, 4.7341, 4.7341, 4.7341, 4.7342, 4.7342, 4.7342,\n",
      "        4.7342, 4.7342, 4.7342], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.861319  [2132924/5599865]\n",
      "average delta from current occupancy tensor([5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710, 5.8710,\n",
      "        5.8710, 5.8710, 5.8710], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.430393  [2145324/5599865]\n",
      "average delta from current occupancy tensor([5.5492, 5.5490, 5.5489, 5.5488, 5.5485, 5.5486, 5.5486, 5.5488, 5.5489,\n",
      "        5.5487, 5.5485, 5.5487, 5.5483, 5.5483, 5.5483, 5.5483, 5.5483, 5.5484,\n",
      "        5.5483, 5.5483, 5.5483, 5.5485, 5.5487, 5.5487, 5.5487, 5.5484, 5.5484,\n",
      "        5.5486, 5.5485, 5.5487, 5.5485, 5.5484, 5.5485, 5.5486, 5.5491, 5.5489,\n",
      "        5.5491, 5.5490, 5.5491, 5.5487, 5.5488, 5.5489, 5.5490, 5.5485, 5.5485,\n",
      "        5.5487, 5.5484, 5.5485, 5.5485, 5.5483, 5.5483, 5.5484, 5.5484, 5.5486,\n",
      "        5.5485, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5485,\n",
      "        5.5485, 5.5484, 5.5487, 5.5489, 5.5486, 5.5486, 5.5487, 5.5485, 5.5485,\n",
      "        5.5488, 5.5487, 5.5487, 5.5487, 5.5485, 5.5483, 5.5484, 5.5483, 5.5483,\n",
      "        5.5483, 5.5484, 5.5483, 5.5483, 5.5483, 5.5484, 5.5485, 5.5484, 5.5484,\n",
      "        5.5485, 5.5484, 5.5483, 5.5484, 5.5485, 5.5484, 5.5488, 5.5485, 5.5484,\n",
      "        5.5488, 5.5484, 5.5484, 5.5483, 5.5484, 5.5485, 5.5485, 5.5484, 5.5483,\n",
      "        5.5484, 5.5484, 5.5485, 5.5488, 5.5488, 5.5487, 5.5491, 5.5490, 5.5490,\n",
      "        5.5491, 5.5493, 5.5494], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.963583  [2157724/5599865]\n",
      "average delta from current occupancy tensor([4.8565, 4.8564, 4.8565, 4.8565, 4.8566, 4.8565, 4.8565, 4.8563, 4.8563,\n",
      "        4.8563, 4.8564, 4.8563, 4.8564, 4.8565, 4.8564, 4.8564, 4.8565, 4.8565,\n",
      "        4.8565, 4.8564, 4.8565, 4.8564, 4.8564, 4.8564, 4.8564, 4.8564, 4.8564,\n",
      "        4.8564, 4.8563, 4.8564, 4.8563, 4.8563, 4.8565, 4.8564, 4.8564, 4.8564,\n",
      "        4.8566, 4.8567, 4.8567, 4.8567, 4.8566, 4.8565, 4.8566, 4.8565, 4.8565,\n",
      "        4.8563, 4.8564, 4.8563, 4.8564, 4.8562, 4.8565, 4.8564, 4.8564, 4.8564,\n",
      "        4.8563, 4.8563, 4.8562, 4.8564, 4.8563, 4.8563, 4.8562, 4.8565, 4.8561,\n",
      "        4.8564, 4.8562, 4.8562, 4.8562, 4.8562, 4.8563, 4.8562, 4.8563, 4.8562,\n",
      "        4.8563, 4.8562, 4.8563, 4.8566, 4.8564, 4.8563, 4.8564, 4.8565, 4.8564,\n",
      "        4.8564, 4.8565, 4.8565, 4.8565, 4.8565, 4.8566, 4.8565, 4.8565, 4.8567,\n",
      "        4.8566, 4.8566, 4.8567, 4.8566, 4.8565, 4.8564, 4.8564, 4.8563, 4.8564,\n",
      "        4.8564, 4.8565, 4.8566, 4.8565, 4.8564, 4.8563, 4.8564, 4.8564, 4.8564,\n",
      "        4.8564, 4.8564, 4.8564, 4.8565, 4.8564, 4.8565, 4.8562, 4.8564, 4.8565,\n",
      "        4.8562, 4.8561, 4.8563], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.451510  [2170124/5599865]\n",
      "average delta from current occupancy tensor([5.0973, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0971, 5.0972, 5.0973,\n",
      "        5.0973, 5.0971, 5.0971, 5.0972, 5.0971, 5.0971, 5.0971, 5.0970, 5.0971,\n",
      "        5.0971, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0971, 5.0971, 5.0971, 5.0970, 5.0971, 5.0971, 5.0971,\n",
      "        5.0971, 5.0972, 5.0972, 5.0972, 5.0972, 5.0971, 5.0971, 5.0971, 5.0970,\n",
      "        5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971,\n",
      "        5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0972,\n",
      "        5.0971, 5.0972, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0972, 5.0971,\n",
      "        5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971,\n",
      "        5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971,\n",
      "        5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0973, 5.0973, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0971,\n",
      "        5.0972, 5.0971, 5.0971], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.825129  [2182524/5599865]\n",
      "average delta from current occupancy tensor([4.7580, 4.7581, 4.7579, 4.7580, 4.7580, 4.7580, 4.7580, 4.7580, 4.7580,\n",
      "        4.7580, 4.7579, 4.7579, 4.7580, 4.7579, 4.7580, 4.7580, 4.7580, 4.7580,\n",
      "        4.7579, 4.7580, 4.7579, 4.7579, 4.7579, 4.7580, 4.7581, 4.7580, 4.7580,\n",
      "        4.7581, 4.7580, 4.7579, 4.7579, 4.7580, 4.7579, 4.7579, 4.7580, 4.7580,\n",
      "        4.7580, 4.7580, 4.7580, 4.7580, 4.7580, 4.7580, 4.7579, 4.7580, 4.7579,\n",
      "        4.7579, 4.7579, 4.7579, 4.7580, 4.7579, 4.7580, 4.7580, 4.7579, 4.7579,\n",
      "        4.7579, 4.7579, 4.7579, 4.7579, 4.7580, 4.7579, 4.7580, 4.7580, 4.7579,\n",
      "        4.7580, 4.7580, 4.7580, 4.7579, 4.7580, 4.7580, 4.7579, 4.7579, 4.7580,\n",
      "        4.7580, 4.7581, 4.7580, 4.7580, 4.7580, 4.7582, 4.7582, 4.7582, 4.7582,\n",
      "        4.7580, 4.7579, 4.7582, 4.7582, 4.7581, 4.7582, 4.7580, 4.7581, 4.7580,\n",
      "        4.7582, 4.7582, 4.7580, 4.7580, 4.7580, 4.7580, 4.7580, 4.7583, 4.7581,\n",
      "        4.7582, 4.7581, 4.7581, 4.7580, 4.7580, 4.7580, 4.7582, 4.7581, 4.7581,\n",
      "        4.7581, 4.7580, 4.7580, 4.7580, 4.7580, 4.7581, 4.7580, 4.7580, 4.7579,\n",
      "        4.7580, 4.7579, 4.7580], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.203531  [2194924/5599865]\n",
      "average delta from current occupancy tensor([4.3548, 4.3548, 4.3549, 4.3547, 4.3552, 4.3553, 4.3553, 4.3549, 4.3549,\n",
      "        4.3551, 4.3552, 4.3552, 4.3550, 4.3548, 4.3546, 4.3544, 4.3545, 4.3545,\n",
      "        4.3548, 4.3548, 4.3548, 4.3549, 4.3550, 4.3550, 4.3549, 4.3549, 4.3552,\n",
      "        4.3552, 4.3548, 4.3552, 4.3551, 4.3551, 4.3548, 4.3551, 4.3546, 4.3549,\n",
      "        4.3548, 4.3546, 4.3547, 4.3550, 4.3547, 4.3549, 4.3550, 4.3546, 4.3547,\n",
      "        4.3552, 4.3550, 4.3548, 4.3548, 4.3548, 4.3546, 4.3546, 4.3546, 4.3546,\n",
      "        4.3546, 4.3546, 4.3547, 4.3549, 4.3547, 4.3548, 4.3545, 4.3545, 4.3547,\n",
      "        4.3546, 4.3547, 4.3546, 4.3549, 4.3547, 4.3547, 4.3546, 4.3549, 4.3547,\n",
      "        4.3547, 4.3548, 4.3547, 4.3547, 4.3547, 4.3547, 4.3549, 4.3548, 4.3546,\n",
      "        4.3547, 4.3546, 4.3546, 4.3546, 4.3546, 4.3546, 4.3547, 4.3547, 4.3548,\n",
      "        4.3546, 4.3547, 4.3547, 4.3549, 4.3549, 4.3548, 4.3547, 4.3547, 4.3547,\n",
      "        4.3548, 4.3548, 4.3547, 4.3548, 4.3549, 4.3547, 4.3548, 4.3547, 4.3548,\n",
      "        4.3548, 4.3548, 4.3547, 4.3547, 4.3548, 4.3548, 4.3548, 4.3548, 4.3547,\n",
      "        4.3547, 4.3546, 4.3546], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.438365  [2207324/5599865]\n",
      "average delta from current occupancy tensor([5.2986, 5.2987, 5.2987, 5.2987, 5.2987, 5.2986, 5.2986, 5.2987, 5.2986,\n",
      "        5.2986, 5.2986, 5.2986, 5.2986, 5.2986, 5.2986, 5.2987, 5.2987, 5.2987,\n",
      "        5.2986, 5.2987, 5.2987, 5.2987, 5.2986, 5.2986, 5.2987, 5.2987, 5.2986,\n",
      "        5.2986, 5.2987, 5.2987, 5.2988, 5.2986, 5.2987, 5.2987, 5.2986, 5.2987,\n",
      "        5.2986, 5.2987, 5.2986, 5.2987, 5.2986, 5.2987, 5.2987, 5.2988, 5.2988,\n",
      "        5.2987, 5.2988, 5.2988, 5.2987, 5.2987, 5.2986, 5.2986, 5.2987, 5.2987,\n",
      "        5.2989, 5.2988, 5.2986, 5.2987, 5.2988, 5.2986, 5.2987, 5.2988, 5.2988,\n",
      "        5.2986, 5.2987, 5.2986, 5.2986, 5.2987, 5.2987, 5.2987, 5.2988, 5.2987,\n",
      "        5.2986, 5.2987, 5.2986, 5.2986, 5.2986, 5.2987, 5.2986, 5.2986, 5.2986,\n",
      "        5.2986, 5.2988, 5.2987, 5.2987, 5.2986, 5.2987, 5.2986, 5.2986, 5.2987,\n",
      "        5.2988, 5.2987, 5.2987, 5.2988, 5.2988, 5.2986, 5.2987, 5.2987, 5.2986,\n",
      "        5.2987, 5.2988, 5.2988, 5.2987, 5.2987, 5.2988, 5.2988, 5.2989, 5.2986,\n",
      "        5.2988, 5.2988, 5.2987, 5.2988, 5.2989, 5.2988, 5.2987, 5.2987, 5.2986,\n",
      "        5.2988, 5.2988, 5.2986], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.872192  [2219724/5599865]\n",
      "average delta from current occupancy tensor([5.0002, 5.0003, 5.0001, 5.0003, 5.0003, 5.0006, 5.0003, 5.0003, 5.0001,\n",
      "        4.9999, 5.0003, 5.0000, 5.0001, 5.0001, 4.9998, 4.9997, 4.9997, 4.9998,\n",
      "        5.0000, 4.9996, 4.9998, 4.9998, 5.0001, 5.0000, 4.9999, 5.0000, 5.0003,\n",
      "        4.9999, 4.9999, 4.9999, 5.0000, 5.0000, 5.0000, 5.0000, 5.0003, 5.0001,\n",
      "        5.0000, 5.0002, 5.0004, 5.0002, 5.0003, 4.9999, 5.0002, 5.0000, 5.0001,\n",
      "        5.0002, 5.0002, 5.0003, 5.0001, 5.0001, 5.0001, 5.0000, 4.9999, 4.9999,\n",
      "        4.9998, 5.0001, 5.0003, 5.0003, 4.9998, 5.0002, 5.0000, 4.9998, 4.9997,\n",
      "        5.0001, 5.0000, 5.0000, 5.0004, 5.0003, 5.0001, 5.0002, 5.0001, 5.0002,\n",
      "        5.0000, 5.0003, 5.0000, 5.0000, 5.0000, 5.0001, 5.0001, 5.0001, 5.0003,\n",
      "        5.0000, 5.0001, 5.0000, 5.0000, 4.9999, 5.0000, 4.9999, 4.9999, 5.0003,\n",
      "        5.0000, 5.0001, 5.0003, 4.9998, 4.9998, 5.0001, 4.9999, 4.9999, 5.0000,\n",
      "        4.9998, 4.9997, 4.9996, 4.9997, 4.9998, 4.9998, 5.0000, 4.9998, 5.0003,\n",
      "        5.0001, 5.0000, 5.0001, 5.0000, 4.9997, 4.9997, 4.9999, 4.9998, 4.9999,\n",
      "        4.9996, 4.9994, 4.9996], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.859347  [2232124/5599865]\n",
      "average delta from current occupancy tensor([4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.367391  [2244524/5599865]\n",
      "average delta from current occupancy tensor([5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4684, 5.4684, 5.4684,\n",
      "        5.4684, 5.4684, 5.4684, 5.4683, 5.4684, 5.4683, 5.4683, 5.4683, 5.4683,\n",
      "        5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4683,\n",
      "        5.4683, 5.4683, 5.4683, 5.4683, 5.4683, 5.4682, 5.4682, 5.4682, 5.4683,\n",
      "        5.4682, 5.4682, 5.4682, 5.4683, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682,\n",
      "        5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682,\n",
      "        5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4681, 5.4681, 5.4681,\n",
      "        5.4682, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681,\n",
      "        5.4681, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681, 5.4682, 5.4682, 5.4682,\n",
      "        5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682, 5.4682,\n",
      "        5.4681, 5.4682, 5.4682, 5.4682, 5.4682, 5.4681, 5.4681, 5.4682, 5.4682,\n",
      "        5.4682, 5.4681, 5.4681, 5.4682, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681,\n",
      "        5.4681, 5.4681, 5.4680, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681, 5.4681,\n",
      "        5.4681, 5.4681, 5.4681], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.002744  [2256924/5599865]\n",
      "average delta from current occupancy tensor([5.1455, 5.1454, 5.1454, 5.1454, 5.1454, 5.1455, 5.1456, 5.1455, 5.1454,\n",
      "        5.1455, 5.1454, 5.1454, 5.1454, 5.1453, 5.1453, 5.1453, 5.1453, 5.1453,\n",
      "        5.1453, 5.1454, 5.1453, 5.1453, 5.1453, 5.1453, 5.1453, 5.1452, 5.1453,\n",
      "        5.1452, 5.1452, 5.1453, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1453, 5.1453, 5.1453, 5.1452,\n",
      "        5.1452, 5.1452, 5.1454, 5.1453, 5.1453, 5.1453, 5.1453, 5.1452, 5.1453,\n",
      "        5.1452, 5.1452, 5.1453, 5.1453, 5.1452, 5.1453, 5.1453, 5.1453, 5.1453,\n",
      "        5.1453, 5.1453, 5.1453, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1453, 5.1453, 5.1453, 5.1453, 5.1453, 5.1453, 5.1453, 5.1453,\n",
      "        5.1453, 5.1453, 5.1453, 5.1452, 5.1453, 5.1452, 5.1452, 5.1453, 5.1453,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1453, 5.1453, 5.1452,\n",
      "        5.1453, 5.1453, 5.1454, 5.1454, 5.1453, 5.1453, 5.1454, 5.1453, 5.1452,\n",
      "        5.1453, 5.1453, 5.1454, 5.1454, 5.1454, 5.1453, 5.1453, 5.1454, 5.1454,\n",
      "        5.1453, 5.1454, 5.1454], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.173791  [2269324/5599865]\n",
      "average delta from current occupancy tensor([5.0334, 5.0334, 5.0333, 5.0333, 5.0333, 5.0333, 5.0335, 5.0335, 5.0333,\n",
      "        5.0334, 5.0333, 5.0334, 5.0334, 5.0334, 5.0336, 5.0334, 5.0335, 5.0336,\n",
      "        5.0335, 5.0333, 5.0333, 5.0334, 5.0335, 5.0336, 5.0336, 5.0334, 5.0336,\n",
      "        5.0336, 5.0337, 5.0337, 5.0336, 5.0336, 5.0336, 5.0334, 5.0335, 5.0336,\n",
      "        5.0333, 5.0334, 5.0335, 5.0334, 5.0336, 5.0336, 5.0335, 5.0335, 5.0336,\n",
      "        5.0336, 5.0336, 5.0334, 5.0334, 5.0334, 5.0335, 5.0335, 5.0336, 5.0335,\n",
      "        5.0336, 5.0337, 5.0336, 5.0335, 5.0336, 5.0333, 5.0335, 5.0335, 5.0336,\n",
      "        5.0336, 5.0335, 5.0336, 5.0337, 5.0337, 5.0337, 5.0337, 5.0337, 5.0337,\n",
      "        5.0336, 5.0337, 5.0336, 5.0336, 5.0336, 5.0337, 5.0335, 5.0336, 5.0335,\n",
      "        5.0335, 5.0337, 5.0336, 5.0336, 5.0335, 5.0335, 5.0336, 5.0335, 5.0337,\n",
      "        5.0336, 5.0334, 5.0335, 5.0335, 5.0336, 5.0332, 5.0336, 5.0336, 5.0336,\n",
      "        5.0336, 5.0336, 5.0334, 5.0336, 5.0336, 5.0335, 5.0335, 5.0335, 5.0335,\n",
      "        5.0335, 5.0336, 5.0335, 5.0334, 5.0333, 5.0335, 5.0334, 5.0334, 5.0335,\n",
      "        5.0335, 5.0333, 5.0334], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.192849  [2281724/5599865]\n",
      "average delta from current occupancy tensor([4.9835, 4.9834, 4.9835, 4.9834, 4.9835, 4.9834, 4.9833, 4.9834, 4.9837,\n",
      "        4.9837, 4.9836, 4.9836, 4.9836, 4.9836, 4.9833, 4.9837, 4.9835, 4.9833,\n",
      "        4.9833, 4.9836, 4.9835, 4.9834, 4.9833, 4.9831, 4.9830, 4.9834, 4.9830,\n",
      "        4.9829, 4.9828, 4.9829, 4.9830, 4.9830, 4.9831, 4.9833, 4.9831, 4.9831,\n",
      "        4.9835, 4.9834, 4.9833, 4.9835, 4.9832, 4.9831, 4.9834, 4.9833, 4.9833,\n",
      "        4.9832, 4.9832, 4.9836, 4.9835, 4.9836, 4.9833, 4.9832, 4.9832, 4.9833,\n",
      "        4.9831, 4.9830, 4.9832, 4.9833, 4.9832, 4.9837, 4.9833, 4.9835, 4.9834,\n",
      "        4.9833, 4.9834, 4.9833, 4.9829, 4.9829, 4.9829, 4.9828, 4.9829, 4.9829,\n",
      "        4.9829, 4.9829, 4.9829, 4.9831, 4.9831, 4.9830, 4.9831, 4.9831, 4.9831,\n",
      "        4.9830, 4.9828, 4.9828, 4.9827, 4.9829, 4.9828, 4.9827, 4.9827, 4.9825,\n",
      "        4.9825, 4.9829, 4.9829, 4.9828, 4.9827, 4.9833, 4.9828, 4.9828, 4.9828,\n",
      "        4.9829, 4.9829, 4.9831, 4.9828, 4.9828, 4.9828, 4.9829, 4.9829, 4.9830,\n",
      "        4.9828, 4.9827, 4.9828, 4.9830, 4.9831, 4.9827, 4.9828, 4.9829, 4.9828,\n",
      "        4.9828, 4.9830, 4.9830], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.454870  [2294124/5599865]\n",
      "average delta from current occupancy tensor([5.3863, 5.3863, 5.3863, 5.3863, 5.3864, 5.3863, 5.3863, 5.3863, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3863, 5.3864, 5.3864, 5.3863,\n",
      "        5.3865, 5.3864, 5.3864, 5.3864, 5.3863, 5.3863, 5.3864, 5.3864, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3863, 5.3863, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3863, 5.3863, 5.3863, 5.3863, 5.3863, 5.3863,\n",
      "        5.3863, 5.3863, 5.3863, 5.3863, 5.3863, 5.3863, 5.3863, 5.3863, 5.3863,\n",
      "        5.3863, 5.3864, 5.3863, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864, 5.3864,\n",
      "        5.3864, 5.3864, 5.3864, 5.3864, 5.3865, 5.3864, 5.3865, 5.3864, 5.3865,\n",
      "        5.3865, 5.3864, 5.3864, 5.3864, 5.3865, 5.3865, 5.3864, 5.3865, 5.3865,\n",
      "        5.3865, 5.3864, 5.3865, 5.3865, 5.3864, 5.3864, 5.3865, 5.3864, 5.3864,\n",
      "        5.3865, 5.3865, 5.3865], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.275562  [2306524/5599865]\n",
      "average delta from current occupancy tensor([5.7342, 5.7342, 5.7342, 5.7342, 5.7342, 5.7342, 5.7342, 5.7342, 5.7343,\n",
      "        5.7342, 5.7343, 5.7342, 5.7342, 5.7342, 5.7342, 5.7342, 5.7343, 5.7342,\n",
      "        5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7344, 5.7343,\n",
      "        5.7343, 5.7344, 5.7344, 5.7343, 5.7343, 5.7344, 5.7343, 5.7344, 5.7343,\n",
      "        5.7344, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343, 5.7342, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7342, 5.7342, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7342,\n",
      "        5.7343, 5.7343, 5.7343, 5.7342, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7344, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343, 5.7343, 5.7344, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343, 5.7343,\n",
      "        5.7343, 5.7343, 5.7343], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.815984  [2318924/5599865]\n",
      "average delta from current occupancy tensor([4.6907, 4.6906, 4.6907, 4.6906, 4.6907, 4.6904, 4.6902, 4.6905, 4.6902,\n",
      "        4.6903, 4.6905, 4.6901, 4.6905, 4.6907, 4.6904, 4.6908, 4.6908, 4.6907,\n",
      "        4.6906, 4.6905, 4.6909, 4.6907, 4.6906, 4.6908, 4.6906, 4.6913, 4.6909,\n",
      "        4.6908, 4.6913, 4.6914, 4.6911, 4.6907, 4.6911, 4.6905, 4.6904, 4.6905,\n",
      "        4.6903, 4.6899, 4.6900, 4.6907, 4.6904, 4.6909, 4.6909, 4.6905, 4.6904,\n",
      "        4.6904, 4.6902, 4.6905, 4.6901, 4.6906, 4.6905, 4.6905, 4.6907, 4.6908,\n",
      "        4.6910, 4.6909, 4.6902, 4.6902, 4.6908, 4.6910, 4.6905, 4.6905, 4.6910,\n",
      "        4.6909, 4.6909, 4.6910, 4.6907, 4.6907, 4.6907, 4.6906, 4.6904, 4.6902,\n",
      "        4.6905, 4.6904, 4.6905, 4.6904, 4.6907, 4.6910, 4.6911, 4.6909, 4.6907,\n",
      "        4.6911, 4.6911, 4.6909, 4.6909, 4.6907, 4.6908, 4.6911, 4.6914, 4.6913,\n",
      "        4.6911, 4.6910, 4.6912, 4.6911, 4.6912, 4.6906, 4.6904, 4.6909, 4.6907,\n",
      "        4.6906, 4.6903, 4.6906, 4.6902, 4.6904, 4.6905, 4.6902, 4.6905, 4.6902,\n",
      "        4.6905, 4.6906, 4.6905, 4.6906, 4.6909, 4.6911, 4.6911, 4.6911, 4.6912,\n",
      "        4.6914, 4.6910, 4.6908], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.731092  [2331324/5599865]\n",
      "average delta from current occupancy tensor([4.4915, 4.4919, 4.4918, 4.4921, 4.4921, 4.4920, 4.4918, 4.4919, 4.4922,\n",
      "        4.4921, 4.4920, 4.4919, 4.4923, 4.4922, 4.4920, 4.4920, 4.4920, 4.4919,\n",
      "        4.4923, 4.4920, 4.4919, 4.4923, 4.4921, 4.4919, 4.4921, 4.4922, 4.4921,\n",
      "        4.4922, 4.4918, 4.4919, 4.4924, 4.4919, 4.4923, 4.4921, 4.4919, 4.4922,\n",
      "        4.4922, 4.4924, 4.4921, 4.4921, 4.4922, 4.4924, 4.4921, 4.4924, 4.4924,\n",
      "        4.4924, 4.4921, 4.4924, 4.4919, 4.4918, 4.4921, 4.4919, 4.4917, 4.4913,\n",
      "        4.4912, 4.4914, 4.4919, 4.4919, 4.4914, 4.4913, 4.4916, 4.4918, 4.4914,\n",
      "        4.4914, 4.4915, 4.4913, 4.4916, 4.4918, 4.4917, 4.4914, 4.4918, 4.4918,\n",
      "        4.4916, 4.4916, 4.4915, 4.4917, 4.4915, 4.4910, 4.4909, 4.4914, 4.4914,\n",
      "        4.4913, 4.4912, 4.4912, 4.4911, 4.4915, 4.4916, 4.4914, 4.4911, 4.4914,\n",
      "        4.4916, 4.4916, 4.4915, 4.4915, 4.4914, 4.4916, 4.4921, 4.4916, 4.4919,\n",
      "        4.4921, 4.4921, 4.4924, 4.4920, 4.4923, 4.4920, 4.4922, 4.4918, 4.4924,\n",
      "        4.4917, 4.4917, 4.4917, 4.4916, 4.4914, 4.4912, 4.4909, 4.4909, 4.4909,\n",
      "        4.4909, 4.4909, 4.4911], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.788085  [2343724/5599865]\n",
      "average delta from current occupancy tensor([5.4946, 5.4940, 5.4941, 5.4948, 5.4946, 5.4949, 5.4940, 5.4943, 5.4938,\n",
      "        5.4938, 5.4940, 5.4931, 5.4940, 5.4945, 5.4943, 5.4946, 5.4944, 5.4940,\n",
      "        5.4939, 5.4936, 5.4942, 5.4940, 5.4936, 5.4939, 5.4935, 5.4934, 5.4939,\n",
      "        5.4938, 5.4932, 5.4936, 5.4933, 5.4939, 5.4930, 5.4935, 5.4939, 5.4935,\n",
      "        5.4935, 5.4933, 5.4932, 5.4937, 5.4937, 5.4935, 5.4941, 5.4935, 5.4936,\n",
      "        5.4937, 5.4939, 5.4936, 5.4943, 5.4941, 5.4930, 5.4937, 5.4930, 5.4931,\n",
      "        5.4936, 5.4935, 5.4937, 5.4928, 5.4934, 5.4934, 5.4928, 5.4931, 5.4935,\n",
      "        5.4937, 5.4933, 5.4935, 5.4933, 5.4934, 5.4934, 5.4933, 5.4938, 5.4934,\n",
      "        5.4929, 5.4931, 5.4934, 5.4933, 5.4938, 5.4944, 5.4947, 5.4937, 5.4936,\n",
      "        5.4937, 5.4939, 5.4937, 5.4941, 5.4934, 5.4932, 5.4934, 5.4936, 5.4935,\n",
      "        5.4934, 5.4937, 5.4932, 5.4930, 5.4933, 5.4940, 5.4939, 5.4935, 5.4945,\n",
      "        5.4937, 5.4943, 5.4940, 5.4943, 5.4936, 5.4941, 5.4940, 5.4945, 5.4935,\n",
      "        5.4943, 5.4945, 5.4946, 5.4944, 5.4938, 5.4937, 5.4940, 5.4941, 5.4945,\n",
      "        5.4947, 5.4946, 5.4947], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.489875  [2356124/5599865]\n",
      "average delta from current occupancy tensor([4.7257, 4.7258, 4.7258, 4.7258, 4.7256, 4.7256, 4.7259, 4.7259, 4.7261,\n",
      "        4.7260, 4.7260, 4.7261, 4.7261, 4.7260, 4.7259, 4.7259, 4.7258, 4.7262,\n",
      "        4.7259, 4.7261, 4.7262, 4.7262, 4.7262, 4.7262, 4.7260, 4.7262, 4.7262,\n",
      "        4.7261, 4.7262, 4.7262, 4.7261, 4.7262, 4.7261, 4.7263, 4.7260, 4.7262,\n",
      "        4.7262, 4.7259, 4.7259, 4.7260, 4.7263, 4.7264, 4.7264, 4.7263, 4.7260,\n",
      "        4.7262, 4.7264, 4.7261, 4.7262, 4.7264, 4.7262, 4.7264, 4.7263, 4.7263,\n",
      "        4.7263, 4.7261, 4.7264, 4.7260, 4.7261, 4.7262, 4.7260, 4.7264, 4.7261,\n",
      "        4.7260, 4.7262, 4.7259, 4.7260, 4.7260, 4.7260, 4.7260, 4.7260, 4.7262,\n",
      "        4.7262, 4.7262, 4.7262, 4.7262, 4.7259, 4.7262, 4.7261, 4.7262, 4.7263,\n",
      "        4.7260, 4.7259, 4.7260, 4.7260, 4.7263, 4.7259, 4.7260, 4.7263, 4.7260,\n",
      "        4.7259, 4.7259, 4.7260, 4.7261, 4.7261, 4.7259, 4.7260, 4.7261, 4.7260,\n",
      "        4.7261, 4.7261, 4.7261, 4.7260, 4.7260, 4.7261, 4.7261, 4.7260, 4.7261,\n",
      "        4.7262, 4.7261, 4.7261, 4.7261, 4.7261, 4.7261, 4.7262, 4.7261, 4.7261,\n",
      "        4.7260, 4.7261, 4.7261], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 3.976926  [2368524/5599865]\n",
      "average delta from current occupancy tensor([3.8632, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8634,\n",
      "        3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634,\n",
      "        3.8634, 3.8634, 3.8634, 3.8634, 3.8633, 3.8634, 3.8634, 3.8634, 3.8634,\n",
      "        3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8635, 3.8635, 3.8634,\n",
      "        3.8635, 3.8635, 3.8635, 3.8635, 3.8634, 3.8634, 3.8634, 3.8635, 3.8635,\n",
      "        3.8634, 3.8635, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634,\n",
      "        3.8634, 3.8634, 3.8634, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633,\n",
      "        3.8633, 3.8633, 3.8633, 3.8633, 3.8634, 3.8633, 3.8633, 3.8633, 3.8633,\n",
      "        3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633,\n",
      "        3.8634, 3.8634, 3.8634, 3.8634, 3.8633, 3.8634, 3.8633, 3.8633, 3.8633,\n",
      "        3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633, 3.8633,\n",
      "        3.8633, 3.8633, 3.8634, 3.8634, 3.8633, 3.8633, 3.8633, 3.8634, 3.8634,\n",
      "        3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634, 3.8634,\n",
      "        3.8634, 3.8634, 3.8634], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.577731  [2380924/5599865]\n",
      "average delta from current occupancy tensor([5.5243, 5.5244, 5.5244, 5.5244, 5.5243, 5.5243, 5.5244, 5.5243, 5.5244,\n",
      "        5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5243,\n",
      "        5.5243, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5245,\n",
      "        5.5244, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245,\n",
      "        5.5244, 5.5244, 5.5245, 5.5244, 5.5245, 5.5246, 5.5245, 5.5245, 5.5245,\n",
      "        5.5245, 5.5244, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245, 5.5246,\n",
      "        5.5244, 5.5243, 5.5244, 5.5244, 5.5243, 5.5243, 5.5243, 5.5242, 5.5243,\n",
      "        5.5243, 5.5243, 5.5242, 5.5242, 5.5243, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5244, 5.5243, 5.5242, 5.5243,\n",
      "        5.5243, 5.5243, 5.5244, 5.5244, 5.5245, 5.5244, 5.5244, 5.5243, 5.5243,\n",
      "        5.5243, 5.5244, 5.5245, 5.5245, 5.5245, 5.5244, 5.5244, 5.5244, 5.5246,\n",
      "        5.5246, 5.5245, 5.5245, 5.5245, 5.5244, 5.5244, 5.5244, 5.5244, 5.5245,\n",
      "        5.5244, 5.5245, 5.5244], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.228427  [2393324/5599865]\n",
      "average delta from current occupancy tensor([5.2912, 5.2909, 5.2909, 5.2911, 5.2911, 5.2911, 5.2911, 5.2911, 5.2911,\n",
      "        5.2911, 5.2910, 5.2910, 5.2910, 5.2911, 5.2912, 5.2910, 5.2911, 5.2912,\n",
      "        5.2911, 5.2910, 5.2910, 5.2912, 5.2911, 5.2910, 5.2911, 5.2911, 5.2910,\n",
      "        5.2907, 5.2910, 5.2908, 5.2909, 5.2907, 5.2908, 5.2908, 5.2911, 5.2912,\n",
      "        5.2912, 5.2911, 5.2909, 5.2911, 5.2909, 5.2909, 5.2908, 5.2910, 5.2909,\n",
      "        5.2908, 5.2911, 5.2912, 5.2912, 5.2911, 5.2912, 5.2911, 5.2912, 5.2910,\n",
      "        5.2912, 5.2912, 5.2911, 5.2912, 5.2911, 5.2910, 5.2909, 5.2911, 5.2911,\n",
      "        5.2912, 5.2912, 5.2912, 5.2913, 5.2912, 5.2912, 5.2912, 5.2912, 5.2910,\n",
      "        5.2912, 5.2913, 5.2912, 5.2913, 5.2913, 5.2912, 5.2912, 5.2913, 5.2912,\n",
      "        5.2913, 5.2911, 5.2910, 5.2911, 5.2912, 5.2911, 5.2911, 5.2912, 5.2913,\n",
      "        5.2912, 5.2911, 5.2910, 5.2909, 5.2911, 5.2912, 5.2910, 5.2911, 5.2910,\n",
      "        5.2911, 5.2909, 5.2909, 5.2911, 5.2911, 5.2910, 5.2910, 5.2909, 5.2908,\n",
      "        5.2909, 5.2909, 5.2910, 5.2909, 5.2910, 5.2909, 5.2909, 5.2908, 5.2908,\n",
      "        5.2910, 5.2906, 5.2908], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.702314  [2405724/5599865]\n",
      "average delta from current occupancy tensor([5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7501, 5.7500, 5.7500, 5.7500, 5.7501, 5.7500, 5.7500, 5.7500, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.620658  [2418124/5599865]\n",
      "average delta from current occupancy tensor([5.6777, 5.6777, 5.6776, 5.6777, 5.6776, 5.6779, 5.6778, 5.6778, 5.6780,\n",
      "        5.6780, 5.6778, 5.6780, 5.6778, 5.6777, 5.6779, 5.6779, 5.6779, 5.6780,\n",
      "        5.6779, 5.6779, 5.6778, 5.6777, 5.6777, 5.6779, 5.6777, 5.6776, 5.6776,\n",
      "        5.6777, 5.6776, 5.6775, 5.6775, 5.6776, 5.6776, 5.6775, 5.6776, 5.6777,\n",
      "        5.6776, 5.6776, 5.6776, 5.6778, 5.6774, 5.6774, 5.6776, 5.6775, 5.6775,\n",
      "        5.6774, 5.6776, 5.6775, 5.6776, 5.6777, 5.6775, 5.6779, 5.6778, 5.6779,\n",
      "        5.6778, 5.6777, 5.6778, 5.6780, 5.6778, 5.6777, 5.6778, 5.6779, 5.6778,\n",
      "        5.6777, 5.6777, 5.6776, 5.6776, 5.6776, 5.6776, 5.6776, 5.6776, 5.6774,\n",
      "        5.6774, 5.6775, 5.6778, 5.6776, 5.6775, 5.6776, 5.6777, 5.6777, 5.6777,\n",
      "        5.6776, 5.6775, 5.6777, 5.6774, 5.6776, 5.6774, 5.6775, 5.6774, 5.6775,\n",
      "        5.6774, 5.6774, 5.6774, 5.6774, 5.6774, 5.6774, 5.6774, 5.6776, 5.6774,\n",
      "        5.6774, 5.6774, 5.6774, 5.6774, 5.6774, 5.6777, 5.6776, 5.6776, 5.6776,\n",
      "        5.6775, 5.6775, 5.6777, 5.6778, 5.6775, 5.6776, 5.6776, 5.6777, 5.6777,\n",
      "        5.6776, 5.6778, 5.6777], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.036325  [2430524/5599865]\n",
      "average delta from current occupancy tensor([5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1051, 5.1051, 5.1050, 5.1051, 5.1051, 5.1051, 5.1051,\n",
      "        5.1050, 5.1051, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1051, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1050, 5.1051, 5.1050, 5.1050, 5.1051, 5.1051, 5.1051,\n",
      "        5.1051, 5.1051, 5.1051, 5.1051, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1051, 5.1051, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1051, 5.1051,\n",
      "        5.1050, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051,\n",
      "        5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051, 5.1051,\n",
      "        5.1051, 5.1051, 5.1051], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.518502  [2442924/5599865]\n",
      "average delta from current occupancy tensor([5.7500, 5.7500, 5.7500, 5.7500, 5.7501, 5.7501, 5.7500, 5.7500, 5.7500,\n",
      "        5.7501, 5.7500, 5.7500, 5.7500, 5.7501, 5.7500, 5.7500, 5.7501, 5.7500,\n",
      "        5.7501, 5.7501, 5.7501, 5.7500, 5.7501, 5.7500, 5.7500, 5.7500, 5.7501,\n",
      "        5.7500, 5.7501, 5.7500, 5.7500, 5.7500, 5.7500, 5.7501, 5.7500, 5.7500,\n",
      "        5.7501, 5.7501, 5.7501, 5.7502, 5.7501, 5.7501, 5.7502, 5.7501, 5.7500,\n",
      "        5.7501, 5.7500, 5.7499, 5.7500, 5.7500, 5.7500, 5.7500, 5.7499, 5.7500,\n",
      "        5.7500, 5.7499, 5.7500, 5.7499, 5.7499, 5.7499, 5.7499, 5.7499, 5.7499,\n",
      "        5.7499, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7500, 5.7499, 5.7500,\n",
      "        5.7499, 5.7499, 5.7500, 5.7500, 5.7500, 5.7499, 5.7499, 5.7499, 5.7499,\n",
      "        5.7500, 5.7501, 5.7499, 5.7499, 5.7499, 5.7499, 5.7499, 5.7499, 5.7500,\n",
      "        5.7500, 5.7500, 5.7500, 5.7500, 5.7501, 5.7500, 5.7500, 5.7500, 5.7503,\n",
      "        5.7500, 5.7502, 5.7502, 5.7500, 5.7500, 5.7502, 5.7502, 5.7502, 5.7501,\n",
      "        5.7501, 5.7501, 5.7500, 5.7501, 5.7501, 5.7502, 5.7499, 5.7499, 5.7500,\n",
      "        5.7499, 5.7500, 5.7499], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.551468  [2455324/5599865]\n",
      "average delta from current occupancy tensor([4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4840,\n",
      "        4.4840, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4839, 4.4840, 4.4840,\n",
      "        4.4840, 4.4839, 4.4840, 4.4839, 4.4840, 4.4839, 4.4839, 4.4840, 4.4840,\n",
      "        4.4840, 4.4840, 4.4840, 4.4840, 4.4840, 4.4840, 4.4840, 4.4840, 4.4840,\n",
      "        4.4839, 4.4840, 4.4840, 4.4840, 4.4840, 4.4839, 4.4840, 4.4840, 4.4840,\n",
      "        4.4839, 4.4840, 4.4839, 4.4839, 4.4839, 4.4839, 4.4840, 4.4840, 4.4840,\n",
      "        4.4840, 4.4840, 4.4840, 4.4840, 4.4840, 4.4839, 4.4839, 4.4839, 4.4839,\n",
      "        4.4839, 4.4839, 4.4839], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.689048  [2467724/5599865]\n",
      "average delta from current occupancy tensor([6.0404, 6.0404, 6.0404, 6.0404, 6.0403, 6.0403, 6.0403, 6.0404, 6.0403,\n",
      "        6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0403, 6.0403, 6.0403, 6.0403,\n",
      "        6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404,\n",
      "        6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404,\n",
      "        6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404,\n",
      "        6.0404, 6.0404, 6.0405, 6.0404, 6.0404, 6.0404, 6.0404, 6.0405, 6.0405,\n",
      "        6.0405, 6.0404, 6.0405, 6.0405, 6.0405, 6.0405, 6.0404, 6.0404, 6.0403,\n",
      "        6.0403, 6.0403, 6.0404, 6.0403, 6.0403, 6.0403, 6.0403, 6.0404, 6.0403,\n",
      "        6.0403, 6.0403, 6.0403, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0403,\n",
      "        6.0403, 6.0404, 6.0404, 6.0403, 6.0404, 6.0403, 6.0403, 6.0404, 6.0403,\n",
      "        6.0403, 6.0404, 6.0404, 6.0403, 6.0404, 6.0403, 6.0404, 6.0404, 6.0404,\n",
      "        6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404, 6.0404,\n",
      "        6.0404, 6.0404, 6.0403, 6.0404, 6.0404, 6.0404, 6.0403, 6.0404, 6.0404,\n",
      "        6.0404, 6.0404, 6.0404], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.544368  [2480124/5599865]\n",
      "average delta from current occupancy tensor([4.7663, 4.7662, 4.7662, 4.7661, 4.7662, 4.7662, 4.7664, 4.7662, 4.7662,\n",
      "        4.7662, 4.7662, 4.7662, 4.7662, 4.7661, 4.7661, 4.7662, 4.7662, 4.7663,\n",
      "        4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662,\n",
      "        4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662, 4.7662,\n",
      "        4.7663, 4.7662, 4.7662, 4.7663, 4.7662, 4.7663, 4.7662, 4.7662, 4.7662,\n",
      "        4.7662, 4.7661, 4.7662, 4.7662, 4.7661, 4.7661, 4.7662, 4.7662, 4.7662,\n",
      "        4.7662, 4.7662, 4.7661, 4.7661, 4.7662, 4.7661, 4.7662, 4.7661, 4.7661,\n",
      "        4.7662, 4.7662, 4.7661, 4.7661, 4.7662, 4.7662, 4.7661, 4.7661, 4.7662,\n",
      "        4.7662, 4.7662, 4.7662, 4.7662, 4.7661, 4.7662, 4.7662, 4.7662, 4.7663,\n",
      "        4.7662, 4.7662, 4.7662, 4.7664, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7664, 4.7662, 4.7663, 4.7663, 4.7662, 4.7664, 4.7662, 4.7663, 4.7662,\n",
      "        4.7663, 4.7662, 4.7662, 4.7663, 4.7663, 4.7663, 4.7663, 4.7664, 4.7664,\n",
      "        4.7664, 4.7663, 4.7665, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664,\n",
      "        4.7665, 4.7667, 4.7664], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.584027  [2492524/5599865]\n",
      "average delta from current occupancy tensor([4.5078, 4.5078, 4.5078, 4.5079, 4.5079, 4.5078, 4.5079, 4.5079, 4.5078,\n",
      "        4.5078, 4.5079, 4.5078, 4.5078, 4.5078, 4.5079, 4.5078, 4.5079, 4.5079,\n",
      "        4.5078, 4.5079, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5079, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5079, 4.5079, 4.5079, 4.5078, 4.5079, 4.5078, 4.5078, 4.5079,\n",
      "        4.5079, 4.5079, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5079, 4.5078, 4.5078, 4.5079, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.105204  [2504924/5599865]\n",
      "average delta from current occupancy tensor([5.1603, 5.1603, 5.1602, 5.1601, 5.1602, 5.1602, 5.1601, 5.1602, 5.1602,\n",
      "        5.1602, 5.1602, 5.1603, 5.1602, 5.1603, 5.1602, 5.1602, 5.1600, 5.1602,\n",
      "        5.1602, 5.1603, 5.1602, 5.1601, 5.1603, 5.1602, 5.1604, 5.1605, 5.1603,\n",
      "        5.1602, 5.1603, 5.1604, 5.1604, 5.1603, 5.1603, 5.1604, 5.1603, 5.1603,\n",
      "        5.1604, 5.1604, 5.1605, 5.1604, 5.1604, 5.1605, 5.1604, 5.1602, 5.1604,\n",
      "        5.1604, 5.1604, 5.1607, 5.1604, 5.1604, 5.1604, 5.1606, 5.1603, 5.1605,\n",
      "        5.1604, 5.1606, 5.1604, 5.1604, 5.1605, 5.1603, 5.1603, 5.1603, 5.1603,\n",
      "        5.1603, 5.1603, 5.1603, 5.1604, 5.1604, 5.1604, 5.1603, 5.1603, 5.1603,\n",
      "        5.1603, 5.1604, 5.1603, 5.1604, 5.1604, 5.1602, 5.1603, 5.1604, 5.1604,\n",
      "        5.1605, 5.1605, 5.1605, 5.1604, 5.1604, 5.1603, 5.1602, 5.1600, 5.1604,\n",
      "        5.1602, 5.1604, 5.1604, 5.1601, 5.1602, 5.1604, 5.1602, 5.1603, 5.1603,\n",
      "        5.1605, 5.1605, 5.1603, 5.1603, 5.1603, 5.1602, 5.1603, 5.1601, 5.1603,\n",
      "        5.1603, 5.1605, 5.1605, 5.1604, 5.1605, 5.1603, 5.1605, 5.1604, 5.1604,\n",
      "        5.1604, 5.1605, 5.1604], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.723603  [2517324/5599865]\n",
      "average delta from current occupancy tensor([4.8466, 4.8467, 4.8466, 4.8466, 4.8466, 4.8466, 4.8465, 4.8466, 4.8466,\n",
      "        4.8465, 4.8467, 4.8466, 4.8467, 4.8467, 4.8467, 4.8467, 4.8468, 4.8467,\n",
      "        4.8467, 4.8467, 4.8467, 4.8466, 4.8468, 4.8466, 4.8467, 4.8466, 4.8466,\n",
      "        4.8467, 4.8466, 4.8466, 4.8466, 4.8468, 4.8467, 4.8467, 4.8466, 4.8466,\n",
      "        4.8467, 4.8467, 4.8467, 4.8467, 4.8467, 4.8466, 4.8466, 4.8467, 4.8467,\n",
      "        4.8467, 4.8466, 4.8468, 4.8467, 4.8466, 4.8467, 4.8468, 4.8467, 4.8467,\n",
      "        4.8467, 4.8467, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466,\n",
      "        4.8466, 4.8466, 4.8466, 4.8467, 4.8466, 4.8466, 4.8467, 4.8466, 4.8465,\n",
      "        4.8467, 4.8467, 4.8466, 4.8467, 4.8466, 4.8466, 4.8467, 4.8466, 4.8467,\n",
      "        4.8467, 4.8467, 4.8466, 4.8467, 4.8466, 4.8467, 4.8466, 4.8467, 4.8466,\n",
      "        4.8466, 4.8467, 4.8466, 4.8466, 4.8467, 4.8467, 4.8467, 4.8466, 4.8467,\n",
      "        4.8466, 4.8467, 4.8468, 4.8466, 4.8466, 4.8466, 4.8467, 4.8466, 4.8467,\n",
      "        4.8466, 4.8466, 4.8467, 4.8467, 4.8467, 4.8466, 4.8466, 4.8467, 4.8466,\n",
      "        4.8467, 4.8466, 4.8467], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.265459  [2529724/5599865]\n",
      "average delta from current occupancy tensor([5.1451, 5.1451, 5.1451, 5.1451, 5.1451, 5.1451, 5.1451, 5.1451, 5.1452,\n",
      "        5.1451, 5.1452, 5.1451, 5.1451, 5.1452, 5.1450, 5.1451, 5.1452, 5.1452,\n",
      "        5.1454, 5.1452, 5.1451, 5.1449, 5.1450, 5.1450, 5.1453, 5.1450, 5.1450,\n",
      "        5.1451, 5.1451, 5.1451, 5.1451, 5.1450, 5.1450, 5.1450, 5.1451, 5.1451,\n",
      "        5.1450, 5.1451, 5.1450, 5.1450, 5.1450, 5.1451, 5.1449, 5.1451, 5.1451,\n",
      "        5.1451, 5.1452, 5.1451, 5.1451, 5.1451, 5.1450, 5.1451, 5.1451, 5.1451,\n",
      "        5.1450, 5.1451, 5.1450, 5.1450, 5.1450, 5.1449, 5.1451, 5.1452, 5.1451,\n",
      "        5.1450, 5.1450, 5.1450, 5.1451, 5.1450, 5.1450, 5.1449, 5.1449, 5.1448,\n",
      "        5.1450, 5.1450, 5.1450, 5.1449, 5.1448, 5.1448, 5.1448, 5.1449, 5.1450,\n",
      "        5.1449, 5.1449, 5.1450, 5.1449, 5.1449, 5.1450, 5.1450, 5.1449, 5.1450,\n",
      "        5.1450, 5.1450, 5.1449, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450,\n",
      "        5.1451, 5.1451, 5.1451, 5.1451, 5.1452, 5.1451, 5.1451, 5.1451, 5.1451,\n",
      "        5.1452, 5.1451, 5.1451, 5.1451, 5.1449, 5.1450, 5.1451, 5.1451, 5.1450,\n",
      "        5.1451, 5.1451, 5.1453], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.210295  [2542124/5599865]\n",
      "average delta from current occupancy tensor([5.2503, 5.2505, 5.2503, 5.2503, 5.2503, 5.2504, 5.2504, 5.2503, 5.2503,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2504,\n",
      "        5.2504, 5.2505, 5.2504, 5.2503, 5.2503, 5.2503, 5.2504, 5.2503, 5.2503,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2502, 5.2503, 5.2503, 5.2503,\n",
      "        5.2502, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503, 5.2503,\n",
      "        5.2503, 5.2504, 5.2503, 5.2503, 5.2503, 5.2504, 5.2503, 5.2503, 5.2504,\n",
      "        5.2504, 5.2504, 5.2503, 5.2504, 5.2503, 5.2504, 5.2503, 5.2504, 5.2504,\n",
      "        5.2503, 5.2503, 5.2503, 5.2503, 5.2504, 5.2504, 5.2504, 5.2503, 5.2503,\n",
      "        5.2503, 5.2504, 5.2504, 5.2504, 5.2504, 5.2504, 5.2504, 5.2503, 5.2504,\n",
      "        5.2504, 5.2504, 5.2503], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.646884  [2554524/5599865]\n",
      "average delta from current occupancy tensor([5.8794, 5.8794, 5.8794, 5.8794, 5.8794, 5.8794, 5.8795, 5.8794, 5.8794,\n",
      "        5.8794, 5.8793, 5.8794, 5.8794, 5.8794, 5.8794, 5.8793, 5.8794, 5.8793,\n",
      "        5.8793, 5.8794, 5.8794, 5.8794, 5.8794, 5.8793, 5.8793, 5.8793, 5.8793,\n",
      "        5.8792, 5.8793, 5.8794, 5.8793, 5.8794, 5.8794, 5.8794, 5.8793, 5.8793,\n",
      "        5.8793, 5.8794, 5.8793, 5.8793, 5.8793, 5.8794, 5.8795, 5.8793, 5.8793,\n",
      "        5.8796, 5.8794, 5.8795, 5.8793, 5.8793, 5.8793, 5.8794, 5.8793, 5.8793,\n",
      "        5.8794, 5.8793, 5.8793, 5.8793, 5.8792, 5.8793, 5.8793, 5.8793, 5.8793,\n",
      "        5.8793, 5.8793, 5.8793, 5.8793, 5.8793, 5.8793, 5.8795, 5.8793, 5.8793,\n",
      "        5.8794, 5.8794, 5.8795, 5.8794, 5.8794, 5.8793, 5.8794, 5.8794, 5.8792,\n",
      "        5.8794, 5.8793, 5.8793, 5.8794, 5.8794, 5.8794, 5.8794, 5.8793, 5.8794,\n",
      "        5.8794, 5.8794, 5.8794, 5.8794, 5.8793, 5.8795, 5.8794, 5.8794, 5.8794,\n",
      "        5.8793, 5.8793, 5.8794, 5.8794, 5.8793, 5.8793, 5.8793, 5.8794, 5.8793,\n",
      "        5.8794, 5.8794, 5.8794, 5.8793, 5.8794, 5.8793, 5.8794, 5.8793, 5.8794,\n",
      "        5.8793, 5.8793, 5.8793], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.365957  [2566924/5599865]\n",
      "average delta from current occupancy tensor([5.4601, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4601, 5.4601, 5.4601, 5.4600, 5.4601, 5.4600, 5.4600, 5.4601,\n",
      "        5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4601, 5.4601,\n",
      "        5.4600, 5.4601, 5.4601, 5.4601, 5.4601, 5.4600, 5.4599, 5.4600, 5.4600,\n",
      "        5.4600, 5.4600, 5.4601, 5.4599, 5.4600, 5.4600, 5.4601, 5.4600, 5.4600,\n",
      "        5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601,\n",
      "        5.4601, 5.4602, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4601, 5.4601,\n",
      "        5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601,\n",
      "        5.4602, 5.4602, 5.4602, 5.4601, 5.4601, 5.4602, 5.4601, 5.4601, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600, 5.4601, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4601, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.207151  [2579324/5599865]\n",
      "average delta from current occupancy tensor([4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693,\n",
      "        4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693,\n",
      "        4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693,\n",
      "        4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693, 4.1693,\n",
      "        4.1693, 4.1693, 4.1693, 4.1693, 4.1695, 4.1694, 4.1693, 4.1695, 4.1694,\n",
      "        4.1694, 4.1694, 4.1694, 4.1694, 4.1694, 4.1695, 4.1694, 4.1695, 4.1695,\n",
      "        4.1696, 4.1695, 4.1695, 4.1695, 4.1695, 4.1696, 4.1695, 4.1694, 4.1693,\n",
      "        4.1693, 4.1695, 4.1693, 4.1693, 4.1694, 4.1694, 4.1693, 4.1694, 4.1693,\n",
      "        4.1693, 4.1693, 4.1693, 4.1693, 4.1694, 4.1693, 4.1694, 4.1695, 4.1695,\n",
      "        4.1693, 4.1694, 4.1694, 4.1694, 4.1693, 4.1694, 4.1695, 4.1695, 4.1695,\n",
      "        4.1695, 4.1694, 4.1695, 4.1695, 4.1695, 4.1694, 4.1695, 4.1694, 4.1695,\n",
      "        4.1694, 4.1695, 4.1694, 4.1694, 4.1695, 4.1694, 4.1694, 4.1694, 4.1695,\n",
      "        4.1694, 4.1694, 4.1694, 4.1694, 4.1695, 4.1695, 4.1694, 4.1695, 4.1695,\n",
      "        4.1695, 4.1694, 4.1693], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.575222  [2591724/5599865]\n",
      "average delta from current occupancy tensor([5.4598, 5.4598, 5.4597, 5.4598, 5.4598, 5.4598, 5.4598, 5.4599, 5.4599,\n",
      "        5.4598, 5.4598, 5.4598, 5.4599, 5.4598, 5.4598, 5.4598, 5.4599, 5.4599,\n",
      "        5.4599, 5.4598, 5.4598, 5.4598, 5.4597, 5.4597, 5.4597, 5.4597, 5.4597,\n",
      "        5.4597, 5.4597, 5.4597, 5.4597, 5.4597, 5.4597, 5.4597, 5.4598, 5.4598,\n",
      "        5.4597, 5.4597, 5.4597, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4597, 5.4598, 5.4598, 5.4598, 5.4599,\n",
      "        5.4598, 5.4599, 5.4598, 5.4598, 5.4599, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4599, 5.4598, 5.4599, 5.4599, 5.4599, 5.4598, 5.4601, 5.4600, 5.4601,\n",
      "        5.4600, 5.4600, 5.4600, 5.4599, 5.4599, 5.4599, 5.4599, 5.4600, 5.4600,\n",
      "        5.4600, 5.4599, 5.4599, 5.4599, 5.4599, 5.4600, 5.4599, 5.4598, 5.4599,\n",
      "        5.4599, 5.4599, 5.4599, 5.4600, 5.4600, 5.4600, 5.4600, 5.4599, 5.4599,\n",
      "        5.4598, 5.4599, 5.4598, 5.4599, 5.4599, 5.4599, 5.4597, 5.4597, 5.4597,\n",
      "        5.4598, 5.4598, 5.4597, 5.4597, 5.4598, 5.4600, 5.4599, 5.4599, 5.4599,\n",
      "        5.4598, 5.4598, 5.4599], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.618130  [2604124/5599865]\n",
      "average delta from current occupancy tensor([4.6294, 4.6293, 4.6293, 4.6293, 4.6293, 4.6292, 4.6291, 4.6290, 4.6291,\n",
      "        4.6292, 4.6292, 4.6291, 4.6292, 4.6292, 4.6291, 4.6291, 4.6291, 4.6292,\n",
      "        4.6291, 4.6290, 4.6291, 4.6292, 4.6293, 4.6293, 4.6293, 4.6293, 4.6293,\n",
      "        4.6293, 4.6292, 4.6292, 4.6292, 4.6292, 4.6292, 4.6292, 4.6292, 4.6292,\n",
      "        4.6292, 4.6292, 4.6293, 4.6292, 4.6292, 4.6292, 4.6292, 4.6292, 4.6292,\n",
      "        4.6292, 4.6292, 4.6291, 4.6292, 4.6293, 4.6292, 4.6292, 4.6291, 4.6291,\n",
      "        4.6292, 4.6292, 4.6294, 4.6294, 4.6294, 4.6293, 4.6292, 4.6293, 4.6292,\n",
      "        4.6291, 4.6291, 4.6292, 4.6291, 4.6292, 4.6292, 4.6290, 4.6292, 4.6294,\n",
      "        4.6292, 4.6293, 4.6294, 4.6294, 4.6293, 4.6293, 4.6293, 4.6295, 4.6293,\n",
      "        4.6294, 4.6295, 4.6296, 4.6295, 4.6296, 4.6296, 4.6294, 4.6294, 4.6294,\n",
      "        4.6296, 4.6295, 4.6296, 4.6294, 4.6294, 4.6295, 4.6293, 4.6294, 4.6293,\n",
      "        4.6292, 4.6292, 4.6292, 4.6293, 4.6294, 4.6294, 4.6294, 4.6294, 4.6294,\n",
      "        4.6293, 4.6294, 4.6293, 4.6293, 4.6293, 4.6293, 4.6293, 4.6294, 4.6294,\n",
      "        4.6296, 4.6295, 4.6295], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.154130  [2616524/5599865]\n",
      "average delta from current occupancy tensor([5.2346, 5.2344, 5.2342, 5.2342, 5.2342, 5.2342, 5.2343, 5.2343, 5.2342,\n",
      "        5.2344, 5.2344, 5.2344, 5.2344, 5.2344, 5.2343, 5.2344, 5.2345, 5.2343,\n",
      "        5.2345, 5.2343, 5.2344, 5.2345, 5.2343, 5.2344, 5.2342, 5.2342, 5.2342,\n",
      "        5.2343, 5.2344, 5.2343, 5.2343, 5.2343, 5.2343, 5.2345, 5.2346, 5.2346,\n",
      "        5.2346, 5.2344, 5.2344, 5.2345, 5.2343, 5.2343, 5.2346, 5.2343, 5.2345,\n",
      "        5.2345, 5.2343, 5.2345, 5.2345, 5.2342, 5.2343, 5.2345, 5.2343, 5.2342,\n",
      "        5.2342, 5.2343, 5.2345, 5.2344, 5.2342, 5.2345, 5.2344, 5.2343, 5.2343,\n",
      "        5.2344, 5.2343, 5.2347, 5.2345, 5.2347, 5.2345, 5.2344, 5.2346, 5.2344,\n",
      "        5.2348, 5.2343, 5.2343, 5.2343, 5.2346, 5.2343, 5.2343, 5.2343, 5.2346,\n",
      "        5.2343, 5.2342, 5.2343, 5.2343, 5.2344, 5.2344, 5.2345, 5.2343, 5.2343,\n",
      "        5.2345, 5.2346, 5.2343, 5.2345, 5.2345, 5.2344, 5.2343, 5.2343, 5.2343,\n",
      "        5.2345, 5.2344, 5.2344, 5.2345, 5.2345, 5.2345, 5.2344, 5.2344, 5.2345,\n",
      "        5.2346, 5.2346, 5.2345, 5.2345, 5.2346, 5.2345, 5.2345, 5.2345, 5.2344,\n",
      "        5.2344, 5.2343, 5.2344], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.547643  [2628924/5599865]\n",
      "average delta from current occupancy tensor([4.6290, 4.6290, 4.6289, 4.6290, 4.6289, 4.6289, 4.6290, 4.6289, 4.6289,\n",
      "        4.6290, 4.6289, 4.6289, 4.6290, 4.6289, 4.6290, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290,\n",
      "        4.6290, 4.6290, 4.6290, 4.6289, 4.6289, 4.6289, 4.6288, 4.6289, 4.6288,\n",
      "        4.6289, 4.6289, 4.6290, 4.6290, 4.6289, 4.6289, 4.6289, 4.6290, 4.6289,\n",
      "        4.6290, 4.6290, 4.6289, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290,\n",
      "        4.6290, 4.6290, 4.6290, 4.6290, 4.6289, 4.6290, 4.6290, 4.6289, 4.6289,\n",
      "        4.6290, 4.6290, 4.6290, 4.6290, 4.6289, 4.6290, 4.6290, 4.6290, 4.6290,\n",
      "        4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6291, 4.6290, 4.6288,\n",
      "        4.6290, 4.6290, 4.6290, 4.6291, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290,\n",
      "        4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6291,\n",
      "        4.6290, 4.6290, 4.6290, 4.6291, 4.6291, 4.6291, 4.6291, 4.6290, 4.6291,\n",
      "        4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6289, 4.6290, 4.6290, 4.6289,\n",
      "        4.6290, 4.6290, 4.6289], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.159962  [2641324/5599865]\n",
      "average delta from current occupancy tensor([4.9512, 4.9513, 4.9512, 4.9513, 4.9513, 4.9513, 4.9513, 4.9514, 4.9513,\n",
      "        4.9512, 4.9513, 4.9513, 4.9513, 4.9513, 4.9513, 4.9512, 4.9513, 4.9512,\n",
      "        4.9512, 4.9513, 4.9513, 4.9512, 4.9512, 4.9512, 4.9513, 4.9512, 4.9512,\n",
      "        4.9513, 4.9512, 4.9512, 4.9513, 4.9512, 4.9512, 4.9512, 4.9512, 4.9514,\n",
      "        4.9513, 4.9513, 4.9513, 4.9512, 4.9512, 4.9513, 4.9512, 4.9511, 4.9511,\n",
      "        4.9512, 4.9513, 4.9511, 4.9513, 4.9512, 4.9514, 4.9512, 4.9513, 4.9511,\n",
      "        4.9512, 4.9511, 4.9512, 4.9512, 4.9511, 4.9512, 4.9512, 4.9513, 4.9511,\n",
      "        4.9511, 4.9512, 4.9512, 4.9512, 4.9511, 4.9513, 4.9513, 4.9513, 4.9513,\n",
      "        4.9515, 4.9514, 4.9513, 4.9514, 4.9513, 4.9515, 4.9514, 4.9514, 4.9513,\n",
      "        4.9514, 4.9515, 4.9514, 4.9516, 4.9515, 4.9515, 4.9514, 4.9515, 4.9515,\n",
      "        4.9515, 4.9515, 4.9515, 4.9513, 4.9514, 4.9514, 4.9513, 4.9514, 4.9513,\n",
      "        4.9514, 4.9513, 4.9513, 4.9514, 4.9513, 4.9513, 4.9514, 4.9515, 4.9515,\n",
      "        4.9516, 4.9513, 4.9515, 4.9514, 4.9514, 4.9514, 4.9515, 4.9514, 4.9514,\n",
      "        4.9513, 4.9514, 4.9513], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.109418  [2653724/5599865]\n",
      "average delta from current occupancy tensor([4.9912, 4.9912, 4.9912, 4.9912, 4.9913, 4.9912, 4.9912, 4.9912, 4.9912,\n",
      "        4.9912, 4.9912, 4.9912, 4.9912, 4.9912, 4.9914, 4.9913, 4.9913, 4.9913,\n",
      "        4.9914, 4.9913, 4.9914, 4.9914, 4.9914, 4.9914, 4.9914, 4.9914, 4.9913,\n",
      "        4.9914, 4.9913, 4.9915, 4.9914, 4.9913, 4.9914, 4.9914, 4.9915, 4.9914,\n",
      "        4.9915, 4.9913, 4.9914, 4.9913, 4.9913, 4.9914, 4.9913, 4.9914, 4.9913,\n",
      "        4.9913, 4.9913, 4.9913, 4.9914, 4.9913, 4.9913, 4.9913, 4.9913, 4.9913,\n",
      "        4.9913, 4.9914, 4.9914, 4.9914, 4.9914, 4.9914, 4.9913, 4.9913, 4.9913,\n",
      "        4.9911, 4.9912, 4.9912, 4.9912, 4.9911, 4.9912, 4.9913, 4.9913, 4.9913,\n",
      "        4.9912, 4.9914, 4.9913, 4.9913, 4.9913, 4.9914, 4.9913, 4.9913, 4.9913,\n",
      "        4.9913, 4.9914, 4.9913, 4.9912, 4.9912, 4.9912, 4.9913, 4.9915, 4.9914,\n",
      "        4.9914, 4.9914, 4.9913, 4.9913, 4.9912, 4.9913, 4.9913, 4.9914, 4.9912,\n",
      "        4.9913, 4.9911, 4.9912, 4.9912, 4.9911, 4.9912, 4.9913, 4.9912, 4.9912,\n",
      "        4.9912, 4.9911, 4.9912, 4.9913, 4.9912, 4.9912, 4.9912, 4.9911, 4.9911,\n",
      "        4.9910, 4.9910, 4.9909], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.183193  [2666124/5599865]\n",
      "average delta from current occupancy tensor([5.1606, 5.1602, 5.1604, 5.1606, 5.1604, 5.1603, 5.1602, 5.1603, 5.1607,\n",
      "        5.1607, 5.1607, 5.1604, 5.1608, 5.1606, 5.1606, 5.1605, 5.1604, 5.1603,\n",
      "        5.1604, 5.1605, 5.1601, 5.1601, 5.1603, 5.1602, 5.1601, 5.1601, 5.1602,\n",
      "        5.1602, 5.1602, 5.1602, 5.1601, 5.1605, 5.1601, 5.1604, 5.1605, 5.1603,\n",
      "        5.1607, 5.1606, 5.1607, 5.1605, 5.1604, 5.1603, 5.1608, 5.1605, 5.1605,\n",
      "        5.1605, 5.1604, 5.1606, 5.1606, 5.1607, 5.1605, 5.1608, 5.1607, 5.1607,\n",
      "        5.1603, 5.1606, 5.1607, 5.1608, 5.1607, 5.1608, 5.1607, 5.1606, 5.1605,\n",
      "        5.1605, 5.1609, 5.1608, 5.1608, 5.1607, 5.1609, 5.1607, 5.1607, 5.1608,\n",
      "        5.1608, 5.1607, 5.1609, 5.1608, 5.1605, 5.1608, 5.1610, 5.1607, 5.1609,\n",
      "        5.1607, 5.1606, 5.1604, 5.1608, 5.1608, 5.1608, 5.1606, 5.1607, 5.1605,\n",
      "        5.1605, 5.1604, 5.1606, 5.1605, 5.1604, 5.1605, 5.1606, 5.1607, 5.1607,\n",
      "        5.1608, 5.1606, 5.1608, 5.1609, 5.1608, 5.1608, 5.1608, 5.1609, 5.1608,\n",
      "        5.1608, 5.1610, 5.1610, 5.1610, 5.1609, 5.1611, 5.1610, 5.1611, 5.1611,\n",
      "        5.1609, 5.1610, 5.1610], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.762590  [2678524/5599865]\n",
      "average delta from current occupancy tensor([4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.044252  [2690924/5599865]\n",
      "average delta from current occupancy tensor([4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9032, 4.9032, 4.9032], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.125950  [2703324/5599865]\n",
      "average delta from current occupancy tensor([6.3554, 6.3553, 6.3553, 6.3552, 6.3553, 6.3554, 6.3554, 6.3554, 6.3555,\n",
      "        6.3556, 6.3555, 6.3555, 6.3557, 6.3555, 6.3553, 6.3554, 6.3554, 6.3554,\n",
      "        6.3553, 6.3553, 6.3552, 6.3554, 6.3553, 6.3554, 6.3554, 6.3554, 6.3554,\n",
      "        6.3553, 6.3553, 6.3553, 6.3554, 6.3554, 6.3554, 6.3554, 6.3555, 6.3555,\n",
      "        6.3556, 6.3556, 6.3555, 6.3554, 6.3554, 6.3556, 6.3556, 6.3556, 6.3556,\n",
      "        6.3555, 6.3555, 6.3556, 6.3556, 6.3556, 6.3556, 6.3556, 6.3557, 6.3557,\n",
      "        6.3555, 6.3556, 6.3555, 6.3556, 6.3555, 6.3555, 6.3555, 6.3556, 6.3555,\n",
      "        6.3557, 6.3557, 6.3556, 6.3555, 6.3557, 6.3556, 6.3557, 6.3557, 6.3557,\n",
      "        6.3557, 6.3558, 6.3558, 6.3558, 6.3558, 6.3558, 6.3558, 6.3559, 6.3558,\n",
      "        6.3556, 6.3557, 6.3557, 6.3556, 6.3556, 6.3557, 6.3557, 6.3556, 6.3555,\n",
      "        6.3557, 6.3557, 6.3557, 6.3555, 6.3556, 6.3557, 6.3556, 6.3555, 6.3556,\n",
      "        6.3554, 6.3556, 6.3554, 6.3554, 6.3553, 6.3555, 6.3556, 6.3556, 6.3557,\n",
      "        6.3556, 6.3556, 6.3557, 6.3557, 6.3556, 6.3556, 6.3555, 6.3556, 6.3556,\n",
      "        6.3555, 6.3556, 6.3554], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.974185  [2715724/5599865]\n",
      "average delta from current occupancy tensor([5.1781, 5.1783, 5.1783, 5.1782, 5.1783, 5.1782, 5.1783, 5.1783, 5.1784,\n",
      "        5.1783, 5.1782, 5.1782, 5.1784, 5.1782, 5.1783, 5.1784, 5.1782, 5.1784,\n",
      "        5.1783, 5.1782, 5.1783, 5.1783, 5.1782, 5.1784, 5.1783, 5.1782, 5.1784,\n",
      "        5.1782, 5.1782, 5.1782, 5.1781, 5.1782, 5.1781, 5.1782, 5.1778, 5.1782,\n",
      "        5.1781, 5.1781, 5.1782, 5.1783, 5.1783, 5.1783, 5.1782, 5.1783, 5.1781,\n",
      "        5.1780, 5.1782, 5.1782, 5.1782, 5.1780, 5.1782, 5.1783, 5.1783, 5.1782,\n",
      "        5.1781, 5.1778, 5.1777, 5.1783, 5.1780, 5.1783, 5.1781, 5.1779, 5.1782,\n",
      "        5.1779, 5.1779, 5.1781, 5.1782, 5.1782, 5.1781, 5.1781, 5.1784, 5.1784,\n",
      "        5.1783, 5.1778, 5.1781, 5.1779, 5.1780, 5.1782, 5.1782, 5.1782, 5.1782,\n",
      "        5.1782, 5.1780, 5.1782, 5.1779, 5.1781, 5.1782, 5.1783, 5.1782, 5.1781,\n",
      "        5.1781, 5.1781, 5.1782, 5.1782, 5.1782, 5.1778, 5.1781, 5.1780, 5.1782,\n",
      "        5.1782, 5.1779, 5.1780, 5.1780, 5.1779, 5.1780, 5.1781, 5.1779, 5.1781,\n",
      "        5.1781, 5.1780, 5.1779, 5.1780, 5.1780, 5.1780, 5.1781, 5.1780, 5.1779,\n",
      "        5.1781, 5.1781, 5.1780], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.776065  [2728124/5599865]\n",
      "average delta from current occupancy tensor([4.7499, 4.7499, 4.7500, 4.7499, 4.7500, 4.7500, 4.7500, 4.7499, 4.7500,\n",
      "        4.7500, 4.7501, 4.7500, 4.7501, 4.7500, 4.7499, 4.7500, 4.7499, 4.7500,\n",
      "        4.7500, 4.7500, 4.7500, 4.7499, 4.7499, 4.7500, 4.7499, 4.7500, 4.7499,\n",
      "        4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499,\n",
      "        4.7500, 4.7500, 4.7500, 4.7499, 4.7499, 4.7500, 4.7499, 4.7499, 4.7500,\n",
      "        4.7500, 4.7501, 4.7500, 4.7499, 4.7500, 4.7499, 4.7500, 4.7500, 4.7501,\n",
      "        4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7500,\n",
      "        4.7498, 4.7498, 4.7499, 4.7499, 4.7499, 4.7498, 4.7498, 4.7499, 4.7499,\n",
      "        4.7499, 4.7498, 4.7498, 4.7498, 4.7498, 4.7499, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499,\n",
      "        4.7499, 4.7500, 4.7499, 4.7499, 4.7498, 4.7499, 4.7499, 4.7499, 4.7499,\n",
      "        4.7498, 4.7498, 4.7500, 4.7499, 4.7500, 4.7500, 4.7499, 4.7499, 4.7499,\n",
      "        4.7500, 4.7499, 4.7500, 4.7500, 4.7500, 4.7499, 4.7499, 4.7500, 4.7501,\n",
      "        4.7500, 4.7499, 4.7500], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.073523  [2740524/5599865]\n",
      "average delta from current occupancy tensor([5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.282019  [2752924/5599865]\n",
      "average delta from current occupancy tensor([4.0967, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0967, 4.0967,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0967, 4.0967, 4.0966, 4.0967, 4.0967, 4.0967, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0967, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966,\n",
      "        4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0966, 4.0967,\n",
      "        4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967,\n",
      "        4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967,\n",
      "        4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0967, 4.0966, 4.0967,\n",
      "        4.0967, 4.0967, 4.0967], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.543622  [2765324/5599865]\n",
      "average delta from current occupancy tensor([4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6290, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.734834  [2777724/5599865]\n",
      "average delta from current occupancy tensor([5.8986, 5.8981, 5.8979, 5.8981, 5.8978, 5.8973, 5.8978, 5.8971, 5.8973,\n",
      "        5.8977, 5.8976, 5.8980, 5.8977, 5.8977, 5.8973, 5.8974, 5.8974, 5.8970,\n",
      "        5.8968, 5.8972, 5.8975, 5.8971, 5.8977, 5.8971, 5.8973, 5.8967, 5.8971,\n",
      "        5.8975, 5.8968, 5.8970, 5.8974, 5.8968, 5.8973, 5.8972, 5.8972, 5.8972,\n",
      "        5.8973, 5.8972, 5.8966, 5.8973, 5.8965, 5.8969, 5.8970, 5.8972, 5.8974,\n",
      "        5.8968, 5.8980, 5.8976, 5.8967, 5.8978, 5.8969, 5.8976, 5.8970, 5.8977,\n",
      "        5.8969, 5.8967, 5.8967, 5.8965, 5.8975, 5.8974, 5.8962, 5.8979, 5.8967,\n",
      "        5.8969, 5.8963, 5.8962, 5.8965, 5.8976, 5.8966, 5.8971, 5.8969, 5.8967,\n",
      "        5.8968, 5.8968, 5.8966, 5.8969, 5.8970, 5.8973, 5.8979, 5.8971, 5.8970,\n",
      "        5.8971, 5.8967, 5.8968, 5.8969, 5.8966, 5.8968, 5.8963, 5.8962, 5.8967,\n",
      "        5.8969, 5.8967, 5.8968, 5.8969, 5.8970, 5.8969, 5.8970, 5.8969, 5.8969,\n",
      "        5.8972, 5.8972, 5.8977, 5.8973, 5.8971, 5.8972, 5.8974, 5.8971, 5.8968,\n",
      "        5.8971, 5.8969, 5.8967, 5.8968, 5.8971, 5.8974, 5.8973, 5.8972, 5.8965,\n",
      "        5.8970, 5.8968, 5.8972], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.142147  [2790124/5599865]\n",
      "average delta from current occupancy tensor([4.8800, 4.8795, 4.8795, 4.8796, 4.8802, 4.8796, 4.8798, 4.8798, 4.8797,\n",
      "        4.8795, 4.8797, 4.8798, 4.8798, 4.8799, 4.8797, 4.8798, 4.8797, 4.8797,\n",
      "        4.8798, 4.8795, 4.8797, 4.8797, 4.8795, 4.8798, 4.8796, 4.8796, 4.8795,\n",
      "        4.8796, 4.8797, 4.8797, 4.8797, 4.8800, 4.8799, 4.8799, 4.8801, 4.8797,\n",
      "        4.8797, 4.8796, 4.8798, 4.8802, 4.8800, 4.8796, 4.8801, 4.8799, 4.8803,\n",
      "        4.8796, 4.8802, 4.8800, 4.8801, 4.8799, 4.8803, 4.8800, 4.8799, 4.8799,\n",
      "        4.8802, 4.8801, 4.8800, 4.8805, 4.8803, 4.8803, 4.8801, 4.8803, 4.8801,\n",
      "        4.8802, 4.8803, 4.8803, 4.8803, 4.8804, 4.8802, 4.8809, 4.8808, 4.8802,\n",
      "        4.8804, 4.8803, 4.8803, 4.8805, 4.8808, 4.8804, 4.8802, 4.8804, 4.8803,\n",
      "        4.8802, 4.8800, 4.8799, 4.8805, 4.8801, 4.8803, 4.8799, 4.8801, 4.8800,\n",
      "        4.8803, 4.8801, 4.8801, 4.8803, 4.8804, 4.8805, 4.8798, 4.8799, 4.8800,\n",
      "        4.8803, 4.8800, 4.8803, 4.8802, 4.8800, 4.8799, 4.8800, 4.8799, 4.8801,\n",
      "        4.8800, 4.8798, 4.8797, 4.8797, 4.8808, 4.8804, 4.8807, 4.8806, 4.8803,\n",
      "        4.8805, 4.8806, 4.8808], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.973380  [2802524/5599865]\n",
      "average delta from current occupancy tensor([6.0867, 6.0866, 6.0865, 6.0866, 6.0865, 6.0864, 6.0862, 6.0862, 6.0862,\n",
      "        6.0865, 6.0859, 6.0863, 6.0859, 6.0859, 6.0861, 6.0860, 6.0862, 6.0859,\n",
      "        6.0860, 6.0859, 6.0858, 6.0857, 6.0859, 6.0857, 6.0860, 6.0856, 6.0855,\n",
      "        6.0855, 6.0854, 6.0859, 6.0856, 6.0861, 6.0859, 6.0859, 6.0861, 6.0859,\n",
      "        6.0852, 6.0857, 6.0861, 6.0856, 6.0860, 6.0861, 6.0859, 6.0855, 6.0859,\n",
      "        6.0860, 6.0861, 6.0860, 6.0852, 6.0857, 6.0853, 6.0853, 6.0857, 6.0855,\n",
      "        6.0855, 6.0853, 6.0851, 6.0856, 6.0857, 6.0856, 6.0857, 6.0856, 6.0854,\n",
      "        6.0854, 6.0855, 6.0855, 6.0856, 6.0855, 6.0855, 6.0858, 6.0859, 6.0863,\n",
      "        6.0861, 6.0860, 6.0860, 6.0857, 6.0860, 6.0862, 6.0864, 6.0865, 6.0866,\n",
      "        6.0865, 6.0865, 6.0865, 6.0864, 6.0866, 6.0868, 6.0868, 6.0866, 6.0866,\n",
      "        6.0867, 6.0869, 6.0870, 6.0870, 6.0867, 6.0867, 6.0866, 6.0866, 6.0870,\n",
      "        6.0869, 6.0868, 6.0865, 6.0869, 6.0862, 6.0866, 6.0864, 6.0859, 6.0861,\n",
      "        6.0860, 6.0863, 6.0861, 6.0863, 6.0858, 6.0862, 6.0860, 6.0863, 6.0865,\n",
      "        6.0864, 6.0862, 6.0865], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.077456  [2814924/5599865]\n",
      "average delta from current occupancy tensor([4.8309, 4.8308, 4.8308, 4.8309, 4.8310, 4.8310, 4.8308, 4.8308, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306,\n",
      "        4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8306, 4.8307, 4.8306, 4.8309,\n",
      "        4.8308, 4.8309, 4.8308, 4.8307, 4.8309, 4.8309, 4.8309, 4.8308, 4.8308,\n",
      "        4.8308, 4.8307, 4.8307, 4.8307, 4.8307, 4.8306, 4.8307, 4.8308, 4.8306,\n",
      "        4.8307, 4.8307, 4.8306, 4.8308, 4.8306, 4.8308, 4.8306, 4.8307, 4.8306,\n",
      "        4.8307, 4.8307, 4.8306, 4.8306, 4.8306, 4.8306, 4.8307, 4.8307, 4.8307,\n",
      "        4.8306, 4.8307, 4.8306], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.399709  [2827324/5599865]\n",
      "average delta from current occupancy tensor([5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5727, 5.5727, 5.5727, 5.5726,\n",
      "        5.5727, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5728, 5.5726, 5.5727, 5.5727,\n",
      "        5.5727, 5.5727, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5727, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5728,\n",
      "        5.5728, 5.5727, 5.5726, 5.5726, 5.5727, 5.5726, 5.5728, 5.5729, 5.5726,\n",
      "        5.5726, 5.5726, 5.5727, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5727, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5728, 5.5726, 5.5727, 5.5727, 5.5728, 5.5727, 5.5726, 5.5726,\n",
      "        5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726, 5.5726,\n",
      "        5.5726, 5.5728, 5.5726], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.280951  [2839724/5599865]\n",
      "average delta from current occupancy tensor([5.3006, 5.3012, 5.3008, 5.3010, 5.3009, 5.3005, 5.3004, 5.3004, 5.3004,\n",
      "        5.3003, 5.3002, 5.3002, 5.2997, 5.3001, 5.2998, 5.2999, 5.3001, 5.3004,\n",
      "        5.2998, 5.3000, 5.2999, 5.2993, 5.2997, 5.2999, 5.2995, 5.2993, 5.2996,\n",
      "        5.2994, 5.2995, 5.2997, 5.3001, 5.3002, 5.2998, 5.2998, 5.2995, 5.3000,\n",
      "        5.3000, 5.2996, 5.2993, 5.2996, 5.2993, 5.2997, 5.2999, 5.2996, 5.2997,\n",
      "        5.2997, 5.3007, 5.2997, 5.2994, 5.2996, 5.2995, 5.2998, 5.2997, 5.2995,\n",
      "        5.3007, 5.3005, 5.3003, 5.3004, 5.3006, 5.3009, 5.3009, 5.3008, 5.3009,\n",
      "        5.3008, 5.3014, 5.3011, 5.3008, 5.3000, 5.3010, 5.3007, 5.3009, 5.3013,\n",
      "        5.3011, 5.3009, 5.3012, 5.3010, 5.3010, 5.3008, 5.3014, 5.3014, 5.3010,\n",
      "        5.3011, 5.3009, 5.3012, 5.3008, 5.3011, 5.3005, 5.3008, 5.3009, 5.3004,\n",
      "        5.3005, 5.3000, 5.3009, 5.3011, 5.3011, 5.3008, 5.3010, 5.3011, 5.3010,\n",
      "        5.3012, 5.3006, 5.3011, 5.3016, 5.3007, 5.3005, 5.3009, 5.3012, 5.3013,\n",
      "        5.3011, 5.3014, 5.3012, 5.3015, 5.3009, 5.3008, 5.3004, 5.3003, 5.3011,\n",
      "        5.3002, 5.3004, 5.3005], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.591883  [2852124/5599865]\n",
      "average delta from current occupancy tensor([5.8236, 5.8233, 5.8233, 5.8237, 5.8236, 5.8237, 5.8236, 5.8236, 5.8235,\n",
      "        5.8236, 5.8234, 5.8236, 5.8234, 5.8234, 5.8232, 5.8232, 5.8233, 5.8233,\n",
      "        5.8233, 5.8233, 5.8233, 5.8236, 5.8235, 5.8232, 5.8234, 5.8235, 5.8234,\n",
      "        5.8236, 5.8236, 5.8235, 5.8236, 5.8238, 5.8238, 5.8234, 5.8235, 5.8235,\n",
      "        5.8236, 5.8234, 5.8233, 5.8235, 5.8235, 5.8235, 5.8236, 5.8237, 5.8235,\n",
      "        5.8236, 5.8239, 5.8236, 5.8236, 5.8235, 5.8234, 5.8238, 5.8238, 5.8237,\n",
      "        5.8239, 5.8236, 5.8235, 5.8238, 5.8235, 5.8235, 5.8239, 5.8239, 5.8238,\n",
      "        5.8237, 5.8238, 5.8240, 5.8237, 5.8235, 5.8237, 5.8234, 5.8236, 5.8235,\n",
      "        5.8234, 5.8232, 5.8234, 5.8234, 5.8232, 5.8231, 5.8233, 5.8233, 5.8234,\n",
      "        5.8236, 5.8236, 5.8237, 5.8236, 5.8238, 5.8235, 5.8234, 5.8236, 5.8234,\n",
      "        5.8238, 5.8235, 5.8237, 5.8238, 5.8240, 5.8237, 5.8241, 5.8238, 5.8243,\n",
      "        5.8237, 5.8240, 5.8237, 5.8236, 5.8241, 5.8241, 5.8236, 5.8236, 5.8235,\n",
      "        5.8235, 5.8237, 5.8239, 5.8237, 5.8238, 5.8241, 5.8241, 5.8239, 5.8242,\n",
      "        5.8238, 5.8238, 5.8240], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.368379  [2864524/5599865]\n",
      "average delta from current occupancy tensor([4.2255, 4.2256, 4.2256, 4.2256, 4.2256, 4.2258, 4.2257, 4.2256, 4.2257,\n",
      "        4.2258, 4.2258, 4.2256, 4.2258, 4.2256, 4.2255, 4.2255, 4.2255, 4.2255,\n",
      "        4.2255, 4.2256, 4.2255, 4.2254, 4.2255, 4.2257, 4.2254, 4.2255, 4.2256,\n",
      "        4.2256, 4.2256, 4.2256, 4.2257, 4.2255, 4.2256, 4.2256, 4.2257, 4.2256,\n",
      "        4.2256, 4.2256, 4.2257, 4.2257, 4.2256, 4.2258, 4.2258, 4.2256, 4.2256,\n",
      "        4.2255, 4.2256, 4.2256, 4.2254, 4.2256, 4.2254, 4.2255, 4.2255, 4.2256,\n",
      "        4.2256, 4.2255, 4.2254, 4.2255, 4.2255, 4.2254, 4.2256, 4.2255, 4.2256,\n",
      "        4.2256, 4.2257, 4.2258, 4.2258, 4.2257, 4.2256, 4.2256, 4.2256, 4.2256,\n",
      "        4.2256, 4.2257, 4.2255, 4.2255, 4.2255, 4.2256, 4.2254, 4.2255, 4.2255,\n",
      "        4.2257, 4.2255, 4.2255, 4.2255, 4.2255, 4.2257, 4.2257, 4.2256, 4.2255,\n",
      "        4.2257, 4.2256, 4.2255, 4.2255, 4.2255, 4.2256, 4.2255, 4.2255, 4.2255,\n",
      "        4.2256, 4.2256, 4.2257, 4.2255, 4.2254, 4.2255, 4.2255, 4.2255, 4.2254,\n",
      "        4.2254, 4.2254, 4.2254, 4.2254, 4.2255, 4.2254, 4.2254, 4.2254, 4.2254,\n",
      "        4.2255, 4.2254, 4.2253], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.750287  [2876924/5599865]\n",
      "average delta from current occupancy tensor([4.9808, 4.9808, 4.9807, 4.9808, 4.9808, 4.9807, 4.9804, 4.9809, 4.9809,\n",
      "        4.9810, 4.9809, 4.9810, 4.9813, 4.9809, 4.9805, 4.9811, 4.9810, 4.9810,\n",
      "        4.9809, 4.9809, 4.9805, 4.9805, 4.9807, 4.9807, 4.9812, 4.9812, 4.9811,\n",
      "        4.9813, 4.9811, 4.9804, 4.9810, 4.9803, 4.9812, 4.9805, 4.9815, 4.9817,\n",
      "        4.9807, 4.9817, 4.9810, 4.9806, 4.9813, 4.9811, 4.9812, 4.9817, 4.9819,\n",
      "        4.9818, 4.9812, 4.9814, 4.9814, 4.9819, 4.9812, 4.9810, 4.9812, 4.9811,\n",
      "        4.9803, 4.9809, 4.9806, 4.9809, 4.9809, 4.9805, 4.9802, 4.9808, 4.9811,\n",
      "        4.9807, 4.9805, 4.9810, 4.9806, 4.9804, 4.9808, 4.9807, 4.9808, 4.9821,\n",
      "        4.9820, 4.9820, 4.9816, 4.9821, 4.9823, 4.9818, 4.9816, 4.9819, 4.9819,\n",
      "        4.9818, 4.9816, 4.9819, 4.9819, 4.9820, 4.9816, 4.9814, 4.9819, 4.9810,\n",
      "        4.9820, 4.9819, 4.9817, 4.9829, 4.9825, 4.9820, 4.9811, 4.9816, 4.9815,\n",
      "        4.9809, 4.9808, 4.9820, 4.9809, 4.9806, 4.9805, 4.9812, 4.9812, 4.9816,\n",
      "        4.9812, 4.9822, 4.9814, 4.9810, 4.9812, 4.9814, 4.9812, 4.9811, 4.9812,\n",
      "        4.9818, 4.9814, 4.9815], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.112171  [2889324/5599865]\n",
      "average delta from current occupancy tensor([5.2843, 5.2842, 5.2841, 5.2839, 5.2838, 5.2839, 5.2841, 5.2838, 5.2838,\n",
      "        5.2838, 5.2839, 5.2837, 5.2837, 5.2835, 5.2838, 5.2836, 5.2836, 5.2836,\n",
      "        5.2836, 5.2838, 5.2839, 5.2838, 5.2837, 5.2838, 5.2835, 5.2835, 5.2833,\n",
      "        5.2833, 5.2834, 5.2837, 5.2834, 5.2837, 5.2833, 5.2838, 5.2833, 5.2833,\n",
      "        5.2836, 5.2831, 5.2834, 5.2836, 5.2834, 5.2836, 5.2835, 5.2834, 5.2831,\n",
      "        5.2831, 5.2836, 5.2833, 5.2833, 5.2829, 5.2833, 5.2834, 5.2833, 5.2835,\n",
      "        5.2840, 5.2836, 5.2836, 5.2833, 5.2832, 5.2835, 5.2836, 5.2832, 5.2833,\n",
      "        5.2836, 5.2838, 5.2836, 5.2839, 5.2839, 5.2838, 5.2838, 5.2840, 5.2834,\n",
      "        5.2833, 5.2835, 5.2836, 5.2833, 5.2831, 5.2835, 5.2834, 5.2832, 5.2833,\n",
      "        5.2833, 5.2835, 5.2834, 5.2833, 5.2833, 5.2833, 5.2834, 5.2831, 5.2835,\n",
      "        5.2830, 5.2832, 5.2833, 5.2830, 5.2828, 5.2830, 5.2835, 5.2833, 5.2834,\n",
      "        5.2838, 5.2837, 5.2831, 5.2836, 5.2839, 5.2839, 5.2835, 5.2837, 5.2835,\n",
      "        5.2837, 5.2834, 5.2837, 5.2839, 5.2838, 5.2838, 5.2839, 5.2839, 5.2842,\n",
      "        5.2837, 5.2838, 5.2836], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.990002  [2901724/5599865]\n",
      "average delta from current occupancy tensor([4.8877, 4.8878, 4.8878, 4.8878, 4.8878, 4.8878, 4.8879, 4.8878, 4.8878,\n",
      "        4.8878, 4.8879, 4.8878, 4.8877, 4.8876, 4.8877, 4.8877, 4.8876, 4.8876,\n",
      "        4.8877, 4.8877, 4.8877, 4.8877, 4.8877, 4.8878, 4.8877, 4.8877, 4.8876,\n",
      "        4.8876, 4.8876, 4.8877, 4.8876, 4.8878, 4.8876, 4.8878, 4.8877, 4.8878,\n",
      "        4.8879, 4.8877, 4.8878, 4.8879, 4.8878, 4.8879, 4.8878, 4.8878, 4.8877,\n",
      "        4.8877, 4.8878, 4.8877, 4.8877, 4.8877, 4.8877, 4.8878, 4.8877, 4.8878,\n",
      "        4.8879, 4.8877, 4.8878, 4.8877, 4.8876, 4.8878, 4.8879, 4.8878, 4.8879,\n",
      "        4.8880, 4.8880, 4.8880, 4.8880, 4.8881, 4.8880, 4.8879, 4.8880, 4.8879,\n",
      "        4.8879, 4.8879, 4.8880, 4.8879, 4.8877, 4.8878, 4.8878, 4.8877, 4.8878,\n",
      "        4.8878, 4.8879, 4.8878, 4.8878, 4.8878, 4.8878, 4.8878, 4.8877, 4.8879,\n",
      "        4.8877, 4.8878, 4.8878, 4.8878, 4.8877, 4.8878, 4.8879, 4.8879, 4.8879,\n",
      "        4.8880, 4.8880, 4.8879, 4.8880, 4.8881, 4.8881, 4.8880, 4.8880, 4.8879,\n",
      "        4.8880, 4.8879, 4.8880, 4.8881, 4.8880, 4.8880, 4.8880, 4.8881, 4.8882,\n",
      "        4.8880, 4.8881, 4.8880], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.927937  [2914124/5599865]\n",
      "average delta from current occupancy tensor([5.0162, 5.0162, 5.0161, 5.0162, 5.0162, 5.0162, 5.0161, 5.0161, 5.0161,\n",
      "        5.0162, 5.0162, 5.0161, 5.0162, 5.0162, 5.0162, 5.0162, 5.0161, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0161, 5.0162,\n",
      "        5.0161, 5.0162, 5.0161, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0161,\n",
      "        5.0162, 5.0161, 5.0162, 5.0161, 5.0162, 5.0161, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0161, 5.0162, 5.0162,\n",
      "        5.0161, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162, 5.0162,\n",
      "        5.0162, 5.0162, 5.0162], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.374518  [2926524/5599865]\n",
      "average delta from current occupancy tensor([5.5968, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969,\n",
      "        5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969,\n",
      "        5.5970, 5.5970, 5.5970, 5.5970, 5.5969, 5.5970, 5.5969, 5.5969, 5.5970,\n",
      "        5.5970, 5.5970, 5.5970, 5.5969, 5.5969, 5.5969, 5.5969, 5.5970, 5.5969,\n",
      "        5.5969, 5.5969, 5.5969, 5.5970, 5.5969, 5.5969, 5.5970, 5.5969, 5.5969,\n",
      "        5.5970, 5.5970, 5.5969, 5.5969, 5.5969, 5.5969, 5.5970, 5.5969, 5.5970,\n",
      "        5.5970, 5.5970, 5.5970, 5.5970, 5.5970, 5.5970, 5.5970, 5.5969, 5.5970,\n",
      "        5.5970, 5.5970, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969,\n",
      "        5.5969, 5.5970, 5.5969, 5.5970, 5.5970, 5.5970, 5.5969, 5.5970, 5.5969,\n",
      "        5.5970, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969,\n",
      "        5.5970, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5968, 5.5969, 5.5969,\n",
      "        5.5968, 5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5968, 5.5969, 5.5969,\n",
      "        5.5969, 5.5969, 5.5969, 5.5969, 5.5969, 5.5968, 5.5969, 5.5969, 5.5969,\n",
      "        5.5969, 5.5969, 5.5968], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.300228  [2938924/5599865]\n",
      "average delta from current occupancy tensor([5.1828, 5.1828, 5.1826, 5.1829, 5.1826, 5.1827, 5.1827, 5.1826, 5.1828,\n",
      "        5.1826, 5.1826, 5.1828, 5.1827, 5.1830, 5.1830, 5.1832, 5.1832, 5.1830,\n",
      "        5.1826, 5.1824, 5.1824, 5.1823, 5.1822, 5.1829, 5.1828, 5.1828, 5.1829,\n",
      "        5.1828, 5.1826, 5.1825, 5.1821, 5.1822, 5.1822, 5.1821, 5.1828, 5.1825,\n",
      "        5.1824, 5.1822, 5.1823, 5.1830, 5.1823, 5.1827, 5.1829, 5.1826, 5.1826,\n",
      "        5.1825, 5.1825, 5.1822, 5.1823, 5.1819, 5.1820, 5.1822, 5.1820, 5.1821,\n",
      "        5.1824, 5.1828, 5.1825, 5.1827, 5.1824, 5.1824, 5.1827, 5.1828, 5.1823,\n",
      "        5.1825, 5.1823, 5.1826, 5.1824, 5.1826, 5.1826, 5.1827, 5.1825, 5.1825,\n",
      "        5.1827, 5.1818, 5.1823, 5.1819, 5.1819, 5.1818, 5.1821, 5.1819, 5.1823,\n",
      "        5.1818, 5.1823, 5.1819, 5.1820, 5.1822, 5.1824, 5.1820, 5.1820, 5.1824,\n",
      "        5.1822, 5.1826, 5.1825, 5.1827, 5.1825, 5.1828, 5.1828, 5.1826, 5.1825,\n",
      "        5.1825, 5.1825, 5.1823, 5.1824, 5.1827, 5.1826, 5.1825, 5.1824, 5.1827,\n",
      "        5.1827, 5.1826, 5.1824, 5.1824, 5.1825, 5.1826, 5.1823, 5.1822, 5.1821,\n",
      "        5.1819, 5.1819, 5.1819], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.672486  [2951324/5599865]\n",
      "average delta from current occupancy tensor([4.5160, 4.5160, 4.5160, 4.5160, 4.5161, 4.5160, 4.5161, 4.5161, 4.5159,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5159, 4.5159, 4.5159, 4.5160, 4.5161,\n",
      "        4.5162, 4.5162, 4.5163, 4.5161, 4.5161, 4.5159, 4.5161, 4.5160, 4.5160,\n",
      "        4.5161, 4.5161, 4.5163, 4.5166, 4.5164, 4.5168, 4.5168, 4.5161, 4.5162,\n",
      "        4.5162, 4.5165, 4.5165, 4.5163, 4.5166, 4.5166, 4.5164, 4.5165, 4.5166,\n",
      "        4.5165, 4.5166, 4.5161, 4.5163, 4.5161, 4.5161, 4.5163, 4.5162, 4.5162,\n",
      "        4.5165, 4.5161, 4.5161, 4.5161, 4.5163, 4.5164, 4.5161, 4.5164, 4.5165,\n",
      "        4.5164, 4.5162, 4.5163, 4.5161, 4.5167, 4.5164, 4.5167, 4.5163, 4.5163,\n",
      "        4.5167, 4.5160, 4.5161, 4.5160, 4.5160, 4.5160, 4.5161, 4.5160, 4.5162,\n",
      "        4.5161, 4.5161, 4.5161, 4.5162, 4.5161, 4.5161, 4.5161, 4.5161, 4.5163,\n",
      "        4.5163, 4.5166, 4.5166, 4.5165, 4.5166, 4.5164, 4.5163, 4.5166, 4.5168,\n",
      "        4.5167, 4.5165, 4.5165, 4.5166, 4.5163, 4.5163, 4.5165, 4.5165, 4.5162,\n",
      "        4.5162, 4.5164, 4.5165, 4.5166, 4.5164, 4.5162, 4.5164, 4.5165, 4.5166,\n",
      "        4.5162, 4.5163, 4.5163], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.689529  [2963724/5599865]\n",
      "average delta from current occupancy tensor([4.6061, 4.6059, 4.6059, 4.6059, 4.6058, 4.6059, 4.6062, 4.6059, 4.6060,\n",
      "        4.6061, 4.6061, 4.6064, 4.6063, 4.6060, 4.6059, 4.6059, 4.6060, 4.6059,\n",
      "        4.6060, 4.6059, 4.6058, 4.6061, 4.6059, 4.6059, 4.6062, 4.6063, 4.6064,\n",
      "        4.6063, 4.6062, 4.6062, 4.6059, 4.6060, 4.6058, 4.6058, 4.6061, 4.6060,\n",
      "        4.6060, 4.6057, 4.6057, 4.6059, 4.6058, 4.6060, 4.6058, 4.6057, 4.6060,\n",
      "        4.6059, 4.6060, 4.6060, 4.6060, 4.6059, 4.6058, 4.6058, 4.6057, 4.6057,\n",
      "        4.6058, 4.6059, 4.6058, 4.6058, 4.6058, 4.6058, 4.6058, 4.6059, 4.6060,\n",
      "        4.6058, 4.6058, 4.6058, 4.6058, 4.6060, 4.6059, 4.6058, 4.6059, 4.6059,\n",
      "        4.6058, 4.6060, 4.6060, 4.6059, 4.6058, 4.6057, 4.6058, 4.6058, 4.6058,\n",
      "        4.6056, 4.6059, 4.6059, 4.6059, 4.6058, 4.6059, 4.6059, 4.6060, 4.6060,\n",
      "        4.6061, 4.6059, 4.6060, 4.6059, 4.6059, 4.6060, 4.6059, 4.6060, 4.6060,\n",
      "        4.6060, 4.6060, 4.6060, 4.6060, 4.6061, 4.6061, 4.6064, 4.6062, 4.6062,\n",
      "        4.6063, 4.6063, 4.6063, 4.6064, 4.6063, 4.6063, 4.6063, 4.6063, 4.6063,\n",
      "        4.6061, 4.6061, 4.6060], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.122541  [2976124/5599865]\n",
      "average delta from current occupancy tensor([5.0253, 5.0252, 5.0253, 5.0249, 5.0250, 5.0252, 5.0258, 5.0251, 5.0248,\n",
      "        5.0248, 5.0249, 5.0259, 5.0256, 5.0250, 5.0251, 5.0257, 5.0257, 5.0255,\n",
      "        5.0257, 5.0252, 5.0259, 5.0256, 5.0257, 5.0255, 5.0256, 5.0257, 5.0256,\n",
      "        5.0255, 5.0250, 5.0252, 5.0250, 5.0251, 5.0249, 5.0250, 5.0250, 5.0250,\n",
      "        5.0250, 5.0250, 5.0251, 5.0252, 5.0253, 5.0250, 5.0251, 5.0251, 5.0250,\n",
      "        5.0250, 5.0252, 5.0254, 5.0253, 5.0252, 5.0253, 5.0253, 5.0252, 5.0253,\n",
      "        5.0251, 5.0252, 5.0251, 5.0253, 5.0252, 5.0253, 5.0251, 5.0252, 5.0253,\n",
      "        5.0252, 5.0252, 5.0253, 5.0254, 5.0253, 5.0255, 5.0254, 5.0256, 5.0254,\n",
      "        5.0254, 5.0254, 5.0255, 5.0254, 5.0254, 5.0255, 5.0254, 5.0256, 5.0256,\n",
      "        5.0254, 5.0252, 5.0253, 5.0253, 5.0252, 5.0252, 5.0253, 5.0251, 5.0251,\n",
      "        5.0254, 5.0253, 5.0253, 5.0252, 5.0253, 5.0255, 5.0255, 5.0255, 5.0253,\n",
      "        5.0252, 5.0250, 5.0252, 5.0249, 5.0249, 5.0247, 5.0253, 5.0248, 5.0249,\n",
      "        5.0249, 5.0248, 5.0249, 5.0250, 5.0251, 5.0251, 5.0252, 5.0249, 5.0248,\n",
      "        5.0249, 5.0248, 5.0249], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.667573  [2988524/5599865]\n",
      "average delta from current occupancy tensor([5.5327, 5.5327, 5.5327, 5.5327, 5.5327, 5.5326, 5.5327, 5.5327, 5.5327,\n",
      "        5.5326, 5.5327, 5.5326, 5.5327, 5.5327, 5.5326, 5.5326, 5.5327, 5.5327,\n",
      "        5.5327, 5.5327, 5.5327, 5.5327, 5.5327, 5.5326, 5.5327, 5.5327, 5.5327,\n",
      "        5.5327, 5.5327, 5.5327, 5.5327, 5.5327, 5.5327, 5.5327, 5.5326, 5.5326,\n",
      "        5.5326, 5.5326, 5.5326, 5.5326, 5.5326, 5.5326, 5.5326, 5.5326, 5.5326,\n",
      "        5.5326, 5.5326, 5.5326, 5.5327, 5.5327, 5.5326, 5.5327, 5.5326, 5.5327,\n",
      "        5.5327, 5.5326, 5.5326, 5.5325, 5.5326, 5.5326, 5.5326, 5.5325, 5.5325,\n",
      "        5.5325, 5.5326, 5.5325, 5.5325, 5.5326, 5.5326, 5.5325, 5.5325, 5.5325,\n",
      "        5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325,\n",
      "        5.5325, 5.5325, 5.5325, 5.5325, 5.5326, 5.5325, 5.5326, 5.5326, 5.5326,\n",
      "        5.5326, 5.5326, 5.5325, 5.5326, 5.5326, 5.5326, 5.5325, 5.5326, 5.5325,\n",
      "        5.5325, 5.5325, 5.5326, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325,\n",
      "        5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325, 5.5325,\n",
      "        5.5325, 5.5325, 5.5325], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.298903  [3000924/5599865]\n",
      "average delta from current occupancy tensor([5.5487, 5.5487, 5.5486, 5.5486, 5.5485, 5.5486, 5.5486, 5.5486, 5.5485,\n",
      "        5.5486, 5.5485, 5.5487, 5.5485, 5.5485, 5.5485, 5.5485, 5.5486, 5.5487,\n",
      "        5.5487, 5.5487, 5.5486, 5.5487, 5.5487, 5.5485, 5.5486, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5487, 5.5487, 5.5486, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5484, 5.5485, 5.5485, 5.5485, 5.5484, 5.5485,\n",
      "        5.5484, 5.5485, 5.5486, 5.5484, 5.5485, 5.5484, 5.5484, 5.5485, 5.5484,\n",
      "        5.5485, 5.5486, 5.5486, 5.5485, 5.5486, 5.5486, 5.5487, 5.5485, 5.5485,\n",
      "        5.5485, 5.5484, 5.5485, 5.5485, 5.5484, 5.5486, 5.5485, 5.5484, 5.5485,\n",
      "        5.5486, 5.5485, 5.5484, 5.5485, 5.5484, 5.5484, 5.5486, 5.5484, 5.5486,\n",
      "        5.5484, 5.5485, 5.5486, 5.5485, 5.5486, 5.5486, 5.5486, 5.5486, 5.5485,\n",
      "        5.5484, 5.5484, 5.5485, 5.5485, 5.5484, 5.5485, 5.5485, 5.5484, 5.5484,\n",
      "        5.5484, 5.5484, 5.5486, 5.5487, 5.5484, 5.5484, 5.5485, 5.5484, 5.5485,\n",
      "        5.5484, 5.5484, 5.5485, 5.5485, 5.5485, 5.5488, 5.5488, 5.5487, 5.5485,\n",
      "        5.5485, 5.5486, 5.5488], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.564667  [3013324/5599865]\n",
      "average delta from current occupancy tensor([4.4569, 4.4570, 4.4571, 4.4569, 4.4568, 4.4573, 4.4572, 4.4570, 4.4573,\n",
      "        4.4574, 4.4570, 4.4570, 4.4568, 4.4566, 4.4567, 4.4566, 4.4562, 4.4560,\n",
      "        4.4562, 4.4562, 4.4563, 4.4564, 4.4562, 4.4565, 4.4564, 4.4566, 4.4567,\n",
      "        4.4567, 4.4567, 4.4563, 4.4564, 4.4563, 4.4566, 4.4566, 4.4571, 4.4567,\n",
      "        4.4567, 4.4568, 4.4568, 4.4571, 4.4571, 4.4568, 4.4570, 4.4571, 4.4571,\n",
      "        4.4570, 4.4567, 4.4568, 4.4572, 4.4567, 4.4568, 4.4567, 4.4565, 4.4568,\n",
      "        4.4564, 4.4569, 4.4571, 4.4569, 4.4565, 4.4564, 4.4570, 4.4570, 4.4571,\n",
      "        4.4569, 4.4569, 4.4568, 4.4569, 4.4570, 4.4565, 4.4573, 4.4568, 4.4569,\n",
      "        4.4568, 4.4567, 4.4568, 4.4567, 4.4570, 4.4568, 4.4569, 4.4570, 4.4568,\n",
      "        4.4572, 4.4568, 4.4569, 4.4568, 4.4569, 4.4569, 4.4567, 4.4566, 4.4566,\n",
      "        4.4571, 4.4569, 4.4565, 4.4567, 4.4568, 4.4567, 4.4568, 4.4570, 4.4572,\n",
      "        4.4569, 4.4571, 4.4568, 4.4570, 4.4574, 4.4570, 4.4568, 4.4569, 4.4566,\n",
      "        4.4568, 4.4571, 4.4566, 4.4566, 4.4569, 4.4570, 4.4569, 4.4570, 4.4568,\n",
      "        4.4567, 4.4569, 4.4574], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.565420  [3025724/5599865]\n",
      "average delta from current occupancy tensor([5.5092, 5.5093, 5.5093, 5.5094, 5.5096, 5.5094, 5.5094, 5.5091, 5.5096,\n",
      "        5.5096, 5.5092, 5.5093, 5.5091, 5.5095, 5.5094, 5.5092, 5.5092, 5.5095,\n",
      "        5.5093, 5.5095, 5.5093, 5.5092, 5.5095, 5.5092, 5.5093, 5.5094, 5.5094,\n",
      "        5.5094, 5.5094, 5.5093, 5.5094, 5.5094, 5.5096, 5.5093, 5.5094, 5.5094,\n",
      "        5.5095, 5.5094, 5.5093, 5.5094, 5.5092, 5.5094, 5.5095, 5.5092, 5.5091,\n",
      "        5.5092, 5.5092, 5.5091, 5.5093, 5.5095, 5.5093, 5.5097, 5.5098, 5.5096,\n",
      "        5.5100, 5.5095, 5.5099, 5.5095, 5.5097, 5.5099, 5.5095, 5.5092, 5.5092,\n",
      "        5.5094, 5.5094, 5.5095, 5.5095, 5.5094, 5.5098, 5.5092, 5.5094, 5.5093,\n",
      "        5.5093, 5.5094, 5.5091, 5.5091, 5.5091, 5.5090, 5.5090, 5.5090, 5.5091,\n",
      "        5.5092, 5.5090, 5.5091, 5.5090, 5.5089, 5.5091, 5.5091, 5.5092, 5.5091,\n",
      "        5.5092, 5.5090, 5.5091, 5.5089, 5.5090, 5.5089, 5.5092, 5.5090, 5.5091,\n",
      "        5.5089, 5.5089, 5.5089, 5.5090, 5.5090, 5.5091, 5.5088, 5.5088, 5.5088,\n",
      "        5.5088, 5.5088, 5.5088, 5.5090, 5.5091, 5.5091, 5.5091, 5.5091, 5.5089,\n",
      "        5.5089, 5.5090, 5.5089], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.712249  [3038124/5599865]\n",
      "average delta from current occupancy tensor([5.8070, 5.8068, 5.8068, 5.8069, 5.8068, 5.8068, 5.8068, 5.8069, 5.8070,\n",
      "        5.8069, 5.8067, 5.8067, 5.8068, 5.8070, 5.8069, 5.8067, 5.8068, 5.8069,\n",
      "        5.8068, 5.8070, 5.8069, 5.8068, 5.8070, 5.8069, 5.8070, 5.8072, 5.8072,\n",
      "        5.8072, 5.8071, 5.8070, 5.8070, 5.8070, 5.8072, 5.8071, 5.8071, 5.8072,\n",
      "        5.8073, 5.8071, 5.8070, 5.8071, 5.8070, 5.8071, 5.8073, 5.8071, 5.8070,\n",
      "        5.8071, 5.8070, 5.8070, 5.8071, 5.8073, 5.8071, 5.8074, 5.8074, 5.8073,\n",
      "        5.8076, 5.8072, 5.8073, 5.8070, 5.8072, 5.8074, 5.8071, 5.8070, 5.8070,\n",
      "        5.8071, 5.8072, 5.8073, 5.8073, 5.8074, 5.8076, 5.8071, 5.8072, 5.8070,\n",
      "        5.8071, 5.8072, 5.8070, 5.8070, 5.8070, 5.8071, 5.8070, 5.8070, 5.8070,\n",
      "        5.8070, 5.8069, 5.8069, 5.8069, 5.8071, 5.8069, 5.8069, 5.8070, 5.8069,\n",
      "        5.8071, 5.8070, 5.8071, 5.8071, 5.8072, 5.8071, 5.8072, 5.8070, 5.8071,\n",
      "        5.8070, 5.8070, 5.8070, 5.8072, 5.8072, 5.8073, 5.8070, 5.8070, 5.8070,\n",
      "        5.8071, 5.8071, 5.8070, 5.8073, 5.8074, 5.8074, 5.8075, 5.8075, 5.8073,\n",
      "        5.8073, 5.8074, 5.8073], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.605075  [3050524/5599865]\n",
      "average delta from current occupancy tensor([5.8494, 5.8495, 5.8495, 5.8495, 5.8496, 5.8496, 5.8496, 5.8493, 5.8495,\n",
      "        5.8494, 5.8497, 5.8497, 5.8498, 5.8494, 5.8494, 5.8494, 5.8495, 5.8494,\n",
      "        5.8494, 5.8494, 5.8498, 5.8498, 5.8496, 5.8498, 5.8496, 5.8496, 5.8494,\n",
      "        5.8495, 5.8496, 5.8499, 5.8495, 5.8496, 5.8495, 5.8495, 5.8494, 5.8491,\n",
      "        5.8489, 5.8493, 5.8492, 5.8491, 5.8489, 5.8491, 5.8487, 5.8490, 5.8489,\n",
      "        5.8489, 5.8487, 5.8487, 5.8487, 5.8484, 5.8490, 5.8487, 5.8486, 5.8487,\n",
      "        5.8490, 5.8489, 5.8488, 5.8489, 5.8487, 5.8485, 5.8489, 5.8490, 5.8490,\n",
      "        5.8489, 5.8489, 5.8489, 5.8489, 5.8489, 5.8492, 5.8492, 5.8493, 5.8494,\n",
      "        5.8496, 5.8493, 5.8494, 5.8495, 5.8495, 5.8494, 5.8496, 5.8495, 5.8494,\n",
      "        5.8495, 5.8494, 5.8494, 5.8496, 5.8495, 5.8496, 5.8497, 5.8497, 5.8496,\n",
      "        5.8494, 5.8492, 5.8492, 5.8490, 5.8492, 5.8493, 5.8491, 5.8492, 5.8492,\n",
      "        5.8492, 5.8494, 5.8495, 5.8493, 5.8494, 5.8490, 5.8493, 5.8494, 5.8494,\n",
      "        5.8495, 5.8494, 5.8493, 5.8488, 5.8494, 5.8495, 5.8495, 5.8496, 5.8493,\n",
      "        5.8496, 5.8493, 5.8491], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.132281  [3062924/5599865]\n",
      "average delta from current occupancy tensor([5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2421, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2421, 5.2421,\n",
      "        5.2421, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2419, 5.2420, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2419, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2419, 5.2420, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2419, 5.2419, 5.2420,\n",
      "        5.2419, 5.2420, 5.2419, 5.2419, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420, 5.2420,\n",
      "        5.2421, 5.2420, 5.2420, 5.2420, 5.2419, 5.2419, 5.2420, 5.2420, 5.2420,\n",
      "        5.2419, 5.2420, 5.2420, 5.2420, 5.2419, 5.2420, 5.2420, 5.2420, 5.2419,\n",
      "        5.2420, 5.2420, 5.2420], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.623847  [3075324/5599865]\n",
      "average delta from current occupancy tensor([5.5161, 5.5161, 5.5161, 5.5161, 5.5161, 5.5161, 5.5161, 5.5161, 5.5162,\n",
      "        5.5162, 5.5161, 5.5163, 5.5164, 5.5166, 5.5165, 5.5165, 5.5163, 5.5163,\n",
      "        5.5162, 5.5161, 5.5164, 5.5162, 5.5161, 5.5161, 5.5164, 5.5161, 5.5163,\n",
      "        5.5161, 5.5161, 5.5163, 5.5162, 5.5165, 5.5162, 5.5165, 5.5165, 5.5164,\n",
      "        5.5164, 5.5165, 5.5165, 5.5163, 5.5163, 5.5163, 5.5166, 5.5165, 5.5164,\n",
      "        5.5167, 5.5168, 5.5166, 5.5167, 5.5166, 5.5166, 5.5166, 5.5166, 5.5168,\n",
      "        5.5168, 5.5168, 5.5169, 5.5168, 5.5167, 5.5169, 5.5169, 5.5167, 5.5169,\n",
      "        5.5167, 5.5168, 5.5168, 5.5169, 5.5169, 5.5169, 5.5167, 5.5170, 5.5170,\n",
      "        5.5168, 5.5168, 5.5169, 5.5167, 5.5168, 5.5168, 5.5164, 5.5169, 5.5171,\n",
      "        5.5169, 5.5168, 5.5167, 5.5166, 5.5162, 5.5163, 5.5164, 5.5163, 5.5164,\n",
      "        5.5167, 5.5165, 5.5164, 5.5164, 5.5166, 5.5168, 5.5169, 5.5164, 5.5164,\n",
      "        5.5169, 5.5166, 5.5168, 5.5165, 5.5165, 5.5161, 5.5165, 5.5163, 5.5166,\n",
      "        5.5164, 5.5165, 5.5163, 5.5163, 5.5161, 5.5161, 5.5161, 5.5165, 5.5165,\n",
      "        5.5165, 5.5166, 5.5165], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.244353  [3087724/5599865]\n",
      "average delta from current occupancy tensor([5.2579, 5.2579, 5.2578, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579,\n",
      "        5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2580, 5.2578, 5.2579,\n",
      "        5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579,\n",
      "        5.2579, 5.2578, 5.2579, 5.2579, 5.2579, 5.2580, 5.2579, 5.2579, 5.2580,\n",
      "        5.2580, 5.2579, 5.2581, 5.2581, 5.2580, 5.2580, 5.2580, 5.2581, 5.2579,\n",
      "        5.2579, 5.2579, 5.2579, 5.2580, 5.2579, 5.2579, 5.2579, 5.2580, 5.2580,\n",
      "        5.2579, 5.2579, 5.2580, 5.2580, 5.2580, 5.2580, 5.2580, 5.2580, 5.2580,\n",
      "        5.2580, 5.2579, 5.2579, 5.2576, 5.2577, 5.2577, 5.2578, 5.2580, 5.2578,\n",
      "        5.2579, 5.2579, 5.2578, 5.2577, 5.2579, 5.2580, 5.2579, 5.2579, 5.2578,\n",
      "        5.2580, 5.2578, 5.2579, 5.2579, 5.2579, 5.2579, 5.2579, 5.2580, 5.2580,\n",
      "        5.2579, 5.2579, 5.2579, 5.2580, 5.2580, 5.2580, 5.2579, 5.2580, 5.2578,\n",
      "        5.2579, 5.2578, 5.2578, 5.2579, 5.2580, 5.2579, 5.2579, 5.2579, 5.2579,\n",
      "        5.2579, 5.2579, 5.2578, 5.2579, 5.2577, 5.2579, 5.2578, 5.2579, 5.2579,\n",
      "        5.2579, 5.2579, 5.2579], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.724453  [3100124/5599865]\n",
      "average delta from current occupancy tensor([6.0001, 6.0002, 6.0000, 6.0000, 6.0000, 6.0003, 6.0000, 6.0000, 6.0001,\n",
      "        6.0000, 6.0001, 6.0000, 6.0000, 6.0000, 6.0000, 6.0004, 5.9999, 6.0002,\n",
      "        6.0000, 6.0002, 6.0005, 6.0000, 6.0003, 6.0004, 6.0000, 6.0002, 6.0001,\n",
      "        6.0000, 6.0003, 6.0004, 6.0001, 6.0003, 6.0000, 6.0007, 6.0001, 6.0003,\n",
      "        6.0000, 6.0002, 6.0005, 6.0004, 6.0003, 6.0005, 6.0002, 6.0003, 6.0002,\n",
      "        6.0002, 6.0002, 6.0000, 6.0000, 6.0000, 6.0002, 6.0003, 6.0007, 6.0003,\n",
      "        6.0000, 6.0007, 6.0006, 6.0004, 6.0002, 6.0004, 6.0000, 6.0009, 6.0000,\n",
      "        6.0000, 6.0006, 6.0008, 6.0007, 6.0000, 6.0000, 6.0000, 6.0005, 6.0000,\n",
      "        6.0004, 6.0001, 6.0000, 6.0001, 6.0000, 6.0001, 6.0002, 6.0000, 6.0004,\n",
      "        6.0006, 6.0005, 6.0006, 6.0003, 6.0005, 6.0005, 6.0010, 6.0010, 6.0009,\n",
      "        6.0011, 6.0008, 6.0011, 6.0010, 6.0012, 6.0006, 6.0014, 6.0004, 6.0006,\n",
      "        6.0007, 6.0006, 6.0009, 6.0011, 6.0011, 6.0011, 6.0010, 6.0011, 6.0011,\n",
      "        6.0009, 6.0014, 6.0007, 6.0013, 6.0013, 6.0012, 6.0019, 6.0018, 6.0015,\n",
      "        6.0014, 6.0015, 6.0017], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.828864  [3112524/5599865]\n",
      "average delta from current occupancy tensor([5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563,\n",
      "        5.0564, 5.0564, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0561, 5.0563,\n",
      "        5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0564, 5.0563, 5.0563, 5.0564,\n",
      "        5.0563, 5.0563, 5.0562, 5.0563, 5.0562, 5.0562, 5.0562, 5.0562, 5.0563,\n",
      "        5.0563, 5.0562, 5.0563, 5.0562, 5.0562, 5.0562, 5.0561, 5.0562, 5.0561,\n",
      "        5.0562, 5.0562, 5.0563, 5.0562, 5.0563, 5.0563, 5.0562, 5.0563, 5.0563,\n",
      "        5.0562, 5.0562, 5.0562, 5.0563, 5.0562, 5.0563, 5.0562, 5.0563, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0563, 5.0562, 5.0562, 5.0562, 5.0563, 5.0563,\n",
      "        5.0563, 5.0562, 5.0562, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563,\n",
      "        5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0563, 5.0564,\n",
      "        5.0564, 5.0563, 5.0562, 5.0563, 5.0563, 5.0564, 5.0562, 5.0562, 5.0562,\n",
      "        5.0563, 5.0562, 5.0562, 5.0562, 5.0562, 5.0563, 5.0562, 5.0562, 5.0562,\n",
      "        5.0563, 5.0562, 5.0563, 5.0562, 5.0563, 5.0562, 5.0563, 5.0562, 5.0564,\n",
      "        5.0563, 5.0563, 5.0563], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.572943  [3124924/5599865]\n",
      "average delta from current occupancy tensor([5.7092, 5.7091, 5.7091, 5.7090, 5.7090, 5.7091, 5.7090, 5.7090, 5.7090,\n",
      "        5.7090, 5.7090, 5.7089, 5.7088, 5.7089, 5.7089, 5.7089, 5.7089, 5.7089,\n",
      "        5.7089, 5.7088, 5.7089, 5.7089, 5.7088, 5.7088, 5.7088, 5.7088, 5.7089,\n",
      "        5.7089, 5.7090, 5.7089, 5.7090, 5.7089, 5.7090, 5.7090, 5.7090, 5.7089,\n",
      "        5.7089, 5.7089, 5.7089, 5.7089, 5.7090, 5.7089, 5.7089, 5.7088, 5.7088,\n",
      "        5.7088, 5.7089, 5.7088, 5.7088, 5.7089, 5.7089, 5.7088, 5.7087, 5.7088,\n",
      "        5.7088, 5.7088, 5.7088, 5.7089, 5.7089, 5.7089, 5.7088, 5.7088, 5.7087,\n",
      "        5.7088, 5.7088, 5.7087, 5.7088, 5.7088, 5.7088, 5.7088, 5.7088, 5.7088,\n",
      "        5.7086, 5.7088, 5.7087, 5.7086, 5.7086, 5.7086, 5.7087, 5.7087, 5.7087,\n",
      "        5.7087, 5.7086, 5.7087, 5.7088, 5.7089, 5.7088, 5.7089, 5.7088, 5.7088,\n",
      "        5.7088, 5.7088, 5.7088, 5.7088, 5.7088, 5.7088, 5.7088, 5.7087, 5.7087,\n",
      "        5.7087, 5.7087, 5.7086, 5.7086, 5.7086, 5.7087, 5.7086, 5.7086, 5.7086,\n",
      "        5.7086, 5.7087, 5.7085, 5.7085, 5.7085, 5.7085, 5.7086, 5.7087, 5.7086,\n",
      "        5.7087, 5.7087, 5.7088], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.179636  [3137324/5599865]\n",
      "average delta from current occupancy tensor([5.1038, 5.1038, 5.1036, 5.1037, 5.1037, 5.1036, 5.1036, 5.1036, 5.1036,\n",
      "        5.1035, 5.1035, 5.1035, 5.1035, 5.1035, 5.1036, 5.1036, 5.1036, 5.1036,\n",
      "        5.1037, 5.1036, 5.1036, 5.1036, 5.1038, 5.1037, 5.1038, 5.1037, 5.1036,\n",
      "        5.1036, 5.1034, 5.1035, 5.1033, 5.1034, 5.1034, 5.1034, 5.1034, 5.1031,\n",
      "        5.1034, 5.1033, 5.1032, 5.1031, 5.1030, 5.1030, 5.1030, 5.1032, 5.1032,\n",
      "        5.1032, 5.1033, 5.1034, 5.1032, 5.1031, 5.1030, 5.1033, 5.1033, 5.1031,\n",
      "        5.1031, 5.1033, 5.1033, 5.1032, 5.1031, 5.1031, 5.1033, 5.1032, 5.1033,\n",
      "        5.1033, 5.1033, 5.1033, 5.1032, 5.1031, 5.1032, 5.1032, 5.1031, 5.1031,\n",
      "        5.1033, 5.1032, 5.1032, 5.1032, 5.1033, 5.1034, 5.1032, 5.1032, 5.1032,\n",
      "        5.1031, 5.1032, 5.1030, 5.1028, 5.1028, 5.1027, 5.1025, 5.1027, 5.1026,\n",
      "        5.1028, 5.1028, 5.1028, 5.1029, 5.1030, 5.1030, 5.1028, 5.1029, 5.1029,\n",
      "        5.1030, 5.1030, 5.1029, 5.1030, 5.1030, 5.1031, 5.1030, 5.1031, 5.1029,\n",
      "        5.1028, 5.1029, 5.1028, 5.1029, 5.1029, 5.1030, 5.1031, 5.1029, 5.1031,\n",
      "        5.1029, 5.1029, 5.1028], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.035112  [3149724/5599865]\n",
      "average delta from current occupancy tensor([5.1536, 5.1536, 5.1538, 5.1537, 5.1537, 5.1539, 5.1538, 5.1538, 5.1537,\n",
      "        5.1537, 5.1537, 5.1537, 5.1536, 5.1537, 5.1537, 5.1536, 5.1537, 5.1535,\n",
      "        5.1535, 5.1535, 5.1536, 5.1535, 5.1535, 5.1535, 5.1535, 5.1535, 5.1536,\n",
      "        5.1535, 5.1536, 5.1535, 5.1536, 5.1536, 5.1536, 5.1536, 5.1535, 5.1537,\n",
      "        5.1536, 5.1536, 5.1536, 5.1537, 5.1538, 5.1537, 5.1537, 5.1536, 5.1536,\n",
      "        5.1536, 5.1536, 5.1535, 5.1536, 5.1536, 5.1537, 5.1536, 5.1535, 5.1536,\n",
      "        5.1536, 5.1535, 5.1535, 5.1536, 5.1536, 5.1536, 5.1535, 5.1535, 5.1535,\n",
      "        5.1535, 5.1535, 5.1535, 5.1535, 5.1536, 5.1535, 5.1534, 5.1535, 5.1535,\n",
      "        5.1534, 5.1535, 5.1535, 5.1535, 5.1535, 5.1535, 5.1536, 5.1536, 5.1536,\n",
      "        5.1535, 5.1535, 5.1535, 5.1537, 5.1537, 5.1538, 5.1538, 5.1537, 5.1538,\n",
      "        5.1538, 5.1537, 5.1538, 5.1537, 5.1537, 5.1537, 5.1539, 5.1538, 5.1538,\n",
      "        5.1538, 5.1537, 5.1537, 5.1537, 5.1538, 5.1537, 5.1538, 5.1537, 5.1538,\n",
      "        5.1538, 5.1538, 5.1538, 5.1537, 5.1537, 5.1538, 5.1537, 5.1538, 5.1538,\n",
      "        5.1538, 5.1538, 5.1539], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.796574  [3162124/5599865]\n",
      "average delta from current occupancy tensor([4.9097, 4.9096, 4.9095, 4.9099, 4.9096, 4.9093, 4.9092, 4.9095, 4.9096,\n",
      "        4.9095, 4.9097, 4.9095, 4.9096, 4.9096, 4.9097, 4.9098, 4.9105, 4.9104,\n",
      "        4.9097, 4.9097, 4.9101, 4.9101, 4.9104, 4.9102, 4.9102, 4.9100, 4.9098,\n",
      "        4.9105, 4.9097, 4.9099, 4.9098, 4.9099, 4.9098, 4.9099, 4.9099, 4.9095,\n",
      "        4.9097, 4.9095, 4.9096, 4.9094, 4.9094, 4.9094, 4.9094, 4.9095, 4.9095,\n",
      "        4.9095, 4.9096, 4.9094, 4.9094, 4.9095, 4.9094, 4.9094, 4.9094, 4.9096,\n",
      "        4.9093, 4.9094, 4.9094, 4.9095, 4.9097, 4.9093, 4.9096, 4.9098, 4.9097,\n",
      "        4.9097, 4.9095, 4.9098, 4.9097, 4.9096, 4.9096, 4.9096, 4.9099, 4.9097,\n",
      "        4.9096, 4.9093, 4.9094, 4.9095, 4.9093, 4.9095, 4.9097, 4.9096, 4.9097,\n",
      "        4.9097, 4.9097, 4.9097, 4.9096, 4.9095, 4.9094, 4.9094, 4.9095, 4.9095,\n",
      "        4.9096, 4.9095, 4.9096, 4.9098, 4.9097, 4.9097, 4.9097, 4.9098, 4.9098,\n",
      "        4.9098, 4.9099, 4.9099, 4.9098, 4.9098, 4.9098, 4.9100, 4.9102, 4.9102,\n",
      "        4.9100, 4.9100, 4.9101, 4.9101, 4.9100, 4.9099, 4.9100, 4.9101, 4.9101,\n",
      "        4.9101, 4.9100, 4.9099], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.898256  [3174524/5599865]\n",
      "average delta from current occupancy tensor([4.9992, 4.9993, 4.9993, 4.9992, 4.9993, 4.9993, 4.9992, 4.9991, 4.9991,\n",
      "        4.9991, 4.9992, 4.9992, 4.9992, 4.9993, 4.9993, 4.9993, 4.9995, 4.9994,\n",
      "        4.9995, 4.9993, 4.9994, 4.9992, 4.9994, 4.9994, 4.9995, 4.9992, 4.9992,\n",
      "        4.9992, 4.9992, 4.9993, 4.9993, 4.9993, 4.9992, 4.9992, 4.9993, 4.9993,\n",
      "        4.9994, 4.9994, 4.9994, 4.9993, 4.9995, 4.9994, 4.9995, 4.9995, 4.9994,\n",
      "        4.9996, 4.9995, 4.9994, 4.9994, 4.9995, 4.9994, 4.9994, 4.9994, 4.9995,\n",
      "        4.9993, 4.9994, 4.9994, 4.9994, 4.9995, 4.9995, 4.9995, 4.9995, 4.9994,\n",
      "        4.9995, 4.9995, 4.9996, 4.9995, 4.9994, 4.9994, 4.9993, 4.9994, 4.9994,\n",
      "        4.9994, 4.9994, 4.9994, 4.9994, 4.9993, 4.9993, 4.9993, 4.9992, 4.9994,\n",
      "        4.9993, 4.9994, 4.9994, 4.9994, 4.9992, 4.9993, 4.9992, 4.9994, 4.9993,\n",
      "        4.9995, 4.9996, 4.9995, 4.9994, 4.9992, 4.9993, 4.9993, 4.9993, 4.9994,\n",
      "        4.9995, 4.9993, 4.9994, 4.9994, 4.9993, 4.9993, 4.9993, 4.9994, 4.9993,\n",
      "        4.9994, 4.9994, 4.9993, 4.9996, 4.9995, 4.9995, 4.9996, 4.9994, 4.9994,\n",
      "        4.9996, 4.9994, 4.9994], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.697884  [3186924/5599865]\n",
      "average delta from current occupancy tensor([4.7007, 4.7008, 4.7007, 4.7008, 4.7007, 4.7008, 4.7007, 4.7006, 4.7010,\n",
      "        4.7008, 4.7007, 4.7007, 4.7007, 4.7006, 4.7007, 4.7006, 4.7006, 4.7006,\n",
      "        4.7007, 4.7008, 4.7008, 4.7008, 4.7006, 4.7007, 4.7007, 4.7009, 4.7008,\n",
      "        4.7008, 4.7008, 4.7008, 4.7009, 4.7010, 4.7008, 4.7010, 4.7010, 4.7010,\n",
      "        4.7009, 4.7011, 4.7009, 4.7009, 4.7010, 4.7009, 4.7009, 4.7010, 4.7010,\n",
      "        4.7007, 4.7007, 4.7008, 4.7009, 4.7009, 4.7008, 4.7010, 4.7010, 4.7009,\n",
      "        4.7010, 4.7009, 4.7007, 4.7008, 4.7008, 4.7010, 4.7010, 4.7010, 4.7009,\n",
      "        4.7010, 4.7011, 4.7009, 4.7010, 4.7008, 4.7006, 4.7005, 4.7007, 4.7007,\n",
      "        4.7006, 4.7004, 4.7004, 4.7006, 4.7004, 4.7005, 4.7003, 4.7003, 4.7003,\n",
      "        4.7004, 4.7002, 4.7004, 4.7004, 4.7003, 4.7005, 4.7009, 4.7005, 4.7004,\n",
      "        4.7005, 4.7005, 4.7007, 4.7008, 4.7007, 4.7011, 4.7008, 4.7009, 4.7006,\n",
      "        4.7005, 4.7007, 4.7005, 4.7007, 4.7008, 4.7008, 4.7008, 4.7008, 4.7006,\n",
      "        4.7008, 4.7010, 4.7009, 4.7008, 4.7008, 4.7010, 4.7008, 4.7009, 4.7010,\n",
      "        4.7009, 4.7008, 4.7006], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.869799  [3199324/5599865]\n",
      "average delta from current occupancy tensor([4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8385, 4.8386, 4.8386,\n",
      "        4.8386, 4.8387, 4.8387, 4.8387, 4.8387, 4.8386, 4.8386, 4.8386, 4.8386,\n",
      "        4.8386, 4.8386, 4.8385, 4.8386, 4.8386, 4.8386, 4.8386, 4.8387, 4.8386,\n",
      "        4.8387, 4.8386, 4.8386, 4.8386, 4.8385, 4.8385, 4.8385, 4.8386, 4.8385,\n",
      "        4.8385, 4.8385, 4.8386, 4.8386, 4.8388, 4.8386, 4.8387, 4.8386, 4.8386,\n",
      "        4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8385, 4.8385, 4.8384, 4.8385,\n",
      "        4.8386, 4.8385, 4.8386, 4.8385, 4.8384, 4.8385, 4.8385, 4.8384, 4.8384,\n",
      "        4.8385, 4.8384, 4.8385, 4.8384, 4.8384, 4.8385, 4.8385, 4.8385, 4.8385,\n",
      "        4.8385, 4.8385, 4.8385, 4.8384, 4.8385, 4.8385, 4.8385, 4.8384, 4.8385,\n",
      "        4.8385, 4.8385, 4.8385, 4.8385, 4.8385, 4.8386, 4.8385, 4.8385, 4.8384,\n",
      "        4.8384, 4.8384, 4.8385, 4.8385, 4.8385, 4.8385, 4.8385, 4.8385, 4.8385,\n",
      "        4.8385, 4.8385, 4.8386, 4.8386, 4.8385, 4.8385, 4.8385, 4.8385, 4.8386,\n",
      "        4.8386, 4.8386, 4.8385, 4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8385,\n",
      "        4.8386, 4.8386, 4.8386], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.020388  [3211724/5599865]\n",
      "average delta from current occupancy tensor([5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0082, 5.0081, 5.0082, 5.0081,\n",
      "        5.0081, 5.0082, 5.0081, 5.0082, 5.0083, 5.0081, 5.0082, 5.0081, 5.0081,\n",
      "        5.0082, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0082,\n",
      "        5.0081, 5.0083, 5.0082, 5.0082, 5.0081, 5.0082, 5.0082, 5.0082, 5.0081,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0082, 5.0083, 5.0081, 5.0082, 5.0081,\n",
      "        5.0082, 5.0081, 5.0081, 5.0082, 5.0083, 5.0082, 5.0081, 5.0082, 5.0081,\n",
      "        5.0081, 5.0082, 5.0083, 5.0082, 5.0082, 5.0082, 5.0081, 5.0081, 5.0081,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082,\n",
      "        5.0082, 5.0082, 5.0081, 5.0082, 5.0081, 5.0081, 5.0081, 5.0081, 5.0083,\n",
      "        5.0081, 5.0082, 5.0082, 5.0082, 5.0081, 5.0081, 5.0081, 5.0081, 5.0082,\n",
      "        5.0081, 5.0082, 5.0082, 5.0082, 5.0081, 5.0082, 5.0081, 5.0081, 5.0082,\n",
      "        5.0082, 5.0081, 5.0081, 5.0082, 5.0082, 5.0081, 5.0082, 5.0082, 5.0082,\n",
      "        5.0082, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082, 5.0082,\n",
      "        5.0082, 5.0082, 5.0082], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.772631  [3224124/5599865]\n",
      "average delta from current occupancy tensor([4.5730, 4.5730, 4.5730, 4.5731, 4.5730, 4.5730, 4.5730, 4.5729, 4.5729,\n",
      "        4.5729, 4.5729, 4.5729, 4.5728, 4.5729, 4.5729, 4.5729, 4.5730, 4.5728,\n",
      "        4.5729, 4.5729, 4.5729, 4.5730, 4.5729, 4.5729, 4.5729, 4.5729, 4.5729,\n",
      "        4.5730, 4.5729, 4.5729, 4.5730, 4.5729, 4.5729, 4.5729, 4.5729, 4.5729,\n",
      "        4.5730, 4.5728, 4.5729, 4.5729, 4.5729, 4.5729, 4.5729, 4.5729, 4.5729,\n",
      "        4.5729, 4.5729, 4.5730, 4.5729, 4.5730, 4.5729, 4.5730, 4.5729, 4.5729,\n",
      "        4.5731, 4.5729, 4.5729, 4.5731, 4.5729, 4.5729, 4.5733, 4.5731, 4.5731,\n",
      "        4.5734, 4.5733, 4.5733, 4.5735, 4.5734, 4.5734, 4.5735, 4.5735, 4.5735,\n",
      "        4.5733, 4.5736, 4.5733, 4.5732, 4.5733, 4.5736, 4.5736, 4.5733, 4.5732,\n",
      "        4.5736, 4.5736, 4.5735, 4.5731, 4.5732, 4.5733, 4.5734, 4.5733, 4.5734,\n",
      "        4.5732, 4.5733, 4.5734, 4.5732, 4.5733, 4.5733, 4.5733, 4.5731, 4.5732,\n",
      "        4.5730, 4.5731, 4.5731, 4.5733, 4.5731, 4.5729, 4.5730, 4.5730, 4.5729,\n",
      "        4.5729, 4.5731, 4.5732, 4.5732, 4.5732, 4.5733, 4.5733, 4.5734, 4.5734,\n",
      "        4.5734, 4.5733, 4.5733], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.193296  [3236524/5599865]\n",
      "average delta from current occupancy tensor([5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450,\n",
      "        5.1450, 5.1450, 5.1449, 5.1450, 5.1450, 5.1449, 5.1450, 5.1450, 5.1450,\n",
      "        5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1449, 5.1449, 5.1449,\n",
      "        5.1450, 5.1450, 5.1449, 5.1450, 5.1449, 5.1449, 5.1450, 5.1450, 5.1449,\n",
      "        5.1450, 5.1449, 5.1449, 5.1449, 5.1450, 5.1449, 5.1449, 5.1450, 5.1449,\n",
      "        5.1449, 5.1450, 5.1449, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450,\n",
      "        5.1449, 5.1450, 5.1450, 5.1450, 5.1450, 5.1450, 5.1449, 5.1449, 5.1449,\n",
      "        5.1449, 5.1449, 5.1448, 5.1449, 5.1448, 5.1448, 5.1448, 5.1448, 5.1448,\n",
      "        5.1447, 5.1449, 5.1448, 5.1448, 5.1448, 5.1448, 5.1448, 5.1448, 5.1448,\n",
      "        5.1448, 5.1447, 5.1448, 5.1448, 5.1448, 5.1448, 5.1447, 5.1447, 5.1447,\n",
      "        5.1447, 5.1447, 5.1447, 5.1447, 5.1446, 5.1446, 5.1447, 5.1447, 5.1447,\n",
      "        5.1447, 5.1447, 5.1447, 5.1447, 5.1447, 5.1447, 5.1447, 5.1448, 5.1447,\n",
      "        5.1448, 5.1447, 5.1448, 5.1447, 5.1447, 5.1447, 5.1447, 5.1448, 5.1448,\n",
      "        5.1447, 5.1447, 5.1447], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.906096  [3248924/5599865]\n",
      "average delta from current occupancy tensor([4.8871, 4.8871, 4.8873, 4.8873, 4.8873, 4.8873, 4.8872, 4.8873, 4.8872,\n",
      "        4.8872, 4.8872, 4.8873, 4.8872, 4.8872, 4.8873, 4.8874, 4.8873, 4.8873,\n",
      "        4.8872, 4.8872, 4.8872, 4.8872, 4.8871, 4.8871, 4.8871, 4.8871, 4.8873,\n",
      "        4.8871, 4.8872, 4.8871, 4.8872, 4.8872, 4.8872, 4.8871, 4.8871, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8871, 4.8873, 4.8872, 4.8873, 4.8874, 4.8873,\n",
      "        4.8872, 4.8876, 4.8873, 4.8873, 4.8874, 4.8872, 4.8872, 4.8871, 4.8874,\n",
      "        4.8873, 4.8873, 4.8874, 4.8873, 4.8874, 4.8875, 4.8875, 4.8873, 4.8874,\n",
      "        4.8875, 4.8875, 4.8873, 4.8876, 4.8874, 4.8873, 4.8874, 4.8874, 4.8874,\n",
      "        4.8875, 4.8874, 4.8872, 4.8872, 4.8872, 4.8873, 4.8873, 4.8874, 4.8874,\n",
      "        4.8871, 4.8872, 4.8873, 4.8873, 4.8871, 4.8872, 4.8872, 4.8871, 4.8871,\n",
      "        4.8873, 4.8871, 4.8873, 4.8872, 4.8874, 4.8874, 4.8873, 4.8873, 4.8874,\n",
      "        4.8874, 4.8873, 4.8874, 4.8874, 4.8872, 4.8873, 4.8873, 4.8873, 4.8873,\n",
      "        4.8873, 4.8873, 4.8873, 4.8873, 4.8872, 4.8875, 4.8873, 4.8872, 4.8872,\n",
      "        4.8871, 4.8872, 4.8873], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.099635  [3261324/5599865]\n",
      "average delta from current occupancy tensor([6.0162, 6.0161, 6.0161, 6.0160, 6.0160, 6.0161, 6.0161, 6.0160, 6.0160,\n",
      "        6.0160, 6.0161, 6.0160, 6.0160, 6.0161, 6.0161, 6.0164, 6.0160, 6.0164,\n",
      "        6.0160, 6.0162, 6.0160, 6.0162, 6.0160, 6.0160, 6.0160, 6.0161, 6.0164,\n",
      "        6.0161, 6.0160, 6.0162, 6.0160, 6.0161, 6.0161, 6.0161, 6.0161, 6.0161,\n",
      "        6.0160, 6.0160, 6.0160, 6.0161, 6.0161, 6.0161, 6.0160, 6.0159, 6.0160,\n",
      "        6.0161, 6.0161, 6.0161, 6.0161, 6.0161, 6.0160, 6.0162, 6.0162, 6.0161,\n",
      "        6.0160, 6.0161, 6.0159, 6.0160, 6.0160, 6.0160, 6.0161, 6.0159, 6.0160,\n",
      "        6.0160, 6.0160, 6.0159, 6.0160, 6.0159, 6.0161, 6.0159, 6.0160, 6.0160,\n",
      "        6.0159, 6.0159, 6.0160, 6.0160, 6.0160, 6.0160, 6.0161, 6.0161, 6.0161,\n",
      "        6.0163, 6.0161, 6.0161, 6.0161, 6.0161, 6.0161, 6.0162, 6.0161, 6.0161,\n",
      "        6.0161, 6.0161, 6.0164, 6.0161, 6.0164, 6.0161, 6.0161, 6.0162, 6.0164,\n",
      "        6.0162, 6.0162, 6.0163, 6.0161, 6.0162, 6.0161, 6.0161, 6.0161, 6.0161,\n",
      "        6.0162, 6.0161, 6.0162, 6.0161, 6.0162, 6.0160, 6.0162, 6.0161, 6.0161,\n",
      "        6.0160, 6.0161, 6.0161], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.995356  [3273724/5599865]\n",
      "average delta from current occupancy tensor([4.7593, 4.7596, 4.7596, 4.7593, 4.7594, 4.7592, 4.7593, 4.7594, 4.7593,\n",
      "        4.7591, 4.7595, 4.7596, 4.7595, 4.7595, 4.7594, 4.7592, 4.7594, 4.7594,\n",
      "        4.7595, 4.7594, 4.7591, 4.7592, 4.7595, 4.7595, 4.7597, 4.7596, 4.7594,\n",
      "        4.7595, 4.7594, 4.7597, 4.7596, 4.7596, 4.7595, 4.7595, 4.7592, 4.7596,\n",
      "        4.7597, 4.7592, 4.7592, 4.7596, 4.7595, 4.7593, 4.7595, 4.7596, 4.7594,\n",
      "        4.7595, 4.7594, 4.7595, 4.7595, 4.7595, 4.7595, 4.7597, 4.7595, 4.7597,\n",
      "        4.7594, 4.7596, 4.7595, 4.7595, 4.7596, 4.7595, 4.7595, 4.7596, 4.7598,\n",
      "        4.7598, 4.7594, 4.7594, 4.7594, 4.7594, 4.7595, 4.7595, 4.7596, 4.7594,\n",
      "        4.7597, 4.7599, 4.7594, 4.7597, 4.7596, 4.7598, 4.7595, 4.7596, 4.7594,\n",
      "        4.7597, 4.7596, 4.7597, 4.7596, 4.7598, 4.7596, 4.7596, 4.7597, 4.7596,\n",
      "        4.7596, 4.7597, 4.7599, 4.7598, 4.7599, 4.7598, 4.7600, 4.7599, 4.7599,\n",
      "        4.7598, 4.7600, 4.7597, 4.7597, 4.7599, 4.7599, 4.7599, 4.7597, 4.7599,\n",
      "        4.7600, 4.7600, 4.7602, 4.7601, 4.7602, 4.7600, 4.7601, 4.7601, 4.7599,\n",
      "        4.7598, 4.7599, 4.7599], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.729977  [3286124/5599865]\n",
      "average delta from current occupancy tensor([4.7000, 4.6994, 4.6993, 4.6998, 4.6998, 4.7001, 4.6999, 4.7001, 4.7002,\n",
      "        4.7006, 4.7000, 4.7000, 4.7003, 4.7003, 4.7005, 4.7005, 4.7002, 4.7003,\n",
      "        4.7002, 4.7001, 4.7004, 4.7004, 4.7000, 4.6998, 4.6997, 4.6998, 4.7003,\n",
      "        4.7001, 4.7001, 4.6998, 4.6999, 4.6997, 4.6999, 4.6999, 4.7001, 4.6995,\n",
      "        4.6993, 4.6999, 4.7000, 4.6996, 4.6997, 4.7000, 4.6996, 4.6997, 4.7000,\n",
      "        4.6997, 4.6999, 4.6998, 4.6997, 4.6997, 4.6997, 4.6995, 4.6997, 4.6995,\n",
      "        4.6999, 4.6997, 4.7000, 4.7001, 4.6999, 4.7000, 4.6999, 4.6999, 4.6997,\n",
      "        4.7000, 4.7005, 4.7006, 4.7005, 4.7004, 4.7002, 4.7003, 4.7003, 4.7005,\n",
      "        4.7001, 4.6999, 4.7005, 4.7001, 4.7005, 4.7000, 4.7003, 4.7002, 4.7005,\n",
      "        4.7002, 4.7004, 4.7004, 4.7005, 4.7002, 4.7003, 4.7004, 4.7005, 4.7004,\n",
      "        4.7005, 4.7005, 4.7002, 4.7003, 4.7001, 4.7004, 4.7001, 4.7000, 4.7002,\n",
      "        4.7002, 4.7002, 4.7005, 4.7006, 4.7003, 4.7004, 4.7003, 4.7007, 4.7005,\n",
      "        4.7004, 4.7003, 4.7000, 4.7001, 4.6998, 4.7002, 4.7001, 4.7002, 4.7005,\n",
      "        4.7004, 4.7003, 4.7002], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.360506  [3298524/5599865]\n",
      "average delta from current occupancy tensor([4.2242, 4.2244, 4.2243, 4.2243, 4.2244, 4.2241, 4.2241, 4.2241, 4.2242,\n",
      "        4.2244, 4.2240, 4.2241, 4.2245, 4.2244, 4.2244, 4.2246, 4.2242, 4.2242,\n",
      "        4.2243, 4.2243, 4.2243, 4.2247, 4.2243, 4.2242, 4.2243, 4.2243, 4.2245,\n",
      "        4.2245, 4.2244, 4.2243, 4.2243, 4.2243, 4.2244, 4.2244, 4.2246, 4.2245,\n",
      "        4.2246, 4.2244, 4.2244, 4.2243, 4.2242, 4.2243, 4.2244, 4.2244, 4.2246,\n",
      "        4.2247, 4.2246, 4.2245, 4.2245, 4.2246, 4.2245, 4.2246, 4.2245, 4.2247,\n",
      "        4.2245, 4.2245, 4.2245, 4.2245, 4.2244, 4.2244, 4.2245, 4.2243, 4.2244,\n",
      "        4.2245, 4.2247, 4.2246, 4.2247, 4.2246, 4.2246, 4.2246, 4.2245, 4.2247,\n",
      "        4.2243, 4.2245, 4.2247, 4.2243, 4.2246, 4.2245, 4.2247, 4.2247, 4.2247,\n",
      "        4.2247, 4.2247, 4.2247, 4.2247, 4.2247, 4.2247, 4.2246, 4.2247, 4.2247,\n",
      "        4.2247, 4.2245, 4.2245, 4.2247, 4.2248, 4.2246, 4.2245, 4.2245, 4.2246,\n",
      "        4.2246, 4.2246, 4.2246, 4.2247, 4.2247, 4.2248, 4.2247, 4.2247, 4.2248,\n",
      "        4.2247, 4.2246, 4.2245, 4.2245, 4.2244, 4.2245, 4.2246, 4.2245, 4.2245,\n",
      "        4.2246, 4.2247, 4.2246], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.254448  [3310924/5599865]\n",
      "average delta from current occupancy tensor([5.2351, 5.2351, 5.2351, 5.2352, 5.2353, 5.2352, 5.2351, 5.2352, 5.2351,\n",
      "        5.2351, 5.2353, 5.2354, 5.2353, 5.2354, 5.2352, 5.2352, 5.2352, 5.2352,\n",
      "        5.2352, 5.2350, 5.2352, 5.2351, 5.2352, 5.2352, 5.2352, 5.2351, 5.2351,\n",
      "        5.2352, 5.2351, 5.2351, 5.2351, 5.2352, 5.2352, 5.2351, 5.2351, 5.2353,\n",
      "        5.2352, 5.2353, 5.2352, 5.2353, 5.2352, 5.2352, 5.2352, 5.2351, 5.2352,\n",
      "        5.2351, 5.2352, 5.2352, 5.2351, 5.2350, 5.2352, 5.2351, 5.2351, 5.2351,\n",
      "        5.2352, 5.2352, 5.2352, 5.2353, 5.2354, 5.2352, 5.2352, 5.2353, 5.2354,\n",
      "        5.2354, 5.2353, 5.2354, 5.2353, 5.2353, 5.2353, 5.2353, 5.2354, 5.2353,\n",
      "        5.2354, 5.2354, 5.2354, 5.2354, 5.2354, 5.2354, 5.2352, 5.2352, 5.2353,\n",
      "        5.2353, 5.2352, 5.2352, 5.2351, 5.2352, 5.2352, 5.2352, 5.2352, 5.2352,\n",
      "        5.2352, 5.2351, 5.2352, 5.2351, 5.2352, 5.2351, 5.2352, 5.2353, 5.2353,\n",
      "        5.2352, 5.2353, 5.2352, 5.2352, 5.2352, 5.2352, 5.2352, 5.2352, 5.2351,\n",
      "        5.2352, 5.2352, 5.2352, 5.2352, 5.2353, 5.2353, 5.2352, 5.2353, 5.2353,\n",
      "        5.2355, 5.2353, 5.2352], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.259722  [3323324/5599865]\n",
      "average delta from current occupancy tensor([5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766,\n",
      "        5.1766, 5.1766, 5.1765, 5.1765, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766,\n",
      "        5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1765, 5.1765,\n",
      "        5.1765, 5.1766, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1766, 5.1766,\n",
      "        5.1765, 5.1765, 5.1766, 5.1765, 5.1766, 5.1765, 5.1765, 5.1766, 5.1765,\n",
      "        5.1765, 5.1765, 5.1765, 5.1765, 5.1766, 5.1765, 5.1765, 5.1765, 5.1766,\n",
      "        5.1765, 5.1765, 5.1765, 5.1766, 5.1765, 5.1765, 5.1766, 5.1765, 5.1766,\n",
      "        5.1766, 5.1766, 5.1766, 5.1766, 5.1766, 5.1765, 5.1766, 5.1766, 5.1766,\n",
      "        5.1766, 5.1765, 5.1765, 5.1765, 5.1765, 5.1766, 5.1765, 5.1765, 5.1765,\n",
      "        5.1765, 5.1765, 5.1765, 5.1765, 5.1766, 5.1765, 5.1765, 5.1765, 5.1765,\n",
      "        5.1765, 5.1765, 5.1765, 5.1766, 5.1766, 5.1765, 5.1765, 5.1765, 5.1765,\n",
      "        5.1766, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765,\n",
      "        5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765, 5.1765,\n",
      "        5.1765, 5.1766, 5.1766], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.508315  [3335724/5599865]\n",
      "average delta from current occupancy tensor([4.4167, 4.4167, 4.4167, 4.4166, 4.4167, 4.4167, 4.4165, 4.4166, 4.4166,\n",
      "        4.4167, 4.4167, 4.4165, 4.4165, 4.4166, 4.4167, 4.4165, 4.4163, 4.4164,\n",
      "        4.4164, 4.4165, 4.4164, 4.4165, 4.4165, 4.4165, 4.4164, 4.4163, 4.4163,\n",
      "        4.4163, 4.4164, 4.4163, 4.4162, 4.4162, 4.4161, 4.4160, 4.4161, 4.4160,\n",
      "        4.4160, 4.4160, 4.4161, 4.4159, 4.4161, 4.4158, 4.4160, 4.4161, 4.4161,\n",
      "        4.4160, 4.4160, 4.4159, 4.4159, 4.4161, 4.4159, 4.4160, 4.4160, 4.4161,\n",
      "        4.4160, 4.4160, 4.4159, 4.4160, 4.4160, 4.4158, 4.4160, 4.4160, 4.4161,\n",
      "        4.4161, 4.4162, 4.4161, 4.4161, 4.4160, 4.4159, 4.4160, 4.4159, 4.4161,\n",
      "        4.4162, 4.4161, 4.4162, 4.4161, 4.4162, 4.4164, 4.4163, 4.4164, 4.4162,\n",
      "        4.4163, 4.4162, 4.4162, 4.4161, 4.4162, 4.4161, 4.4162, 4.4161, 4.4159,\n",
      "        4.4161, 4.4161, 4.4162, 4.4163, 4.4161, 4.4162, 4.4162, 4.4161, 4.4160,\n",
      "        4.4161, 4.4158, 4.4159, 4.4159, 4.4161, 4.4160, 4.4160, 4.4160, 4.4160,\n",
      "        4.4160, 4.4160, 4.4159, 4.4159, 4.4159, 4.4160, 4.4161, 4.4160, 4.4160,\n",
      "        4.4160, 4.4161, 4.4162], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.575108  [3348124/5599865]\n",
      "average delta from current occupancy tensor([5.4841, 5.4841, 5.4841, 5.4841, 5.4841, 5.4842, 5.4842, 5.4841, 5.4841,\n",
      "        5.4842, 5.4841, 5.4841, 5.4841, 5.4841, 5.4841, 5.4841, 5.4840, 5.4841,\n",
      "        5.4840, 5.4841, 5.4841, 5.4843, 5.4843, 5.4843, 5.4842, 5.4842, 5.4840,\n",
      "        5.4840, 5.4841, 5.4840, 5.4840, 5.4841, 5.4841, 5.4842, 5.4841, 5.4841,\n",
      "        5.4842, 5.4842, 5.4842, 5.4842, 5.4841, 5.4842, 5.4841, 5.4840, 5.4840,\n",
      "        5.4841, 5.4842, 5.4841, 5.4841, 5.4841, 5.4842, 5.4842, 5.4842, 5.4842,\n",
      "        5.4842, 5.4841, 5.4842, 5.4841, 5.4841, 5.4842, 5.4842, 5.4841, 5.4841,\n",
      "        5.4841, 5.4842, 5.4841, 5.4842, 5.4841, 5.4842, 5.4841, 5.4842, 5.4841,\n",
      "        5.4840, 5.4841, 5.4841, 5.4841, 5.4841, 5.4842, 5.4840, 5.4840, 5.4841,\n",
      "        5.4840, 5.4841, 5.4841, 5.4841, 5.4841, 5.4842, 5.4841, 5.4842, 5.4842,\n",
      "        5.4842, 5.4842, 5.4842, 5.4841, 5.4842, 5.4841, 5.4840, 5.4840, 5.4841,\n",
      "        5.4840, 5.4842, 5.4841, 5.4842, 5.4841, 5.4841, 5.4841, 5.4841, 5.4841,\n",
      "        5.4841, 5.4841, 5.4842, 5.4842, 5.4841, 5.4841, 5.4841, 5.4841, 5.4841,\n",
      "        5.4840, 5.4840, 5.4841], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.522232  [3360524/5599865]\n",
      "average delta from current occupancy tensor([5.4454, 5.4454, 5.4453, 5.4455, 5.4454, 5.4451, 5.4451, 5.4453, 5.4453,\n",
      "        5.4451, 5.4453, 5.4455, 5.4455, 5.4455, 5.4455, 5.4453, 5.4455, 5.4455,\n",
      "        5.4456, 5.4454, 5.4456, 5.4457, 5.4455, 5.4456, 5.4454, 5.4455, 5.4457,\n",
      "        5.4455, 5.4456, 5.4456, 5.4456, 5.4455, 5.4456, 5.4453, 5.4453, 5.4454,\n",
      "        5.4452, 5.4451, 5.4449, 5.4453, 5.4455, 5.4453, 5.4455, 5.4456, 5.4455,\n",
      "        5.4454, 5.4453, 5.4453, 5.4454, 5.4454, 5.4451, 5.4451, 5.4451, 5.4452,\n",
      "        5.4452, 5.4453, 5.4452, 5.4452, 5.4452, 5.4449, 5.4449, 5.4452, 5.4451,\n",
      "        5.4453, 5.4450, 5.4451, 5.4449, 5.4450, 5.4449, 5.4449, 5.4449, 5.4450,\n",
      "        5.4452, 5.4451, 5.4449, 5.4451, 5.4452, 5.4450, 5.4451, 5.4452, 5.4452,\n",
      "        5.4452, 5.4451, 5.4451, 5.4452, 5.4453, 5.4451, 5.4453, 5.4452, 5.4449,\n",
      "        5.4448, 5.4446, 5.4447, 5.4450, 5.4449, 5.4451, 5.4451, 5.4452, 5.4451,\n",
      "        5.4452, 5.4451, 5.4451, 5.4449, 5.4451, 5.4450, 5.4451, 5.4452, 5.4451,\n",
      "        5.4451, 5.4450, 5.4449, 5.4449, 5.4451, 5.4451, 5.4450, 5.4450, 5.4449,\n",
      "        5.4450, 5.4450, 5.4450], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.649507  [3372924/5599865]\n",
      "average delta from current occupancy tensor([5.7995, 5.7993, 5.7992, 5.7997, 5.7995, 5.7990, 5.7988, 5.7995, 5.7990,\n",
      "        5.7990, 5.7991, 5.7997, 5.8001, 5.7999, 5.8001, 5.7999, 5.8005, 5.8000,\n",
      "        5.8001, 5.8000, 5.8001, 5.8004, 5.7999, 5.7999, 5.7994, 5.7994, 5.7995,\n",
      "        5.7994, 5.7993, 5.7993, 5.7994, 5.7992, 5.7992, 5.7987, 5.7993, 5.7994,\n",
      "        5.7988, 5.7985, 5.7986, 5.7988, 5.7994, 5.7987, 5.7987, 5.7989, 5.7984,\n",
      "        5.7982, 5.7982, 5.7982, 5.7982, 5.7986, 5.7983, 5.7982, 5.7982, 5.7982,\n",
      "        5.7983, 5.7982, 5.7982, 5.7982, 5.7984, 5.7988, 5.7990, 5.7984, 5.7985,\n",
      "        5.7982, 5.7988, 5.7988, 5.7993, 5.7990, 5.7992, 5.7992, 5.7992, 5.7992,\n",
      "        5.7989, 5.7989, 5.7992, 5.7991, 5.7991, 5.7991, 5.7991, 5.7991, 5.7992,\n",
      "        5.7992, 5.7993, 5.7994, 5.7995, 5.7993, 5.7995, 5.7992, 5.7995, 5.7999,\n",
      "        5.7997, 5.7997, 5.7998, 5.7993, 5.7995, 5.7991, 5.7993, 5.7992, 5.7995,\n",
      "        5.7992, 5.7995, 5.7994, 5.7995, 5.7995, 5.7996, 5.7995, 5.7993, 5.7995,\n",
      "        5.7997, 5.7996, 5.7997, 5.7997, 5.7994, 5.7993, 5.7995, 5.7996, 5.7998,\n",
      "        5.7996, 5.7997, 5.7996], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.241429  [3385324/5599865]\n",
      "average delta from current occupancy tensor([5.1376, 5.1377, 5.1377, 5.1377, 5.1377, 5.1376, 5.1376, 5.1376, 5.1377,\n",
      "        5.1377, 5.1376, 5.1376, 5.1376, 5.1376, 5.1376, 5.1377, 5.1377, 5.1377,\n",
      "        5.1377, 5.1378, 5.1376, 5.1376, 5.1378, 5.1377, 5.1377, 5.1376, 5.1377,\n",
      "        5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1376,\n",
      "        5.1376, 5.1376, 5.1377, 5.1377, 5.1376, 5.1376, 5.1377, 5.1376, 5.1377,\n",
      "        5.1377, 5.1377, 5.1376, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1376,\n",
      "        5.1376, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1378, 5.1377,\n",
      "        5.1378, 5.1377, 5.1377, 5.1377, 5.1377, 5.1377, 5.1378, 5.1377, 5.1378,\n",
      "        5.1378, 5.1377, 5.1378, 5.1378, 5.1378, 5.1377, 5.1377, 5.1377, 5.1377,\n",
      "        5.1377, 5.1377, 5.1378, 5.1378, 5.1377, 5.1378, 5.1377, 5.1377, 5.1377,\n",
      "        5.1377, 5.1377, 5.1378, 5.1377, 5.1377, 5.1376, 5.1376, 5.1377, 5.1376,\n",
      "        5.1378, 5.1378, 5.1378, 5.1378, 5.1378, 5.1377, 5.1378, 5.1379, 5.1379,\n",
      "        5.1378, 5.1378, 5.1378, 5.1378, 5.1377, 5.1377, 5.1378, 5.1378, 5.1378,\n",
      "        5.1378, 5.1377, 5.1378], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.122242  [3397724/5599865]\n",
      "average delta from current occupancy tensor([4.9435, 4.9435, 4.9435, 4.9436, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9434, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9434,\n",
      "        4.9434, 4.9435, 4.9435, 4.9434, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9436, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9435, 4.9435], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.681162  [3410124/5599865]\n",
      "average delta from current occupancy tensor([4.6308, 4.6307, 4.6307, 4.6310, 4.6306, 4.6309, 4.6307, 4.6310, 4.6308,\n",
      "        4.6306, 4.6307, 4.6309, 4.6308, 4.6309, 4.6310, 4.6309, 4.6310, 4.6309,\n",
      "        4.6310, 4.6310, 4.6311, 4.6311, 4.6308, 4.6309, 4.6310, 4.6308, 4.6306,\n",
      "        4.6308, 4.6314, 4.6314, 4.6306, 4.6308, 4.6308, 4.6310, 4.6307, 4.6305,\n",
      "        4.6307, 4.6309, 4.6309, 4.6310, 4.6310, 4.6310, 4.6305, 4.6305, 4.6309,\n",
      "        4.6311, 4.6310, 4.6309, 4.6311, 4.6309, 4.6310, 4.6309, 4.6311, 4.6311,\n",
      "        4.6310, 4.6312, 4.6308, 4.6307, 4.6310, 4.6305, 4.6310, 4.6309, 4.6312,\n",
      "        4.6304, 4.6312, 4.6310, 4.6311, 4.6311, 4.6310, 4.6311, 4.6312, 4.6311,\n",
      "        4.6310, 4.6311, 4.6309, 4.6308, 4.6313, 4.6311, 4.6308, 4.6310, 4.6310,\n",
      "        4.6307, 4.6312, 4.6311, 4.6308, 4.6313, 4.6312, 4.6313, 4.6311, 4.6314,\n",
      "        4.6313, 4.6314, 4.6312, 4.6313, 4.6311, 4.6314, 4.6316, 4.6312, 4.6317,\n",
      "        4.6318, 4.6308, 4.6317, 4.6314, 4.6310, 4.6311, 4.6312, 4.6309, 4.6311,\n",
      "        4.6311, 4.6307, 4.6314, 4.6309, 4.6309, 4.6310, 4.6310, 4.6312, 4.6314,\n",
      "        4.6312, 4.6311, 4.6308], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.302668  [3422524/5599865]\n",
      "average delta from current occupancy tensor([5.2650, 5.2652, 5.2651, 5.2652, 5.2651, 5.2652, 5.2651, 5.2651, 5.2651,\n",
      "        5.2651, 5.2649, 5.2650, 5.2651, 5.2651, 5.2653, 5.2652, 5.2652, 5.2651,\n",
      "        5.2651, 5.2652, 5.2651, 5.2651, 5.2652, 5.2652, 5.2652, 5.2651, 5.2652,\n",
      "        5.2651, 5.2653, 5.2652, 5.2651, 5.2653, 5.2653, 5.2653, 5.2651, 5.2650,\n",
      "        5.2650, 5.2651, 5.2651, 5.2652, 5.2651, 5.2651, 5.2651, 5.2650, 5.2650,\n",
      "        5.2651, 5.2649, 5.2648, 5.2651, 5.2652, 5.2649, 5.2651, 5.2651, 5.2653,\n",
      "        5.2652, 5.2652, 5.2652, 5.2653, 5.2651, 5.2651, 5.2651, 5.2650, 5.2652,\n",
      "        5.2650, 5.2654, 5.2652, 5.2653, 5.2653, 5.2654, 5.2654, 5.2653, 5.2654,\n",
      "        5.2656, 5.2653, 5.2654, 5.2652, 5.2653, 5.2652, 5.2652, 5.2651, 5.2652,\n",
      "        5.2650, 5.2652, 5.2651, 5.2650, 5.2651, 5.2650, 5.2651, 5.2652, 5.2652,\n",
      "        5.2650, 5.2652, 5.2652, 5.2651, 5.2651, 5.2652, 5.2651, 5.2652, 5.2650,\n",
      "        5.2651, 5.2650, 5.2652, 5.2652, 5.2650, 5.2651, 5.2650, 5.2651, 5.2653,\n",
      "        5.2652, 5.2651, 5.2653, 5.2653, 5.2652, 5.2652, 5.2651, 5.2651, 5.2652,\n",
      "        5.2652, 5.2653, 5.2652], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.471953  [3434924/5599865]\n",
      "average delta from current occupancy tensor([5.4423, 5.4424, 5.4425, 5.4424, 5.4424, 5.4423, 5.4424, 5.4423, 5.4423,\n",
      "        5.4423, 5.4423, 5.4423, 5.4423, 5.4423, 5.4423, 5.4423, 5.4423, 5.4423,\n",
      "        5.4423, 5.4424, 5.4424, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425,\n",
      "        5.4425, 5.4424, 5.4425, 5.4424, 5.4424, 5.4424, 5.4424, 5.4424, 5.4424,\n",
      "        5.4425, 5.4424, 5.4425, 5.4424, 5.4424, 5.4424, 5.4423, 5.4424, 5.4424,\n",
      "        5.4424, 5.4424, 5.4423, 5.4424, 5.4424, 5.4424, 5.4423, 5.4423, 5.4423,\n",
      "        5.4423, 5.4422, 5.4423, 5.4423, 5.4423, 5.4422, 5.4422, 5.4422, 5.4423,\n",
      "        5.4423, 5.4423, 5.4423, 5.4423, 5.4423, 5.4423, 5.4424, 5.4423, 5.4424,\n",
      "        5.4423, 5.4424, 5.4424, 5.4423, 5.4424, 5.4423, 5.4424, 5.4424, 5.4423,\n",
      "        5.4424, 5.4423, 5.4424, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4424,\n",
      "        5.4425, 5.4424, 5.4424, 5.4424, 5.4425, 5.4424, 5.4423, 5.4422, 5.4422,\n",
      "        5.4422, 5.4422, 5.4422, 5.4422, 5.4424, 5.4423, 5.4423, 5.4423, 5.4423,\n",
      "        5.4423, 5.4422, 5.4422, 5.4422, 5.4423, 5.4422, 5.4422, 5.4421, 5.4422,\n",
      "        5.4422, 5.4422, 5.4422], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.581315  [3447324/5599865]\n",
      "average delta from current occupancy tensor([4.5564, 4.5564, 4.5562, 4.5564, 4.5564, 4.5564, 4.5564, 4.5564, 4.5563,\n",
      "        4.5564, 4.5564, 4.5564, 4.5564, 4.5564, 4.5564, 4.5564, 4.5564, 4.5564,\n",
      "        4.5564, 4.5564, 4.5564, 4.5564, 4.5563, 4.5564, 4.5563, 4.5563, 4.5563,\n",
      "        4.5563, 4.5564, 4.5564, 4.5564, 4.5564, 4.5565, 4.5565, 4.5564, 4.5565,\n",
      "        4.5565, 4.5564, 4.5565, 4.5565, 4.5564, 4.5564, 4.5565, 4.5565, 4.5565,\n",
      "        4.5565, 4.5565, 4.5565, 4.5565, 4.5565, 4.5565, 4.5565, 4.5565, 4.5565,\n",
      "        4.5565, 4.5565, 4.5564, 4.5564, 4.5564, 4.5563, 4.5563, 4.5563, 4.5565,\n",
      "        4.5565, 4.5564, 4.5564, 4.5564, 4.5562, 4.5563, 4.5564, 4.5564, 4.5565,\n",
      "        4.5565, 4.5565, 4.5565, 4.5564, 4.5565, 4.5565, 4.5565, 4.5565, 4.5562,\n",
      "        4.5564, 4.5562, 4.5564, 4.5564, 4.5565, 4.5564, 4.5565, 4.5564, 4.5565,\n",
      "        4.5565, 4.5565, 4.5565, 4.5565, 4.5565, 4.5565, 4.5564, 4.5563, 4.5562,\n",
      "        4.5560, 4.5561, 4.5561, 4.5562, 4.5565, 4.5564, 4.5564, 4.5563, 4.5563,\n",
      "        4.5563, 4.5563, 4.5563, 4.5564, 4.5563, 4.5563, 4.5561, 4.5559, 4.5561,\n",
      "        4.5561, 4.5563, 4.5562], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.408549  [3459724/5599865]\n",
      "average delta from current occupancy tensor([5.4766, 5.4768, 5.4765, 5.4766, 5.4765, 5.4762, 5.4761, 5.4762, 5.4763,\n",
      "        5.4762, 5.4763, 5.4764, 5.4764, 5.4764, 5.4766, 5.4765, 5.4762, 5.4763,\n",
      "        5.4763, 5.4763, 5.4763, 5.4762, 5.4762, 5.4761, 5.4762, 5.4762, 5.4763,\n",
      "        5.4762, 5.4763, 5.4763, 5.4760, 5.4762, 5.4762, 5.4763, 5.4761, 5.4762,\n",
      "        5.4764, 5.4764, 5.4764, 5.4765, 5.4768, 5.4768, 5.4765, 5.4768, 5.4767,\n",
      "        5.4767, 5.4763, 5.4763, 5.4763, 5.4764, 5.4762, 5.4763, 5.4765, 5.4766,\n",
      "        5.4763, 5.4766, 5.4766, 5.4767, 5.4766, 5.4763, 5.4765, 5.4764, 5.4762,\n",
      "        5.4762, 5.4764, 5.4763, 5.4763, 5.4767, 5.4766, 5.4762, 5.4762, 5.4761,\n",
      "        5.4759, 5.4762, 5.4763, 5.4763, 5.4763, 5.4760, 5.4759, 5.4761, 5.4763,\n",
      "        5.4759, 5.4760, 5.4759, 5.4759, 5.4764, 5.4764, 5.4766, 5.4762, 5.4763,\n",
      "        5.4766, 5.4763, 5.4764, 5.4763, 5.4764, 5.4761, 5.4762, 5.4763, 5.4766,\n",
      "        5.4768, 5.4767, 5.4768, 5.4765, 5.4762, 5.4763, 5.4762, 5.4762, 5.4761,\n",
      "        5.4761, 5.4759, 5.4758, 5.4759, 5.4759, 5.4759, 5.4758, 5.4761, 5.4758,\n",
      "        5.4758, 5.4759, 5.4759], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.438303  [3472124/5599865]\n",
      "average delta from current occupancy tensor([4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177,\n",
      "        4.2177, 4.2177, 4.2177], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.699817  [3484524/5599865]\n",
      "average delta from current occupancy tensor([4.5886, 4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5885, 4.5885, 4.5885, 4.5885, 4.5885,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5885, 4.5885,\n",
      "        4.5886, 4.5886, 4.5885, 4.5885, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5887, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5885, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5887, 4.5886, 4.5886,\n",
      "        4.5887, 4.5887, 4.5887, 4.5886, 4.5887, 4.5886, 4.5886, 4.5887, 4.5886,\n",
      "        4.5886, 4.5886, 4.5885, 4.5886, 4.5885, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5887, 4.5887, 4.5887, 4.5887, 4.5887, 4.5887,\n",
      "        4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5887, 4.5887, 4.5887, 4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5887, 4.5886, 4.5886], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.763496  [3496924/5599865]\n",
      "average delta from current occupancy tensor([4.5743, 4.5742, 4.5741, 4.5740, 4.5740, 4.5739, 4.5739, 4.5738, 4.5739,\n",
      "        4.5738, 4.5739, 4.5740, 4.5740, 4.5740, 4.5739, 4.5737, 4.5738, 4.5738,\n",
      "        4.5737, 4.5736, 4.5740, 4.5739, 4.5739, 4.5738, 4.5738, 4.5740, 4.5740,\n",
      "        4.5740, 4.5740, 4.5742, 4.5743, 4.5742, 4.5744, 4.5742, 4.5743, 4.5744,\n",
      "        4.5744, 4.5746, 4.5743, 4.5741, 4.5741, 4.5741, 4.5740, 4.5741, 4.5742,\n",
      "        4.5742, 4.5742, 4.5743, 4.5743, 4.5740, 4.5739, 4.5742, 4.5741, 4.5740,\n",
      "        4.5738, 4.5740, 4.5739, 4.5739, 4.5741, 4.5741, 4.5742, 4.5738, 4.5740,\n",
      "        4.5740, 4.5740, 4.5739, 4.5737, 4.5740, 4.5738, 4.5737, 4.5741, 4.5738,\n",
      "        4.5737, 4.5739, 4.5735, 4.5738, 4.5736, 4.5738, 4.5737, 4.5739, 4.5740,\n",
      "        4.5739, 4.5738, 4.5741, 4.5740, 4.5741, 4.5740, 4.5739, 4.5736, 4.5736,\n",
      "        4.5741, 4.5738, 4.5738, 4.5734, 4.5734, 4.5736, 4.5738, 4.5738, 4.5736,\n",
      "        4.5738, 4.5741, 4.5740, 4.5739, 4.5742, 4.5740, 4.5740, 4.5739, 4.5737,\n",
      "        4.5737, 4.5738, 4.5737, 4.5738, 4.5739, 4.5736, 4.5738, 4.5735, 4.5736,\n",
      "        4.5735, 4.5735, 4.5737], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.267035  [3509324/5599865]\n",
      "average delta from current occupancy tensor([4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5081, 4.5080, 4.5080, 4.5080,\n",
      "        4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080,\n",
      "        4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5081, 4.5081, 4.5080,\n",
      "        4.5081, 4.5081, 4.5081, 4.5081, 4.5080, 4.5080, 4.5081, 4.5080, 4.5080,\n",
      "        4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080,\n",
      "        4.5080, 4.5080, 4.5080, 4.5080, 4.5081, 4.5080, 4.5081, 4.5081, 4.5080,\n",
      "        4.5080, 4.5081, 4.5080, 4.5081, 4.5081, 4.5080, 4.5080, 4.5080, 4.5080,\n",
      "        4.5080, 4.5080, 4.5080, 4.5080, 4.5081, 4.5080, 4.5080, 4.5080, 4.5080,\n",
      "        4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080, 4.5080,\n",
      "        4.5081, 4.5080, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5080, 4.5081,\n",
      "        4.5080, 4.5080, 4.5080, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081,\n",
      "        4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081,\n",
      "        4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081, 4.5081,\n",
      "        4.5081, 4.5081, 4.5081], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.351314  [3521724/5599865]\n",
      "average delta from current occupancy tensor([5.0645, 5.0645, 5.0646, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0646, 5.0646, 5.0647, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0645, 5.0645, 5.0646, 5.0646,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0647, 5.0647, 5.0646, 5.0645,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646, 5.0645,\n",
      "        5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645,\n",
      "        5.0646, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0645, 5.0646, 5.0645, 5.0646, 5.0646, 5.0647, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646, 5.0645, 5.0645,\n",
      "        5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646,\n",
      "        5.0646, 5.0645, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645,\n",
      "        5.0645, 5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0645, 5.0646], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.434027  [3534124/5599865]\n",
      "average delta from current occupancy tensor([4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159,\n",
      "        4.5159, 4.5160, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159,\n",
      "        4.5159, 4.5160, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159,\n",
      "        4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5160,\n",
      "        4.5159, 4.5159, 4.5160, 4.5159, 4.5160, 4.5160, 4.5159, 4.5159, 4.5160,\n",
      "        4.5159, 4.5160, 4.5159, 4.5159, 4.5160, 4.5159, 4.5159, 4.5159, 4.5159,\n",
      "        4.5160, 4.5159, 4.5159, 4.5159, 4.5160, 4.5160, 4.5160, 4.5160, 4.5159,\n",
      "        4.5160, 4.5159, 4.5160, 4.5159, 4.5160, 4.5160, 4.5160, 4.5160, 4.5159,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5159, 4.5159, 4.5159, 4.5160,\n",
      "        4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5160, 4.5159, 4.5159, 4.5159,\n",
      "        4.5160, 4.5159, 4.5160, 4.5159, 4.5159, 4.5160, 4.5159, 4.5159, 4.5159,\n",
      "        4.5159, 4.5160, 4.5159, 4.5160, 4.5159, 4.5160, 4.5160, 4.5160, 4.5159,\n",
      "        4.5160, 4.5159, 4.5159, 4.5159, 4.5160, 4.5159, 4.5159, 4.5159, 4.5159,\n",
      "        4.5159, 4.5159, 4.5159], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.558177  [3546524/5599865]\n",
      "average delta from current occupancy tensor([5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387, 5.8387,\n",
      "        5.8387, 5.8387, 5.8387], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.610045  [3558924/5599865]\n",
      "average delta from current occupancy tensor([4.6179, 4.6177, 4.6178, 4.6179, 4.6180, 4.6179, 4.6176, 4.6181, 4.6181,\n",
      "        4.6181, 4.6182, 4.6181, 4.6183, 4.6183, 4.6182, 4.6184, 4.6183, 4.6183,\n",
      "        4.6184, 4.6182, 4.6183, 4.6182, 4.6184, 4.6182, 4.6184, 4.6182, 4.6180,\n",
      "        4.6178, 4.6180, 4.6179, 4.6181, 4.6178, 4.6177, 4.6179, 4.6181, 4.6181,\n",
      "        4.6180, 4.6179, 4.6178, 4.6176, 4.6179, 4.6177, 4.6178, 4.6178, 4.6176,\n",
      "        4.6176, 4.6176, 4.6178, 4.6176, 4.6179, 4.6176, 4.6175, 4.6175, 4.6176,\n",
      "        4.6177, 4.6176, 4.6179, 4.6179, 4.6177, 4.6178, 4.6178, 4.6177, 4.6176,\n",
      "        4.6175, 4.6178, 4.6176, 4.6178, 4.6176, 4.6177, 4.6178, 4.6176, 4.6178,\n",
      "        4.6176, 4.6180, 4.6176, 4.6175, 4.6174, 4.6173, 4.6176, 4.6173, 4.6174,\n",
      "        4.6175, 4.6174, 4.6175, 4.6174, 4.6176, 4.6176, 4.6176, 4.6177, 4.6176,\n",
      "        4.6177, 4.6177, 4.6177, 4.6178, 4.6180, 4.6182, 4.6179, 4.6180, 4.6180,\n",
      "        4.6182, 4.6181, 4.6181, 4.6182, 4.6177, 4.6178, 4.6179, 4.6176, 4.6182,\n",
      "        4.6183, 4.6184, 4.6183, 4.6183, 4.6182, 4.6181, 4.6181, 4.6180, 4.6182,\n",
      "        4.6181, 4.6181, 4.6182], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.534908  [3571324/5599865]\n",
      "average delta from current occupancy tensor([5.5298, 5.5297, 5.5297, 5.5298, 5.5299, 5.5298, 5.5297, 5.5299, 5.5300,\n",
      "        5.5299, 5.5300, 5.5298, 5.5300, 5.5300, 5.5300, 5.5301, 5.5301, 5.5301,\n",
      "        5.5302, 5.5301, 5.5301, 5.5300, 5.5300, 5.5299, 5.5300, 5.5299, 5.5297,\n",
      "        5.5296, 5.5298, 5.5298, 5.5300, 5.5299, 5.5297, 5.5297, 5.5298, 5.5298,\n",
      "        5.5298, 5.5299, 5.5298, 5.5297, 5.5298, 5.5295, 5.5297, 5.5297, 5.5296,\n",
      "        5.5296, 5.5296, 5.5298, 5.5297, 5.5298, 5.5296, 5.5295, 5.5295, 5.5295,\n",
      "        5.5296, 5.5296, 5.5298, 5.5300, 5.5299, 5.5300, 5.5301, 5.5300, 5.5299,\n",
      "        5.5298, 5.5300, 5.5298, 5.5299, 5.5298, 5.5299, 5.5299, 5.5297, 5.5299,\n",
      "        5.5297, 5.5299, 5.5296, 5.5295, 5.5295, 5.5294, 5.5295, 5.5293, 5.5293,\n",
      "        5.5293, 5.5293, 5.5295, 5.5295, 5.5296, 5.5296, 5.5297, 5.5298, 5.5297,\n",
      "        5.5298, 5.5299, 5.5299, 5.5299, 5.5300, 5.5301, 5.5300, 5.5301, 5.5300,\n",
      "        5.5301, 5.5300, 5.5300, 5.5301, 5.5298, 5.5298, 5.5298, 5.5297, 5.5302,\n",
      "        5.5302, 5.5303, 5.5302, 5.5303, 5.5302, 5.5302, 5.5302, 5.5302, 5.5302,\n",
      "        5.5302, 5.5302, 5.5302], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.688377  [3583724/5599865]\n",
      "average delta from current occupancy tensor([4.5868, 4.5867, 4.5867, 4.5870, 4.5871, 4.5870, 4.5867, 4.5871, 4.5874,\n",
      "        4.5874, 4.5875, 4.5873, 4.5877, 4.5876, 4.5876, 4.5875, 4.5876, 4.5877,\n",
      "        4.5876, 4.5874, 4.5875, 4.5872, 4.5871, 4.5867, 4.5870, 4.5867, 4.5867,\n",
      "        4.5863, 4.5865, 4.5867, 4.5869, 4.5868, 4.5864, 4.5864, 4.5866, 4.5866,\n",
      "        4.5867, 4.5868, 4.5867, 4.5864, 4.5865, 4.5862, 4.5864, 4.5865, 4.5863,\n",
      "        4.5864, 4.5863, 4.5866, 4.5864, 4.5867, 4.5864, 4.5862, 4.5862, 4.5860,\n",
      "        4.5860, 4.5859, 4.5863, 4.5865, 4.5865, 4.5866, 4.5867, 4.5865, 4.5863,\n",
      "        4.5862, 4.5865, 4.5862, 4.5864, 4.5864, 4.5866, 4.5866, 4.5864, 4.5865,\n",
      "        4.5862, 4.5865, 4.5863, 4.5861, 4.5862, 4.5860, 4.5861, 4.5856, 4.5858,\n",
      "        4.5859, 4.5858, 4.5860, 4.5859, 4.5862, 4.5861, 4.5863, 4.5866, 4.5864,\n",
      "        4.5866, 4.5868, 4.5867, 4.5868, 4.5870, 4.5870, 4.5868, 4.5870, 4.5867,\n",
      "        4.5869, 4.5868, 4.5867, 4.5869, 4.5866, 4.5865, 4.5866, 4.5866, 4.5875,\n",
      "        4.5875, 4.5876, 4.5876, 4.5877, 4.5877, 4.5877, 4.5876, 4.5875, 4.5875,\n",
      "        4.5873, 4.5871, 4.5871], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.900768  [3596124/5599865]\n",
      "average delta from current occupancy tensor([4.6856, 4.6856, 4.6855, 4.6856, 4.6857, 4.6857, 4.6856, 4.6857, 4.6856,\n",
      "        4.6856, 4.6856, 4.6855, 4.6856, 4.6856, 4.6857, 4.6857, 4.6855, 4.6856,\n",
      "        4.6857, 4.6856, 4.6855, 4.6856, 4.6856, 4.6857, 4.6857, 4.6856, 4.6856,\n",
      "        4.6856, 4.6856, 4.6856, 4.6856, 4.6855, 4.6857, 4.6856, 4.6856, 4.6855,\n",
      "        4.6855, 4.6857, 4.6856, 4.6857, 4.6858, 4.6856, 4.6857, 4.6858, 4.6856,\n",
      "        4.6856, 4.6856, 4.6857, 4.6857, 4.6855, 4.6857, 4.6855, 4.6855, 4.6856,\n",
      "        4.6856, 4.6856, 4.6855, 4.6857, 4.6855, 4.6857, 4.6857, 4.6856, 4.6856,\n",
      "        4.6857, 4.6855, 4.6857, 4.6855, 4.6855, 4.6856, 4.6855, 4.6855, 4.6855,\n",
      "        4.6858, 4.6855, 4.6857, 4.6858, 4.6858, 4.6858, 4.6858, 4.6862, 4.6862,\n",
      "        4.6861, 4.6862, 4.6861, 4.6862, 4.6860, 4.6860, 4.6860, 4.6858, 4.6858,\n",
      "        4.6858, 4.6857, 4.6858, 4.6856, 4.6855, 4.6855, 4.6856, 4.6855, 4.6858,\n",
      "        4.6856, 4.6857, 4.6856, 4.6856, 4.6856, 4.6857, 4.6856, 4.6855, 4.6858,\n",
      "        4.6858, 4.6858, 4.6857, 4.6858, 4.6857, 4.6858, 4.6858, 4.6858, 4.6859,\n",
      "        4.6859, 4.6860, 4.6857], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.551523  [3608524/5599865]\n",
      "average delta from current occupancy tensor([4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2506, 4.2505,\n",
      "        4.2506, 4.2506, 4.2506, 4.2506, 4.2506, 4.2506, 4.2506, 4.2505, 4.2506,\n",
      "        4.2506, 4.2506, 4.2506, 4.2506, 4.2505, 4.2506, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2506, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2506, 4.2506,\n",
      "        4.2506, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2504, 4.2504, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2505,\n",
      "        4.2505, 4.2505, 4.2505, 4.2505, 4.2505, 4.2504, 4.2505, 4.2504, 4.2504,\n",
      "        4.2505, 4.2505, 4.2504, 4.2504, 4.2504, 4.2504, 4.2504, 4.2504, 4.2504,\n",
      "        4.2503, 4.2503, 4.2504], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.531667  [3620924/5599865]\n",
      "average delta from current occupancy tensor([5.5007, 5.5006, 5.5008, 5.5008, 5.5006, 5.5007, 5.5005, 5.5006, 5.5005,\n",
      "        5.5006, 5.5006, 5.5004, 5.5006, 5.5006, 5.5006, 5.5005, 5.5003, 5.5004,\n",
      "        5.5004, 5.5003, 5.5005, 5.5003, 5.5002, 5.5002, 5.5002, 5.5001, 5.5002,\n",
      "        5.5001, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5001, 5.5002, 5.5001, 5.5003, 5.5001, 5.5001, 5.5003, 5.5001,\n",
      "        5.5000, 5.5001, 5.5002, 5.5001, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5001, 5.5001, 5.5002, 5.5003, 5.5003, 5.5002, 5.5002,\n",
      "        5.5002, 5.5005, 5.5003, 5.5003, 5.5004, 5.5003, 5.5003, 5.5001, 5.5000,\n",
      "        5.5000, 5.5001, 5.5002, 5.5002, 5.5001, 5.5001, 5.5002, 5.5002, 5.5004,\n",
      "        5.5002, 5.5002, 5.5003, 5.5004, 5.5005, 5.5007, 5.5008, 5.5006, 5.5007,\n",
      "        5.5009, 5.5009, 5.5010], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.006009  [3633324/5599865]\n",
      "average delta from current occupancy tensor([5.0647, 5.0646, 5.0647, 5.0648, 5.0646, 5.0648, 5.0647, 5.0647, 5.0648,\n",
      "        5.0649, 5.0647, 5.0646, 5.0646, 5.0647, 5.0648, 5.0645, 5.0646, 5.0645,\n",
      "        5.0646, 5.0646, 5.0646, 5.0647, 5.0646, 5.0646, 5.0647, 5.0647, 5.0646,\n",
      "        5.0645, 5.0646, 5.0646, 5.0646, 5.0647, 5.0647, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0645, 5.0645, 5.0646, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0646, 5.0645, 5.0646, 5.0646, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0646, 5.0645, 5.0646, 5.0646, 5.0646, 5.0646, 5.0647, 5.0647, 5.0646,\n",
      "        5.0647, 5.0647, 5.0646, 5.0646, 5.0645, 5.0646, 5.0646, 5.0645, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0646, 5.0645, 5.0646, 5.0646,\n",
      "        5.0645, 5.0646, 5.0645, 5.0646, 5.0645, 5.0646, 5.0646, 5.0645, 5.0646,\n",
      "        5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646, 5.0647, 5.0646, 5.0646,\n",
      "        5.0646, 5.0647, 5.0647], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.599073  [3645724/5599865]\n",
      "average delta from current occupancy tensor([4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3948,\n",
      "        4.3948, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3949, 4.3948, 4.3949,\n",
      "        4.3949, 4.3949, 4.3949], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.796361  [3658124/5599865]\n",
      "average delta from current occupancy tensor([4.7906, 4.7905, 4.7904, 4.7903, 4.7903, 4.7903, 4.7904, 4.7902, 4.7905,\n",
      "        4.7903, 4.7905, 4.7905, 4.7903, 4.7902, 4.7903, 4.7902, 4.7903, 4.7905,\n",
      "        4.7905, 4.7905, 4.7903, 4.7905, 4.7907, 4.7906, 4.7906, 4.7907, 4.7906,\n",
      "        4.7909, 4.7908, 4.7909, 4.7909, 4.7908, 4.7907, 4.7909, 4.7907, 4.7907,\n",
      "        4.7906, 4.7905, 4.7909, 4.7907, 4.7908, 4.7905, 4.7907, 4.7906, 4.7906,\n",
      "        4.7906, 4.7907, 4.7908, 4.7904, 4.7904, 4.7905, 4.7906, 4.7904, 4.7903,\n",
      "        4.7904, 4.7903, 4.7905, 4.7907, 4.7908, 4.7908, 4.7908, 4.7909, 4.7908,\n",
      "        4.7909, 4.7907, 4.7905, 4.7907, 4.7909, 4.7908, 4.7908, 4.7909, 4.7907,\n",
      "        4.7905, 4.7907, 4.7906, 4.7904, 4.7905, 4.7903, 4.7902, 4.7903, 4.7900,\n",
      "        4.7903, 4.7902, 4.7903, 4.7903, 4.7906, 4.7905, 4.7906, 4.7903, 4.7906,\n",
      "        4.7903, 4.7902, 4.7904, 4.7901, 4.7905, 4.7905, 4.7907, 4.7907, 4.7908,\n",
      "        4.7905, 4.7904, 4.7904, 4.7902, 4.7903, 4.7901, 4.7903, 4.7905, 4.7902,\n",
      "        4.7902, 4.7901, 4.7901, 4.7899, 4.7899, 4.7899, 4.7900, 4.7899, 4.7899,\n",
      "        4.7900, 4.7899, 4.7901], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.126143  [3670524/5599865]\n",
      "average delta from current occupancy tensor([5.3550, 5.3550, 5.3550, 5.3551, 5.3551, 5.3551, 5.3551, 5.3552, 5.3552,\n",
      "        5.3552, 5.3552, 5.3551, 5.3552, 5.3552, 5.3551, 5.3551, 5.3551, 5.3551,\n",
      "        5.3551, 5.3551, 5.3552, 5.3551, 5.3550, 5.3551, 5.3550, 5.3550, 5.3551,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3551, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3551, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3551,\n",
      "        5.3551, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3551, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3551, 5.3551, 5.3550, 5.3550, 5.3551, 5.3550, 5.3551,\n",
      "        5.3551, 5.3551, 5.3551, 5.3551, 5.3551, 5.3551, 5.3551, 5.3551, 5.3551,\n",
      "        5.3551, 5.3551, 5.3551], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.642271  [3682924/5599865]\n",
      "average delta from current occupancy tensor([4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5485, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484, 4.5484,\n",
      "        4.5484, 4.5484, 4.5484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.169607  [3695324/5599865]\n",
      "average delta from current occupancy tensor([4.9437, 4.9438, 4.9437, 4.9438, 4.9438, 4.9437, 4.9438, 4.9438, 4.9438,\n",
      "        4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438,\n",
      "        4.9438, 4.9438, 4.9437, 4.9438, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437,\n",
      "        4.9438, 4.9438, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437,\n",
      "        4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9438,\n",
      "        4.9437, 4.9437, 4.9438, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437,\n",
      "        4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438,\n",
      "        4.9438, 4.9438, 4.9438, 4.9438, 4.9437, 4.9437, 4.9438, 4.9438, 4.9437,\n",
      "        4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438, 4.9438,\n",
      "        4.9438, 4.9438, 4.9438, 4.9438, 4.9437, 4.9437, 4.9437, 4.9438, 4.9437,\n",
      "        4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437,\n",
      "        4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9437,\n",
      "        4.9437, 4.9437, 4.9437, 4.9437, 4.9437, 4.9438, 4.9437, 4.9437, 4.9437,\n",
      "        4.9437, 4.9437, 4.9437], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.830430  [3707724/5599865]\n",
      "average delta from current occupancy tensor([4.7337, 4.7337, 4.7338, 4.7337, 4.7337, 4.7337, 4.7336, 4.7336, 4.7337,\n",
      "        4.7337, 4.7337, 4.7337, 4.7338, 4.7339, 4.7337, 4.7338, 4.7338, 4.7337,\n",
      "        4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7338, 4.7338, 4.7338,\n",
      "        4.7337, 4.7338, 4.7339, 4.7338, 4.7339, 4.7337, 4.7339, 4.7337, 4.7337,\n",
      "        4.7337, 4.7338, 4.7338, 4.7339, 4.7337, 4.7340, 4.7337, 4.7339, 4.7339,\n",
      "        4.7340, 4.7338, 4.7338, 4.7338, 4.7338, 4.7338, 4.7337, 4.7337, 4.7339,\n",
      "        4.7338, 4.7339, 4.7338, 4.7336, 4.7337, 4.7336, 4.7337, 4.7336, 4.7336,\n",
      "        4.7336, 4.7337, 4.7337, 4.7335, 4.7337, 4.7337, 4.7336, 4.7336, 4.7337,\n",
      "        4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7337, 4.7338, 4.7336, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7337, 4.7337, 4.7338, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7337, 4.7337, 4.7337, 4.7339, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7337, 4.7338, 4.7339, 4.7338, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7338, 4.7338, 4.7338], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.035442  [3720124/5599865]\n",
      "average delta from current occupancy tensor([4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9437, 4.9437,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9435, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436, 4.9436, 4.9436, 4.9435, 4.9436, 4.9436, 4.9436,\n",
      "        4.9436, 4.9436, 4.9436], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.156466  [3732524/5599865]\n",
      "average delta from current occupancy tensor([5.0638, 5.0635, 5.0639, 5.0640, 5.0638, 5.0639, 5.0638, 5.0639, 5.0636,\n",
      "        5.0635, 5.0636, 5.0631, 5.0635, 5.0637, 5.0637, 5.0633, 5.0633, 5.0630,\n",
      "        5.0632, 5.0632, 5.0633, 5.0632, 5.0635, 5.0634, 5.0632, 5.0632, 5.0632,\n",
      "        5.0634, 5.0636, 5.0631, 5.0636, 5.0637, 5.0636, 5.0638, 5.0638, 5.0637,\n",
      "        5.0637, 5.0637, 5.0634, 5.0634, 5.0633, 5.0632, 5.0632, 5.0634, 5.0634,\n",
      "        5.0636, 5.0632, 5.0632, 5.0631, 5.0638, 5.0635, 5.0637, 5.0637, 5.0637,\n",
      "        5.0638, 5.0638, 5.0633, 5.0634, 5.0636, 5.0636, 5.0637, 5.0637, 5.0635,\n",
      "        5.0634, 5.0635, 5.0636, 5.0634, 5.0634, 5.0635, 5.0634, 5.0633, 5.0633,\n",
      "        5.0634, 5.0635, 5.0635, 5.0634, 5.0633, 5.0633, 5.0634, 5.0633, 5.0632,\n",
      "        5.0633, 5.0635, 5.0635, 5.0634, 5.0634, 5.0632, 5.0633, 5.0634, 5.0636,\n",
      "        5.0637, 5.0633, 5.0634, 5.0634, 5.0636, 5.0633, 5.0632, 5.0629, 5.0629,\n",
      "        5.0633, 5.0630, 5.0628, 5.0628, 5.0628, 5.0629, 5.0630, 5.0629, 5.0630,\n",
      "        5.0628, 5.0627, 5.0627, 5.0632, 5.0630, 5.0633, 5.0635, 5.0632, 5.0633,\n",
      "        5.0631, 5.0631, 5.0630], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.713494  [3744924/5599865]\n",
      "average delta from current occupancy tensor([5.7338, 5.7338, 5.7339, 5.7339, 5.7339, 5.7339, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7337, 5.7337, 5.7338,\n",
      "        5.7338, 5.7338, 5.7337, 5.7338, 5.7338, 5.7337, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7337, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7337, 5.7337, 5.7337, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7337, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338, 5.7338,\n",
      "        5.7338, 5.7338, 5.7338], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.159606  [3757324/5599865]\n",
      "average delta from current occupancy tensor([5.2736, 5.2737, 5.2735, 5.2731, 5.2732, 5.2732, 5.2736, 5.2736, 5.2731,\n",
      "        5.2730, 5.2732, 5.2731, 5.2730, 5.2731, 5.2733, 5.2733, 5.2733, 5.2733,\n",
      "        5.2733, 5.2733, 5.2732, 5.2731, 5.2732, 5.2734, 5.2732, 5.2734, 5.2732,\n",
      "        5.2733, 5.2732, 5.2732, 5.2732, 5.2732, 5.2734, 5.2734, 5.2735, 5.2732,\n",
      "        5.2732, 5.2732, 5.2733, 5.2732, 5.2732, 5.2731, 5.2733, 5.2731, 5.2731,\n",
      "        5.2731, 5.2731, 5.2732, 5.2732, 5.2731, 5.2733, 5.2732, 5.2733, 5.2732,\n",
      "        5.2732, 5.2729, 5.2731, 5.2731, 5.2731, 5.2731, 5.2730, 5.2729, 5.2730,\n",
      "        5.2730, 5.2730, 5.2731, 5.2730, 5.2731, 5.2730, 5.2731, 5.2731, 5.2731,\n",
      "        5.2732, 5.2732, 5.2731, 5.2731, 5.2731, 5.2731, 5.2730, 5.2731, 5.2731,\n",
      "        5.2730, 5.2730, 5.2729, 5.2730, 5.2731, 5.2730, 5.2729, 5.2730, 5.2731,\n",
      "        5.2730, 5.2729, 5.2730, 5.2732, 5.2731, 5.2730, 5.2731, 5.2730, 5.2731,\n",
      "        5.2731, 5.2731, 5.2731, 5.2730, 5.2730, 5.2732, 5.2732, 5.2731, 5.2731,\n",
      "        5.2731, 5.2732, 5.2733, 5.2733, 5.2732, 5.2731, 5.2734, 5.2732, 5.2733,\n",
      "        5.2732, 5.2733, 5.2732], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.011749  [3769724/5599865]\n",
      "average delta from current occupancy tensor([4.9696, 4.9697, 4.9697, 4.9698, 4.9698, 4.9699, 4.9699, 4.9699, 4.9701,\n",
      "        4.9701, 4.9701, 4.9701, 4.9701, 4.9701, 4.9700, 4.9701, 4.9702, 4.9702,\n",
      "        4.9701, 4.9700, 4.9700, 4.9700, 4.9701, 4.9699, 4.9700, 4.9701, 4.9702,\n",
      "        4.9702, 4.9703, 4.9703, 4.9703, 4.9703, 4.9701, 4.9701, 4.9699, 4.9701,\n",
      "        4.9700, 4.9699, 4.9698, 4.9699, 4.9697, 4.9697, 4.9698, 4.9697, 4.9699,\n",
      "        4.9697, 4.9696, 4.9699, 4.9700, 4.9697, 4.9698, 4.9697, 4.9698, 4.9696,\n",
      "        4.9698, 4.9698, 4.9697, 4.9697, 4.9698, 4.9699, 4.9698, 4.9697, 4.9698,\n",
      "        4.9700, 4.9699, 4.9700, 4.9699, 4.9699, 4.9699, 4.9699, 4.9700, 4.9700,\n",
      "        4.9700, 4.9701, 4.9699, 4.9700, 4.9699, 4.9696, 4.9697, 4.9698, 4.9698,\n",
      "        4.9695, 4.9698, 4.9697, 4.9696, 4.9696, 4.9694, 4.9694, 4.9695, 4.9698,\n",
      "        4.9694, 4.9693, 4.9692, 4.9696, 4.9694, 4.9692, 4.9692, 4.9692, 4.9692,\n",
      "        4.9693, 4.9694, 4.9695, 4.9695, 4.9696, 4.9692, 4.9691, 4.9693, 4.9693,\n",
      "        4.9692, 4.9693, 4.9693, 4.9693, 4.9693, 4.9691, 4.9692, 4.9693, 4.9695,\n",
      "        4.9694, 4.9693, 4.9692], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.745030  [3782124/5599865]\n",
      "average delta from current occupancy tensor([4.7661, 4.7662, 4.7663, 4.7662, 4.7661, 4.7664, 4.7663, 4.7662, 4.7661,\n",
      "        4.7661, 4.7662, 4.7663, 4.7662, 4.7665, 4.7661, 4.7661, 4.7661, 4.7663,\n",
      "        4.7662, 4.7661, 4.7664, 4.7664, 4.7661, 4.7664, 4.7662, 4.7662, 4.7661,\n",
      "        4.7662, 4.7663, 4.7663, 4.7665, 4.7662, 4.7664, 4.7663, 4.7665, 4.7662,\n",
      "        4.7663, 4.7666, 4.7665, 4.7664, 4.7664, 4.7665, 4.7662, 4.7661, 4.7661,\n",
      "        4.7664, 4.7663, 4.7662, 4.7663, 4.7661, 4.7663, 4.7666, 4.7665, 4.7668,\n",
      "        4.7663, 4.7665, 4.7665, 4.7665, 4.7662, 4.7665, 4.7664, 4.7666, 4.7664,\n",
      "        4.7666, 4.7666, 4.7664, 4.7665, 4.7661, 4.7663, 4.7661, 4.7664, 4.7664,\n",
      "        4.7665, 4.7665, 4.7663, 4.7661, 4.7661, 4.7664, 4.7665, 4.7662, 4.7664,\n",
      "        4.7661, 4.7662, 4.7667, 4.7666, 4.7665, 4.7665, 4.7667, 4.7666, 4.7664,\n",
      "        4.7661, 4.7663, 4.7662, 4.7662, 4.7661, 4.7663, 4.7661, 4.7663, 4.7661,\n",
      "        4.7664, 4.7663, 4.7661, 4.7660, 4.7660, 4.7660, 4.7661, 4.7661, 4.7661,\n",
      "        4.7660, 4.7661, 4.7661, 4.7660, 4.7661, 4.7661, 4.7663, 4.7661, 4.7665,\n",
      "        4.7661, 4.7663, 4.7664], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.575668  [3794524/5599865]\n",
      "average delta from current occupancy tensor([5.5734, 5.5734, 5.5732, 5.5733, 5.5730, 5.5730, 5.5731, 5.5734, 5.5729,\n",
      "        5.5732, 5.5732, 5.5729, 5.5732, 5.5727, 5.5723, 5.5725, 5.5726, 5.5726,\n",
      "        5.5721, 5.5724, 5.5729, 5.5728, 5.5730, 5.5728, 5.5727, 5.5734, 5.5736,\n",
      "        5.5734, 5.5735, 5.5731, 5.5732, 5.5732, 5.5738, 5.5733, 5.5730, 5.5735,\n",
      "        5.5733, 5.5735, 5.5730, 5.5734, 5.5735, 5.5735, 5.5732, 5.5736, 5.5734,\n",
      "        5.5731, 5.5736, 5.5733, 5.5730, 5.5729, 5.5736, 5.5734, 5.5730, 5.5735,\n",
      "        5.5731, 5.5733, 5.5735, 5.5729, 5.5734, 5.5734, 5.5728, 5.5730, 5.5731,\n",
      "        5.5733, 5.5731, 5.5728, 5.5728, 5.5732, 5.5731, 5.5727, 5.5727, 5.5726,\n",
      "        5.5727, 5.5729, 5.5728, 5.5730, 5.5730, 5.5732, 5.5730, 5.5730, 5.5730,\n",
      "        5.5728, 5.5729, 5.5727, 5.5725, 5.5723, 5.5725, 5.5725, 5.5725, 5.5727,\n",
      "        5.5723, 5.5725, 5.5721, 5.5718, 5.5723, 5.5717, 5.5720, 5.5724, 5.5722,\n",
      "        5.5722, 5.5720, 5.5724, 5.5723, 5.5721, 5.5722, 5.5722, 5.5724, 5.5725,\n",
      "        5.5724, 5.5726, 5.5725, 5.5726, 5.5724, 5.5726, 5.5722, 5.5727, 5.5725,\n",
      "        5.5727, 5.5724, 5.5723], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.803654  [3806924/5599865]\n",
      "average delta from current occupancy tensor([4.8870, 4.8871, 4.8870, 4.8870, 4.8871, 4.8871, 4.8871, 4.8870, 4.8871,\n",
      "        4.8869, 4.8869, 4.8870, 4.8870, 4.8869, 4.8870, 4.8869, 4.8870, 4.8870,\n",
      "        4.8871, 4.8871, 4.8869, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8869,\n",
      "        4.8871, 4.8870, 4.8870, 4.8871, 4.8870, 4.8870, 4.8870, 4.8871, 4.8870,\n",
      "        4.8871, 4.8870, 4.8871, 4.8870, 4.8871, 4.8871, 4.8871, 4.8870, 4.8870,\n",
      "        4.8871, 4.8870, 4.8870, 4.8871, 4.8870, 4.8869, 4.8870, 4.8870, 4.8870,\n",
      "        4.8870, 4.8870, 4.8870, 4.8870, 4.8870, 4.8870, 4.8871, 4.8871, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8872, 4.8872, 4.8872, 4.8871, 4.8871, 4.8871,\n",
      "        4.8871, 4.8872, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8872, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8871, 4.8872, 4.8871, 4.8871, 4.8871, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8872, 4.8872, 4.8871,\n",
      "        4.8872, 4.8872, 4.8872, 4.8872, 4.8872, 4.8871, 4.8872, 4.8871, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8871, 4.8870, 4.8871, 4.8871, 4.8871, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.488363  [3819324/5599865]\n",
      "average delta from current occupancy tensor([5.4208, 5.4204, 5.4205, 5.4207, 5.4208, 5.4205, 5.4208, 5.4208, 5.4208,\n",
      "        5.4208, 5.4208, 5.4207, 5.4208, 5.4207, 5.4206, 5.4206, 5.4207, 5.4207,\n",
      "        5.4207, 5.4207, 5.4207, 5.4206, 5.4207, 5.4206, 5.4206, 5.4206, 5.4206,\n",
      "        5.4207, 5.4207, 5.4207, 5.4207, 5.4207, 5.4208, 5.4208, 5.4208, 5.4206,\n",
      "        5.4206, 5.4207, 5.4207, 5.4207, 5.4206, 5.4206, 5.4208, 5.4209, 5.4206,\n",
      "        5.4207, 5.4210, 5.4211, 5.4212, 5.4209, 5.4207, 5.4207, 5.4211, 5.4210,\n",
      "        5.4212, 5.4211, 5.4208, 5.4210, 5.4207, 5.4210, 5.4209, 5.4211, 5.4206,\n",
      "        5.4209, 5.4207, 5.4209, 5.4206, 5.4208, 5.4208, 5.4205, 5.4210, 5.4209,\n",
      "        5.4209, 5.4208, 5.4208, 5.4210, 5.4210, 5.4210, 5.4206, 5.4210, 5.4209,\n",
      "        5.4206, 5.4207, 5.4207, 5.4209, 5.4208, 5.4209, 5.4210, 5.4209, 5.4210,\n",
      "        5.4210, 5.4208, 5.4207, 5.4207, 5.4208, 5.4210, 5.4209, 5.4209, 5.4210,\n",
      "        5.4210, 5.4209, 5.4207, 5.4211, 5.4210, 5.4210, 5.4212, 5.4211, 5.4212,\n",
      "        5.4208, 5.4210, 5.4212, 5.4211, 5.4213, 5.4212, 5.4210, 5.4212, 5.4211,\n",
      "        5.4212, 5.4210, 5.4208], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.571720  [3831724/5599865]\n",
      "average delta from current occupancy tensor([4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288,\n",
      "        4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288,\n",
      "        4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288,\n",
      "        4.6288, 4.6289, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288, 4.6288,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6288, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6290, 4.6289, 4.6289, 4.6289, 4.6290, 4.6289, 4.6289, 4.6289, 4.6289,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6290,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6289, 4.6290, 4.6290, 4.6290, 4.6290,\n",
      "        4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6290, 4.6289, 4.6290,\n",
      "        4.6289, 4.6289, 4.6289], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.195744  [3844124/5599865]\n",
      "average delta from current occupancy tensor([5.3139, 5.3140, 5.3139, 5.3137, 5.3138, 5.3141, 5.3139, 5.3137, 5.3139,\n",
      "        5.3142, 5.3138, 5.3140, 5.3141, 5.3140, 5.3143, 5.3141, 5.3142, 5.3140,\n",
      "        5.3141, 5.3141, 5.3144, 5.3143, 5.3142, 5.3142, 5.3143, 5.3141, 5.3142,\n",
      "        5.3144, 5.3143, 5.3145, 5.3143, 5.3143, 5.3143, 5.3143, 5.3141, 5.3143,\n",
      "        5.3142, 5.3143, 5.3143, 5.3143, 5.3142, 5.3141, 5.3140, 5.3141, 5.3140,\n",
      "        5.3139, 5.3141, 5.3134, 5.3138, 5.3134, 5.3135, 5.3136, 5.3138, 5.3139,\n",
      "        5.3138, 5.3139, 5.3137, 5.3137, 5.3139, 5.3136, 5.3139, 5.3138, 5.3139,\n",
      "        5.3139, 5.3139, 5.3141, 5.3138, 5.3137, 5.3138, 5.3139, 5.3138, 5.3140,\n",
      "        5.3141, 5.3140, 5.3142, 5.3142, 5.3142, 5.3143, 5.3142, 5.3141, 5.3140,\n",
      "        5.3138, 5.3139, 5.3138, 5.3138, 5.3138, 5.3137, 5.3140, 5.3139, 5.3137,\n",
      "        5.3138, 5.3137, 5.3137, 5.3138, 5.3137, 5.3136, 5.3135, 5.3135, 5.3133,\n",
      "        5.3133, 5.3133, 5.3135, 5.3132, 5.3131, 5.3132, 5.3134, 5.3133, 5.3132,\n",
      "        5.3132, 5.3135, 5.3134, 5.3138, 5.3137, 5.3140, 5.3141, 5.3143, 5.3140,\n",
      "        5.3141, 5.3141, 5.3143], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.408317  [3856524/5599865]\n",
      "average delta from current occupancy tensor([5.3699, 5.3697, 5.3698, 5.3696, 5.3695, 5.3694, 5.3696, 5.3695, 5.3693,\n",
      "        5.3693, 5.3693, 5.3693, 5.3694, 5.3694, 5.3693, 5.3693, 5.3692, 5.3692,\n",
      "        5.3690, 5.3692, 5.3692, 5.3692, 5.3691, 5.3692, 5.3693, 5.3692, 5.3691,\n",
      "        5.3692, 5.3691, 5.3691, 5.3689, 5.3690, 5.3690, 5.3690, 5.3692, 5.3693,\n",
      "        5.3692, 5.3693, 5.3695, 5.3695, 5.3693, 5.3693, 5.3694, 5.3694, 5.3695,\n",
      "        5.3696, 5.3695, 5.3698, 5.3698, 5.3699, 5.3698, 5.3697, 5.3696, 5.3696,\n",
      "        5.3694, 5.3695, 5.3697, 5.3698, 5.3697, 5.3694, 5.3695, 5.3698, 5.3698,\n",
      "        5.3698, 5.3699, 5.3697, 5.3698, 5.3696, 5.3697, 5.3698, 5.3696, 5.3698,\n",
      "        5.3696, 5.3695, 5.3695, 5.3697, 5.3696, 5.3697, 5.3699, 5.3696, 5.3698,\n",
      "        5.3697, 5.3696, 5.3698, 5.3700, 5.3700, 5.3701, 5.3699, 5.3699, 5.3698,\n",
      "        5.3699, 5.3696, 5.3696, 5.3696, 5.3696, 5.3697, 5.3696, 5.3695, 5.3697,\n",
      "        5.3697, 5.3697, 5.3696, 5.3696, 5.3700, 5.3701, 5.3696, 5.3695, 5.3697,\n",
      "        5.3697, 5.3693, 5.3693, 5.3693, 5.3692, 5.3693, 5.3692, 5.3694, 5.3694,\n",
      "        5.3695, 5.3694, 5.3693], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.434654  [3868924/5599865]\n",
      "average delta from current occupancy tensor([5.4428, 5.4428, 5.4429, 5.4429, 5.4429, 5.4430, 5.4430, 5.4429, 5.4430,\n",
      "        5.4430, 5.4431, 5.4430, 5.4429, 5.4429, 5.4430, 5.4431, 5.4431, 5.4431,\n",
      "        5.4430, 5.4431, 5.4430, 5.4430, 5.4430, 5.4430, 5.4430, 5.4429, 5.4429,\n",
      "        5.4430, 5.4429, 5.4429, 5.4428, 5.4428, 5.4429, 5.4429, 5.4432, 5.4432,\n",
      "        5.4430, 5.4431, 5.4432, 5.4431, 5.4431, 5.4432, 5.4432, 5.4431, 5.4432,\n",
      "        5.4432, 5.4432, 5.4432, 5.4432, 5.4431, 5.4431, 5.4431, 5.4432, 5.4432,\n",
      "        5.4432, 5.4432, 5.4431, 5.4432, 5.4432, 5.4432, 5.4432, 5.4432, 5.4432,\n",
      "        5.4433, 5.4431, 5.4432, 5.4431, 5.4432, 5.4432, 5.4432, 5.4433, 5.4433,\n",
      "        5.4432, 5.4433, 5.4433, 5.4432, 5.4431, 5.4431, 5.4431, 5.4431, 5.4431,\n",
      "        5.4431, 5.4431, 5.4431, 5.4430, 5.4431, 5.4430, 5.4431, 5.4430, 5.4431,\n",
      "        5.4431, 5.4432, 5.4432, 5.4432, 5.4432, 5.4432, 5.4431, 5.4432, 5.4432,\n",
      "        5.4432, 5.4431, 5.4431, 5.4431, 5.4431, 5.4430, 5.4432, 5.4432, 5.4431,\n",
      "        5.4431, 5.4431, 5.4431, 5.4432, 5.4432, 5.4431, 5.4431, 5.4431, 5.4430,\n",
      "        5.4430, 5.4430, 5.4430], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.078824  [3881324/5599865]\n",
      "average delta from current occupancy tensor([4.8707, 4.8708, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8708, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708,\n",
      "        4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708, 4.8708,\n",
      "        4.8708, 4.8707, 4.8708, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8708, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8708, 4.8708, 4.8708, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.216431  [3893724/5599865]\n",
      "average delta from current occupancy tensor([5.5511, 5.5509, 5.5510, 5.5508, 5.5508, 5.5508, 5.5507, 5.5507, 5.5507,\n",
      "        5.5507, 5.5506, 5.5505, 5.5506, 5.5506, 5.5504, 5.5504, 5.5504, 5.5504,\n",
      "        5.5503, 5.5502, 5.5502, 5.5501, 5.5500, 5.5498, 5.5500, 5.5502, 5.5502,\n",
      "        5.5502, 5.5502, 5.5502, 5.5502, 5.5503, 5.5501, 5.5501, 5.5502, 5.5502,\n",
      "        5.5500, 5.5502, 5.5500, 5.5501, 5.5501, 5.5503, 5.5503, 5.5503, 5.5503,\n",
      "        5.5504, 5.5505, 5.5505, 5.5504, 5.5503, 5.5504, 5.5502, 5.5503, 5.5501,\n",
      "        5.5501, 5.5502, 5.5499, 5.5499, 5.5500, 5.5499, 5.5500, 5.5500, 5.5497,\n",
      "        5.5496, 5.5495, 5.5496, 5.5495, 5.5497, 5.5495, 5.5496, 5.5495, 5.5495,\n",
      "        5.5495, 5.5497, 5.5494, 5.5494, 5.5496, 5.5499, 5.5499, 5.5497, 5.5498,\n",
      "        5.5498, 5.5497, 5.5498, 5.5497, 5.5500, 5.5500, 5.5500, 5.5499, 5.5496,\n",
      "        5.5498, 5.5500, 5.5498, 5.5496, 5.5497, 5.5498, 5.5498, 5.5500, 5.5500,\n",
      "        5.5499, 5.5498, 5.5498, 5.5499, 5.5499, 5.5499, 5.5499, 5.5499, 5.5499,\n",
      "        5.5498, 5.5499, 5.5499, 5.5500, 5.5500, 5.5499, 5.5500, 5.5502, 5.5500,\n",
      "        5.5502, 5.5502, 5.5499], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.859010  [3906124/5599865]\n",
      "average delta from current occupancy tensor([5.5164, 5.5164, 5.5164, 5.5165, 5.5164, 5.5165, 5.5164, 5.5165, 5.5164,\n",
      "        5.5164, 5.5164, 5.5164, 5.5164, 5.5165, 5.5165, 5.5165, 5.5164, 5.5166,\n",
      "        5.5166, 5.5164, 5.5165, 5.5166, 5.5164, 5.5163, 5.5164, 5.5163, 5.5164,\n",
      "        5.5163, 5.5164, 5.5163, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164, 5.5163,\n",
      "        5.5163, 5.5165, 5.5164, 5.5164, 5.5164, 5.5165, 5.5164, 5.5163, 5.5163,\n",
      "        5.5163, 5.5164, 5.5163, 5.5163, 5.5163, 5.5163, 5.5163, 5.5163, 5.5163,\n",
      "        5.5163, 5.5164, 5.5164, 5.5164, 5.5164, 5.5163, 5.5163, 5.5164, 5.5164,\n",
      "        5.5164, 5.5164, 5.5164, 5.5164, 5.5165, 5.5165, 5.5164, 5.5164, 5.5165,\n",
      "        5.5165, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164,\n",
      "        5.5164, 5.5164, 5.5163, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164,\n",
      "        5.5164, 5.5164, 5.5164, 5.5164, 5.5164, 5.5165, 5.5165, 5.5165, 5.5165,\n",
      "        5.5164, 5.5166, 5.5166, 5.5165, 5.5166, 5.5165, 5.5165, 5.5166, 5.5166,\n",
      "        5.5165, 5.5165, 5.5165, 5.5166, 5.5165, 5.5164, 5.5165, 5.5164, 5.5164,\n",
      "        5.5164, 5.5166, 5.5165], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.646103  [3918524/5599865]\n",
      "average delta from current occupancy tensor([4.9217, 4.9218, 4.9218, 4.9218, 4.9217, 4.9217, 4.9217, 4.9217, 4.9217,\n",
      "        4.9217, 4.9216, 4.9216, 4.9217, 4.9217, 4.9216, 4.9217, 4.9217, 4.9218,\n",
      "        4.9217, 4.9217, 4.9218, 4.9218, 4.9216, 4.9217, 4.9216, 4.9216, 4.9216,\n",
      "        4.9215, 4.9216, 4.9217, 4.9216, 4.9216, 4.9215, 4.9215, 4.9216, 4.9217,\n",
      "        4.9216, 4.9215, 4.9215, 4.9216, 4.9216, 4.9216, 4.9216, 4.9217, 4.9217,\n",
      "        4.9216, 4.9216, 4.9215, 4.9217, 4.9216, 4.9218, 4.9217, 4.9218, 4.9217,\n",
      "        4.9218, 4.9217, 4.9217, 4.9217, 4.9218, 4.9218, 4.9217, 4.9218, 4.9217,\n",
      "        4.9218, 4.9218, 4.9218, 4.9218, 4.9218, 4.9218, 4.9217, 4.9217, 4.9217,\n",
      "        4.9218, 4.9217, 4.9218, 4.9217, 4.9217, 4.9217, 4.9217, 4.9217, 4.9218,\n",
      "        4.9217, 4.9216, 4.9217, 4.9218, 4.9217, 4.9217, 4.9217, 4.9217, 4.9218,\n",
      "        4.9217, 4.9217, 4.9217, 4.9216, 4.9218, 4.9217, 4.9217, 4.9218, 4.9217,\n",
      "        4.9216, 4.9216, 4.9216, 4.9217, 4.9216, 4.9216, 4.9215, 4.9216, 4.9216,\n",
      "        4.9216, 4.9216, 4.9215, 4.9215, 4.9216, 4.9217, 4.9216, 4.9216, 4.9215,\n",
      "        4.9215, 4.9216, 4.9216], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.375477  [3930924/5599865]\n",
      "average delta from current occupancy tensor([5.1613, 5.1614, 5.1614, 5.1614, 5.1613, 5.1613, 5.1614, 5.1613, 5.1613,\n",
      "        5.1614, 5.1614, 5.1614, 5.1615, 5.1615, 5.1615, 5.1613, 5.1613, 5.1614,\n",
      "        5.1613, 5.1613, 5.1614, 5.1614, 5.1613, 5.1613, 5.1614, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1614, 5.1614, 5.1614, 5.1614, 5.1613,\n",
      "        5.1614, 5.1614, 5.1613, 5.1613, 5.1614, 5.1613, 5.1614, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1614, 5.1613, 5.1613, 5.1614, 5.1614, 5.1614, 5.1614,\n",
      "        5.1613, 5.1614, 5.1614, 5.1613, 5.1613, 5.1615, 5.1615, 5.1615, 5.1614,\n",
      "        5.1614, 5.1613, 5.1613, 5.1614, 5.1613, 5.1613, 5.1614, 5.1613, 5.1614,\n",
      "        5.1614, 5.1614, 5.1616, 5.1616, 5.1614, 5.1614, 5.1614, 5.1614, 5.1615,\n",
      "        5.1616, 5.1616, 5.1616, 5.1615, 5.1615, 5.1614, 5.1614, 5.1615, 5.1614,\n",
      "        5.1614, 5.1615, 5.1615, 5.1613, 5.1613, 5.1615, 5.1616, 5.1616, 5.1615,\n",
      "        5.1616, 5.1616, 5.1616, 5.1616, 5.1616, 5.1615, 5.1615, 5.1616, 5.1617,\n",
      "        5.1616, 5.1615, 5.1615], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.468487  [3943324/5599865]\n",
      "average delta from current occupancy tensor([4.4509, 4.4508, 4.4508, 4.4509, 4.4509, 4.4508, 4.4509, 4.4508, 4.4508,\n",
      "        4.4509, 4.4509, 4.4509, 4.4509, 4.4508, 4.4510, 4.4510, 4.4509, 4.4510,\n",
      "        4.4510, 4.4508, 4.4508, 4.4508, 4.4510, 4.4507, 4.4509, 4.4508, 4.4508,\n",
      "        4.4511, 4.4511, 4.4510, 4.4508, 4.4509, 4.4509, 4.4509, 4.4510, 4.4509,\n",
      "        4.4509, 4.4507, 4.4509, 4.4510, 4.4510, 4.4508, 4.4509, 4.4510, 4.4512,\n",
      "        4.4510, 4.4509, 4.4509, 4.4510, 4.4509, 4.4509, 4.4509, 4.4510, 4.4510,\n",
      "        4.4509, 4.4510, 4.4510, 4.4509, 4.4509, 4.4510, 4.4509, 4.4508, 4.4510,\n",
      "        4.4510, 4.4510, 4.4510, 4.4509, 4.4510, 4.4509, 4.4509, 4.4510, 4.4509,\n",
      "        4.4509, 4.4511, 4.4510, 4.4510, 4.4509, 4.4509, 4.4511, 4.4509, 4.4510,\n",
      "        4.4509, 4.4511, 4.4510, 4.4509, 4.4511, 4.4510, 4.4510, 4.4510, 4.4510,\n",
      "        4.4510, 4.4510, 4.4510, 4.4510, 4.4509, 4.4509, 4.4509, 4.4508, 4.4508,\n",
      "        4.4508, 4.4508, 4.4508, 4.4508, 4.4508, 4.4509, 4.4509, 4.4508, 4.4509,\n",
      "        4.4508, 4.4510, 4.4509, 4.4509, 4.4509, 4.4509, 4.4510, 4.4509, 4.4508,\n",
      "        4.4509, 4.4508, 4.4508], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.006488  [3955724/5599865]\n",
      "average delta from current occupancy tensor([4.9275, 4.9275, 4.9275, 4.9276, 4.9276, 4.9276, 4.9276, 4.9275, 4.9276,\n",
      "        4.9275, 4.9276, 4.9276, 4.9276, 4.9276, 4.9276, 4.9276, 4.9276, 4.9275,\n",
      "        4.9275, 4.9276, 4.9275, 4.9276, 4.9275, 4.9276, 4.9275, 4.9276, 4.9276,\n",
      "        4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275,\n",
      "        4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9274, 4.9275, 4.9275, 4.9275,\n",
      "        4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9274,\n",
      "        4.9275, 4.9274, 4.9275, 4.9274, 4.9275, 4.9275, 4.9274, 4.9275, 4.9274,\n",
      "        4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9274, 4.9275, 4.9275,\n",
      "        4.9275, 4.9276, 4.9275, 4.9275, 4.9275, 4.9274, 4.9275, 4.9275, 4.9275,\n",
      "        4.9275, 4.9275, 4.9275, 4.9274, 4.9275, 4.9275, 4.9275, 4.9274, 4.9274,\n",
      "        4.9275, 4.9274, 4.9274, 4.9274, 4.9274, 4.9275, 4.9275, 4.9274, 4.9274,\n",
      "        4.9275, 4.9274, 4.9274, 4.9274, 4.9275, 4.9274, 4.9274, 4.9275, 4.9274,\n",
      "        4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275, 4.9275,\n",
      "        4.9275, 4.9275, 4.9276], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.881392  [3968124/5599865]\n",
      "average delta from current occupancy tensor([4.9756, 4.9756, 4.9757, 4.9757, 4.9755, 4.9756, 4.9755, 4.9752, 4.9752,\n",
      "        4.9755, 4.9754, 4.9755, 4.9752, 4.9751, 4.9755, 4.9752, 4.9752, 4.9753,\n",
      "        4.9752, 4.9752, 4.9753, 4.9752, 4.9753, 4.9754, 4.9754, 4.9754, 4.9755,\n",
      "        4.9757, 4.9753, 4.9753, 4.9752, 4.9753, 4.9751, 4.9754, 4.9753, 4.9754,\n",
      "        4.9754, 4.9757, 4.9755, 4.9754, 4.9756, 4.9756, 4.9756, 4.9755, 4.9753,\n",
      "        4.9754, 4.9753, 4.9753, 4.9753, 4.9754, 4.9753, 4.9754, 4.9756, 4.9756,\n",
      "        4.9757, 4.9756, 4.9757, 4.9760, 4.9757, 4.9756, 4.9756, 4.9756, 4.9758,\n",
      "        4.9755, 4.9754, 4.9756, 4.9753, 4.9756, 4.9756, 4.9755, 4.9754, 4.9753,\n",
      "        4.9757, 4.9755, 4.9754, 4.9754, 4.9754, 4.9752, 4.9755, 4.9752, 4.9751,\n",
      "        4.9754, 4.9752, 4.9753, 4.9756, 4.9753, 4.9755, 4.9756, 4.9754, 4.9754,\n",
      "        4.9754, 4.9753, 4.9754, 4.9755, 4.9752, 4.9754, 4.9756, 4.9754, 4.9756,\n",
      "        4.9754, 4.9754, 4.9754, 4.9753, 4.9753, 4.9752, 4.9754, 4.9755, 4.9753,\n",
      "        4.9754, 4.9755, 4.9755, 4.9754, 4.9755, 4.9755, 4.9755, 4.9755, 4.9756,\n",
      "        4.9756, 4.9756, 4.9756], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.932520  [3980524/5599865]\n",
      "average delta from current occupancy tensor([5.7581, 5.7581, 5.7581, 5.7581, 5.7581, 5.7582, 5.7584, 5.7586, 5.7584,\n",
      "        5.7583, 5.7582, 5.7581, 5.7583, 5.7584, 5.7582, 5.7584, 5.7583, 5.7584,\n",
      "        5.7585, 5.7585, 5.7585, 5.7584, 5.7582, 5.7583, 5.7581, 5.7581, 5.7581,\n",
      "        5.7582, 5.7582, 5.7582, 5.7583, 5.7583, 5.7585, 5.7582, 5.7584, 5.7582,\n",
      "        5.7581, 5.7581, 5.7581, 5.7582, 5.7582, 5.7582, 5.7581, 5.7581, 5.7582,\n",
      "        5.7581, 5.7581, 5.7582, 5.7582, 5.7582, 5.7581, 5.7582, 5.7582, 5.7582,\n",
      "        5.7582, 5.7583, 5.7583, 5.7583, 5.7583, 5.7583, 5.7583, 5.7583, 5.7583,\n",
      "        5.7583, 5.7583, 5.7584, 5.7583, 5.7583, 5.7583, 5.7584, 5.7584, 5.7583,\n",
      "        5.7583, 5.7584, 5.7583, 5.7583, 5.7583, 5.7583, 5.7583, 5.7583, 5.7582,\n",
      "        5.7583, 5.7582, 5.7584, 5.7583, 5.7584, 5.7583, 5.7582, 5.7584, 5.7584,\n",
      "        5.7584, 5.7583, 5.7582, 5.7582, 5.7582, 5.7582, 5.7583, 5.7582, 5.7582,\n",
      "        5.7582, 5.7582, 5.7582, 5.7582, 5.7582, 5.7581, 5.7582, 5.7582, 5.7582,\n",
      "        5.7581, 5.7581, 5.7582, 5.7581, 5.7582, 5.7582, 5.7582, 5.7582, 5.7582,\n",
      "        5.7582, 5.7582, 5.7582], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.345675  [3992924/5599865]\n",
      "average delta from current occupancy tensor([5.2339, 5.2339, 5.2339, 5.2339, 5.2339, 5.2338, 5.2340, 5.2341, 5.2342,\n",
      "        5.2338, 5.2338, 5.2338, 5.2339, 5.2339, 5.2338, 5.2339, 5.2338, 5.2338,\n",
      "        5.2338, 5.2339, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2339, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2339, 5.2339, 5.2338,\n",
      "        5.2338, 5.2339, 5.2339, 5.2339, 5.2339, 5.2339, 5.2339, 5.2339, 5.2339,\n",
      "        5.2338, 5.2338, 5.2338, 5.2339, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2339, 5.2339, 5.2338, 5.2339, 5.2339, 5.2339, 5.2339, 5.2339,\n",
      "        5.2339, 5.2338, 5.2338, 5.2338, 5.2338, 5.2339, 5.2338, 5.2338, 5.2338,\n",
      "        5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338, 5.2338,\n",
      "        5.2339, 5.2339, 5.2338, 5.2338, 5.2338, 5.2338, 5.2339, 5.2339, 5.2339,\n",
      "        5.2339, 5.2339, 5.2339, 5.2339, 5.2339, 5.2338, 5.2338, 5.2339, 5.2339,\n",
      "        5.2340, 5.2340, 5.2340], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.142254  [4005324/5599865]\n",
      "average delta from current occupancy tensor([5.1051, 5.1049, 5.1049, 5.1049, 5.1050, 5.1050, 5.1049, 5.1050, 5.1051,\n",
      "        5.1050, 5.1050, 5.1050, 5.1049, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050,\n",
      "        5.1049, 5.1049, 5.1049, 5.1051, 5.1050, 5.1049, 5.1049, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1051, 5.1049, 5.1050, 5.1050, 5.1050, 5.1050, 5.1049,\n",
      "        5.1049, 5.1050, 5.1049, 5.1052, 5.1050, 5.1049, 5.1049, 5.1050, 5.1050,\n",
      "        5.1049, 5.1050, 5.1049, 5.1049, 5.1050, 5.1049, 5.1049, 5.1048, 5.1049,\n",
      "        5.1049, 5.1050, 5.1049, 5.1050, 5.1049, 5.1049, 5.1049, 5.1048, 5.1048,\n",
      "        5.1049, 5.1050, 5.1050, 5.1049, 5.1050, 5.1049, 5.1050, 5.1050, 5.1050,\n",
      "        5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1050, 5.1049,\n",
      "        5.1049, 5.1049, 5.1051, 5.1049, 5.1049, 5.1049, 5.1050, 5.1049, 5.1049,\n",
      "        5.1050, 5.1048, 5.1048, 5.1050, 5.1050, 5.1050, 5.1049, 5.1050, 5.1049,\n",
      "        5.1049, 5.1050, 5.1050, 5.1049, 5.1050, 5.1051, 5.1050, 5.1050, 5.1050,\n",
      "        5.1049, 5.1050, 5.1050, 5.1049, 5.1049, 5.1049, 5.1050, 5.1050, 5.1049,\n",
      "        5.1050, 5.1049, 5.1049], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.689637  [4017724/5599865]\n",
      "average delta from current occupancy tensor([5.8147, 5.8144, 5.8144, 5.8145, 5.8144, 5.8144, 5.8144, 5.8142, 5.8143,\n",
      "        5.8143, 5.8147, 5.8146, 5.8152, 5.8146, 5.8150, 5.8146, 5.8149, 5.8150,\n",
      "        5.8147, 5.8146, 5.8146, 5.8150, 5.8147, 5.8148, 5.8144, 5.8144, 5.8144,\n",
      "        5.8144, 5.8145, 5.8145, 5.8148, 5.8150, 5.8147, 5.8147, 5.8147, 5.8154,\n",
      "        5.8152, 5.8148, 5.8152, 5.8149, 5.8150, 5.8153, 5.8152, 5.8154, 5.8153,\n",
      "        5.8152, 5.8152, 5.8155, 5.8158, 5.8154, 5.8158, 5.8158, 5.8160, 5.8157,\n",
      "        5.8158, 5.8157, 5.8158, 5.8157, 5.8161, 5.8160, 5.8156, 5.8158, 5.8158,\n",
      "        5.8158, 5.8153, 5.8152, 5.8157, 5.8154, 5.8155, 5.8153, 5.8151, 5.8152,\n",
      "        5.8153, 5.8148, 5.8146, 5.8147, 5.8148, 5.8146, 5.8147, 5.8149, 5.8150,\n",
      "        5.8154, 5.8156, 5.8153, 5.8152, 5.8157, 5.8154, 5.8151, 5.8155, 5.8158,\n",
      "        5.8151, 5.8158, 5.8159, 5.8157, 5.8158, 5.8157, 5.8163, 5.8157, 5.8160,\n",
      "        5.8160, 5.8155, 5.8159, 5.8159, 5.8157, 5.8159, 5.8156, 5.8157, 5.8157,\n",
      "        5.8161, 5.8158, 5.8157, 5.8162, 5.8161, 5.8160, 5.8156, 5.8158, 5.8161,\n",
      "        5.8159, 5.8161, 5.8160], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.724569  [4030124/5599865]\n",
      "average delta from current occupancy tensor([5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1452, 5.1452, 5.1452], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.825370  [4042524/5599865]\n",
      "average delta from current occupancy tensor([4.9194, 4.9195, 4.9193, 4.9193, 4.9193, 4.9193, 4.9193, 4.9197, 4.9196,\n",
      "        4.9197, 4.9197, 4.9198, 4.9194, 4.9195, 4.9197, 4.9198, 4.9197, 4.9197,\n",
      "        4.9193, 4.9197, 4.9192, 4.9198, 4.9197, 4.9196, 4.9193, 4.9193, 4.9192,\n",
      "        4.9193, 4.9193, 4.9192, 4.9192, 4.9191, 4.9191, 4.9192, 4.9192, 4.9191,\n",
      "        4.9192, 4.9192, 4.9192, 4.9192, 4.9192, 4.9193, 4.9192, 4.9191, 4.9192,\n",
      "        4.9192, 4.9193, 4.9193, 4.9193, 4.9197, 4.9192, 4.9194, 4.9193, 4.9195,\n",
      "        4.9195, 4.9192, 4.9192, 4.9193, 4.9192, 4.9192, 4.9194, 4.9196, 4.9197,\n",
      "        4.9198, 4.9194, 4.9193, 4.9195, 4.9197, 4.9195, 4.9193, 4.9194, 4.9195,\n",
      "        4.9197, 4.9197, 4.9197, 4.9196, 4.9198, 4.9198, 4.9198, 4.9194, 4.9198,\n",
      "        4.9198, 4.9197, 4.9195, 4.9195, 4.9195, 4.9195, 4.9196, 4.9197, 4.9196,\n",
      "        4.9193, 4.9194, 4.9194, 4.9194, 4.9194, 4.9193, 4.9191, 4.9192, 4.9192,\n",
      "        4.9197, 4.9196, 4.9196, 4.9196, 4.9196, 4.9195, 4.9193, 4.9192, 4.9192,\n",
      "        4.9193, 4.9193, 4.9192, 4.9192, 4.9192, 4.9192, 4.9192, 4.9192, 4.9193,\n",
      "        4.9192, 4.9193, 4.9193], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.744240  [4054924/5599865]\n",
      "average delta from current occupancy tensor([5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6210,\n",
      "        5.6209, 5.6210, 5.6210, 5.6209, 5.6209, 5.6210, 5.6213, 5.6212, 5.6210,\n",
      "        5.6210, 5.6212, 5.6209, 5.6214, 5.6216, 5.6214, 5.6210, 5.6210, 5.6209,\n",
      "        5.6210, 5.6211, 5.6209, 5.6209, 5.6210, 5.6209, 5.6209, 5.6210, 5.6210,\n",
      "        5.6209, 5.6209, 5.6209, 5.6211, 5.6210, 5.6210, 5.6209, 5.6210, 5.6211,\n",
      "        5.6210, 5.6216, 5.6210, 5.6213, 5.6216, 5.6210, 5.6213, 5.6210, 5.6212,\n",
      "        5.6210, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6213, 5.6211, 5.6211,\n",
      "        5.6214, 5.6209, 5.6209, 5.6211, 5.6214, 5.6214, 5.6212, 5.6216, 5.6215,\n",
      "        5.6215, 5.6215, 5.6213, 5.6218, 5.6214, 5.6215, 5.6217, 5.6215, 5.6213,\n",
      "        5.6212, 5.6212, 5.6209, 5.6209, 5.6210, 5.6210, 5.6210, 5.6211, 5.6210,\n",
      "        5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209,\n",
      "        5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6209,\n",
      "        5.6209, 5.6209, 5.6209, 5.6209, 5.6209, 5.6208, 5.6209, 5.6209, 5.6209,\n",
      "        5.6209, 5.6209, 5.6209], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.128422  [4067324/5599865]\n",
      "average delta from current occupancy tensor([5.2577, 5.2578, 5.2577, 5.2578, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577,\n",
      "        5.2578, 5.2578, 5.2577, 5.2578, 5.2577, 5.2578, 5.2577, 5.2577, 5.2577,\n",
      "        5.2577, 5.2577, 5.2577, 5.2576, 5.2576, 5.2576, 5.2577, 5.2577, 5.2577,\n",
      "        5.2577, 5.2577, 5.2577, 5.2578, 5.2578, 5.2577, 5.2578, 5.2578, 5.2578,\n",
      "        5.2578, 5.2578, 5.2578, 5.2578, 5.2578, 5.2578, 5.2577, 5.2577, 5.2577,\n",
      "        5.2578, 5.2578, 5.2577, 5.2577, 5.2577, 5.2577, 5.2578, 5.2577, 5.2577,\n",
      "        5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2576, 5.2577,\n",
      "        5.2577, 5.2576, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577,\n",
      "        5.2578, 5.2578, 5.2577, 5.2578, 5.2578, 5.2578, 5.2578, 5.2577, 5.2577,\n",
      "        5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577, 5.2578, 5.2578,\n",
      "        5.2577, 5.2578, 5.2577, 5.2577, 5.2577, 5.2578, 5.2578, 5.2578, 5.2578,\n",
      "        5.2578, 5.2578, 5.2578, 5.2578, 5.2577, 5.2578, 5.2578, 5.2577, 5.2577,\n",
      "        5.2577, 5.2577, 5.2577, 5.2576, 5.2577, 5.2577, 5.2577, 5.2577, 5.2577,\n",
      "        5.2577, 5.2577, 5.2577], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.251736  [4079724/5599865]\n",
      "average delta from current occupancy tensor([5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3308, 5.3308, 5.3308, 5.3309, 5.3308, 5.3308, 5.3307, 5.3306,\n",
      "        5.3307, 5.3307, 5.3309, 5.3307, 5.3308, 5.3308, 5.3308, 5.3308, 5.3308,\n",
      "        5.3308, 5.3308, 5.3307, 5.3309, 5.3307, 5.3309, 5.3306, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3309, 5.3309,\n",
      "        5.3306, 5.3306, 5.3309, 5.3307, 5.3307, 5.3307, 5.3307, 5.3309, 5.3309,\n",
      "        5.3307, 5.3307, 5.3309, 5.3308, 5.3310, 5.3309, 5.3309, 5.3309, 5.3307,\n",
      "        5.3307, 5.3310, 5.3308, 5.3309, 5.3309, 5.3307, 5.3307, 5.3307, 5.3309,\n",
      "        5.3307, 5.3308, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3306, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3309, 5.3307, 5.3306, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3308, 5.3306, 5.3307], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.928107  [4092124/5599865]\n",
      "average delta from current occupancy tensor([4.8860, 4.8864, 4.8861, 4.8863, 4.8863, 4.8858, 4.8857, 4.8859, 4.8858,\n",
      "        4.8863, 4.8858, 4.8860, 4.8861, 4.8861, 4.8862, 4.8863, 4.8859, 4.8862,\n",
      "        4.8864, 4.8865, 4.8859, 4.8860, 4.8861, 4.8864, 4.8859, 4.8856, 4.8854,\n",
      "        4.8850, 4.8854, 4.8853, 4.8849, 4.8848, 4.8847, 4.8846, 4.8851, 4.8848,\n",
      "        4.8852, 4.8847, 4.8848, 4.8846, 4.8848, 4.8845, 4.8847, 4.8848, 4.8845,\n",
      "        4.8846, 4.8846, 4.8844, 4.8846, 4.8846, 4.8848, 4.8848, 4.8850, 4.8851,\n",
      "        4.8851, 4.8852, 4.8851, 4.8852, 4.8853, 4.8854, 4.8857, 4.8858, 4.8856,\n",
      "        4.8856, 4.8855, 4.8855, 4.8855, 4.8856, 4.8854, 4.8854, 4.8853, 4.8854,\n",
      "        4.8850, 4.8852, 4.8851, 4.8852, 4.8852, 4.8852, 4.8851, 4.8849, 4.8850,\n",
      "        4.8851, 4.8850, 4.8853, 4.8852, 4.8852, 4.8849, 4.8849, 4.8852, 4.8851,\n",
      "        4.8852, 4.8852, 4.8852, 4.8850, 4.8850, 4.8852, 4.8852, 4.8851, 4.8852,\n",
      "        4.8853, 4.8855, 4.8853, 4.8853, 4.8856, 4.8855, 4.8852, 4.8851, 4.8848,\n",
      "        4.8848, 4.8848, 4.8852, 4.8852, 4.8850, 4.8850, 4.8848, 4.8848, 4.8849,\n",
      "        4.8849, 4.8849, 4.8847], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.538589  [4104524/5599865]\n",
      "average delta from current occupancy tensor([4.5806, 4.5806, 4.5806, 4.5805, 4.5806, 4.5806, 4.5805, 4.5805, 4.5806,\n",
      "        4.5806, 4.5806, 4.5805, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5805, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5805, 4.5805, 4.5806, 4.5806, 4.5805, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5805, 4.5805, 4.5806, 4.5806, 4.5806, 4.5806, 4.5805, 4.5806, 4.5805,\n",
      "        4.5805, 4.5805, 4.5805, 4.5805, 4.5806, 4.5805, 4.5805, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5805, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806,\n",
      "        4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5806, 4.5805,\n",
      "        4.5806, 4.5806, 4.5805], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.869164  [4116924/5599865]\n",
      "average delta from current occupancy tensor([4.8624, 4.8624, 4.8624, 4.8624, 4.8623, 4.8623, 4.8624, 4.8624, 4.8623,\n",
      "        4.8622, 4.8624, 4.8623, 4.8624, 4.8623, 4.8622, 4.8624, 4.8623, 4.8624,\n",
      "        4.8623, 4.8622, 4.8623, 4.8624, 4.8622, 4.8622, 4.8623, 4.8623, 4.8623,\n",
      "        4.8624, 4.8624, 4.8623, 4.8623, 4.8624, 4.8624, 4.8624, 4.8623, 4.8624,\n",
      "        4.8624, 4.8624, 4.8624, 4.8624, 4.8624, 4.8624, 4.8624, 4.8623, 4.8624,\n",
      "        4.8624, 4.8624, 4.8623, 4.8624, 4.8624, 4.8624, 4.8625, 4.8625, 4.8625,\n",
      "        4.8623, 4.8624, 4.8624, 4.8623, 4.8624, 4.8624, 4.8624, 4.8624, 4.8624,\n",
      "        4.8624, 4.8624, 4.8624, 4.8623, 4.8623, 4.8624, 4.8623, 4.8623, 4.8623,\n",
      "        4.8623, 4.8623, 4.8623, 4.8623, 4.8620, 4.8624, 4.8624, 4.8621, 4.8624,\n",
      "        4.8624, 4.8623, 4.8624, 4.8624, 4.8623, 4.8624, 4.8623, 4.8623, 4.8623,\n",
      "        4.8622, 4.8623, 4.8622, 4.8624, 4.8622, 4.8621, 4.8621, 4.8621, 4.8622,\n",
      "        4.8622, 4.8622, 4.8624, 4.8624, 4.8624, 4.8624, 4.8623, 4.8623, 4.8623,\n",
      "        4.8622, 4.8624, 4.8623, 4.8623, 4.8621, 4.8623, 4.8623, 4.8621, 4.8622,\n",
      "        4.8622, 4.8623, 4.8624], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.418123  [4129324/5599865]\n",
      "average delta from current occupancy tensor([5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081, 5.5081,\n",
      "        5.5081, 5.5081, 5.5081], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.351094  [4141724/5599865]\n",
      "average delta from current occupancy tensor([5.4598, 5.4598, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599,\n",
      "        5.4599, 5.4599, 5.4600, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599,\n",
      "        5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4600,\n",
      "        5.4599, 5.4599, 5.4600, 5.4600, 5.4599, 5.4599, 5.4600, 5.4600, 5.4599,\n",
      "        5.4600, 5.4599, 5.4600, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599,\n",
      "        5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599, 5.4599,\n",
      "        5.4600, 5.4599, 5.4598, 5.4598, 5.4599, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4599, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598, 5.4598,\n",
      "        5.4598, 5.4598, 5.4598], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.514637  [4154124/5599865]\n",
      "average delta from current occupancy tensor([4.6941, 4.6941, 4.6941, 4.6941, 4.6941, 4.6941, 4.6941, 4.6939, 4.6940,\n",
      "        4.6940, 4.6939, 4.6940, 4.6939, 4.6939, 4.6940, 4.6939, 4.6940, 4.6939,\n",
      "        4.6939, 4.6941, 4.6939, 4.6941, 4.6940, 4.6939, 4.6941, 4.6940, 4.6943,\n",
      "        4.6940, 4.6941, 4.6941, 4.6942, 4.6939, 4.6939, 4.6943, 4.6942, 4.6941,\n",
      "        4.6942, 4.6941, 4.6942, 4.6939, 4.6939, 4.6939, 4.6940, 4.6940, 4.6939,\n",
      "        4.6939, 4.6940, 4.6939, 4.6940, 4.6942, 4.6942, 4.6943, 4.6943, 4.6942,\n",
      "        4.6942, 4.6939, 4.6939, 4.6941, 4.6939, 4.6941, 4.6942, 4.6943, 4.6942,\n",
      "        4.6941, 4.6944, 4.6943, 4.6942, 4.6943, 4.6941, 4.6944, 4.6943, 4.6944,\n",
      "        4.6942, 4.6942, 4.6942, 4.6942, 4.6942, 4.6942, 4.6941, 4.6940, 4.6941,\n",
      "        4.6941, 4.6940, 4.6942, 4.6941, 4.6941, 4.6941, 4.6941, 4.6940, 4.6942,\n",
      "        4.6941, 4.6943, 4.6942, 4.6943, 4.6941, 4.6940, 4.6941, 4.6942, 4.6940,\n",
      "        4.6940, 4.6940, 4.6940, 4.6940, 4.6940, 4.6941, 4.6940, 4.6941, 4.6941,\n",
      "        4.6941, 4.6941, 4.6941, 4.6941, 4.6941, 4.6941, 4.6941, 4.6942, 4.6940,\n",
      "        4.6941, 4.6940, 4.6941], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.846965  [4166524/5599865]\n",
      "average delta from current occupancy tensor([4.8552, 4.8551, 4.8552, 4.8552, 4.8552, 4.8552, 4.8552, 4.8551, 4.8552,\n",
      "        4.8551, 4.8551, 4.8552, 4.8552, 4.8552, 4.8552, 4.8552, 4.8552, 4.8551,\n",
      "        4.8550, 4.8552, 4.8551, 4.8551, 4.8552, 4.8549, 4.8552, 4.8552, 4.8549,\n",
      "        4.8551, 4.8551, 4.8549, 4.8549, 4.8552, 4.8550, 4.8548, 4.8550, 4.8551,\n",
      "        4.8550, 4.8551, 4.8549, 4.8550, 4.8549, 4.8549, 4.8552, 4.8550, 4.8549,\n",
      "        4.8550, 4.8550, 4.8550, 4.8549, 4.8550, 4.8550, 4.8549, 4.8550, 4.8550,\n",
      "        4.8549, 4.8549, 4.8549, 4.8550, 4.8550, 4.8549, 4.8549, 4.8550, 4.8549,\n",
      "        4.8550, 4.8553, 4.8550, 4.8549, 4.8550, 4.8549, 4.8551, 4.8550, 4.8552,\n",
      "        4.8550, 4.8550, 4.8550, 4.8551, 4.8550, 4.8550, 4.8549, 4.8549, 4.8548,\n",
      "        4.8549, 4.8549, 4.8548, 4.8550, 4.8549, 4.8549, 4.8549, 4.8549, 4.8551,\n",
      "        4.8549, 4.8551, 4.8550, 4.8551, 4.8549, 4.8549, 4.8549, 4.8550, 4.8549,\n",
      "        4.8549, 4.8551, 4.8549, 4.8551, 4.8550, 4.8549, 4.8550, 4.8550, 4.8551,\n",
      "        4.8551, 4.8552, 4.8551, 4.8551, 4.8551, 4.8550, 4.8550, 4.8549, 4.8552,\n",
      "        4.8551, 4.8551, 4.8550], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.373810  [4178924/5599865]\n",
      "average delta from current occupancy tensor([5.3223, 5.3223, 5.3222, 5.3222, 5.3221, 5.3223, 5.3222, 5.3222, 5.3223,\n",
      "        5.3221, 5.3222, 5.3221, 5.3222, 5.3222, 5.3222, 5.3223, 5.3223, 5.3223,\n",
      "        5.3222, 5.3223, 5.3222, 5.3223, 5.3223, 5.3221, 5.3222, 5.3222, 5.3221,\n",
      "        5.3221, 5.3221, 5.3221, 5.3220, 5.3221, 5.3220, 5.3221, 5.3221, 5.3220,\n",
      "        5.3220, 5.3221, 5.3221, 5.3221, 5.3220, 5.3221, 5.3221, 5.3221, 5.3221,\n",
      "        5.3221, 5.3220, 5.3221, 5.3220, 5.3221, 5.3221, 5.3220, 5.3221, 5.3220,\n",
      "        5.3221, 5.3221, 5.3221, 5.3222, 5.3220, 5.3221, 5.3221, 5.3221, 5.3221,\n",
      "        5.3221, 5.3221, 5.3220, 5.3221, 5.3221, 5.3221, 5.3221, 5.3221, 5.3220,\n",
      "        5.3221, 5.3221, 5.3221, 5.3220, 5.3220, 5.3220, 5.3220, 5.3221, 5.3221,\n",
      "        5.3221, 5.3221, 5.3222, 5.3222, 5.3221, 5.3222, 5.3221, 5.3222, 5.3221,\n",
      "        5.3221, 5.3222, 5.3222, 5.3222, 5.3223, 5.3222, 5.3222, 5.3223, 5.3222,\n",
      "        5.3223, 5.3223, 5.3222, 5.3222, 5.3222, 5.3222, 5.3222, 5.3222, 5.3222,\n",
      "        5.3222, 5.3223, 5.3222, 5.3221, 5.3221, 5.3221, 5.3222, 5.3221, 5.3222,\n",
      "        5.3223, 5.3223, 5.3223], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.057661  [4191324/5599865]\n",
      "average delta from current occupancy tensor([4.9348, 4.9349, 4.9351, 4.9350, 4.9348, 4.9351, 4.9348, 4.9350, 4.9350,\n",
      "        4.9348, 4.9349, 4.9349, 4.9349, 4.9350, 4.9349, 4.9351, 4.9350, 4.9351,\n",
      "        4.9350, 4.9351, 4.9351, 4.9351, 4.9349, 4.9348, 4.9352, 4.9350, 4.9348,\n",
      "        4.9349, 4.9348, 4.9349, 4.9348, 4.9348, 4.9349, 4.9351, 4.9350, 4.9349,\n",
      "        4.9348, 4.9352, 4.9350, 4.9351, 4.9349, 4.9349, 4.9350, 4.9351, 4.9351,\n",
      "        4.9350, 4.9350, 4.9349, 4.9349, 4.9350, 4.9348, 4.9349, 4.9349, 4.9350,\n",
      "        4.9350, 4.9350, 4.9350, 4.9353, 4.9350, 4.9351, 4.9350, 4.9351, 4.9350,\n",
      "        4.9349, 4.9351, 4.9348, 4.9351, 4.9351, 4.9349, 4.9348, 4.9349, 4.9348,\n",
      "        4.9352, 4.9351, 4.9352, 4.9349, 4.9349, 4.9348, 4.9349, 4.9350, 4.9350,\n",
      "        4.9350, 4.9351, 4.9350, 4.9350, 4.9350, 4.9350, 4.9350, 4.9350, 4.9349,\n",
      "        4.9349, 4.9349, 4.9350, 4.9350, 4.9350, 4.9350, 4.9350, 4.9350, 4.9351,\n",
      "        4.9350, 4.9351, 4.9349, 4.9350, 4.9349, 4.9350, 4.9350, 4.9349, 4.9350,\n",
      "        4.9350, 4.9351, 4.9351, 4.9352, 4.9352, 4.9351, 4.9353, 4.9351, 4.9353,\n",
      "        4.9352, 4.9352, 4.9352], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.379965  [4203724/5599865]\n",
      "average delta from current occupancy tensor([5.4440, 5.4439, 5.4437, 5.4438, 5.4440, 5.4439, 5.4441, 5.4437, 5.4439,\n",
      "        5.4441, 5.4439, 5.4440, 5.4440, 5.4437, 5.4440, 5.4438, 5.4438, 5.4439,\n",
      "        5.4439, 5.4439, 5.4439, 5.4439, 5.4439, 5.4439, 5.4442, 5.4442, 5.4441,\n",
      "        5.4438, 5.4440, 5.4441, 5.4439, 5.4441, 5.4439, 5.4444, 5.4443, 5.4441,\n",
      "        5.4442, 5.4441, 5.4440, 5.4439, 5.4442, 5.4440, 5.4442, 5.4442, 5.4441,\n",
      "        5.4442, 5.4440, 5.4441, 5.4440, 5.4442, 5.4439, 5.4440, 5.4442, 5.4440,\n",
      "        5.4442, 5.4440, 5.4441, 5.4443, 5.4441, 5.4441, 5.4441, 5.4439, 5.4440,\n",
      "        5.4439, 5.4440, 5.4442, 5.4440, 5.4441, 5.4440, 5.4443, 5.4441, 5.4441,\n",
      "        5.4442, 5.4440, 5.4440, 5.4442, 5.4442, 5.4443, 5.4442, 5.4443, 5.4441,\n",
      "        5.4441, 5.4441, 5.4441, 5.4441, 5.4442, 5.4440, 5.4442, 5.4442, 5.4442,\n",
      "        5.4443, 5.4443, 5.4443, 5.4444, 5.4442, 5.4443, 5.4440, 5.4441, 5.4442,\n",
      "        5.4441, 5.4441, 5.4442, 5.4441, 5.4441, 5.4441, 5.4440, 5.4442, 5.4440,\n",
      "        5.4440, 5.4442, 5.4441, 5.4442, 5.4440, 5.4440, 5.4442, 5.4441, 5.4442,\n",
      "        5.4441, 5.4440, 5.4440], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.216187  [4216124/5599865]\n",
      "average delta from current occupancy tensor([5.2025, 5.2024, 5.2023, 5.2024, 5.2026, 5.2024, 5.2023, 5.2022, 5.2024,\n",
      "        5.2025, 5.2023, 5.2024, 5.2024, 5.2023, 5.2024, 5.2024, 5.2024, 5.2025,\n",
      "        5.2024, 5.2024, 5.2024, 5.2023, 5.2024, 5.2024, 5.2024, 5.2024, 5.2024,\n",
      "        5.2022, 5.2023, 5.2024, 5.2023, 5.2023, 5.2021, 5.2022, 5.2022, 5.2022,\n",
      "        5.2022, 5.2022, 5.2021, 5.2022, 5.2022, 5.2022, 5.2023, 5.2024, 5.2024,\n",
      "        5.2024, 5.2023, 5.2024, 5.2023, 5.2024, 5.2023, 5.2023, 5.2025, 5.2024,\n",
      "        5.2026, 5.2025, 5.2024, 5.2024, 5.2024, 5.2024, 5.2023, 5.2025, 5.2025,\n",
      "        5.2024, 5.2024, 5.2025, 5.2024, 5.2025, 5.2025, 5.2023, 5.2024, 5.2025,\n",
      "        5.2024, 5.2024, 5.2022, 5.2023, 5.2024, 5.2023, 5.2023, 5.2022, 5.2024,\n",
      "        5.2023, 5.2024, 5.2024, 5.2024, 5.2024, 5.2023, 5.2024, 5.2023, 5.2024,\n",
      "        5.2024, 5.2024, 5.2024, 5.2022, 5.2024, 5.2023, 5.2023, 5.2023, 5.2023,\n",
      "        5.2021, 5.2022, 5.2021, 5.2021, 5.2022, 5.2021, 5.2021, 5.2022, 5.2022,\n",
      "        5.2021, 5.2022, 5.2021, 5.2023, 5.2022, 5.2021, 5.2023, 5.2022, 5.2022,\n",
      "        5.2022, 5.2022, 5.2022], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.279420  [4228524/5599865]\n",
      "average delta from current occupancy tensor([5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1695, 5.1695, 5.1694, 5.1694, 5.1695, 5.1695,\n",
      "        5.1695, 5.1695, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1695,\n",
      "        5.1694, 5.1694, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695,\n",
      "        5.1695, 5.1695, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695,\n",
      "        5.1695, 5.1695, 5.1694, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695, 5.1695,\n",
      "        5.1695, 5.1695, 5.1695, 5.1695, 5.1694, 5.1695, 5.1695, 5.1695, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1695, 5.1695, 5.1695,\n",
      "        5.1695, 5.1695, 5.1695, 5.1694, 5.1694, 5.1695, 5.1695, 5.1694, 5.1695,\n",
      "        5.1695, 5.1695, 5.1695, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.936206  [4240924/5599865]\n",
      "average delta from current occupancy tensor([4.8388, 4.8388, 4.8389, 4.8389, 4.8388, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8389, 4.8390, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8389, 4.8389, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8389, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8389, 4.8388, 4.8388, 4.8389,\n",
      "        4.8389, 4.8388, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8388, 4.8389,\n",
      "        4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8389, 4.8388, 4.8388, 4.8389, 4.8389, 4.8388, 4.8389, 4.8389,\n",
      "        4.8389, 4.8390, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8390, 4.8390,\n",
      "        4.8390, 4.8390, 4.8390, 4.8390, 4.8390, 4.8391, 4.8390, 4.8391, 4.8390,\n",
      "        4.8391, 4.8390, 4.8390, 4.8390, 4.8390, 4.8390, 4.8390, 4.8390, 4.8390,\n",
      "        4.8390, 4.8390, 4.8390], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.525246  [4253324/5599865]\n",
      "average delta from current occupancy tensor([5.5271, 5.5278, 5.5284, 5.5285, 5.5285, 5.5286, 5.5288, 5.5285, 5.5283,\n",
      "        5.5284, 5.5287, 5.5284, 5.5285, 5.5286, 5.5286, 5.5288, 5.5288, 5.5286,\n",
      "        5.5288, 5.5287, 5.5286, 5.5288, 5.5289, 5.5288, 5.5288, 5.5287, 5.5285,\n",
      "        5.5288, 5.5287, 5.5286, 5.5286, 5.5283, 5.5284, 5.5284, 5.5285, 5.5281,\n",
      "        5.5284, 5.5282, 5.5284, 5.5283, 5.5288, 5.5285, 5.5286, 5.5287, 5.5287,\n",
      "        5.5285, 5.5285, 5.5280, 5.5281, 5.5284, 5.5283, 5.5282, 5.5281, 5.5282,\n",
      "        5.5283, 5.5284, 5.5286, 5.5286, 5.5286, 5.5283, 5.5281, 5.5285, 5.5282,\n",
      "        5.5283, 5.5279, 5.5279, 5.5280, 5.5280, 5.5284, 5.5285, 5.5284, 5.5286,\n",
      "        5.5283, 5.5279, 5.5286, 5.5282, 5.5285, 5.5285, 5.5284, 5.5281, 5.5281,\n",
      "        5.5283, 5.5282, 5.5286, 5.5284, 5.5285, 5.5282, 5.5283, 5.5282, 5.5281,\n",
      "        5.5280, 5.5275, 5.5278, 5.5279, 5.5278, 5.5278, 5.5280, 5.5277, 5.5276,\n",
      "        5.5280, 5.5279, 5.5278, 5.5278, 5.5278, 5.5281, 5.5281, 5.5278, 5.5276,\n",
      "        5.5276, 5.5272, 5.5272, 5.5275, 5.5273, 5.5270, 5.5271, 5.5270, 5.5273,\n",
      "        5.5272, 5.5273, 5.5274], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.238600  [4265724/5599865]\n",
      "average delta from current occupancy tensor([5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3469, 5.3468, 5.3468, 5.3469, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3469, 5.3468, 5.3468, 5.3469,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3469, 5.3469,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3469, 5.3468, 5.3468, 5.3468,\n",
      "        5.3469, 5.3469, 5.3469], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.511811  [4278124/5599865]\n",
      "average delta from current occupancy tensor([5.6694, 5.6693, 5.6694, 5.6695, 5.6694, 5.6695, 5.6693, 5.6694, 5.6693,\n",
      "        5.6693, 5.6693, 5.6694, 5.6694, 5.6693, 5.6694, 5.6693, 5.6693, 5.6693,\n",
      "        5.6693, 5.6692, 5.6692, 5.6693, 5.6692, 5.6692, 5.6693, 5.6694, 5.6692,\n",
      "        5.6692, 5.6692, 5.6693, 5.6693, 5.6692, 5.6692, 5.6692, 5.6692, 5.6692,\n",
      "        5.6692, 5.6692, 5.6692, 5.6692, 5.6692, 5.6692, 5.6692, 5.6693, 5.6693,\n",
      "        5.6693, 5.6693, 5.6694, 5.6692, 5.6692, 5.6692, 5.6693, 5.6692, 5.6693,\n",
      "        5.6693, 5.6692, 5.6693, 5.6692, 5.6692, 5.6692, 5.6692, 5.6692, 5.6692,\n",
      "        5.6692, 5.6692, 5.6693, 5.6693, 5.6692, 5.6693, 5.6693, 5.6693, 5.6693,\n",
      "        5.6693, 5.6693, 5.6693, 5.6692, 5.6693, 5.6693, 5.6693, 5.6693, 5.6692,\n",
      "        5.6693, 5.6693, 5.6693, 5.6693, 5.6693, 5.6694, 5.6694, 5.6693, 5.6693,\n",
      "        5.6693, 5.6693, 5.6693, 5.6693, 5.6693, 5.6692, 5.6693, 5.6692, 5.6693,\n",
      "        5.6693, 5.6693, 5.6693, 5.6692, 5.6693, 5.6692, 5.6692, 5.6693, 5.6693,\n",
      "        5.6692, 5.6693, 5.6692, 5.6693, 5.6691, 5.6693, 5.6692, 5.6692, 5.6692,\n",
      "        5.6691, 5.6690, 5.6691], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.444817  [4290524/5599865]\n",
      "average delta from current occupancy tensor([4.4356, 4.4358, 4.4357, 4.4356, 4.4356, 4.4358, 4.4360, 4.4358, 4.4357,\n",
      "        4.4358, 4.4359, 4.4358, 4.4359, 4.4360, 4.4360, 4.4363, 4.4365, 4.4363,\n",
      "        4.4365, 4.4366, 4.4366, 4.4367, 4.4367, 4.4367, 4.4367, 4.4367, 4.4369,\n",
      "        4.4370, 4.4368, 4.4369, 4.4369, 4.4368, 4.4367, 4.4369, 4.4368, 4.4365,\n",
      "        4.4367, 4.4367, 4.4365, 4.4364, 4.4365, 4.4365, 4.4362, 4.4364, 4.4362,\n",
      "        4.4363, 4.4360, 4.4363, 4.4363, 4.4364, 4.4363, 4.4365, 4.4364, 4.4362,\n",
      "        4.4364, 4.4364, 4.4364, 4.4365, 4.4365, 4.4367, 4.4366, 4.4368, 4.4368,\n",
      "        4.4368, 4.4369, 4.4368, 4.4368, 4.4371, 4.4369, 4.4370, 4.4373, 4.4373,\n",
      "        4.4372, 4.4370, 4.4372, 4.4370, 4.4369, 4.4369, 4.4366, 4.4370, 4.4369,\n",
      "        4.4366, 4.4367, 4.4367, 4.4363, 4.4361, 4.4361, 4.4363, 4.4365, 4.4361,\n",
      "        4.4363, 4.4363, 4.4360, 4.4359, 4.4357, 4.4359, 4.4357, 4.4361, 4.4362,\n",
      "        4.4363, 4.4363, 4.4363, 4.4365, 4.4367, 4.4365, 4.4364, 4.4366, 4.4364,\n",
      "        4.4366, 4.4364, 4.4364, 4.4363, 4.4363, 4.4364, 4.4363, 4.4362, 4.4360,\n",
      "        4.4360, 4.4363, 4.4363], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.395245  [4302924/5599865]\n",
      "average delta from current occupancy tensor([5.3951, 5.3951, 5.3951, 5.3951, 5.3950, 5.3951, 5.3951, 5.3951, 5.3951,\n",
      "        5.3951, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950,\n",
      "        5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950,\n",
      "        5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950,\n",
      "        5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950,\n",
      "        5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3951, 5.3951, 5.3951, 5.3951,\n",
      "        5.3951, 5.3951, 5.3950, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951,\n",
      "        5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3950, 5.3950, 5.3950, 5.3950,\n",
      "        5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950, 5.3950,\n",
      "        5.3950, 5.3950, 5.3950, 5.3951, 5.3951, 5.3950, 5.3951, 5.3951, 5.3951,\n",
      "        5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951,\n",
      "        5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3950, 5.3951, 5.3950, 5.3950,\n",
      "        5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3951, 5.3950, 5.3951,\n",
      "        5.3950, 5.3951, 5.3951], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.152880  [4315324/5599865]\n",
      "average delta from current occupancy tensor([5.2333, 5.2333, 5.2333, 5.2334, 5.2334, 5.2334, 5.2333, 5.2334, 5.2333,\n",
      "        5.2334, 5.2334, 5.2335, 5.2334, 5.2335, 5.2334, 5.2335, 5.2335, 5.2335,\n",
      "        5.2335, 5.2335, 5.2335, 5.2335, 5.2335, 5.2335, 5.2335, 5.2335, 5.2334,\n",
      "        5.2336, 5.2335, 5.2335, 5.2335, 5.2336, 5.2335, 5.2335, 5.2335, 5.2335,\n",
      "        5.2335, 5.2335, 5.2335, 5.2334, 5.2334, 5.2335, 5.2335, 5.2334, 5.2334,\n",
      "        5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334,\n",
      "        5.2333, 5.2333, 5.2333, 5.2333, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334,\n",
      "        5.2333, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2335, 5.2335, 5.2335,\n",
      "        5.2334, 5.2334, 5.2333, 5.2333, 5.2334, 5.2333, 5.2334, 5.2334, 5.2334,\n",
      "        5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2333, 5.2334, 5.2335,\n",
      "        5.2334, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333,\n",
      "        5.2332, 5.2333, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2333, 5.2332,\n",
      "        5.2333, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332,\n",
      "        5.2331, 5.2332, 5.2332], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.355160  [4327724/5599865]\n",
      "average delta from current occupancy tensor([5.0908, 5.0908, 5.0906, 5.0907, 5.0904, 5.0907, 5.0906, 5.0903, 5.0905,\n",
      "        5.0905, 5.0901, 5.0903, 5.0903, 5.0902, 5.0902, 5.0903, 5.0901, 5.0898,\n",
      "        5.0899, 5.0899, 5.0900, 5.0900, 5.0894, 5.0896, 5.0895, 5.0894, 5.0894,\n",
      "        5.0894, 5.0896, 5.0895, 5.0895, 5.0896, 5.0895, 5.0902, 5.0900, 5.0901,\n",
      "        5.0903, 5.0904, 5.0905, 5.0906, 5.0906, 5.0907, 5.0905, 5.0906, 5.0906,\n",
      "        5.0903, 5.0902, 5.0903, 5.0902, 5.0900, 5.0901, 5.0903, 5.0901, 5.0900,\n",
      "        5.0903, 5.0903, 5.0903, 5.0901, 5.0902, 5.0903, 5.0902, 5.0903, 5.0902,\n",
      "        5.0907, 5.0902, 5.0903, 5.0900, 5.0903, 5.0901, 5.0903, 5.0900, 5.0901,\n",
      "        5.0902, 5.0902, 5.0903, 5.0901, 5.0901, 5.0901, 5.0899, 5.0902, 5.0898,\n",
      "        5.0903, 5.0900, 5.0899, 5.0898, 5.0898, 5.0897, 5.0897, 5.0895, 5.0898,\n",
      "        5.0898, 5.0895, 5.0896, 5.0896, 5.0897, 5.0897, 5.0894, 5.0893, 5.0896,\n",
      "        5.0894, 5.0893, 5.0894, 5.0895, 5.0896, 5.0893, 5.0896, 5.0898, 5.0895,\n",
      "        5.0895, 5.0896, 5.0896, 5.0896, 5.0896, 5.0895, 5.0894, 5.0896, 5.0896,\n",
      "        5.0896, 5.0896, 5.0897], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.736640  [4340124/5599865]\n",
      "average delta from current occupancy tensor([4.7975, 4.7976, 4.7976, 4.7976, 4.7977, 4.7975, 4.7975, 4.7977, 4.7977,\n",
      "        4.7976, 4.7978, 4.7977, 4.7977, 4.7977, 4.7978, 4.7977, 4.7978, 4.7979,\n",
      "        4.7979, 4.7979, 4.7980, 4.7979, 4.7979, 4.7979, 4.7979, 4.7978, 4.7978,\n",
      "        4.7978, 4.7977, 4.7977, 4.7977, 4.7976, 4.7976, 4.7977, 4.7977, 4.7976,\n",
      "        4.7977, 4.7979, 4.7979, 4.7977, 4.7977, 4.7979, 4.7979, 4.7977, 4.7977,\n",
      "        4.7977, 4.7977, 4.7978, 4.7978, 4.7979, 4.7977, 4.7977, 4.7977, 4.7977,\n",
      "        4.7976, 4.7976, 4.7977, 4.7977, 4.7977, 4.7976, 4.7977, 4.7976, 4.7976,\n",
      "        4.7975, 4.7976, 4.7977, 4.7977, 4.7975, 4.7975, 4.7978, 4.7978, 4.7976,\n",
      "        4.7977, 4.7978, 4.7978, 4.7979, 4.7978, 4.7978, 4.7979, 4.7977, 4.7978,\n",
      "        4.7978, 4.7978, 4.7978, 4.7976, 4.7977, 4.7976, 4.7977, 4.7978, 4.7978,\n",
      "        4.7977, 4.7977, 4.7978, 4.7978, 4.7978, 4.7978, 4.7978, 4.7978, 4.7979,\n",
      "        4.7979, 4.7979, 4.7978, 4.7978, 4.7978, 4.7977, 4.7978, 4.7978, 4.7977,\n",
      "        4.7976, 4.7975, 4.7975, 4.7975, 4.7974, 4.7976, 4.7976, 4.7977, 4.7978,\n",
      "        4.7977, 4.7977, 4.7977], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.234875  [4352524/5599865]\n",
      "average delta from current occupancy tensor([4.9839, 4.9838, 4.9839, 4.9838, 4.9839, 4.9839, 4.9838, 4.9839, 4.9838,\n",
      "        4.9838, 4.9839, 4.9839, 4.9839, 4.9838, 4.9839, 4.9838, 4.9839, 4.9839,\n",
      "        4.9839, 4.9839, 4.9840, 4.9839, 4.9838, 4.9838, 4.9839, 4.9839, 4.9839,\n",
      "        4.9838, 4.9839, 4.9838, 4.9837, 4.9838, 4.9839, 4.9838, 4.9838, 4.9839,\n",
      "        4.9838, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9840, 4.9839, 4.9839,\n",
      "        4.9839, 4.9839, 4.9838, 4.9838, 4.9839, 4.9838, 4.9839, 4.9838, 4.9840,\n",
      "        4.9839, 4.9839, 4.9838, 4.9838, 4.9838, 4.9838, 4.9838, 4.9839, 4.9839,\n",
      "        4.9838, 4.9840, 4.9839, 4.9840, 4.9838, 4.9837, 4.9838, 4.9840, 4.9837,\n",
      "        4.9837, 4.9840, 4.9838, 4.9838, 4.9839, 4.9839, 4.9838, 4.9838, 4.9838,\n",
      "        4.9838, 4.9838, 4.9839, 4.9838, 4.9838, 4.9838, 4.9839, 4.9839, 4.9839,\n",
      "        4.9838, 4.9839, 4.9839, 4.9838, 4.9839, 4.9839, 4.9838, 4.9838, 4.9838,\n",
      "        4.9839, 4.9838, 4.9840, 4.9839, 4.9839, 4.9837, 4.9837, 4.9836, 4.9839,\n",
      "        4.9840, 4.9838, 4.9838, 4.9838, 4.9837, 4.9839, 4.9838, 4.9837, 4.9836,\n",
      "        4.9836, 4.9836, 4.9836], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.261473  [4364924/5599865]\n",
      "average delta from current occupancy tensor([5.3145, 5.3145, 5.3145, 5.3146, 5.3146, 5.3146, 5.3146, 5.3145, 5.3146,\n",
      "        5.3146, 5.3146, 5.3145, 5.3146, 5.3146, 5.3145, 5.3145, 5.3146, 5.3145,\n",
      "        5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3147,\n",
      "        5.3145, 5.3145, 5.3147, 5.3148, 5.3145, 5.3147, 5.3146, 5.3146, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3146, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3146,\n",
      "        5.3145, 5.3145, 5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3146, 5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3146, 5.3146, 5.3145, 5.3146, 5.3146, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3145, 5.3147, 5.3147, 5.3145, 5.3145,\n",
      "        5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3146, 5.3145,\n",
      "        5.3145, 5.3146, 5.3145, 5.3145, 5.3146, 5.3145, 5.3146, 5.3145, 5.3147,\n",
      "        5.3147, 5.3146, 5.3146], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.040358  [4377324/5599865]\n",
      "average delta from current occupancy tensor([5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2500,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2500,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502,\n",
      "        5.2502, 5.2502, 5.2502, 5.2502, 5.2501, 5.2502, 5.2502, 5.2502, 5.2502,\n",
      "        5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2502,\n",
      "        5.2502, 5.2502, 5.2502, 5.2502, 5.2502, 5.2501, 5.2501, 5.2502, 5.2502,\n",
      "        5.2502, 5.2501, 5.2502, 5.2502, 5.2502, 5.2501, 5.2501, 5.2502, 5.2501,\n",
      "        5.2502, 5.2502, 5.2501], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.895763  [4389724/5599865]\n",
      "average delta from current occupancy tensor([5.0081, 5.0080, 5.0081, 5.0081, 5.0080, 5.0081, 5.0082, 5.0081, 5.0081,\n",
      "        5.0081, 5.0080, 5.0080, 5.0080, 5.0080, 5.0081, 5.0080, 5.0081, 5.0081,\n",
      "        5.0081, 5.0080, 5.0081, 5.0081, 5.0080, 5.0081, 5.0081, 5.0081, 5.0082,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0080, 5.0081, 5.0081, 5.0081,\n",
      "        5.0080, 5.0080, 5.0080, 5.0081, 5.0080, 5.0080, 5.0080, 5.0081, 5.0081,\n",
      "        5.0081, 5.0081, 5.0081, 5.0080, 5.0081, 5.0080, 5.0082, 5.0081, 5.0082,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0080, 5.0080, 5.0081, 5.0080, 5.0081,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0080, 5.0082, 5.0081, 5.0081, 5.0081,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0080,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0081, 5.0080, 5.0080, 5.0081,\n",
      "        5.0081, 5.0081, 5.0081, 5.0082, 5.0081, 5.0081, 5.0081, 5.0081, 5.0080,\n",
      "        5.0080, 5.0080, 5.0081, 5.0081, 5.0080, 5.0081, 5.0081, 5.0080, 5.0081,\n",
      "        5.0081, 5.0080, 5.0081, 5.0080, 5.0080, 5.0080, 5.0081, 5.0080, 5.0081,\n",
      "        5.0081, 5.0080, 5.0080], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.818036  [4402124/5599865]\n",
      "average delta from current occupancy tensor([4.6520, 4.6521, 4.6521, 4.6522, 4.6520, 4.6522, 4.6525, 4.6522, 4.6521,\n",
      "        4.6521, 4.6521, 4.6522, 4.6523, 4.6522, 4.6525, 4.6523, 4.6523, 4.6525,\n",
      "        4.6525, 4.6524, 4.6527, 4.6526, 4.6524, 4.6529, 4.6528, 4.6524, 4.6525,\n",
      "        4.6525, 4.6528, 4.6529, 4.6526, 4.6525, 4.6525, 4.6526, 4.6526, 4.6527,\n",
      "        4.6526, 4.6527, 4.6527, 4.6528, 4.6528, 4.6527, 4.6530, 4.6528, 4.6528,\n",
      "        4.6529, 4.6524, 4.6525, 4.6525, 4.6524, 4.6525, 4.6525, 4.6526, 4.6525,\n",
      "        4.6523, 4.6523, 4.6523, 4.6524, 4.6524, 4.6523, 4.6524, 4.6522, 4.6525,\n",
      "        4.6522, 4.6524, 4.6526, 4.6524, 4.6523, 4.6522, 4.6521, 4.6523, 4.6523,\n",
      "        4.6524, 4.6524, 4.6523, 4.6524, 4.6523, 4.6524, 4.6522, 4.6524, 4.6524,\n",
      "        4.6523, 4.6523, 4.6525, 4.6525, 4.6527, 4.6526, 4.6527, 4.6527, 4.6525,\n",
      "        4.6528, 4.6526, 4.6527, 4.6529, 4.6529, 4.6529, 4.6530, 4.6530, 4.6529,\n",
      "        4.6530, 4.6528, 4.6528, 4.6529, 4.6530, 4.6529, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6531, 4.6530, 4.6532, 4.6531, 4.6529, 4.6529, 4.6529, 4.6528,\n",
      "        4.6528, 4.6525, 4.6527], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.675795  [4414524/5599865]\n",
      "average delta from current occupancy tensor([4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5885, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5885, 4.5885, 4.5885, 4.5886, 4.5886, 4.5885, 4.5886, 4.5886,\n",
      "        4.5885, 4.5885, 4.5884, 4.5885, 4.5885, 4.5886, 4.5885, 4.5885, 4.5885,\n",
      "        4.5885, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5885, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5885,\n",
      "        4.5885, 4.5886, 4.5885, 4.5886, 4.5885, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5887, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5887, 4.5886, 4.5886, 4.5887, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886, 4.5886,\n",
      "        4.5885, 4.5886, 4.5886], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.761568  [4426924/5599865]\n",
      "average delta from current occupancy tensor([4.8455, 4.8453, 4.8457, 4.8452, 4.8457, 4.8452, 4.8452, 4.8452, 4.8453,\n",
      "        4.8452, 4.8455, 4.8454, 4.8457, 4.8455, 4.8455, 4.8455, 4.8455, 4.8454,\n",
      "        4.8456, 4.8455, 4.8454, 4.8453, 4.8452, 4.8451, 4.8451, 4.8454, 4.8454,\n",
      "        4.8453, 4.8451, 4.8453, 4.8454, 4.8454, 4.8457, 4.8459, 4.8462, 4.8461,\n",
      "        4.8461, 4.8462, 4.8461, 4.8463, 4.8461, 4.8461, 4.8461, 4.8459, 4.8458,\n",
      "        4.8458, 4.8459, 4.8460, 4.8459, 4.8459, 4.8458, 4.8458, 4.8460, 4.8458,\n",
      "        4.8457, 4.8458, 4.8459, 4.8456, 4.8457, 4.8455, 4.8455, 4.8454, 4.8453,\n",
      "        4.8454, 4.8461, 4.8457, 4.8459, 4.8457, 4.8457, 4.8456, 4.8455, 4.8457,\n",
      "        4.8454, 4.8453, 4.8453, 4.8455, 4.8454, 4.8455, 4.8453, 4.8454, 4.8454,\n",
      "        4.8453, 4.8457, 4.8456, 4.8456, 4.8456, 4.8454, 4.8453, 4.8457, 4.8457,\n",
      "        4.8457, 4.8457, 4.8456, 4.8459, 4.8457, 4.8457, 4.8457, 4.8455, 4.8455,\n",
      "        4.8455, 4.8456, 4.8457, 4.8459, 4.8458, 4.8459, 4.8457, 4.8461, 4.8459,\n",
      "        4.8461, 4.8458, 4.8460, 4.8460, 4.8457, 4.8457, 4.8457, 4.8458, 4.8459,\n",
      "        4.8461, 4.8459, 4.8457], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.473477  [4439324/5599865]\n",
      "average delta from current occupancy tensor([5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4195, 5.4195, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4195, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4195, 5.4195, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4195, 5.4195,\n",
      "        5.4194, 5.4194, 5.4194, 5.4195, 5.4195, 5.4195, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4195, 5.4195, 5.4194, 5.4194, 5.4195, 5.4195, 5.4195,\n",
      "        5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4194, 5.4195, 5.4195, 5.4195,\n",
      "        5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195,\n",
      "        5.4195, 5.4195, 5.4196, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195,\n",
      "        5.4195, 5.4195, 5.4195], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.368937  [4451724/5599865]\n",
      "average delta from current occupancy tensor([4.3551, 4.3552, 4.3553, 4.3554, 4.3554, 4.3551, 4.3548, 4.3553, 4.3548,\n",
      "        4.3551, 4.3554, 4.3553, 4.3554, 4.3554, 4.3554, 4.3551, 4.3550, 4.3551,\n",
      "        4.3551, 4.3553, 4.3554, 4.3550, 4.3549, 4.3557, 4.3556, 4.3557, 4.3551,\n",
      "        4.3547, 4.3545, 4.3546, 4.3545, 4.3543, 4.3546, 4.3544, 4.3542, 4.3541,\n",
      "        4.3536, 4.3541, 4.3539, 4.3540, 4.3541, 4.3543, 4.3542, 4.3541, 4.3538,\n",
      "        4.3538, 4.3537, 4.3536, 4.3536, 4.3533, 4.3534, 4.3538, 4.3537, 4.3539,\n",
      "        4.3539, 4.3543, 4.3539, 4.3539, 4.3540, 4.3545, 4.3539, 4.3540, 4.3540,\n",
      "        4.3544, 4.3544, 4.3547, 4.3545, 4.3543, 4.3546, 4.3543, 4.3542, 4.3544,\n",
      "        4.3542, 4.3540, 4.3538, 4.3537, 4.3538, 4.3537, 4.3539, 4.3540, 4.3543,\n",
      "        4.3543, 4.3547, 4.3551, 4.3550, 4.3546, 4.3546, 4.3551, 4.3548, 4.3546,\n",
      "        4.3543, 4.3550, 4.3550, 4.3548, 4.3553, 4.3544, 4.3545, 4.3549, 4.3551,\n",
      "        4.3551, 4.3549, 4.3549, 4.3551, 4.3550, 4.3545, 4.3548, 4.3546, 4.3548,\n",
      "        4.3545, 4.3544, 4.3543, 4.3544, 4.3546, 4.3546, 4.3548, 4.3549, 4.3548,\n",
      "        4.3552, 4.3551, 4.3551], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.146146  [4464124/5599865]\n",
      "average delta from current occupancy tensor([5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0808, 5.0807, 5.0807,\n",
      "        5.0807, 5.0808, 5.0807, 5.0808, 5.0807, 5.0807, 5.0807, 5.0807, 5.0808,\n",
      "        5.0807, 5.0807, 5.0807], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.201805  [4476524/5599865]\n",
      "average delta from current occupancy tensor([5.0811, 5.0810, 5.0810, 5.0811, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0811, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0811, 5.0810,\n",
      "        5.0810, 5.0810, 5.0811, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0811, 5.0811, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0811, 5.0811, 5.0811,\n",
      "        5.0811, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0811, 5.0811,\n",
      "        5.0811, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0809, 5.0809, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0811, 5.0810, 5.0810, 5.0811,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0811, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.000806  [4488924/5599865]\n",
      "average delta from current occupancy tensor([4.8707, 4.8706, 4.8707, 4.8707, 4.8706, 4.8707, 4.8705, 4.8705, 4.8705,\n",
      "        4.8706, 4.8706, 4.8705, 4.8707, 4.8707, 4.8706, 4.8706, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8706, 4.8705, 4.8706, 4.8707, 4.8707, 4.8706,\n",
      "        4.8707, 4.8707, 4.8706, 4.8708, 4.8707, 4.8707, 4.8707, 4.8706, 4.8706,\n",
      "        4.8706, 4.8707, 4.8707, 4.8706, 4.8707, 4.8707, 4.8707, 4.8708, 4.8707,\n",
      "        4.8709, 4.8708, 4.8708, 4.8707, 4.8708, 4.8708, 4.8708, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8706, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707,\n",
      "        4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8707, 4.8708, 4.8708, 4.8709,\n",
      "        4.8707, 4.8707, 4.8708, 4.8706, 4.8707, 4.8707, 4.8705, 4.8707, 4.8705,\n",
      "        4.8707, 4.8708, 4.8707, 4.8707, 4.8707, 4.8707, 4.8706, 4.8707, 4.8706,\n",
      "        4.8707, 4.8706, 4.8706, 4.8706, 4.8706, 4.8706, 4.8706, 4.8705, 4.8706,\n",
      "        4.8705, 4.8706, 4.8706, 4.8706, 4.8706, 4.8706, 4.8707, 4.8708, 4.8708,\n",
      "        4.8707, 4.8707, 4.8706, 4.8706, 4.8706, 4.8706, 4.8706, 4.8706, 4.8705,\n",
      "        4.8706, 4.8706, 4.8706], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.557547  [4501324/5599865]\n",
      "average delta from current occupancy tensor([4.6453, 4.6452, 4.6453, 4.6452, 4.6453, 4.6453, 4.6453, 4.6453, 4.6453,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6453, 4.6452, 4.6453, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.003859  [4513724/5599865]\n",
      "average delta from current occupancy tensor([5.0329, 5.0330, 5.0329, 5.0329, 5.0330, 5.0330, 5.0331, 5.0331, 5.0332,\n",
      "        5.0331, 5.0332, 5.0330, 5.0332, 5.0332, 5.0331, 5.0332, 5.0330, 5.0331,\n",
      "        5.0331, 5.0331, 5.0331, 5.0330, 5.0331, 5.0331, 5.0331, 5.0331, 5.0331,\n",
      "        5.0331, 5.0332, 5.0332, 5.0331, 5.0331, 5.0332, 5.0331, 5.0331, 5.0331,\n",
      "        5.0330, 5.0332, 5.0331, 5.0332, 5.0332, 5.0331, 5.0332, 5.0331, 5.0330,\n",
      "        5.0331, 5.0331, 5.0331, 5.0330, 5.0330, 5.0332, 5.0331, 5.0331, 5.0331,\n",
      "        5.0330, 5.0330, 5.0330, 5.0330, 5.0331, 5.0330, 5.0330, 5.0330, 5.0330,\n",
      "        5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330,\n",
      "        5.0330, 5.0330, 5.0330, 5.0331, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330,\n",
      "        5.0331, 5.0331, 5.0330, 5.0331, 5.0331, 5.0331, 5.0331, 5.0331, 5.0331,\n",
      "        5.0331, 5.0331, 5.0331, 5.0330, 5.0331, 5.0331, 5.0330, 5.0330, 5.0330,\n",
      "        5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0329,\n",
      "        5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330, 5.0330,\n",
      "        5.0330, 5.0330, 5.0330], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.342286  [4526124/5599865]\n",
      "average delta from current occupancy tensor([5.3145, 5.3146, 5.3146, 5.3146, 5.3146, 5.3145, 5.3144, 5.3145, 5.3144,\n",
      "        5.3145, 5.3145, 5.3149, 5.3145, 5.3145, 5.3146, 5.3146, 5.3147, 5.3147,\n",
      "        5.3147, 5.3148, 5.3148, 5.3148, 5.3147, 5.3149, 5.3149, 5.3149, 5.3149,\n",
      "        5.3148, 5.3149, 5.3145, 5.3147, 5.3149, 5.3147, 5.3147, 5.3147, 5.3148,\n",
      "        5.3151, 5.3147, 5.3149, 5.3147, 5.3148, 5.3150, 5.3147, 5.3147, 5.3148,\n",
      "        5.3146, 5.3144, 5.3145, 5.3145, 5.3144, 5.3144, 5.3144, 5.3145, 5.3144,\n",
      "        5.3145, 5.3145, 5.3145, 5.3144, 5.3144, 5.3144, 5.3144, 5.3144, 5.3144,\n",
      "        5.3144, 5.3144, 5.3144, 5.3144, 5.3144, 5.3144, 5.3145, 5.3146, 5.3145,\n",
      "        5.3145, 5.3146, 5.3146, 5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3146,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3144, 5.3146,\n",
      "        5.3148, 5.3149, 5.3150, 5.3150, 5.3147, 5.3146, 5.3148, 5.3149, 5.3149,\n",
      "        5.3149, 5.3151, 5.3149, 5.3148, 5.3146, 5.3146, 5.3146, 5.3145, 5.3146,\n",
      "        5.3145, 5.3145, 5.3146, 5.3145, 5.3145, 5.3148, 5.3150, 5.3150, 5.3151,\n",
      "        5.3150, 5.3151, 5.3150], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.730999  [4538524/5599865]\n",
      "average delta from current occupancy tensor([5.2992, 5.2994, 5.2993, 5.2991, 5.2992, 5.2992, 5.2991, 5.2992, 5.2991,\n",
      "        5.2994, 5.2993, 5.2993, 5.2992, 5.2993, 5.2992, 5.2992, 5.2992, 5.2993,\n",
      "        5.2992, 5.2992, 5.2993, 5.2992, 5.2994, 5.2992, 5.2992, 5.2992, 5.2993,\n",
      "        5.2991, 5.2991, 5.2993, 5.2992, 5.2992, 5.2992, 5.2992, 5.2992, 5.2993,\n",
      "        5.2993, 5.2993, 5.2991, 5.2991, 5.2991, 5.2991, 5.2993, 5.2991, 5.2992,\n",
      "        5.2992, 5.2992, 5.2993, 5.2991, 5.2991, 5.2991, 5.2991, 5.2993, 5.2993,\n",
      "        5.2993, 5.2994, 5.2994, 5.2993, 5.2993, 5.2993, 5.2992, 5.2993, 5.2993,\n",
      "        5.2992, 5.2992, 5.2992, 5.2992, 5.2991, 5.2992, 5.2991, 5.2992, 5.2992,\n",
      "        5.2993, 5.2994, 5.2993, 5.2994, 5.2993, 5.2994, 5.2994, 5.2994, 5.2995,\n",
      "        5.2996, 5.2996, 5.2996, 5.2996, 5.2996, 5.2996, 5.2996, 5.2996, 5.2996,\n",
      "        5.2996, 5.2995, 5.2995, 5.2994, 5.2995, 5.2994, 5.2994, 5.2995, 5.2996,\n",
      "        5.2994, 5.2994, 5.2995, 5.2996, 5.2996, 5.2995, 5.2995, 5.2994, 5.2995,\n",
      "        5.2995, 5.2995, 5.2995, 5.2995, 5.2994, 5.2994, 5.2995, 5.2995, 5.2994,\n",
      "        5.2994, 5.2993, 5.2994], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.259089  [4550924/5599865]\n",
      "average delta from current occupancy tensor([5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192,\n",
      "        5.4193, 5.4192, 5.4193, 5.4193, 5.4193, 5.4193, 5.4192, 5.4192, 5.4192,\n",
      "        5.4192, 5.4192, 5.4192, 5.4192, 5.4193, 5.4192, 5.4192, 5.4192, 5.4192,\n",
      "        5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192,\n",
      "        5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4192, 5.4193, 5.4192, 5.4193,\n",
      "        5.4193, 5.4193, 5.4193, 5.4193, 5.4192, 5.4192, 5.4192, 5.4192, 5.4193,\n",
      "        5.4193, 5.4193, 5.4193, 5.4194, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193,\n",
      "        5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193,\n",
      "        5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193,\n",
      "        5.4193, 5.4193, 5.4194, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193,\n",
      "        5.4194, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193, 5.4194,\n",
      "        5.4194, 5.4193, 5.4193, 5.4193, 5.4194, 5.4193, 5.4194, 5.4193, 5.4193,\n",
      "        5.4193, 5.4193, 5.4194, 5.4193, 5.4194, 5.4193, 5.4194, 5.4194, 5.4194,\n",
      "        5.4193, 5.4193, 5.4193], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.424557  [4563324/5599865]\n",
      "average delta from current occupancy tensor([5.4061, 5.4061, 5.4061, 5.4058, 5.4060, 5.4062, 5.4062, 5.4061, 5.4063,\n",
      "        5.4062, 5.4062, 5.4062, 5.4061, 5.4063, 5.4066, 5.4067, 5.4064, 5.4064,\n",
      "        5.4068, 5.4067, 5.4066, 5.4066, 5.4062, 5.4068, 5.4066, 5.4067, 5.4065,\n",
      "        5.4067, 5.4069, 5.4067, 5.4066, 5.4065, 5.4066, 5.4066, 5.4065, 5.4060,\n",
      "        5.4060, 5.4064, 5.4066, 5.4065, 5.4066, 5.4063, 5.4063, 5.4062, 5.4060,\n",
      "        5.4062, 5.4063, 5.4062, 5.4059, 5.4067, 5.4065, 5.4064, 5.4063, 5.4059,\n",
      "        5.4057, 5.4059, 5.4061, 5.4062, 5.4061, 5.4058, 5.4061, 5.4056, 5.4054,\n",
      "        5.4056, 5.4059, 5.4059, 5.4062, 5.4060, 5.4059, 5.4061, 5.4059, 5.4062,\n",
      "        5.4062, 5.4064, 5.4065, 5.4063, 5.4061, 5.4062, 5.4061, 5.4063, 5.4063,\n",
      "        5.4061, 5.4063, 5.4062, 5.4062, 5.4061, 5.4060, 5.4058, 5.4058, 5.4057,\n",
      "        5.4057, 5.4059, 5.4055, 5.4058, 5.4059, 5.4058, 5.4058, 5.4057, 5.4056,\n",
      "        5.4059, 5.4059, 5.4059, 5.4055, 5.4057, 5.4056, 5.4058, 5.4054, 5.4058,\n",
      "        5.4059, 5.4061, 5.4060, 5.4060, 5.4059, 5.4061, 5.4062, 5.4061, 5.4059,\n",
      "        5.4062, 5.4061, 5.4062], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.737015  [4575724/5599865]\n",
      "average delta from current occupancy tensor([5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7340, 5.7339, 5.7340, 5.7340, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7340, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7340,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7340, 5.7339, 5.7339, 5.7339,\n",
      "        5.7340, 5.7340, 5.7341, 5.7340, 5.7339, 5.7340, 5.7340, 5.7340, 5.7340,\n",
      "        5.7341, 5.7340, 5.7339, 5.7339, 5.7340, 5.7340, 5.7340, 5.7340, 5.7340,\n",
      "        5.7340, 5.7340, 5.7341, 5.7341, 5.7340, 5.7341, 5.7340, 5.7340, 5.7340,\n",
      "        5.7340, 5.7340, 5.7340, 5.7341, 5.7339, 5.7340, 5.7340, 5.7341, 5.7340,\n",
      "        5.7341, 5.7341, 5.7340, 5.7340, 5.7340, 5.7340, 5.7340, 5.7339, 5.7340,\n",
      "        5.7339, 5.7339, 5.7339, 5.7340, 5.7339, 5.7340, 5.7340, 5.7339, 5.7339,\n",
      "        5.7340, 5.7340, 5.7339], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.652164  [4588124/5599865]\n",
      "average delta from current occupancy tensor([5.8967, 5.8961, 5.8962, 5.8962, 5.8961, 5.8965, 5.8964, 5.8966, 5.8961,\n",
      "        5.8966, 5.8965, 5.8964, 5.8963, 5.8965, 5.8961, 5.8960, 5.8962, 5.8965,\n",
      "        5.8961, 5.8967, 5.8967, 5.8965, 5.8963, 5.8967, 5.8965, 5.8966, 5.8965,\n",
      "        5.8963, 5.8966, 5.8966, 5.8966, 5.8965, 5.8965, 5.8961, 5.8961, 5.8962,\n",
      "        5.8962, 5.8960, 5.8959, 5.8960, 5.8959, 5.8961, 5.8960, 5.8960, 5.8962,\n",
      "        5.8960, 5.8959, 5.8960, 5.8961, 5.8959, 5.8962, 5.8960, 5.8959, 5.8960,\n",
      "        5.8960, 5.8960, 5.8960, 5.8960, 5.8960, 5.8963, 5.8961, 5.8960, 5.8961,\n",
      "        5.8959, 5.8960, 5.8959, 5.8959, 5.8960, 5.8961, 5.8962, 5.8960, 5.8961,\n",
      "        5.8958, 5.8956, 5.8959, 5.8958, 5.8957, 5.8958, 5.8957, 5.8960, 5.8957,\n",
      "        5.8959, 5.8962, 5.8961, 5.8958, 5.8959, 5.8960, 5.8959, 5.8961, 5.8960,\n",
      "        5.8961, 5.8959, 5.8960, 5.8960, 5.8960, 5.8958, 5.8960, 5.8958, 5.8961,\n",
      "        5.8962, 5.8962, 5.8960, 5.8962, 5.8961, 5.8963, 5.8961, 5.8962, 5.8962,\n",
      "        5.8961, 5.8962, 5.8963, 5.8962, 5.8962, 5.8963, 5.8961, 5.8962, 5.8960,\n",
      "        5.8962, 5.8962, 5.8962], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.071526  [4600524/5599865]\n",
      "average delta from current occupancy tensor([5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581, 5.2581,\n",
      "        5.2581, 5.2581, 5.2581], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.581882  [4612924/5599865]\n",
      "average delta from current occupancy tensor([4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242, 4.5242,\n",
      "        4.5242, 4.5242, 4.5242], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.584772  [4625324/5599865]\n",
      "average delta from current occupancy tensor([5.7507, 5.7507, 5.7507, 5.7507, 5.7507, 5.7506, 5.7506, 5.7506, 5.7505,\n",
      "        5.7505, 5.7506, 5.7506, 5.7506, 5.7506, 5.7506, 5.7505, 5.7506, 5.7505,\n",
      "        5.7505, 5.7505, 5.7506, 5.7506, 5.7505, 5.7504, 5.7505, 5.7505, 5.7506,\n",
      "        5.7505, 5.7506, 5.7506, 5.7506, 5.7506, 5.7506, 5.7505, 5.7506, 5.7506,\n",
      "        5.7506, 5.7505, 5.7505, 5.7505, 5.7505, 5.7505, 5.7504, 5.7504, 5.7505,\n",
      "        5.7505, 5.7505, 5.7505, 5.7505, 5.7504, 5.7504, 5.7504, 5.7505, 5.7505,\n",
      "        5.7505, 5.7505, 5.7505, 5.7505, 5.7505, 5.7505, 5.7505, 5.7504, 5.7504,\n",
      "        5.7504, 5.7505, 5.7505, 5.7504, 5.7505, 5.7505, 5.7504, 5.7505, 5.7505,\n",
      "        5.7506, 5.7505, 5.7506, 5.7506, 5.7505, 5.7505, 5.7505, 5.7506, 5.7507,\n",
      "        5.7507, 5.7506, 5.7506, 5.7506, 5.7507, 5.7506, 5.7505, 5.7506, 5.7506,\n",
      "        5.7506, 5.7506, 5.7507, 5.7506, 5.7506, 5.7505, 5.7504, 5.7505, 5.7505,\n",
      "        5.7506, 5.7505, 5.7505, 5.7507, 5.7507, 5.7507, 5.7507, 5.7507, 5.7508,\n",
      "        5.7507, 5.7506, 5.7506, 5.7507, 5.7506, 5.7506, 5.7506, 5.7506, 5.7506,\n",
      "        5.7506, 5.7506, 5.7506], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.182720  [4637724/5599865]\n",
      "average delta from current occupancy tensor([5.0888, 5.0889, 5.0889, 5.0886, 5.0886, 5.0889, 5.0888, 5.0889, 5.0888,\n",
      "        5.0887, 5.0887, 5.0887, 5.0887, 5.0886, 5.0886, 5.0886, 5.0885, 5.0886,\n",
      "        5.0885, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0887, 5.0887, 5.0886,\n",
      "        5.0886, 5.0887, 5.0885, 5.0886, 5.0886, 5.0885, 5.0886, 5.0886, 5.0885,\n",
      "        5.0886, 5.0886, 5.0885, 5.0885, 5.0885, 5.0886, 5.0885, 5.0884, 5.0885,\n",
      "        5.0885, 5.0885, 5.0885, 5.0885, 5.0886, 5.0885, 5.0886, 5.0885, 5.0886,\n",
      "        5.0885, 5.0885, 5.0886, 5.0886, 5.0885, 5.0885, 5.0885, 5.0885, 5.0888,\n",
      "        5.0886, 5.0887, 5.0887, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0885,\n",
      "        5.0887, 5.0886, 5.0886, 5.0886, 5.0887, 5.0888, 5.0885, 5.0886, 5.0887,\n",
      "        5.0887, 5.0889, 5.0887, 5.0885, 5.0885, 5.0886, 5.0885, 5.0886, 5.0885,\n",
      "        5.0887, 5.0885, 5.0886, 5.0885, 5.0885, 5.0885, 5.0885, 5.0885, 5.0884,\n",
      "        5.0885, 5.0884, 5.0885, 5.0885, 5.0887, 5.0885, 5.0885, 5.0885, 5.0885,\n",
      "        5.0885, 5.0885, 5.0885], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.627883  [4650124/5599865]\n",
      "average delta from current occupancy tensor([4.7177, 4.7177, 4.7178, 4.7183, 4.7183, 4.7179, 4.7179, 4.7177, 4.7180,\n",
      "        4.7178, 4.7177, 4.7178, 4.7179, 4.7182, 4.7181, 4.7181, 4.7179, 4.7177,\n",
      "        4.7178, 4.7181, 4.7181, 4.7182, 4.7180, 4.7182, 4.7180, 4.7181, 4.7177,\n",
      "        4.7176, 4.7177, 4.7177, 4.7178, 4.7177, 4.7177, 4.7178, 4.7181, 4.7182,\n",
      "        4.7181, 4.7177, 4.7181, 4.7180, 4.7181, 4.7180, 4.7180, 4.7180, 4.7178,\n",
      "        4.7177, 4.7179, 4.7179, 4.7177, 4.7177, 4.7178, 4.7177, 4.7177, 4.7178,\n",
      "        4.7177, 4.7178, 4.7179, 4.7178, 4.7177, 4.7177, 4.7177, 4.7178, 4.7178,\n",
      "        4.7177, 4.7179, 4.7177, 4.7177, 4.7181, 4.7179, 4.7181, 4.7177, 4.7177,\n",
      "        4.7177, 4.7178, 4.7180, 4.7181, 4.7177, 4.7180, 4.7177, 4.7177, 4.7181,\n",
      "        4.7177, 4.7180, 4.7178, 4.7178, 4.7178, 4.7177, 4.7177, 4.7177, 4.7177,\n",
      "        4.7177, 4.7177, 4.7177, 4.7179, 4.7178, 4.7177, 4.7178, 4.7177, 4.7177,\n",
      "        4.7177, 4.7177, 4.7177, 4.7178, 4.7179, 4.7177, 4.7178, 4.7177, 4.7177,\n",
      "        4.7178, 4.7180, 4.7177, 4.7182, 4.7179, 4.7178, 4.7181, 4.7181, 4.7180,\n",
      "        4.7178, 4.7181, 4.7181], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.474826  [4662524/5599865]\n",
      "average delta from current occupancy tensor([4.1862, 4.1858, 4.1855, 4.1860, 4.1855, 4.1855, 4.1858, 4.1855, 4.1856,\n",
      "        4.1855, 4.1857, 4.1857, 4.1858, 4.1857, 4.1856, 4.1857, 4.1856, 4.1859,\n",
      "        4.1855, 4.1855, 4.1856, 4.1858, 4.1859, 4.1855, 4.1855, 4.1855, 4.1858,\n",
      "        4.1863, 4.1859, 4.1859, 4.1861, 4.1860, 4.1859, 4.1859, 4.1855, 4.1856,\n",
      "        4.1855, 4.1858, 4.1857, 4.1855, 4.1855, 4.1855, 4.1855, 4.1855, 4.1855,\n",
      "        4.1855, 4.1855, 4.1855, 4.1855, 4.1855, 4.1855, 4.1856, 4.1860, 4.1862,\n",
      "        4.1858, 4.1865, 4.1859, 4.1857, 4.1861, 4.1863, 4.1863, 4.1859, 4.1862,\n",
      "        4.1861, 4.1860, 4.1860, 4.1856, 4.1857, 4.1859, 4.1857, 4.1860, 4.1860,\n",
      "        4.1860, 4.1859, 4.1858, 4.1858, 4.1863, 4.1857, 4.1861, 4.1863, 4.1859,\n",
      "        4.1860, 4.1859, 4.1860, 4.1862, 4.1862, 4.1864, 4.1862, 4.1861, 4.1859,\n",
      "        4.1861, 4.1860, 4.1862, 4.1859, 4.1859, 4.1861, 4.1859, 4.1859, 4.1860,\n",
      "        4.1859, 4.1859, 4.1859, 4.1860, 4.1858, 4.1858, 4.1856, 4.1858, 4.1855,\n",
      "        4.1855, 4.1855, 4.1855, 4.1855, 4.1854, 4.1855, 4.1855, 4.1855, 4.1855,\n",
      "        4.1855, 4.1855, 4.1855], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.767376  [4674924/5599865]\n",
      "average delta from current occupancy tensor([6.7038, 6.7037, 6.7037, 6.7040, 6.7039, 6.7037, 6.7038, 6.7042, 6.7039,\n",
      "        6.7038, 6.7038, 6.7039, 6.7037, 6.7037, 6.7036, 6.7036, 6.7035, 6.7036,\n",
      "        6.7039, 6.7040, 6.7036, 6.7039, 6.7036, 6.7037, 6.7041, 6.7042, 6.7039,\n",
      "        6.7040, 6.7037, 6.7040, 6.7040, 6.7040, 6.7039, 6.7040, 6.7042, 6.7041,\n",
      "        6.7040, 6.7042, 6.7041, 6.7041, 6.7041, 6.7043, 6.7042, 6.7042, 6.7040,\n",
      "        6.7043, 6.7043, 6.7044, 6.7045, 6.7043, 6.7043, 6.7042, 6.7039, 6.7039,\n",
      "        6.7043, 6.7039, 6.7040, 6.7044, 6.7043, 6.7043, 6.7040, 6.7041, 6.7042,\n",
      "        6.7043, 6.7043, 6.7044, 6.7044, 6.7045, 6.7042, 6.7043, 6.7043, 6.7041,\n",
      "        6.7042, 6.7041, 6.7044, 6.7044, 6.7043, 6.7043, 6.7043, 6.7044, 6.7043,\n",
      "        6.7044, 6.7044, 6.7043, 6.7043, 6.7042, 6.7043, 6.7043, 6.7044, 6.7044,\n",
      "        6.7042, 6.7041, 6.7042, 6.7043, 6.7042, 6.7043, 6.7041, 6.7040, 6.7040,\n",
      "        6.7039, 6.7041, 6.7040, 6.7039, 6.7039, 6.7040, 6.7039, 6.7040, 6.7042,\n",
      "        6.7040, 6.7040, 6.7040, 6.7041, 6.7040, 6.7040, 6.7040, 6.7041, 6.7042,\n",
      "        6.7039, 6.7040, 6.7042], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.379313  [4687324/5599865]\n",
      "average delta from current occupancy tensor([5.2758, 5.2759, 5.2760, 5.2755, 5.2759, 5.2761, 5.2761, 5.2757, 5.2762,\n",
      "        5.2761, 5.2762, 5.2757, 5.2762, 5.2761, 5.2761, 5.2761, 5.2761, 5.2760,\n",
      "        5.2754, 5.2753, 5.2764, 5.2758, 5.2765, 5.2764, 5.2757, 5.2760, 5.2761,\n",
      "        5.2759, 5.2764, 5.2761, 5.2757, 5.2758, 5.2760, 5.2756, 5.2755, 5.2758,\n",
      "        5.2757, 5.2755, 5.2755, 5.2757, 5.2756, 5.2758, 5.2755, 5.2755, 5.2756,\n",
      "        5.2757, 5.2758, 5.2754, 5.2755, 5.2756, 5.2759, 5.2759, 5.2759, 5.2759,\n",
      "        5.2762, 5.2763, 5.2760, 5.2758, 5.2759, 5.2760, 5.2757, 5.2757, 5.2763,\n",
      "        5.2764, 5.2762, 5.2763, 5.2761, 5.2762, 5.2760, 5.2761, 5.2762, 5.2760,\n",
      "        5.2761, 5.2758, 5.2759, 5.2755, 5.2759, 5.2758, 5.2756, 5.2756, 5.2757,\n",
      "        5.2758, 5.2757, 5.2758, 5.2756, 5.2757, 5.2758, 5.2756, 5.2755, 5.2757,\n",
      "        5.2758, 5.2755, 5.2756, 5.2758, 5.2754, 5.2758, 5.2754, 5.2757, 5.2757,\n",
      "        5.2757, 5.2756, 5.2755, 5.2757, 5.2757, 5.2755, 5.2756, 5.2756, 5.2756,\n",
      "        5.2755, 5.2754, 5.2754, 5.2753, 5.2755, 5.2755, 5.2753, 5.2756, 5.2756,\n",
      "        5.2758, 5.2754, 5.2757], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.905519  [4699724/5599865]\n",
      "average delta from current occupancy tensor([5.2903, 5.2902, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903,\n",
      "        5.2903, 5.2903, 5.2902, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903,\n",
      "        5.2903, 5.2902, 5.2902, 5.2903, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2903, 5.2902, 5.2902, 5.2902, 5.2902, 5.2903, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2903,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2903, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2903, 5.2902, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903,\n",
      "        5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2902, 5.2903,\n",
      "        5.2903, 5.2902, 5.2903, 5.2902, 5.2902, 5.2902, 5.2903, 5.2903, 5.2903,\n",
      "        5.2902, 5.2903, 5.2902, 5.2903, 5.2903, 5.2903, 5.2903, 5.2902, 5.2903,\n",
      "        5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903, 5.2903,\n",
      "        5.2903, 5.2903, 5.2903], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.393141  [4712124/5599865]\n",
      "average delta from current occupancy tensor([5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871, 5.3871,\n",
      "        5.3871, 5.3871, 5.3871], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.839407  [4724524/5599865]\n",
      "average delta from current occupancy tensor([4.7828, 4.7830, 4.7830, 4.7827, 4.7830, 4.7828, 4.7827, 4.7829, 4.7828,\n",
      "        4.7826, 4.7826, 4.7828, 4.7828, 4.7827, 4.7827, 4.7827, 4.7826, 4.7828,\n",
      "        4.7827, 4.7828, 4.7829, 4.7828, 4.7827, 4.7829, 4.7830, 4.7829, 4.7830,\n",
      "        4.7830, 4.7830, 4.7831, 4.7829, 4.7830, 4.7828, 4.7828, 4.7827, 4.7828,\n",
      "        4.7827, 4.7829, 4.7827, 4.7829, 4.7828, 4.7828, 4.7827, 4.7827, 4.7828,\n",
      "        4.7828, 4.7829, 4.7828, 4.7827, 4.7828, 4.7828, 4.7827, 4.7827, 4.7828,\n",
      "        4.7828, 4.7827, 4.7826, 4.7827, 4.7826, 4.7826, 4.7826, 4.7826, 4.7825,\n",
      "        4.7826, 4.7830, 4.7828, 4.7826, 4.7827, 4.7826, 4.7827, 4.7827, 4.7826,\n",
      "        4.7828, 4.7827, 4.7828, 4.7828, 4.7827, 4.7826, 4.7828, 4.7828, 4.7827,\n",
      "        4.7826, 4.7826, 4.7826, 4.7825, 4.7825, 4.7824, 4.7825, 4.7825, 4.7825,\n",
      "        4.7824, 4.7824, 4.7825, 4.7824, 4.7824, 4.7825, 4.7826, 4.7825, 4.7827,\n",
      "        4.7826, 4.7826, 4.7826, 4.7827, 4.7826, 4.7827, 4.7826, 4.7827, 4.7827,\n",
      "        4.7827, 4.7827, 4.7827, 4.7828, 4.7827, 4.7828, 4.7827, 4.7827, 4.7826,\n",
      "        4.7827, 4.7827, 4.7825], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.787282  [4736924/5599865]\n",
      "average delta from current occupancy tensor([4.5727, 4.5727, 4.5727, 4.5727, 4.5727, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5727, 4.5727, 4.5726, 4.5727, 4.5727, 4.5727, 4.5727,\n",
      "        4.5726, 4.5727, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5727, 4.5727,\n",
      "        4.5727, 4.5727, 4.5727, 4.5726, 4.5727, 4.5726, 4.5726, 4.5727, 4.5727,\n",
      "        4.5727, 4.5727, 4.5727, 4.5727, 4.5727, 4.5728, 4.5727, 4.5727, 4.5727,\n",
      "        4.5727, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5727, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728, 4.5727, 4.5727, 4.5727, 4.5727, 4.5727, 4.5727,\n",
      "        4.5727, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728, 4.5728,\n",
      "        4.5728, 4.5728, 4.5728], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.044282  [4749324/5599865]\n",
      "average delta from current occupancy tensor([5.2083, 5.2084, 5.2083, 5.2082, 5.2082, 5.2082, 5.2082, 5.2081, 5.2082,\n",
      "        5.2082, 5.2081, 5.2081, 5.2081, 5.2082, 5.2082, 5.2082, 5.2082, 5.2082,\n",
      "        5.2083, 5.2082, 5.2082, 5.2081, 5.2082, 5.2083, 5.2082, 5.2081, 5.2080,\n",
      "        5.2080, 5.2080, 5.2080, 5.2079, 5.2080, 5.2080, 5.2081, 5.2080, 5.2081,\n",
      "        5.2081, 5.2080, 5.2081, 5.2080, 5.2081, 5.2080, 5.2080, 5.2079, 5.2079,\n",
      "        5.2079, 5.2079, 5.2079, 5.2079, 5.2079, 5.2078, 5.2080, 5.2080, 5.2081,\n",
      "        5.2081, 5.2082, 5.2081, 5.2082, 5.2081, 5.2082, 5.2082, 5.2083, 5.2084,\n",
      "        5.2084, 5.2083, 5.2084, 5.2084, 5.2083, 5.2084, 5.2084, 5.2083, 5.2084,\n",
      "        5.2084, 5.2083, 5.2084, 5.2084, 5.2082, 5.2083, 5.2084, 5.2084, 5.2084,\n",
      "        5.2082, 5.2083, 5.2083, 5.2084, 5.2082, 5.2081, 5.2082, 5.2082, 5.2081,\n",
      "        5.2082, 5.2083, 5.2082, 5.2083, 5.2081, 5.2082, 5.2081, 5.2081, 5.2081,\n",
      "        5.2082, 5.2082, 5.2082, 5.2082, 5.2081, 5.2081, 5.2081, 5.2081, 5.2081,\n",
      "        5.2081, 5.2082, 5.2082, 5.2083, 5.2083, 5.2083, 5.2083, 5.2082, 5.2082,\n",
      "        5.2082, 5.2083, 5.2081], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.023306  [4761724/5599865]\n",
      "average delta from current occupancy tensor([4.8783, 4.8783, 4.8783, 4.8783, 4.8782, 4.8782, 4.8784, 4.8782, 4.8781,\n",
      "        4.8781, 4.8780, 4.8781, 4.8783, 4.8782, 4.8783, 4.8782, 4.8783, 4.8783,\n",
      "        4.8782, 4.8782, 4.8782, 4.8781, 4.8782, 4.8783, 4.8782, 4.8781, 4.8779,\n",
      "        4.8779, 4.8780, 4.8780, 4.8779, 4.8780, 4.8780, 4.8779, 4.8779, 4.8780,\n",
      "        4.8779, 4.8778, 4.8779, 4.8778, 4.8777, 4.8777, 4.8776, 4.8775, 4.8776,\n",
      "        4.8775, 4.8776, 4.8776, 4.8776, 4.8776, 4.8778, 4.8779, 4.8779, 4.8780,\n",
      "        4.8780, 4.8782, 4.8782, 4.8782, 4.8781, 4.8783, 4.8783, 4.8783, 4.8784,\n",
      "        4.8783, 4.8783, 4.8784, 4.8784, 4.8784, 4.8785, 4.8786, 4.8785, 4.8786,\n",
      "        4.8787, 4.8784, 4.8786, 4.8787, 4.8787, 4.8788, 4.8787, 4.8788, 4.8787,\n",
      "        4.8788, 4.8788, 4.8789, 4.8788, 4.8787, 4.8785, 4.8785, 4.8786, 4.8785,\n",
      "        4.8785, 4.8786, 4.8786, 4.8786, 4.8784, 4.8785, 4.8786, 4.8783, 4.8783,\n",
      "        4.8785, 4.8786, 4.8785, 4.8784, 4.8782, 4.8782, 4.8783, 4.8784, 4.8783,\n",
      "        4.8784, 4.8785, 4.8785, 4.8786, 4.8787, 4.8788, 4.8787, 4.8786, 4.8787,\n",
      "        4.8787, 4.8787, 4.8784], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.009576  [4774124/5599865]\n",
      "average delta from current occupancy tensor([4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9598, 4.9597,\n",
      "        4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9598, 4.9598, 4.9598, 4.9598,\n",
      "        4.9597, 4.9597, 4.9598, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597,\n",
      "        4.9597, 4.9598, 4.9597, 4.9598, 4.9597, 4.9598, 4.9598, 4.9598, 4.9598,\n",
      "        4.9597, 4.9597, 4.9599, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597,\n",
      "        4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9599,\n",
      "        4.9598, 4.9598, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597,\n",
      "        4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597,\n",
      "        4.9597, 4.9597, 4.9598, 4.9597, 4.9598, 4.9598, 4.9597, 4.9597, 4.9597,\n",
      "        4.9597, 4.9599, 4.9599, 4.9598, 4.9598, 4.9598, 4.9598, 4.9597, 4.9597,\n",
      "        4.9597, 4.9598, 4.9597, 4.9598, 4.9597, 4.9598, 4.9598, 4.9597, 4.9597,\n",
      "        4.9597, 4.9597, 4.9598, 4.9597, 4.9598, 4.9597, 4.9597, 4.9597, 4.9597,\n",
      "        4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9597, 4.9598, 4.9597, 4.9598,\n",
      "        4.9597, 4.9597, 4.9597], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.989758  [4786524/5599865]\n",
      "average delta from current occupancy tensor([5.1848, 5.1845, 5.1845, 5.1846, 5.1846, 5.1846, 5.1846, 5.1847, 5.1846,\n",
      "        5.1847, 5.1847, 5.1847, 5.1845, 5.1846, 5.1848, 5.1847, 5.1847, 5.1846,\n",
      "        5.1848, 5.1847, 5.1848, 5.1848, 5.1847, 5.1849, 5.1849, 5.1848, 5.1849,\n",
      "        5.1849, 5.1849, 5.1848, 5.1848, 5.1848, 5.1850, 5.1850, 5.1850, 5.1849,\n",
      "        5.1849, 5.1846, 5.1848, 5.1848, 5.1846, 5.1846, 5.1846, 5.1846, 5.1848,\n",
      "        5.1846, 5.1846, 5.1846, 5.1847, 5.1846, 5.1846, 5.1846, 5.1846, 5.1848,\n",
      "        5.1848, 5.1848, 5.1846, 5.1846, 5.1846, 5.1846, 5.1846, 5.1847, 5.1846,\n",
      "        5.1845, 5.1846, 5.1845, 5.1846, 5.1846, 5.1846, 5.1847, 5.1847, 5.1847,\n",
      "        5.1847, 5.1846, 5.1847, 5.1846, 5.1846, 5.1845, 5.1846, 5.1846, 5.1846,\n",
      "        5.1846, 5.1846, 5.1846, 5.1847, 5.1847, 5.1847, 5.1848, 5.1847, 5.1848,\n",
      "        5.1848, 5.1848, 5.1847, 5.1848, 5.1847, 5.1849, 5.1849, 5.1848, 5.1849,\n",
      "        5.1849, 5.1848, 5.1851, 5.1848, 5.1850, 5.1849, 5.1850, 5.1849, 5.1847,\n",
      "        5.1847, 5.1847, 5.1847, 5.1846, 5.1847, 5.1847, 5.1848, 5.1848, 5.1847,\n",
      "        5.1846, 5.1847, 5.1847], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.983487  [4798924/5599865]\n",
      "average delta from current occupancy tensor([5.1585, 5.1583, 5.1583, 5.1582, 5.1584, 5.1585, 5.1585, 5.1584, 5.1582,\n",
      "        5.1585, 5.1584, 5.1585, 5.1586, 5.1587, 5.1584, 5.1583, 5.1585, 5.1583,\n",
      "        5.1584, 5.1584, 5.1584, 5.1583, 5.1583, 5.1584, 5.1583, 5.1583, 5.1583,\n",
      "        5.1586, 5.1585, 5.1583, 5.1584, 5.1582, 5.1586, 5.1586, 5.1586, 5.1585,\n",
      "        5.1586, 5.1585, 5.1587, 5.1583, 5.1586, 5.1583, 5.1584, 5.1584, 5.1581,\n",
      "        5.1579, 5.1580, 5.1582, 5.1581, 5.1582, 5.1581, 5.1584, 5.1582, 5.1583,\n",
      "        5.1582, 5.1582, 5.1583, 5.1581, 5.1581, 5.1582, 5.1582, 5.1582, 5.1583,\n",
      "        5.1583, 5.1583, 5.1584, 5.1585, 5.1584, 5.1585, 5.1583, 5.1584, 5.1585,\n",
      "        5.1584, 5.1586, 5.1584, 5.1583, 5.1584, 5.1586, 5.1586, 5.1584, 5.1585,\n",
      "        5.1583, 5.1584, 5.1582, 5.1584, 5.1585, 5.1584, 5.1584, 5.1583, 5.1583,\n",
      "        5.1583, 5.1585, 5.1585, 5.1587, 5.1586, 5.1585, 5.1585, 5.1584, 5.1585,\n",
      "        5.1584, 5.1584, 5.1583, 5.1583, 5.1586, 5.1585, 5.1585, 5.1587, 5.1585,\n",
      "        5.1585, 5.1585, 5.1584, 5.1584, 5.1584, 5.1585, 5.1586, 5.1585, 5.1585,\n",
      "        5.1583, 5.1583, 5.1584], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.506321  [4811324/5599865]\n",
      "average delta from current occupancy tensor([5.6650, 5.6645, 5.6648, 5.6648, 5.6651, 5.6652, 5.6652, 5.6651, 5.6646,\n",
      "        5.6650, 5.6651, 5.6651, 5.6652, 5.6651, 5.6647, 5.6645, 5.6647, 5.6645,\n",
      "        5.6645, 5.6646, 5.6652, 5.6649, 5.6649, 5.6648, 5.6648, 5.6649, 5.6649,\n",
      "        5.6650, 5.6649, 5.6649, 5.6648, 5.6642, 5.6647, 5.6649, 5.6647, 5.6648,\n",
      "        5.6649, 5.6650, 5.6649, 5.6648, 5.6649, 5.6647, 5.6650, 5.6649, 5.6645,\n",
      "        5.6641, 5.6644, 5.6647, 5.6648, 5.6648, 5.6645, 5.6647, 5.6645, 5.6647,\n",
      "        5.6647, 5.6648, 5.6646, 5.6645, 5.6643, 5.6643, 5.6640, 5.6644, 5.6642,\n",
      "        5.6648, 5.6650, 5.6649, 5.6651, 5.6648, 5.6650, 5.6646, 5.6651, 5.6649,\n",
      "        5.6653, 5.6651, 5.6650, 5.6653, 5.6655, 5.6651, 5.6657, 5.6651, 5.6649,\n",
      "        5.6651, 5.6651, 5.6652, 5.6655, 5.6654, 5.6655, 5.6659, 5.6653, 5.6660,\n",
      "        5.6653, 5.6657, 5.6659, 5.6657, 5.6658, 5.6649, 5.6651, 5.6654, 5.6652,\n",
      "        5.6649, 5.6646, 5.6647, 5.6647, 5.6646, 5.6646, 5.6646, 5.6652, 5.6645,\n",
      "        5.6646, 5.6648, 5.6647, 5.6647, 5.6648, 5.6645, 5.6641, 5.6643, 5.6640,\n",
      "        5.6641, 5.6642, 5.6640], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.975891  [4823724/5599865]\n",
      "average delta from current occupancy tensor([4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.146202  [4836124/5599865]\n",
      "average delta from current occupancy tensor([4.9023, 4.9023, 4.9022, 4.9023, 4.9024, 4.9023, 4.9023, 4.9024, 4.9023,\n",
      "        4.9023, 4.9024, 4.9022, 4.9024, 4.9024, 4.9023, 4.9023, 4.9024, 4.9024,\n",
      "        4.9024, 4.9025, 4.9025, 4.9026, 4.9024, 4.9024, 4.9025, 4.9023, 4.9023,\n",
      "        4.9023, 4.9023, 4.9023, 4.9023, 4.9022, 4.9023, 4.9021, 4.9022, 4.9023,\n",
      "        4.9021, 4.9023, 4.9023, 4.9022, 4.9023, 4.9023, 4.9024, 4.9024, 4.9024,\n",
      "        4.9024, 4.9024, 4.9022, 4.9022, 4.9023, 4.9024, 4.9024, 4.9024, 4.9023,\n",
      "        4.9024, 4.9025, 4.9023, 4.9025, 4.9023, 4.9024, 4.9024, 4.9024, 4.9025,\n",
      "        4.9026, 4.9028, 4.9028, 4.9027, 4.9027, 4.9028, 4.9026, 4.9026, 4.9026,\n",
      "        4.9025, 4.9025, 4.9025, 4.9023, 4.9024, 4.9025, 4.9027, 4.9027, 4.9025,\n",
      "        4.9023, 4.9027, 4.9024, 4.9027, 4.9026, 4.9027, 4.9026, 4.9024, 4.9027,\n",
      "        4.9026, 4.9025, 4.9026, 4.9024, 4.9026, 4.9027, 4.9025, 4.9025, 4.9023,\n",
      "        4.9028, 4.9027, 4.9023, 4.9023, 4.9024, 4.9024, 4.9024, 4.9025, 4.9023,\n",
      "        4.9023, 4.9024, 4.9025, 4.9024, 4.9024, 4.9025, 4.9025, 4.9027, 4.9027,\n",
      "        4.9027, 4.9025, 4.9029], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.325106  [4848524/5599865]\n",
      "average delta from current occupancy tensor([5.3470, 5.3470, 5.3470, 5.3470, 5.3470, 5.3469, 5.3469, 5.3469, 5.3469,\n",
      "        5.3469, 5.3469, 5.3469, 5.3469, 5.3469, 5.3470, 5.3469, 5.3469, 5.3469,\n",
      "        5.3470, 5.3470, 5.3470, 5.3469, 5.3469, 5.3470, 5.3470, 5.3469, 5.3469,\n",
      "        5.3470, 5.3470, 5.3469, 5.3468, 5.3469, 5.3469, 5.3470, 5.3470, 5.3470,\n",
      "        5.3470, 5.3470, 5.3471, 5.3470, 5.3469, 5.3468, 5.3469, 5.3470, 5.3470,\n",
      "        5.3470, 5.3469, 5.3469, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3470,\n",
      "        5.3469, 5.3468, 5.3469, 5.3468, 5.3469, 5.3469, 5.3468, 5.3469, 5.3469,\n",
      "        5.3469, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3469, 5.3469, 5.3468,\n",
      "        5.3469, 5.3468, 5.3468, 5.3469, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3467, 5.3468, 5.3467, 5.3467, 5.3467, 5.3467, 5.3468, 5.3467,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3466, 5.3466, 5.3465, 5.3466,\n",
      "        5.3465, 5.3464, 5.3466, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3464,\n",
      "        5.3465, 5.3465, 5.3466, 5.3466, 5.3467, 5.3466, 5.3467, 5.3466, 5.3466,\n",
      "        5.3465, 5.3467, 5.3466], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.891468  [4860924/5599865]\n",
      "average delta from current occupancy tensor([5.1378, 5.1377, 5.1379, 5.1379, 5.1378, 5.1379, 5.1378, 5.1377, 5.1380,\n",
      "        5.1379, 5.1379, 5.1380, 5.1379, 5.1379, 5.1380, 5.1379, 5.1378, 5.1378,\n",
      "        5.1377, 5.1377, 5.1377, 5.1378, 5.1377, 5.1380, 5.1377, 5.1379, 5.1378,\n",
      "        5.1379, 5.1378, 5.1378, 5.1377, 5.1378, 5.1378, 5.1377, 5.1380, 5.1382,\n",
      "        5.1381, 5.1382, 5.1380, 5.1382, 5.1381, 5.1379, 5.1379, 5.1379, 5.1380,\n",
      "        5.1379, 5.1379, 5.1380, 5.1378, 5.1379, 5.1379, 5.1376, 5.1376, 5.1376,\n",
      "        5.1376, 5.1376, 5.1376, 5.1377, 5.1377, 5.1377, 5.1377, 5.1376, 5.1378,\n",
      "        5.1377, 5.1377, 5.1377, 5.1376, 5.1378, 5.1378, 5.1377, 5.1378, 5.1377,\n",
      "        5.1377, 5.1379, 5.1378, 5.1378, 5.1380, 5.1377, 5.1379, 5.1379, 5.1378,\n",
      "        5.1378, 5.1378, 5.1378, 5.1378, 5.1378, 5.1378, 5.1378, 5.1377, 5.1378,\n",
      "        5.1379, 5.1377, 5.1379, 5.1378, 5.1377, 5.1377, 5.1378, 5.1378, 5.1379,\n",
      "        5.1378, 5.1380, 5.1378, 5.1378, 5.1379, 5.1380, 5.1379, 5.1379, 5.1380,\n",
      "        5.1379, 5.1379, 5.1379, 5.1379, 5.1379, 5.1379, 5.1378, 5.1379, 5.1379,\n",
      "        5.1378, 5.1380, 5.1378], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.129405  [4873324/5599865]\n",
      "average delta from current occupancy tensor([5.2747, 5.2747, 5.2747, 5.2746, 5.2746, 5.2746, 5.2744, 5.2745, 5.2746,\n",
      "        5.2745, 5.2745, 5.2746, 5.2745, 5.2745, 5.2744, 5.2745, 5.2746, 5.2744,\n",
      "        5.2745, 5.2744, 5.2744, 5.2745, 5.2744, 5.2743, 5.2745, 5.2745, 5.2745,\n",
      "        5.2745, 5.2744, 5.2744, 5.2745, 5.2745, 5.2745, 5.2747, 5.2745, 5.2747,\n",
      "        5.2746, 5.2748, 5.2746, 5.2748, 5.2746, 5.2747, 5.2747, 5.2747, 5.2748,\n",
      "        5.2746, 5.2748, 5.2747, 5.2748, 5.2748, 5.2747, 5.2746, 5.2747, 5.2747,\n",
      "        5.2747, 5.2746, 5.2747, 5.2745, 5.2746, 5.2746, 5.2746, 5.2748, 5.2747,\n",
      "        5.2747, 5.2748, 5.2748, 5.2747, 5.2748, 5.2746, 5.2747, 5.2746, 5.2745,\n",
      "        5.2746, 5.2747, 5.2746, 5.2747, 5.2746, 5.2748, 5.2747, 5.2747, 5.2747,\n",
      "        5.2746, 5.2748, 5.2747, 5.2747, 5.2746, 5.2746, 5.2747, 5.2746, 5.2746,\n",
      "        5.2746, 5.2745, 5.2746, 5.2747, 5.2747, 5.2747, 5.2747, 5.2748, 5.2747,\n",
      "        5.2749, 5.2748, 5.2748, 5.2748, 5.2748, 5.2748, 5.2747, 5.2748, 5.2748,\n",
      "        5.2748, 5.2748, 5.2747, 5.2747, 5.2748, 5.2748, 5.2749, 5.2748, 5.2746,\n",
      "        5.2747, 5.2748, 5.2746], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.280220  [4885724/5599865]\n",
      "average delta from current occupancy tensor([4.3706, 4.3706, 4.3706, 4.3706, 4.3706, 4.3706, 4.3706, 4.3706, 4.3706,\n",
      "        4.3705, 4.3706, 4.3705, 4.3704, 4.3704, 4.3705, 4.3704, 4.3705, 4.3705,\n",
      "        4.3704, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705,\n",
      "        4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705, 4.3705,\n",
      "        4.3705, 4.3705, 4.3705, 4.3706, 4.3705, 4.3705, 4.3707, 4.3706, 4.3707,\n",
      "        4.3705, 4.3707, 4.3708, 4.3708, 4.3708, 4.3706, 4.3708, 4.3708, 4.3707,\n",
      "        4.3706, 4.3707, 4.3706, 4.3708, 4.3706, 4.3707, 4.3707, 4.3708, 4.3707,\n",
      "        4.3707, 4.3708, 4.3708, 4.3707, 4.3708, 4.3707, 4.3708, 4.3708, 4.3706,\n",
      "        4.3707, 4.3707, 4.3707, 4.3707, 4.3707, 4.3709, 4.3708, 4.3708, 4.3708,\n",
      "        4.3707, 4.3708, 4.3708, 4.3707, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3707, 4.3707, 4.3707, 4.3707, 4.3707, 4.3707, 4.3708, 4.3707, 4.3708,\n",
      "        4.3708, 4.3707, 4.3708, 4.3708, 4.3708, 4.3707, 4.3707, 4.3707, 4.3707,\n",
      "        4.3707, 4.3707, 4.3707, 4.3707, 4.3708, 4.3707, 4.3708, 4.3707, 4.3707,\n",
      "        4.3707, 4.3707, 4.3707], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.436899  [4898124/5599865]\n",
      "average delta from current occupancy tensor([5.5981, 5.5982, 5.5981, 5.5982, 5.5983, 5.5982, 5.5982, 5.5982, 5.5983,\n",
      "        5.5983, 5.5983, 5.5982, 5.5983, 5.5981, 5.5980, 5.5981, 5.5982, 5.5982,\n",
      "        5.5981, 5.5983, 5.5983, 5.5982, 5.5981, 5.5980, 5.5981, 5.5980, 5.5981,\n",
      "        5.5981, 5.5981, 5.5981, 5.5981, 5.5980, 5.5981, 5.5982, 5.5982, 5.5982,\n",
      "        5.5982, 5.5983, 5.5983, 5.5983, 5.5983, 5.5984, 5.5982, 5.5982, 5.5982,\n",
      "        5.5985, 5.5982, 5.5982, 5.5981, 5.5982, 5.5984, 5.5985, 5.5983, 5.5984,\n",
      "        5.5985, 5.5985, 5.5982, 5.5983, 5.5981, 5.5981, 5.5980, 5.5982, 5.5981,\n",
      "        5.5981, 5.5983, 5.5983, 5.5982, 5.5982, 5.5983, 5.5983, 5.5982, 5.5982,\n",
      "        5.5982, 5.5982, 5.5981, 5.5981, 5.5981, 5.5981, 5.5980, 5.5981, 5.5980,\n",
      "        5.5980, 5.5980, 5.5981, 5.5981, 5.5981, 5.5980, 5.5981, 5.5981, 5.5981,\n",
      "        5.5980, 5.5980, 5.5980, 5.5981, 5.5982, 5.5982, 5.5982, 5.5982, 5.5982,\n",
      "        5.5981, 5.5981, 5.5982, 5.5982, 5.5982, 5.5981, 5.5981, 5.5981, 5.5981,\n",
      "        5.5981, 5.5980, 5.5981, 5.5981, 5.5981, 5.5980, 5.5981, 5.5981, 5.5981,\n",
      "        5.5980, 5.5981, 5.5980], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.253489  [4910524/5599865]\n",
      "average delta from current occupancy tensor([5.4434, 5.4434, 5.4435, 5.4434, 5.4434, 5.4434, 5.4434, 5.4434, 5.4434,\n",
      "        5.4435, 5.4434, 5.4434, 5.4433, 5.4434, 5.4435, 5.4434, 5.4434, 5.4433,\n",
      "        5.4434, 5.4434, 5.4433, 5.4434, 5.4433, 5.4434, 5.4434, 5.4434, 5.4434,\n",
      "        5.4435, 5.4433, 5.4434, 5.4434, 5.4433, 5.4434, 5.4434, 5.4434, 5.4434,\n",
      "        5.4434, 5.4435, 5.4434, 5.4433, 5.4433, 5.4434, 5.4435, 5.4433, 5.4434,\n",
      "        5.4434, 5.4433, 5.4434, 5.4434, 5.4433, 5.4434, 5.4434, 5.4434, 5.4434,\n",
      "        5.4433, 5.4435, 5.4434, 5.4434, 5.4434, 5.4434, 5.4433, 5.4435, 5.4434,\n",
      "        5.4434, 5.4435, 5.4435, 5.4434, 5.4434, 5.4434, 5.4434, 5.4434, 5.4434,\n",
      "        5.4434, 5.4434, 5.4434, 5.4434, 5.4433, 5.4434, 5.4433, 5.4434, 5.4434,\n",
      "        5.4433, 5.4433, 5.4433, 5.4433, 5.4433, 5.4433, 5.4434, 5.4434, 5.4433,\n",
      "        5.4435, 5.4434, 5.4433, 5.4434, 5.4433, 5.4433, 5.4434, 5.4433, 5.4433,\n",
      "        5.4434, 5.4434, 5.4434, 5.4433, 5.4434, 5.4433, 5.4433, 5.4434, 5.4434,\n",
      "        5.4434, 5.4433, 5.4433, 5.4434, 5.4433, 5.4434, 5.4434, 5.4434, 5.4433,\n",
      "        5.4433, 5.4434, 5.4434], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.265305  [4922924/5599865]\n",
      "average delta from current occupancy tensor([5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3549, 5.3549, 5.3549, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550, 5.3550,\n",
      "        5.3550, 5.3550, 5.3550], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.014441  [4935324/5599865]\n",
      "average delta from current occupancy tensor([4.8673, 4.8676, 4.8678, 4.8673, 4.8670, 4.8675, 4.8675, 4.8674, 4.8678,\n",
      "        4.8675, 4.8671, 4.8677, 4.8679, 4.8679, 4.8678, 4.8676, 4.8676, 4.8678,\n",
      "        4.8678, 4.8677, 4.8677, 4.8675, 4.8680, 4.8678, 4.8679, 4.8676, 4.8674,\n",
      "        4.8679, 4.8676, 4.8674, 4.8673, 4.8672, 4.8676, 4.8676, 4.8672, 4.8671,\n",
      "        4.8670, 4.8673, 4.8676, 4.8672, 4.8672, 4.8674, 4.8676, 4.8676, 4.8676,\n",
      "        4.8673, 4.8671, 4.8672, 4.8676, 4.8679, 4.8678, 4.8681, 4.8679, 4.8675,\n",
      "        4.8678, 4.8681, 4.8675, 4.8677, 4.8676, 4.8681, 4.8680, 4.8681, 4.8681,\n",
      "        4.8683, 4.8676, 4.8676, 4.8678, 4.8675, 4.8678, 4.8681, 4.8684, 4.8683,\n",
      "        4.8682, 4.8681, 4.8680, 4.8681, 4.8674, 4.8674, 4.8675, 4.8674, 4.8676,\n",
      "        4.8673, 4.8671, 4.8677, 4.8676, 4.8675, 4.8675, 4.8676, 4.8671, 4.8668,\n",
      "        4.8674, 4.8666, 4.8666, 4.8671, 4.8666, 4.8669, 4.8665, 4.8668, 4.8669,\n",
      "        4.8664, 4.8666, 4.8667, 4.8668, 4.8667, 4.8667, 4.8667, 4.8666, 4.8664,\n",
      "        4.8665, 4.8664, 4.8667, 4.8667, 4.8671, 4.8669, 4.8667, 4.8669, 4.8668,\n",
      "        4.8667, 4.8669, 4.8672], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.149666  [4947724/5599865]\n",
      "average delta from current occupancy tensor([4.8866, 4.8866, 4.8867, 4.8866, 4.8865, 4.8866, 4.8866, 4.8866, 4.8867,\n",
      "        4.8866, 4.8866, 4.8867, 4.8867, 4.8867, 4.8867, 4.8867, 4.8867, 4.8867,\n",
      "        4.8867, 4.8867, 4.8868, 4.8867, 4.8868, 4.8868, 4.8868, 4.8867, 4.8867,\n",
      "        4.8868, 4.8867, 4.8867, 4.8867, 4.8867, 4.8867, 4.8867, 4.8866, 4.8866,\n",
      "        4.8866, 4.8867, 4.8867, 4.8866, 4.8866, 4.8867, 4.8867, 4.8867, 4.8867,\n",
      "        4.8867, 4.8866, 4.8867, 4.8867, 4.8868, 4.8868, 4.8868, 4.8868, 4.8867,\n",
      "        4.8868, 4.8868, 4.8867, 4.8867, 4.8868, 4.8868, 4.8868, 4.8868, 4.8869,\n",
      "        4.8869, 4.8868, 4.8868, 4.8868, 4.8868, 4.8868, 4.8868, 4.8869, 4.8869,\n",
      "        4.8869, 4.8868, 4.8868, 4.8868, 4.8867, 4.8867, 4.8867, 4.8866, 4.8867,\n",
      "        4.8867, 4.8866, 4.8867, 4.8867, 4.8867, 4.8866, 4.8867, 4.8866, 4.8866,\n",
      "        4.8866, 4.8866, 4.8866, 4.8866, 4.8865, 4.8866, 4.8866, 4.8866, 4.8866,\n",
      "        4.8865, 4.8866, 4.8866, 4.8866, 4.8866, 4.8866, 4.8865, 4.8866, 4.8865,\n",
      "        4.8865, 4.8865, 4.8866, 4.8866, 4.8867, 4.8866, 4.8865, 4.8866, 4.8866,\n",
      "        4.8865, 4.8866, 4.8866], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.766325  [4960124/5599865]\n",
      "average delta from current occupancy tensor([5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484,\n",
      "        5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484,\n",
      "        5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484,\n",
      "        5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5485,\n",
      "        5.5485, 5.5484, 5.5484, 5.5484, 5.5485, 5.5484, 5.5485, 5.5484, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5484, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5484, 5.5485, 5.5485, 5.5485, 5.5485, 5.5484, 5.5485, 5.5484,\n",
      "        5.5485, 5.5484, 5.5485, 5.5484, 5.5485, 5.5484, 5.5484, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484,\n",
      "        5.5484, 5.5485, 5.5484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.500394  [4972524/5599865]\n",
      "average delta from current occupancy tensor([5.3218, 5.3218, 5.3219, 5.3220, 5.3220, 5.3219, 5.3216, 5.3217, 5.3218,\n",
      "        5.3220, 5.3218, 5.3218, 5.3218, 5.3218, 5.3217, 5.3216, 5.3215, 5.3217,\n",
      "        5.3217, 5.3218, 5.3217, 5.3218, 5.3220, 5.3219, 5.3221, 5.3222, 5.3221,\n",
      "        5.3223, 5.3223, 5.3221, 5.3219, 5.3220, 5.3221, 5.3222, 5.3223, 5.3225,\n",
      "        5.3223, 5.3224, 5.3225, 5.3223, 5.3222, 5.3224, 5.3224, 5.3224, 5.3223,\n",
      "        5.3223, 5.3223, 5.3224, 5.3224, 5.3225, 5.3223, 5.3222, 5.3222, 5.3222,\n",
      "        5.3220, 5.3219, 5.3218, 5.3219, 5.3219, 5.3220, 5.3220, 5.3219, 5.3219,\n",
      "        5.3220, 5.3220, 5.3217, 5.3219, 5.3218, 5.3217, 5.3219, 5.3218, 5.3218,\n",
      "        5.3218, 5.3219, 5.3219, 5.3222, 5.3220, 5.3222, 5.3222, 5.3220, 5.3220,\n",
      "        5.3220, 5.3221, 5.3220, 5.3220, 5.3219, 5.3219, 5.3219, 5.3219, 5.3219,\n",
      "        5.3219, 5.3219, 5.3221, 5.3219, 5.3219, 5.3220, 5.3222, 5.3220, 5.3221,\n",
      "        5.3221, 5.3222, 5.3221, 5.3221, 5.3220, 5.3221, 5.3223, 5.3220, 5.3222,\n",
      "        5.3221, 5.3221, 5.3221, 5.3222, 5.3220, 5.3222, 5.3222, 5.3223, 5.3222,\n",
      "        5.3222, 5.3222, 5.3222], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.339239  [4984924/5599865]\n",
      "average delta from current occupancy tensor([5.1526, 5.1526, 5.1527, 5.1527, 5.1527, 5.1527, 5.1526, 5.1527, 5.1527,\n",
      "        5.1525, 5.1527, 5.1525, 5.1524, 5.1525, 5.1525, 5.1526, 5.1525, 5.1525,\n",
      "        5.1524, 5.1524, 5.1526, 5.1525, 5.1524, 5.1524, 5.1524, 5.1524, 5.1524,\n",
      "        5.1524, 5.1524, 5.1524, 5.1525, 5.1523, 5.1523, 5.1524, 5.1524, 5.1524,\n",
      "        5.1524, 5.1524, 5.1523, 5.1523, 5.1523, 5.1523, 5.1523, 5.1523, 5.1523,\n",
      "        5.1523, 5.1524, 5.1524, 5.1522, 5.1523, 5.1524, 5.1524, 5.1524, 5.1525,\n",
      "        5.1524, 5.1524, 5.1524, 5.1523, 5.1523, 5.1522, 5.1523, 5.1523, 5.1523,\n",
      "        5.1523, 5.1522, 5.1524, 5.1524, 5.1523, 5.1528, 5.1524, 5.1523, 5.1524,\n",
      "        5.1526, 5.1525, 5.1527, 5.1526, 5.1525, 5.1526, 5.1526, 5.1526, 5.1526,\n",
      "        5.1526, 5.1526, 5.1527, 5.1528, 5.1526, 5.1526, 5.1526, 5.1525, 5.1524,\n",
      "        5.1525, 5.1525, 5.1526, 5.1527, 5.1526, 5.1525, 5.1526, 5.1526, 5.1527,\n",
      "        5.1525, 5.1525, 5.1524, 5.1526, 5.1526, 5.1525, 5.1526, 5.1525, 5.1525,\n",
      "        5.1525, 5.1524, 5.1524, 5.1525, 5.1524, 5.1524, 5.1523, 5.1523, 5.1523,\n",
      "        5.1523, 5.1524, 5.1524], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.220376  [4997324/5599865]\n",
      "average delta from current occupancy tensor([5.1742, 5.1740, 5.1735, 5.1732, 5.1732, 5.1730, 5.1736, 5.1732, 5.1729,\n",
      "        5.1735, 5.1727, 5.1734, 5.1738, 5.1734, 5.1732, 5.1728, 5.1728, 5.1733,\n",
      "        5.1730, 5.1733, 5.1725, 5.1728, 5.1731, 5.1733, 5.1736, 5.1732, 5.1734,\n",
      "        5.1734, 5.1734, 5.1730, 5.1731, 5.1736, 5.1737, 5.1734, 5.1731, 5.1729,\n",
      "        5.1727, 5.1730, 5.1728, 5.1731, 5.1730, 5.1733, 5.1730, 5.1731, 5.1733,\n",
      "        5.1736, 5.1733, 5.1734, 5.1739, 5.1734, 5.1733, 5.1733, 5.1733, 5.1732,\n",
      "        5.1736, 5.1736, 5.1738, 5.1737, 5.1739, 5.1739, 5.1734, 5.1737, 5.1734,\n",
      "        5.1732, 5.1738, 5.1729, 5.1726, 5.1727, 5.1710, 5.1721, 5.1725, 5.1723,\n",
      "        5.1716, 5.1720, 5.1717, 5.1721, 5.1724, 5.1726, 5.1726, 5.1730, 5.1729,\n",
      "        5.1728, 5.1727, 5.1726, 5.1724, 5.1728, 5.1728, 5.1728, 5.1734, 5.1738,\n",
      "        5.1736, 5.1739, 5.1735, 5.1735, 5.1739, 5.1743, 5.1743, 5.1739, 5.1741,\n",
      "        5.1747, 5.1749, 5.1749, 5.1744, 5.1742, 5.1745, 5.1746, 5.1748, 5.1747,\n",
      "        5.1746, 5.1746, 5.1748, 5.1745, 5.1746, 5.1746, 5.1749, 5.1749, 5.1749,\n",
      "        5.1753, 5.1751, 5.1750], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.264526  [5009724/5599865]\n",
      "average delta from current occupancy tensor([4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306, 4.3306,\n",
      "        4.3306, 4.3306, 4.3306], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.831217  [5022124/5599865]\n",
      "average delta from current occupancy tensor([4.8061, 4.8062, 4.8060, 4.8060, 4.8061, 4.8061, 4.8061, 4.8062, 4.8061,\n",
      "        4.8061, 4.8061, 4.8060, 4.8061, 4.8061, 4.8061, 4.8061, 4.8061, 4.8060,\n",
      "        4.8061, 4.8061, 4.8061, 4.8061, 4.8061, 4.8061, 4.8062, 4.8061, 4.8060,\n",
      "        4.8062, 4.8062, 4.8061, 4.8061, 4.8061, 4.8060, 4.8061, 4.8060, 4.8061,\n",
      "        4.8061, 4.8062, 4.8062, 4.8062, 4.8060, 4.8061, 4.8060, 4.8060, 4.8059,\n",
      "        4.8060, 4.8061, 4.8060, 4.8060, 4.8061, 4.8059, 4.8060, 4.8061, 4.8060,\n",
      "        4.8060, 4.8061, 4.8060, 4.8060, 4.8060, 4.8061, 4.8060, 4.8059, 4.8058,\n",
      "        4.8060, 4.8060, 4.8061, 4.8060, 4.8059, 4.8060, 4.8061, 4.8061, 4.8061,\n",
      "        4.8061, 4.8061, 4.8060, 4.8061, 4.8059, 4.8060, 4.8059, 4.8058, 4.8059,\n",
      "        4.8059, 4.8061, 4.8059, 4.8059, 4.8058, 4.8060, 4.8060, 4.8061, 4.8058,\n",
      "        4.8059, 4.8059, 4.8059, 4.8059, 4.8061, 4.8057, 4.8058, 4.8058, 4.8058,\n",
      "        4.8061, 4.8061, 4.8061, 4.8057, 4.8059, 4.8058, 4.8058, 4.8058, 4.8060,\n",
      "        4.8060, 4.8058, 4.8061, 4.8057, 4.8059, 4.8057, 4.8061, 4.8061, 4.8061,\n",
      "        4.8057, 4.8056, 4.8058], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.507245  [5034524/5599865]\n",
      "average delta from current occupancy tensor([5.4104, 5.4104, 5.4103, 5.4104, 5.4105, 5.4107, 5.4106, 5.4104, 5.4106,\n",
      "        5.4107, 5.4106, 5.4106, 5.4107, 5.4107, 5.4107, 5.4107, 5.4107, 5.4107,\n",
      "        5.4107, 5.4106, 5.4106, 5.4107, 5.4106, 5.4107, 5.4105, 5.4106, 5.4105,\n",
      "        5.4106, 5.4105, 5.4106, 5.4106, 5.4106, 5.4105, 5.4106, 5.4106, 5.4105,\n",
      "        5.4105, 5.4105, 5.4105, 5.4105, 5.4106, 5.4106, 5.4105, 5.4105, 5.4106,\n",
      "        5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4105,\n",
      "        5.4105, 5.4106, 5.4106, 5.4106, 5.4106, 5.4105, 5.4106, 5.4106, 5.4106,\n",
      "        5.4106, 5.4105, 5.4106, 5.4106, 5.4106, 5.4106, 5.4107, 5.4106, 5.4106,\n",
      "        5.4106, 5.4107, 5.4107, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106,\n",
      "        5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4106, 5.4105,\n",
      "        5.4105, 5.4105, 5.4106, 5.4106, 5.4106, 5.4105, 5.4105, 5.4105, 5.4105,\n",
      "        5.4105, 5.4105, 5.4106, 5.4105, 5.4104, 5.4104, 5.4105, 5.4105, 5.4106,\n",
      "        5.4106, 5.4106, 5.4107, 5.4106, 5.4106, 5.4106, 5.4107, 5.4106, 5.4106,\n",
      "        5.4106, 5.4106, 5.4106], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.564004  [5046924/5599865]\n",
      "average delta from current occupancy tensor([4.3971, 4.3970, 4.3971, 4.3970, 4.3969, 4.3966, 4.3967, 4.3971, 4.3966,\n",
      "        4.3966, 4.3966, 4.3966, 4.3963, 4.3966, 4.3966, 4.3965, 4.3966, 4.3966,\n",
      "        4.3967, 4.3968, 4.3968, 4.3966, 4.3967, 4.3966, 4.3970, 4.3968, 4.3969,\n",
      "        4.3968, 4.3969, 4.3968, 4.3970, 4.3970, 4.3972, 4.3972, 4.3971, 4.3972,\n",
      "        4.3972, 4.3972, 4.3970, 4.3971, 4.3967, 4.3966, 4.3967, 4.3967, 4.3967,\n",
      "        4.3966, 4.3965, 4.3965, 4.3965, 4.3965, 4.3965, 4.3964, 4.3963, 4.3963,\n",
      "        4.3964, 4.3962, 4.3963, 4.3963, 4.3964, 4.3966, 4.3967, 4.3967, 4.3968,\n",
      "        4.3968, 4.3968, 4.3967, 4.3968, 4.3966, 4.3966, 4.3964, 4.3965, 4.3965,\n",
      "        4.3967, 4.3967, 4.3966, 4.3966, 4.3966, 4.3967, 4.3967, 4.3968, 4.3967,\n",
      "        4.3966, 4.3965, 4.3965, 4.3963, 4.3965, 4.3964, 4.3964, 4.3963, 4.3964,\n",
      "        4.3965, 4.3965, 4.3964, 4.3965, 4.3963, 4.3963, 4.3964, 4.3965, 4.3964,\n",
      "        4.3963, 4.3961, 4.3960, 4.3961, 4.3962, 4.3961, 4.3960, 4.3959, 4.3958,\n",
      "        4.3958, 4.3960, 4.3956, 4.3957, 4.3959, 4.3956, 4.3955, 4.3956, 4.3958,\n",
      "        4.3958, 4.3956, 4.3958], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.486517  [5059324/5599865]\n",
      "average delta from current occupancy tensor([5.2753, 5.2752, 5.2753, 5.2749, 5.2748, 5.2751, 5.2751, 5.2746, 5.2753,\n",
      "        5.2752, 5.2751, 5.2750, 5.2751, 5.2753, 5.2753, 5.2751, 5.2752, 5.2751,\n",
      "        5.2751, 5.2752, 5.2752, 5.2750, 5.2751, 5.2750, 5.2750, 5.2751, 5.2750,\n",
      "        5.2750, 5.2748, 5.2749, 5.2747, 5.2747, 5.2745, 5.2745, 5.2745, 5.2743,\n",
      "        5.2744, 5.2746, 5.2747, 5.2747, 5.2748, 5.2749, 5.2747, 5.2747, 5.2749,\n",
      "        5.2748, 5.2748, 5.2747, 5.2746, 5.2747, 5.2748, 5.2748, 5.2747, 5.2748,\n",
      "        5.2747, 5.2749, 5.2748, 5.2747, 5.2749, 5.2747, 5.2747, 5.2746, 5.2746,\n",
      "        5.2745, 5.2744, 5.2746, 5.2744, 5.2746, 5.2744, 5.2746, 5.2746, 5.2745,\n",
      "        5.2745, 5.2744, 5.2744, 5.2744, 5.2745, 5.2743, 5.2742, 5.2742, 5.2742,\n",
      "        5.2742, 5.2743, 5.2745, 5.2745, 5.2747, 5.2745, 5.2746, 5.2745, 5.2746,\n",
      "        5.2746, 5.2746, 5.2746, 5.2744, 5.2745, 5.2745, 5.2745, 5.2745, 5.2745,\n",
      "        5.2744, 5.2745, 5.2747, 5.2747, 5.2747, 5.2747, 5.2748, 5.2747, 5.2746,\n",
      "        5.2748, 5.2746, 5.2746, 5.2744, 5.2746, 5.2745, 5.2745, 5.2745, 5.2745,\n",
      "        5.2745, 5.2742, 5.2745], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.393969  [5071724/5599865]\n",
      "average delta from current occupancy tensor([5.2121, 5.2120, 5.2115, 5.2118, 5.2117, 5.2118, 5.2122, 5.2116, 5.2116,\n",
      "        5.2117, 5.2116, 5.2120, 5.2119, 5.2119, 5.2118, 5.2120, 5.2122, 5.2121,\n",
      "        5.2121, 5.2121, 5.2123, 5.2119, 5.2119, 5.2120, 5.2119, 5.2125, 5.2122,\n",
      "        5.2120, 5.2117, 5.2119, 5.2115, 5.2115, 5.2120, 5.2118, 5.2118, 5.2115,\n",
      "        5.2118, 5.2121, 5.2117, 5.2115, 5.2118, 5.2119, 5.2118, 5.2117, 5.2119,\n",
      "        5.2122, 5.2122, 5.2121, 5.2118, 5.2118, 5.2116, 5.2119, 5.2120, 5.2120,\n",
      "        5.2120, 5.2118, 5.2118, 5.2117, 5.2115, 5.2117, 5.2114, 5.2121, 5.2121,\n",
      "        5.2119, 5.2121, 5.2115, 5.2118, 5.2117, 5.2120, 5.2119, 5.2120, 5.2120,\n",
      "        5.2121, 5.2120, 5.2117, 5.2119, 5.2121, 5.2121, 5.2119, 5.2117, 5.2113,\n",
      "        5.2119, 5.2120, 5.2120, 5.2121, 5.2120, 5.2121, 5.2119, 5.2120, 5.2119,\n",
      "        5.2116, 5.2117, 5.2117, 5.2120, 5.2119, 5.2119, 5.2118, 5.2120, 5.2117,\n",
      "        5.2117, 5.2120, 5.2117, 5.2114, 5.2113, 5.2113, 5.2113, 5.2112, 5.2118,\n",
      "        5.2114, 5.2117, 5.2117, 5.2116, 5.2118, 5.2115, 5.2117, 5.2120, 5.2118,\n",
      "        5.2117, 5.2119, 5.2120], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.233365  [5084124/5599865]\n",
      "average delta from current occupancy tensor([5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291, 5.1291,\n",
      "        5.1291, 5.1291, 5.1291], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.293443  [5096524/5599865]\n",
      "average delta from current occupancy tensor([4.2179, 4.2177, 4.2180, 4.2180, 4.2176, 4.2176, 4.2176, 4.2175, 4.2176,\n",
      "        4.2176, 4.2177, 4.2177, 4.2176, 4.2177, 4.2177, 4.2178, 4.2180, 4.2176,\n",
      "        4.2179, 4.2180, 4.2180, 4.2179, 4.2177, 4.2178, 4.2178, 4.2180, 4.2181,\n",
      "        4.2179, 4.2180, 4.2179, 4.2181, 4.2181, 4.2181, 4.2180, 4.2181, 4.2179,\n",
      "        4.2181, 4.2180, 4.2177, 4.2179, 4.2179, 4.2180, 4.2181, 4.2180, 4.2179,\n",
      "        4.2181, 4.2180, 4.2181, 4.2181, 4.2181, 4.2182, 4.2181, 4.2181, 4.2180,\n",
      "        4.2181, 4.2181, 4.2179, 4.2181, 4.2179, 4.2180, 4.2181, 4.2180, 4.2180,\n",
      "        4.2181, 4.2181, 4.2177, 4.2178, 4.2180, 4.2178, 4.2178, 4.2180, 4.2180,\n",
      "        4.2179, 4.2177, 4.2176, 4.2177, 4.2176, 4.2177, 4.2177, 4.2180, 4.2178,\n",
      "        4.2182, 4.2180, 4.2177, 4.2179, 4.2177, 4.2177, 4.2176, 4.2177, 4.2176,\n",
      "        4.2176, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2177, 4.2178, 4.2181,\n",
      "        4.2181, 4.2180, 4.2182, 4.2181, 4.2179, 4.2181, 4.2181, 4.2181, 4.2177,\n",
      "        4.2179, 4.2179, 4.2178, 4.2178, 4.2178, 4.2180, 4.2180, 4.2179, 4.2179,\n",
      "        4.2180, 4.2179, 4.2179], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.634058  [5108924/5599865]\n",
      "average delta from current occupancy tensor([4.7994, 4.7993, 4.7992, 4.7994, 4.7996, 4.7995, 4.7997, 4.7997, 4.7994,\n",
      "        4.7995, 4.7994, 4.7995, 4.7995, 4.7995, 4.7995, 4.7995, 4.7997, 4.7997,\n",
      "        4.7997, 4.7994, 4.7995, 4.7992, 4.7993, 4.7992, 4.7993, 4.7991, 4.7991,\n",
      "        4.7993, 4.7991, 4.7992, 4.7992, 4.7992, 4.7993, 4.7992, 4.7993, 4.7992,\n",
      "        4.7993, 4.7993, 4.7994, 4.7993, 4.7993, 4.7993, 4.7994, 4.7994, 4.7994,\n",
      "        4.7994, 4.7992, 4.7992, 4.7992, 4.7993, 4.7993, 4.7989, 4.7990, 4.7989,\n",
      "        4.7989, 4.7991, 4.7990, 4.7990, 4.7990, 4.7991, 4.7990, 4.7993, 4.7991,\n",
      "        4.7989, 4.7989, 4.7989, 4.7990, 4.7990, 4.7991, 4.7990, 4.7989, 4.7991,\n",
      "        4.7990, 4.7991, 4.7991, 4.7991, 4.7991, 4.7991, 4.7992, 4.7990, 4.7991,\n",
      "        4.7990, 4.7991, 4.7993, 4.7992, 4.7993, 4.7992, 4.7990, 4.7990, 4.7990,\n",
      "        4.7989, 4.7989, 4.7988, 4.7991, 4.7991, 4.7990, 4.7989, 4.7989, 4.7990,\n",
      "        4.7989, 4.7990, 4.7987, 4.7989, 4.7988, 4.7989, 4.7988, 4.7989, 4.7988,\n",
      "        4.7987, 4.7986, 4.7988, 4.7986, 4.7986, 4.7986, 4.7989, 4.7988, 4.7988,\n",
      "        4.7990, 4.7989, 4.7990], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.433713  [5121324/5599865]\n",
      "average delta from current occupancy tensor([5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.938838  [5133724/5599865]\n",
      "average delta from current occupancy tensor([5.9114, 5.9113, 5.9113, 5.9113, 5.9113, 5.9113, 5.9114, 5.9114, 5.9114,\n",
      "        5.9114, 5.9113, 5.9113, 5.9113, 5.9113, 5.9114, 5.9115, 5.9114, 5.9114,\n",
      "        5.9114, 5.9113, 5.9113, 5.9114, 5.9114, 5.9114, 5.9113, 5.9113, 5.9113,\n",
      "        5.9113, 5.9114, 5.9114, 5.9113, 5.9113, 5.9113, 5.9114, 5.9113, 5.9114,\n",
      "        5.9114, 5.9113, 5.9114, 5.9114, 5.9115, 5.9114, 5.9114, 5.9113, 5.9114,\n",
      "        5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9113, 5.9114, 5.9115,\n",
      "        5.9114, 5.9114, 5.9113, 5.9114, 5.9114, 5.9115, 5.9114, 5.9114, 5.9114,\n",
      "        5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9115, 5.9114, 5.9114,\n",
      "        5.9114, 5.9115, 5.9114, 5.9115, 5.9115, 5.9115, 5.9114, 5.9114, 5.9113,\n",
      "        5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9114, 5.9115, 5.9115,\n",
      "        5.9114, 5.9115, 5.9115, 5.9114, 5.9115, 5.9115, 5.9116, 5.9115, 5.9115,\n",
      "        5.9115, 5.9114, 5.9114, 5.9115, 5.9115, 5.9115, 5.9116, 5.9115, 5.9115,\n",
      "        5.9115, 5.9115, 5.9116, 5.9116, 5.9116, 5.9115, 5.9115, 5.9115, 5.9116,\n",
      "        5.9116, 5.9115, 5.9116], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.466152  [5146124/5599865]\n",
      "average delta from current occupancy tensor([5.3465, 5.3465, 5.3465, 5.3466, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465,\n",
      "        5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465,\n",
      "        5.3465, 5.3466, 5.3465, 5.3466, 5.3466, 5.3465, 5.3466, 5.3466, 5.3466,\n",
      "        5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466,\n",
      "        5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3465, 5.3466,\n",
      "        5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466,\n",
      "        5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466, 5.3466,\n",
      "        5.3466, 5.3466, 5.3466, 5.3465, 5.3466, 5.3464, 5.3466, 5.3464, 5.3464,\n",
      "        5.3464, 5.3466, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3466, 5.3465,\n",
      "        5.3466, 5.3466, 5.3466, 5.3466, 5.3465, 5.3465, 5.3466, 5.3466, 5.3465,\n",
      "        5.3465, 5.3466, 5.3466, 5.3466, 5.3466, 5.3465, 5.3465, 5.3465, 5.3465,\n",
      "        5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3465, 5.3464, 5.3464, 5.3464,\n",
      "        5.3464, 5.3464, 5.3464, 5.3465, 5.3464, 5.3464, 5.3464, 5.3465, 5.3465,\n",
      "        5.3464, 5.3464, 5.3464], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.738712  [5158524/5599865]\n",
      "average delta from current occupancy tensor([4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7499, 4.7499, 4.7499,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7499,\n",
      "        4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7499, 4.7498, 4.7499,\n",
      "        4.7498, 4.7499, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7499, 4.7499, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498, 4.7498,\n",
      "        4.7498, 4.7498, 4.7498], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.855220  [5170924/5599865]\n",
      "average delta from current occupancy tensor([4.7264, 4.7262, 4.7262, 4.7263, 4.7265, 4.7264, 4.7263, 4.7261, 4.7262,\n",
      "        4.7262, 4.7263, 4.7263, 4.7262, 4.7263, 4.7262, 4.7260, 4.7261, 4.7261,\n",
      "        4.7262, 4.7262, 4.7261, 4.7262, 4.7262, 4.7262, 4.7262, 4.7262, 4.7262,\n",
      "        4.7262, 4.7262, 4.7260, 4.7258, 4.7258, 4.7259, 4.7258, 4.7258, 4.7261,\n",
      "        4.7261, 4.7258, 4.7258, 4.7258, 4.7258, 4.7259, 4.7258, 4.7258, 4.7258,\n",
      "        4.7258, 4.7260, 4.7259, 4.7259, 4.7260, 4.7260, 4.7258, 4.7261, 4.7260,\n",
      "        4.7261, 4.7260, 4.7261, 4.7261, 4.7263, 4.7262, 4.7261, 4.7262, 4.7260,\n",
      "        4.7261, 4.7262, 4.7261, 4.7263, 4.7261, 4.7262, 4.7262, 4.7262, 4.7263,\n",
      "        4.7262, 4.7264, 4.7262, 4.7264, 4.7264, 4.7264, 4.7264, 4.7263, 4.7263,\n",
      "        4.7263, 4.7261, 4.7263, 4.7262, 4.7262, 4.7262, 4.7262, 4.7261, 4.7264,\n",
      "        4.7263, 4.7262, 4.7262, 4.7263, 4.7264, 4.7264, 4.7264, 4.7264, 4.7261,\n",
      "        4.7263, 4.7264, 4.7261, 4.7261, 4.7262, 4.7263, 4.7263, 4.7262, 4.7262,\n",
      "        4.7262, 4.7262, 4.7263, 4.7264, 4.7264, 4.7264, 4.7263, 4.7264, 4.7264,\n",
      "        4.7264, 4.7263, 4.7264], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.010948  [5183324/5599865]\n",
      "average delta from current occupancy tensor([5.0727, 5.0728, 5.0727, 5.0728, 5.0728, 5.0727, 5.0728, 5.0728, 5.0728,\n",
      "        5.0728, 5.0728, 5.0729, 5.0727, 5.0727, 5.0728, 5.0727, 5.0727, 5.0727,\n",
      "        5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0728, 5.0728, 5.0727,\n",
      "        5.0728, 5.0727, 5.0727, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0726,\n",
      "        5.0726, 5.0728, 5.0727, 5.0727, 5.0729, 5.0728, 5.0728, 5.0728, 5.0728,\n",
      "        5.0729, 5.0728, 5.0727, 5.0727, 5.0727, 5.0728, 5.0728, 5.0728, 5.0728,\n",
      "        5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0728, 5.0728, 5.0728, 5.0728,\n",
      "        5.0727, 5.0727, 5.0728, 5.0727, 5.0728, 5.0728, 5.0728, 5.0727, 5.0728,\n",
      "        5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0729, 5.0728, 5.0728, 5.0727,\n",
      "        5.0728, 5.0728, 5.0727, 5.0728, 5.0727, 5.0728, 5.0727, 5.0727, 5.0727,\n",
      "        5.0726, 5.0727, 5.0728, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727,\n",
      "        5.0728, 5.0728, 5.0727, 5.0727, 5.0727, 5.0728, 5.0728, 5.0727, 5.0727,\n",
      "        5.0726, 5.0727, 5.0727, 5.0728, 5.0727, 5.0728, 5.0727, 5.0727, 5.0727,\n",
      "        5.0727, 5.0726, 5.0726], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.306214  [5195724/5599865]\n",
      "average delta from current occupancy tensor([4.4752, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4752, 4.4752, 4.4752, 4.4751, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4752,\n",
      "        4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4751, 4.4752, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4751, 4.4752, 4.4751, 4.4751, 4.4751, 4.4751, 4.4752,\n",
      "        4.4752, 4.4751, 4.4752, 4.4751, 4.4752, 4.4751, 4.4751, 4.4751, 4.4751,\n",
      "        4.4752, 4.4751, 4.4751, 4.4751, 4.4751, 4.4752, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4750, 4.4750, 4.4751, 4.4751, 4.4750, 4.4750, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4752, 4.4751, 4.4752, 4.4752, 4.4751, 4.4751, 4.4751,\n",
      "        4.4751, 4.4751, 4.4751, 4.4750, 4.4750, 4.4750, 4.4751, 4.4751, 4.4752,\n",
      "        4.4751, 4.4751, 4.4751], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.382187  [5208124/5599865]\n",
      "average delta from current occupancy tensor([4.3577, 4.3576, 4.3577, 4.3577, 4.3581, 4.3583, 4.3578, 4.3577, 4.3575,\n",
      "        4.3574, 4.3573, 4.3571, 4.3570, 4.3572, 4.3574, 4.3574, 4.3572, 4.3571,\n",
      "        4.3573, 4.3575, 4.3580, 4.3573, 4.3573, 4.3576, 4.3574, 4.3570, 4.3579,\n",
      "        4.3581, 4.3578, 4.3578, 4.3581, 4.3580, 4.3577, 4.3575, 4.3574, 4.3574,\n",
      "        4.3576, 4.3573, 4.3574, 4.3572, 4.3573, 4.3569, 4.3572, 4.3573, 4.3572,\n",
      "        4.3575, 4.3579, 4.3576, 4.3577, 4.3577, 4.3571, 4.3574, 4.3574, 4.3575,\n",
      "        4.3571, 4.3576, 4.3576, 4.3577, 4.3572, 4.3570, 4.3571, 4.3569, 4.3571,\n",
      "        4.3575, 4.3571, 4.3576, 4.3568, 4.3570, 4.3571, 4.3573, 4.3570, 4.3570,\n",
      "        4.3569, 4.3571, 4.3570, 4.3569, 4.3570, 4.3571, 4.3571, 4.3572, 4.3577,\n",
      "        4.3568, 4.3567, 4.3570, 4.3569, 4.3569, 4.3570, 4.3572, 4.3573, 4.3569,\n",
      "        4.3570, 4.3574, 4.3575, 4.3572, 4.3569, 4.3578, 4.3571, 4.3567, 4.3569,\n",
      "        4.3568, 4.3567, 4.3565, 4.3565, 4.3565, 4.3566, 4.3566, 4.3565, 4.3566,\n",
      "        4.3568, 4.3568, 4.3569, 4.3570, 4.3567, 4.3569, 4.3571, 4.3568, 4.3569,\n",
      "        4.3569, 4.3572, 4.3573], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.847306  [5220524/5599865]\n",
      "average delta from current occupancy tensor([4.9447, 4.9448, 4.9448, 4.9448, 4.9444, 4.9443, 4.9445, 4.9449, 4.9448,\n",
      "        4.9451, 4.9452, 4.9453, 4.9452, 4.9450, 4.9449, 4.9448, 4.9450, 4.9449,\n",
      "        4.9447, 4.9446, 4.9442, 4.9447, 4.9449, 4.9446, 4.9446, 4.9445, 4.9438,\n",
      "        4.9437, 4.9439, 4.9441, 4.9440, 4.9441, 4.9442, 4.9443, 4.9446, 4.9446,\n",
      "        4.9444, 4.9447, 4.9447, 4.9447, 4.9448, 4.9451, 4.9450, 4.9447, 4.9447,\n",
      "        4.9447, 4.9446, 4.9450, 4.9446, 4.9448, 4.9450, 4.9449, 4.9451, 4.9452,\n",
      "        4.9453, 4.9450, 4.9450, 4.9450, 4.9453, 4.9453, 4.9453, 4.9453, 4.9452,\n",
      "        4.9448, 4.9453, 4.9450, 4.9455, 4.9455, 4.9456, 4.9456, 4.9454, 4.9455,\n",
      "        4.9455, 4.9453, 4.9453, 4.9454, 4.9453, 4.9453, 4.9453, 4.9451, 4.9447,\n",
      "        4.9453, 4.9454, 4.9452, 4.9455, 4.9456, 4.9454, 4.9451, 4.9449, 4.9452,\n",
      "        4.9451, 4.9449, 4.9448, 4.9450, 4.9454, 4.9448, 4.9453, 4.9456, 4.9456,\n",
      "        4.9460, 4.9461, 4.9462, 4.9458, 4.9460, 4.9461, 4.9460, 4.9461, 4.9460,\n",
      "        4.9458, 4.9457, 4.9458, 4.9458, 4.9460, 4.9458, 4.9459, 4.9459, 4.9459,\n",
      "        4.9457, 4.9456, 4.9454], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.382070  [5232924/5599865]\n",
      "average delta from current occupancy tensor([5.3473, 5.3471, 5.3473, 5.3470, 5.3470, 5.3470, 5.3470, 5.3471, 5.3471,\n",
      "        5.3471, 5.3467, 5.3470, 5.3468, 5.3471, 5.3469, 5.3468, 5.3467, 5.3467,\n",
      "        5.3468, 5.3467, 5.3468, 5.3468, 5.3467, 5.3468, 5.3467, 5.3470, 5.3470,\n",
      "        5.3471, 5.3472, 5.3471, 5.3472, 5.3472, 5.3472, 5.3473, 5.3472, 5.3474,\n",
      "        5.3472, 5.3473, 5.3473, 5.3473, 5.3472, 5.3473, 5.3474, 5.3473, 5.3472,\n",
      "        5.3473, 5.3473, 5.3472, 5.3471, 5.3471, 5.3471, 5.3474, 5.3472, 5.3474,\n",
      "        5.3469, 5.3472, 5.3472, 5.3469, 5.3467, 5.3468, 5.3468, 5.3468, 5.3467,\n",
      "        5.3471, 5.3467, 5.3471, 5.3468, 5.3469, 5.3470, 5.3472, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3467, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3467, 5.3468, 5.3468, 5.3468, 5.3473, 5.3468, 5.3467, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3469, 5.3468, 5.3470, 5.3467, 5.3468, 5.3468,\n",
      "        5.3472, 5.3469, 5.3471, 5.3473, 5.3472, 5.3471, 5.3471, 5.3471, 5.3470,\n",
      "        5.3471, 5.3472, 5.3471, 5.3473, 5.3472, 5.3472, 5.3473, 5.3472, 5.3472,\n",
      "        5.3468, 5.3468, 5.3468], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.313595  [5245324/5599865]\n",
      "average delta from current occupancy tensor([5.3715, 5.3716, 5.3716, 5.3717, 5.3716, 5.3715, 5.3716, 5.3716, 5.3717,\n",
      "        5.3714, 5.3715, 5.3716, 5.3715, 5.3716, 5.3716, 5.3716, 5.3715, 5.3716,\n",
      "        5.3716, 5.3716, 5.3716, 5.3716, 5.3717, 5.3717, 5.3716, 5.3717, 5.3717,\n",
      "        5.3717, 5.3715, 5.3717, 5.3717, 5.3717, 5.3717, 5.3717, 5.3716, 5.3715,\n",
      "        5.3716, 5.3716, 5.3716, 5.3716, 5.3716, 5.3715, 5.3714, 5.3716, 5.3716,\n",
      "        5.3716, 5.3716, 5.3716, 5.3715, 5.3715, 5.3716, 5.3715, 5.3715, 5.3715,\n",
      "        5.3716, 5.3716, 5.3716, 5.3716, 5.3716, 5.3716, 5.3715, 5.3715, 5.3714,\n",
      "        5.3716, 5.3714, 5.3716, 5.3714, 5.3716, 5.3716, 5.3715, 5.3716, 5.3716,\n",
      "        5.3715, 5.3715, 5.3715, 5.3715, 5.3715, 5.3714, 5.3715, 5.3716, 5.3715,\n",
      "        5.3715, 5.3716, 5.3715, 5.3716, 5.3716, 5.3715, 5.3715, 5.3715, 5.3715,\n",
      "        5.3716, 5.3716, 5.3716, 5.3716, 5.3717, 5.3715, 5.3717, 5.3717, 5.3719,\n",
      "        5.3716, 5.3717, 5.3716, 5.3715, 5.3717, 5.3716, 5.3715, 5.3715, 5.3715,\n",
      "        5.3715, 5.3715, 5.3716, 5.3716, 5.3715, 5.3716, 5.3716, 5.3716, 5.3716,\n",
      "        5.3715, 5.3716, 5.3716], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.321947  [5257724/5599865]\n",
      "average delta from current occupancy tensor([5.3712, 5.3713, 5.3712, 5.3713, 5.3713, 5.3712, 5.3713, 5.3713, 5.3712,\n",
      "        5.3712, 5.3712, 5.3713, 5.3713, 5.3713, 5.3713, 5.3713, 5.3713, 5.3713,\n",
      "        5.3713, 5.3713, 5.3713, 5.3712, 5.3712, 5.3711, 5.3711, 5.3711, 5.3712,\n",
      "        5.3713, 5.3714, 5.3712, 5.3713, 5.3713, 5.3712, 5.3713, 5.3714, 5.3713,\n",
      "        5.3713, 5.3713, 5.3713, 5.3713, 5.3713, 5.3713, 5.3713, 5.3713, 5.3712,\n",
      "        5.3712, 5.3713, 5.3713, 5.3712, 5.3713, 5.3712, 5.3712, 5.3712, 5.3712,\n",
      "        5.3713, 5.3713, 5.3713, 5.3712, 5.3714, 5.3714, 5.3714, 5.3714, 5.3713,\n",
      "        5.3714, 5.3713, 5.3714, 5.3714, 5.3714, 5.3714, 5.3714, 5.3714, 5.3714,\n",
      "        5.3714, 5.3713, 5.3714, 5.3714, 5.3713, 5.3713, 5.3712, 5.3713, 5.3713,\n",
      "        5.3713, 5.3714, 5.3714, 5.3714, 5.3714, 5.3713, 5.3713, 5.3713, 5.3713,\n",
      "        5.3712, 5.3714, 5.3714, 5.3714, 5.3713, 5.3712, 5.3714, 5.3712, 5.3713,\n",
      "        5.3714, 5.3714, 5.3715, 5.3716, 5.3714, 5.3715, 5.3714, 5.3713, 5.3714,\n",
      "        5.3713, 5.3714, 5.3714, 5.3714, 5.3713, 5.3713, 5.3713, 5.3715, 5.3714,\n",
      "        5.3715, 5.3715, 5.3715], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.625335  [5270124/5599865]\n",
      "average delta from current occupancy tensor([4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452, 4.6452,\n",
      "        4.6452, 4.6452, 4.6452], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.865368  [5282524/5599865]\n",
      "average delta from current occupancy tensor([5.9678, 5.9678, 5.9680, 5.9679, 5.9680, 5.9680, 5.9680, 5.9680, 5.9679,\n",
      "        5.9679, 5.9678, 5.9678, 5.9679, 5.9678, 5.9679, 5.9678, 5.9678, 5.9679,\n",
      "        5.9678, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9678, 5.9679, 5.9678,\n",
      "        5.9678, 5.9679, 5.9679, 5.9678, 5.9679, 5.9678, 5.9678, 5.9680, 5.9678,\n",
      "        5.9681, 5.9680, 5.9678, 5.9679, 5.9679, 5.9681, 5.9678, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9680, 5.9679, 5.9678, 5.9678, 5.9678, 5.9678, 5.9681,\n",
      "        5.9679, 5.9679, 5.9678, 5.9681, 5.9679, 5.9681, 5.9681, 5.9682, 5.9681,\n",
      "        5.9682, 5.9681, 5.9682, 5.9682, 5.9681, 5.9682, 5.9680, 5.9681, 5.9680,\n",
      "        5.9678, 5.9678, 5.9679, 5.9679, 5.9680, 5.9680, 5.9681, 5.9681, 5.9682,\n",
      "        5.9682, 5.9681, 5.9678, 5.9680, 5.9680, 5.9679, 5.9680, 5.9681, 5.9678,\n",
      "        5.9681, 5.9679, 5.9678, 5.9678, 5.9679, 5.9679, 5.9679, 5.9678, 5.9680,\n",
      "        5.9678, 5.9678, 5.9678, 5.9680, 5.9679, 5.9678, 5.9678, 5.9678, 5.9678,\n",
      "        5.9678, 5.9678, 5.9678, 5.9678, 5.9679, 5.9678, 5.9679, 5.9678, 5.9680,\n",
      "        5.9678, 5.9678, 5.9679], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.006660  [5294924/5599865]\n",
      "average delta from current occupancy tensor([4.9681, 4.9681, 4.9681, 4.9681, 4.9680, 4.9681, 4.9681, 4.9681, 4.9681,\n",
      "        4.9681, 4.9680, 4.9681, 4.9681, 4.9681, 4.9681, 4.9681, 4.9681, 4.9682,\n",
      "        4.9682, 4.9682, 4.9682, 4.9682, 4.9681, 4.9682, 4.9682, 4.9682, 4.9682,\n",
      "        4.9681, 4.9682, 4.9681, 4.9681, 4.9681, 4.9681, 4.9681, 4.9681, 4.9680,\n",
      "        4.9681, 4.9681, 4.9680, 4.9680, 4.9680, 4.9680, 4.9680, 4.9680, 4.9680,\n",
      "        4.9680, 4.9680, 4.9681, 4.9681, 4.9680, 4.9680, 4.9680, 4.9680, 4.9681,\n",
      "        4.9681, 4.9681, 4.9680, 4.9681, 4.9681, 4.9681, 4.9681, 4.9680, 4.9680,\n",
      "        4.9680, 4.9680, 4.9680, 4.9681, 4.9681, 4.9681, 4.9681, 4.9681, 4.9681,\n",
      "        4.9680, 4.9680, 4.9680, 4.9681, 4.9681, 4.9681, 4.9680, 4.9681, 4.9680,\n",
      "        4.9681, 4.9681, 4.9680, 4.9681, 4.9681, 4.9680, 4.9681, 4.9680, 4.9680,\n",
      "        4.9681, 4.9680, 4.9680, 4.9680, 4.9680, 4.9681, 4.9681, 4.9681, 4.9681,\n",
      "        4.9681, 4.9680, 4.9680, 4.9681, 4.9681, 4.9680, 4.9680, 4.9681, 4.9681,\n",
      "        4.9681, 4.9680, 4.9680, 4.9681, 4.9682, 4.9682, 4.9681, 4.9681, 4.9681,\n",
      "        4.9681, 4.9681, 4.9682], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.488283  [5307324/5599865]\n",
      "average delta from current occupancy tensor([5.3877, 5.3875, 5.3875, 5.3876, 5.3876, 5.3875, 5.3876, 5.3875, 5.3874,\n",
      "        5.3875, 5.3876, 5.3876, 5.3875, 5.3874, 5.3876, 5.3876, 5.3876, 5.3876,\n",
      "        5.3876, 5.3876, 5.3876, 5.3875, 5.3875, 5.3875, 5.3876, 5.3873, 5.3875,\n",
      "        5.3875, 5.3875, 5.3874, 5.3874, 5.3875, 5.3874, 5.3877, 5.3875, 5.3873,\n",
      "        5.3878, 5.3876, 5.3874, 5.3873, 5.3874, 5.3875, 5.3876, 5.3876, 5.3876,\n",
      "        5.3874, 5.3873, 5.3875, 5.3874, 5.3875, 5.3876, 5.3873, 5.3876, 5.3877,\n",
      "        5.3877, 5.3876, 5.3877, 5.3876, 5.3875, 5.3874, 5.3875, 5.3877, 5.3875,\n",
      "        5.3875, 5.3875, 5.3874, 5.3875, 5.3876, 5.3876, 5.3876, 5.3876, 5.3875,\n",
      "        5.3872, 5.3873, 5.3876, 5.3876, 5.3874, 5.3875, 5.3873, 5.3875, 5.3875,\n",
      "        5.3875, 5.3876, 5.3876, 5.3875, 5.3876, 5.3876, 5.3875, 5.3877, 5.3874,\n",
      "        5.3877, 5.3876, 5.3878, 5.3876, 5.3877, 5.3875, 5.3875, 5.3876, 5.3877,\n",
      "        5.3875, 5.3874, 5.3875, 5.3876, 5.3871, 5.3876, 5.3876, 5.3875, 5.3872,\n",
      "        5.3875, 5.3872, 5.3877, 5.3876, 5.3872, 5.3876, 5.3877, 5.3877, 5.3872,\n",
      "        5.3878, 5.3875, 5.3877], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.638468  [5319724/5599865]\n",
      "average delta from current occupancy tensor([4.5400, 4.5400, 4.5400, 4.5399, 4.5400, 4.5399, 4.5399, 4.5400, 4.5400,\n",
      "        4.5400, 4.5400, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399,\n",
      "        4.5400, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399,\n",
      "        4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399,\n",
      "        4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5399,\n",
      "        4.5399, 4.5399, 4.5399, 4.5399, 4.5400, 4.5399, 4.5400, 4.5400, 4.5400,\n",
      "        4.5399, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400,\n",
      "        4.5400, 4.5399, 4.5400, 4.5400, 4.5400, 4.5399, 4.5400, 4.5400, 4.5399,\n",
      "        4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400,\n",
      "        4.5400, 4.5400, 4.5400, 4.5400, 4.5399, 4.5400, 4.5400, 4.5400, 4.5400,\n",
      "        4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5399,\n",
      "        4.5400, 4.5400, 4.5400, 4.5400, 4.5400, 4.5399, 4.5399, 4.5399, 4.5399,\n",
      "        4.5399, 4.5399, 4.5399, 4.5399, 4.5399, 4.5400, 4.5400, 4.5399, 4.5399,\n",
      "        4.5400, 4.5400, 4.5399], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.919554  [5332124/5599865]\n",
      "average delta from current occupancy tensor([4.8682, 4.8682, 4.8682, 4.8682, 4.8682, 4.8682, 4.8681, 4.8682, 4.8684,\n",
      "        4.8684, 4.8685, 4.8685, 4.8683, 4.8683, 4.8683, 4.8681, 4.8682, 4.8681,\n",
      "        4.8683, 4.8682, 4.8681, 4.8682, 4.8682, 4.8683, 4.8684, 4.8681, 4.8681,\n",
      "        4.8681, 4.8681, 4.8681, 4.8682, 4.8683, 4.8682, 4.8681, 4.8684, 4.8684,\n",
      "        4.8684, 4.8685, 4.8684, 4.8683, 4.8683, 4.8682, 4.8683, 4.8686, 4.8686,\n",
      "        4.8686, 4.8685, 4.8685, 4.8683, 4.8685, 4.8683, 4.8683, 4.8685, 4.8683,\n",
      "        4.8683, 4.8687, 4.8685, 4.8685, 4.8684, 4.8685, 4.8686, 4.8684, 4.8683,\n",
      "        4.8685, 4.8684, 4.8685, 4.8685, 4.8684, 4.8683, 4.8683, 4.8683, 4.8682,\n",
      "        4.8683, 4.8682, 4.8683, 4.8683, 4.8684, 4.8685, 4.8685, 4.8684, 4.8685,\n",
      "        4.8685, 4.8686, 4.8689, 4.8688, 4.8686, 4.8689, 4.8689, 4.8690, 4.8689,\n",
      "        4.8690, 4.8689, 4.8690, 4.8689, 4.8688, 4.8688, 4.8687, 4.8686, 4.8686,\n",
      "        4.8686, 4.8686, 4.8684, 4.8683, 4.8683, 4.8680, 4.8681, 4.8682, 4.8682,\n",
      "        4.8683, 4.8683, 4.8683, 4.8683, 4.8684, 4.8685, 4.8686, 4.8679, 4.8682,\n",
      "        4.8683, 4.8685, 4.8683], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.404700  [5344524/5599865]\n",
      "average delta from current occupancy tensor([5.5329, 5.5330, 5.5330, 5.5329, 5.5331, 5.5331, 5.5331, 5.5331, 5.5330,\n",
      "        5.5330, 5.5331, 5.5330, 5.5332, 5.5332, 5.5331, 5.5331, 5.5331, 5.5332,\n",
      "        5.5331, 5.5330, 5.5332, 5.5332, 5.5333, 5.5331, 5.5330, 5.5332, 5.5331,\n",
      "        5.5332, 5.5332, 5.5331, 5.5331, 5.5328, 5.5330, 5.5330, 5.5328, 5.5328,\n",
      "        5.5328, 5.5329, 5.5329, 5.5329, 5.5329, 5.5329, 5.5328, 5.5327, 5.5327,\n",
      "        5.5327, 5.5327, 5.5327, 5.5330, 5.5328, 5.5330, 5.5331, 5.5329, 5.5330,\n",
      "        5.5328, 5.5327, 5.5329, 5.5329, 5.5328, 5.5327, 5.5327, 5.5327, 5.5328,\n",
      "        5.5326, 5.5325, 5.5325, 5.5325, 5.5324, 5.5325, 5.5325, 5.5326, 5.5326,\n",
      "        5.5325, 5.5324, 5.5326, 5.5325, 5.5326, 5.5324, 5.5325, 5.5325, 5.5326,\n",
      "        5.5325, 5.5326, 5.5327, 5.5325, 5.5323, 5.5326, 5.5327, 5.5327, 5.5326,\n",
      "        5.5327, 5.5327, 5.5327, 5.5326, 5.5325, 5.5324, 5.5324, 5.5324, 5.5324,\n",
      "        5.5324, 5.5326, 5.5325, 5.5326, 5.5325, 5.5326, 5.5324, 5.5324, 5.5324,\n",
      "        5.5324, 5.5324, 5.5325, 5.5326, 5.5325, 5.5325, 5.5327, 5.5329, 5.5327,\n",
      "        5.5326, 5.5325, 5.5325], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.138226  [5356924/5599865]\n",
      "average delta from current occupancy tensor([5.0576, 5.0576, 5.0575, 5.0576, 5.0575, 5.0574, 5.0575, 5.0576, 5.0574,\n",
      "        5.0574, 5.0577, 5.0576, 5.0576, 5.0575, 5.0575, 5.0576, 5.0576, 5.0578,\n",
      "        5.0576, 5.0576, 5.0578, 5.0576, 5.0577, 5.0577, 5.0575, 5.0577, 5.0577,\n",
      "        5.0574, 5.0574, 5.0573, 5.0577, 5.0575, 5.0578, 5.0577, 5.0574, 5.0576,\n",
      "        5.0576, 5.0578, 5.0577, 5.0577, 5.0576, 5.0576, 5.0575, 5.0574, 5.0574,\n",
      "        5.0574, 5.0577, 5.0575, 5.0576, 5.0574, 5.0575, 5.0577, 5.0578, 5.0576,\n",
      "        5.0577, 5.0575, 5.0576, 5.0576, 5.0576, 5.0574, 5.0574, 5.0575, 5.0575,\n",
      "        5.0575, 5.0574, 5.0575, 5.0576, 5.0577, 5.0576, 5.0577, 5.0573, 5.0573,\n",
      "        5.0577, 5.0573, 5.0575, 5.0575, 5.0574, 5.0573, 5.0573, 5.0576, 5.0574,\n",
      "        5.0578, 5.0572, 5.0575, 5.0575, 5.0576, 5.0572, 5.0575, 5.0576, 5.0573,\n",
      "        5.0573, 5.0574, 5.0576, 5.0574, 5.0574, 5.0574, 5.0576, 5.0577, 5.0579,\n",
      "        5.0575, 5.0574, 5.0574, 5.0578, 5.0578, 5.0577, 5.0578, 5.0577, 5.0579,\n",
      "        5.0577, 5.0577, 5.0577, 5.0576, 5.0578, 5.0575, 5.0574, 5.0576, 5.0575,\n",
      "        5.0575, 5.0578, 5.0579], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.828568  [5369324/5599865]\n",
      "average delta from current occupancy tensor([4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257, 4.7257,\n",
      "        4.7257, 4.7257, 4.7257], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.205890  [5381724/5599865]\n",
      "average delta from current occupancy tensor([5.1044, 5.1044, 5.1045, 5.1045, 5.1045, 5.1045, 5.1046, 5.1045, 5.1045,\n",
      "        5.1045, 5.1045, 5.1045, 5.1044, 5.1045, 5.1046, 5.1046, 5.1045, 5.1045,\n",
      "        5.1045, 5.1045, 5.1045, 5.1045, 5.1047, 5.1046, 5.1047, 5.1046, 5.1047,\n",
      "        5.1047, 5.1047, 5.1047, 5.1046, 5.1047, 5.1046, 5.1046, 5.1046, 5.1046,\n",
      "        5.1046, 5.1046, 5.1047, 5.1046, 5.1047, 5.1046, 5.1046, 5.1047, 5.1046,\n",
      "        5.1046, 5.1046, 5.1045, 5.1045, 5.1046, 5.1045, 5.1045, 5.1045, 5.1045,\n",
      "        5.1045, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1047,\n",
      "        5.1046, 5.1047, 5.1046, 5.1047, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046,\n",
      "        5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046,\n",
      "        5.1046, 5.1046, 5.1047, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046, 5.1046,\n",
      "        5.1047, 5.1047, 5.1046, 5.1046, 5.1047, 5.1047, 5.1046, 5.1047, 5.1047,\n",
      "        5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047,\n",
      "        5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1047, 5.1046,\n",
      "        5.1047, 5.1047, 5.1047], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.704515  [5394124/5599865]\n",
      "average delta from current occupancy tensor([4.5968, 4.5968, 4.5968, 4.5969, 4.5969, 4.5970, 4.5970, 4.5969, 4.5969,\n",
      "        4.5969, 4.5969, 4.5969, 4.5969, 4.5968, 4.5968, 4.5972, 4.5972, 4.5968,\n",
      "        4.5969, 4.5969, 4.5970, 4.5972, 4.5970, 4.5974, 4.5973, 4.5973, 4.5972,\n",
      "        4.5972, 4.5972, 4.5972, 4.5973, 4.5972, 4.5973, 4.5973, 4.5973, 4.5971,\n",
      "        4.5973, 4.5970, 4.5970, 4.5972, 4.5973, 4.5971, 4.5970, 4.5972, 4.5971,\n",
      "        4.5971, 4.5971, 4.5971, 4.5972, 4.5972, 4.5973, 4.5971, 4.5971, 4.5972,\n",
      "        4.5972, 4.5972, 4.5972, 4.5971, 4.5971, 4.5969, 4.5971, 4.5973, 4.5973,\n",
      "        4.5974, 4.5971, 4.5971, 4.5971, 4.5972, 4.5974, 4.5974, 4.5972, 4.5973,\n",
      "        4.5971, 4.5970, 4.5972, 4.5969, 4.5971, 4.5970, 4.5972, 4.5973, 4.5973,\n",
      "        4.5970, 4.5971, 4.5970, 4.5968, 4.5969, 4.5969, 4.5968, 4.5969, 4.5969,\n",
      "        4.5971, 4.5969, 4.5969, 4.5968, 4.5968, 4.5968, 4.5969, 4.5970, 4.5975,\n",
      "        4.5973, 4.5973, 4.5970, 4.5972, 4.5971, 4.5974, 4.5973, 4.5973, 4.5972,\n",
      "        4.5973, 4.5972, 4.5972, 4.5972, 4.5971, 4.5971, 4.5969, 4.5971, 4.5968,\n",
      "        4.5971, 4.5972, 4.5972], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.835191  [5406524/5599865]\n",
      "average delta from current occupancy tensor([4.8549, 4.8549, 4.8551, 4.8552, 4.8552, 4.8551, 4.8552, 4.8551, 4.8554,\n",
      "        4.8553, 4.8553, 4.8556, 4.8555, 4.8554, 4.8556, 4.8558, 4.8552, 4.8556,\n",
      "        4.8551, 4.8550, 4.8552, 4.8549, 4.8549, 4.8550, 4.8551, 4.8548, 4.8550,\n",
      "        4.8553, 4.8550, 4.8550, 4.8550, 4.8549, 4.8554, 4.8551, 4.8553, 4.8550,\n",
      "        4.8552, 4.8548, 4.8546, 4.8547, 4.8550, 4.8548, 4.8547, 4.8548, 4.8551,\n",
      "        4.8548, 4.8548, 4.8550, 4.8551, 4.8550, 4.8552, 4.8546, 4.8545, 4.8546,\n",
      "        4.8549, 4.8549, 4.8547, 4.8547, 4.8546, 4.8548, 4.8548, 4.8548, 4.8551,\n",
      "        4.8551, 4.8553, 4.8547, 4.8547, 4.8546, 4.8548, 4.8549, 4.8546, 4.8551,\n",
      "        4.8548, 4.8546, 4.8550, 4.8549, 4.8550, 4.8548, 4.8550, 4.8552, 4.8555,\n",
      "        4.8554, 4.8552, 4.8552, 4.8552, 4.8553, 4.8555, 4.8553, 4.8554, 4.8554,\n",
      "        4.8552, 4.8553, 4.8551, 4.8551, 4.8550, 4.8550, 4.8549, 4.8550, 4.8551,\n",
      "        4.8552, 4.8550, 4.8548, 4.8550, 4.8550, 4.8552, 4.8555, 4.8556, 4.8553,\n",
      "        4.8554, 4.8554, 4.8556, 4.8555, 4.8557, 4.8556, 4.8556, 4.8556, 4.8556,\n",
      "        4.8556, 4.8555, 4.8555], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.576558  [5418924/5599865]\n",
      "average delta from current occupancy tensor([5.5984, 5.5983, 5.5985, 5.5985, 5.5988, 5.5986, 5.5987, 5.5986, 5.5985,\n",
      "        5.5984, 5.5984, 5.5987, 5.5987, 5.5985, 5.5989, 5.5988, 5.5985, 5.5986,\n",
      "        5.5983, 5.5982, 5.5983, 5.5982, 5.5983, 5.5984, 5.5984, 5.5981, 5.5980,\n",
      "        5.5982, 5.5982, 5.5982, 5.5982, 5.5984, 5.5988, 5.5985, 5.5986, 5.5985,\n",
      "        5.5987, 5.5980, 5.5976, 5.5976, 5.5980, 5.5982, 5.5978, 5.5979, 5.5979,\n",
      "        5.5981, 5.5979, 5.5978, 5.5978, 5.5975, 5.5978, 5.5977, 5.5975, 5.5975,\n",
      "        5.5979, 5.5979, 5.5977, 5.5977, 5.5980, 5.5981, 5.5982, 5.5981, 5.5983,\n",
      "        5.5983, 5.5984, 5.5978, 5.5979, 5.5980, 5.5980, 5.5983, 5.5977, 5.5981,\n",
      "        5.5975, 5.5977, 5.5982, 5.5983, 5.5982, 5.5982, 5.5983, 5.5986, 5.5984,\n",
      "        5.5986, 5.5987, 5.5988, 5.5985, 5.5986, 5.5986, 5.5984, 5.5985, 5.5986,\n",
      "        5.5984, 5.5985, 5.5985, 5.5985, 5.5987, 5.5986, 5.5986, 5.5984, 5.5985,\n",
      "        5.5985, 5.5986, 5.5986, 5.5983, 5.5986, 5.5987, 5.5991, 5.5988, 5.5985,\n",
      "        5.5988, 5.5989, 5.5989, 5.5988, 5.5987, 5.5986, 5.5985, 5.5985, 5.5982,\n",
      "        5.5983, 5.5982, 5.5981], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.712734  [5431324/5599865]\n",
      "average delta from current occupancy tensor([5.7409, 5.7410, 5.7410, 5.7410, 5.7410, 5.7410, 5.7410, 5.7412, 5.7411,\n",
      "        5.7411, 5.7409, 5.7409, 5.7409, 5.7408, 5.7410, 5.7410, 5.7409, 5.7411,\n",
      "        5.7410, 5.7410, 5.7410, 5.7410, 5.7410, 5.7409, 5.7408, 5.7408, 5.7407,\n",
      "        5.7408, 5.7409, 5.7409, 5.7409, 5.7409, 5.7408, 5.7407, 5.7407, 5.7407,\n",
      "        5.7407, 5.7408, 5.7408, 5.7407, 5.7408, 5.7407, 5.7407, 5.7407, 5.7407,\n",
      "        5.7409, 5.7409, 5.7408, 5.7408, 5.7408, 5.7407, 5.7406, 5.7407, 5.7408,\n",
      "        5.7407, 5.7407, 5.7407, 5.7406, 5.7407, 5.7406, 5.7406, 5.7405, 5.7405,\n",
      "        5.7406, 5.7405, 5.7406, 5.7407, 5.7407, 5.7408, 5.7409, 5.7408, 5.7407,\n",
      "        5.7407, 5.7408, 5.7408, 5.7409, 5.7407, 5.7406, 5.7408, 5.7407, 5.7407,\n",
      "        5.7408, 5.7406, 5.7407, 5.7405, 5.7405, 5.7405, 5.7405, 5.7407, 5.7406,\n",
      "        5.7406, 5.7407, 5.7406, 5.7407, 5.7405, 5.7406, 5.7406, 5.7404, 5.7405,\n",
      "        5.7405, 5.7403, 5.7404, 5.7404, 5.7405, 5.7405, 5.7405, 5.7404, 5.7404,\n",
      "        5.7405, 5.7405, 5.7406, 5.7405, 5.7406, 5.7406, 5.7408, 5.7408, 5.7409,\n",
      "        5.7408, 5.7409, 5.7410], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.078281  [5443724/5599865]\n",
      "average delta from current occupancy tensor([5.1467, 5.1465, 5.1464, 5.1455, 5.1457, 5.1455, 5.1459, 5.1457, 5.1456,\n",
      "        5.1456, 5.1465, 5.1465, 5.1464, 5.1464, 5.1456, 5.1455, 5.1461, 5.1457,\n",
      "        5.1461, 5.1460, 5.1460, 5.1463, 5.1466, 5.1468, 5.1465, 5.1464, 5.1466,\n",
      "        5.1466, 5.1461, 5.1461, 5.1463, 5.1462, 5.1462, 5.1467, 5.1464, 5.1463,\n",
      "        5.1463, 5.1457, 5.1460, 5.1460, 5.1460, 5.1461, 5.1459, 5.1461, 5.1462,\n",
      "        5.1459, 5.1461, 5.1461, 5.1460, 5.1460, 5.1463, 5.1461, 5.1461, 5.1459,\n",
      "        5.1462, 5.1460, 5.1462, 5.1463, 5.1462, 5.1462, 5.1461, 5.1455, 5.1459,\n",
      "        5.1457, 5.1455, 5.1460, 5.1460, 5.1459, 5.1459, 5.1456, 5.1456, 5.1463,\n",
      "        5.1461, 5.1460, 5.1461, 5.1459, 5.1458, 5.1458, 5.1456, 5.1460, 5.1458,\n",
      "        5.1461, 5.1461, 5.1459, 5.1462, 5.1459, 5.1461, 5.1459, 5.1460, 5.1461,\n",
      "        5.1461, 5.1460, 5.1466, 5.1467, 5.1466, 5.1465, 5.1466, 5.1462, 5.1466,\n",
      "        5.1467, 5.1464, 5.1466, 5.1461, 5.1469, 5.1467, 5.1467, 5.1464, 5.1463,\n",
      "        5.1467, 5.1469, 5.1466, 5.1469, 5.1465, 5.1463, 5.1461, 5.1464, 5.1465,\n",
      "        5.1464, 5.1463, 5.1463], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.661098  [5456124/5599865]\n",
      "average delta from current occupancy tensor([4.6620, 4.6620, 4.6619, 4.6619, 4.6619, 4.6619, 4.6619, 4.6619, 4.6620,\n",
      "        4.6619, 4.6620, 4.6621, 4.6620, 4.6620, 4.6620, 4.6620, 4.6620, 4.6620,\n",
      "        4.6619, 4.6619, 4.6621, 4.6620, 4.6620, 4.6620, 4.6620, 4.6620, 4.6620,\n",
      "        4.6619, 4.6618, 4.6620, 4.6619, 4.6619, 4.6619, 4.6618, 4.6618, 4.6617,\n",
      "        4.6618, 4.6618, 4.6618, 4.6618, 4.6618, 4.6618, 4.6618, 4.6619, 4.6618,\n",
      "        4.6618, 4.6619, 4.6619, 4.6619, 4.6619, 4.6620, 4.6619, 4.6620, 4.6619,\n",
      "        4.6620, 4.6619, 4.6619, 4.6620, 4.6620, 4.6621, 4.6621, 4.6621, 4.6620,\n",
      "        4.6620, 4.6619, 4.6619, 4.6619, 4.6618, 4.6619, 4.6619, 4.6619, 4.6619,\n",
      "        4.6619, 4.6619, 4.6619, 4.6619, 4.6619, 4.6619, 4.6619, 4.6620, 4.6620,\n",
      "        4.6620, 4.6619, 4.6620, 4.6618, 4.6618, 4.6617, 4.6618, 4.6618, 4.6619,\n",
      "        4.6619, 4.6620, 4.6620, 4.6621, 4.6620, 4.6621, 4.6621, 4.6621, 4.6621,\n",
      "        4.6621, 4.6621, 4.6621, 4.6620, 4.6620, 4.6620, 4.6620, 4.6620, 4.6620,\n",
      "        4.6620, 4.6620, 4.6619, 4.6619, 4.6620, 4.6620, 4.6621, 4.6620, 4.6620,\n",
      "        4.6620, 4.6620, 4.6620], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.860384  [5468524/5599865]\n",
      "average delta from current occupancy tensor([4.7998, 4.7999, 4.7998, 4.7998, 4.7999, 4.7998, 4.7997, 4.7996, 4.7997,\n",
      "        4.7998, 4.7999, 4.8001, 4.8000, 4.8001, 4.8002, 4.8001, 4.8000, 4.7999,\n",
      "        4.7999, 4.7999, 4.8002, 4.8001, 4.8000, 4.8001, 4.8001, 4.8001, 4.8001,\n",
      "        4.8001, 4.7999, 4.8000, 4.7998, 4.7997, 4.7995, 4.7995, 4.7996, 4.7996,\n",
      "        4.7997, 4.7998, 4.7997, 4.7996, 4.7995, 4.7996, 4.7995, 4.7996, 4.7997,\n",
      "        4.7996, 4.7998, 4.7998, 4.7997, 4.7998, 4.7999, 4.7998, 4.8000, 4.7999,\n",
      "        4.8001, 4.8001, 4.8001, 4.8001, 4.8001, 4.8002, 4.8002, 4.8002, 4.7999,\n",
      "        4.7999, 4.7998, 4.7996, 4.7997, 4.7996, 4.7997, 4.7998, 4.7998, 4.7998,\n",
      "        4.7999, 4.8000, 4.7999, 4.8000, 4.7997, 4.7997, 4.7997, 4.8000, 4.8000,\n",
      "        4.8000, 4.7998, 4.7998, 4.7996, 4.7996, 4.7995, 4.7997, 4.7996, 4.7998,\n",
      "        4.7997, 4.7999, 4.7999, 4.7999, 4.7999, 4.7998, 4.7997, 4.7999, 4.8000,\n",
      "        4.7999, 4.8000, 4.8000, 4.7999, 4.7998, 4.7997, 4.7999, 4.8001, 4.8000,\n",
      "        4.8001, 4.8001, 4.8001, 4.8000, 4.8002, 4.8003, 4.8004, 4.8004, 4.8003,\n",
      "        4.8004, 4.8005, 4.8005], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.877623  [5480924/5599865]\n",
      "average delta from current occupancy tensor([4.8389, 4.8388, 4.8389, 4.8389, 4.8388, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8388, 4.8389,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8389,\n",
      "        4.8388, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8388, 4.8388, 4.8389, 4.8388, 4.8389, 4.8389, 4.8389, 4.8388, 4.8388,\n",
      "        4.8388, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389,\n",
      "        4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8389, 4.8388,\n",
      "        4.8389, 4.8388, 4.8388, 4.8389, 4.8389, 4.8389, 4.8389, 4.8388, 4.8388,\n",
      "        4.8388, 4.8388, 4.8388, 4.8388, 4.8388, 4.8389, 4.8389, 4.8389, 4.8388,\n",
      "        4.8389, 4.8389, 4.8389], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.966292  [5493324/5599865]\n",
      "average delta from current occupancy tensor([5.8217, 5.8218, 5.8216, 5.8215, 5.8219, 5.8217, 5.8216, 5.8212, 5.8214,\n",
      "        5.8218, 5.8218, 5.8215, 5.8215, 5.8221, 5.8222, 5.8221, 5.8216, 5.8214,\n",
      "        5.8221, 5.8223, 5.8223, 5.8223, 5.8216, 5.8222, 5.8217, 5.8216, 5.8215,\n",
      "        5.8218, 5.8217, 5.8217, 5.8214, 5.8216, 5.8216, 5.8218, 5.8216, 5.8214,\n",
      "        5.8216, 5.8213, 5.8214, 5.8212, 5.8212, 5.8212, 5.8210, 5.8211, 5.8212,\n",
      "        5.8212, 5.8212, 5.8213, 5.8215, 5.8212, 5.8216, 5.8213, 5.8215, 5.8215,\n",
      "        5.8216, 5.8215, 5.8215, 5.8215, 5.8214, 5.8214, 5.8214, 5.8220, 5.8212,\n",
      "        5.8214, 5.8215, 5.8216, 5.8216, 5.8214, 5.8214, 5.8215, 5.8217, 5.8215,\n",
      "        5.8215, 5.8213, 5.8215, 5.8217, 5.8216, 5.8217, 5.8216, 5.8216, 5.8216,\n",
      "        5.8216, 5.8216, 5.8216, 5.8216, 5.8213, 5.8212, 5.8213, 5.8212, 5.8210,\n",
      "        5.8213, 5.8213, 5.8213, 5.8215, 5.8216, 5.8215, 5.8214, 5.8215, 5.8218,\n",
      "        5.8221, 5.8221, 5.8214, 5.8217, 5.8212, 5.8214, 5.8214, 5.8216, 5.8214,\n",
      "        5.8216, 5.8222, 5.8221, 5.8215, 5.8217, 5.8213, 5.8212, 5.8216, 5.8218,\n",
      "        5.8219, 5.8216, 5.8216], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.181271  [5505724/5599865]\n",
      "average delta from current occupancy tensor([5.0174, 5.0173, 5.0173, 5.0174, 5.0171, 5.0172, 5.0175, 5.0178, 5.0176,\n",
      "        5.0174, 5.0173, 5.0177, 5.0177, 5.0173, 5.0172, 5.0172, 5.0174, 5.0175,\n",
      "        5.0170, 5.0170, 5.0170, 5.0170, 5.0174, 5.0169, 5.0172, 5.0174, 5.0175,\n",
      "        5.0174, 5.0174, 5.0176, 5.0177, 5.0175, 5.0173, 5.0171, 5.0174, 5.0177,\n",
      "        5.0175, 5.0177, 5.0178, 5.0180, 5.0179, 5.0181, 5.0182, 5.0179, 5.0178,\n",
      "        5.0179, 5.0179, 5.0178, 5.0176, 5.0178, 5.0177, 5.0179, 5.0177, 5.0178,\n",
      "        5.0178, 5.0179, 5.0178, 5.0178, 5.0178, 5.0180, 5.0181, 5.0179, 5.0183,\n",
      "        5.0183, 5.0182, 5.0182, 5.0181, 5.0183, 5.0183, 5.0183, 5.0182, 5.0182,\n",
      "        5.0182, 5.0181, 5.0179, 5.0178, 5.0179, 5.0179, 5.0179, 5.0178, 5.0177,\n",
      "        5.0176, 5.0176, 5.0175, 5.0176, 5.0178, 5.0178, 5.0178, 5.0179, 5.0180,\n",
      "        5.0178, 5.0179, 5.0180, 5.0179, 5.0178, 5.0176, 5.0178, 5.0178, 5.0178,\n",
      "        5.0176, 5.0175, 5.0180, 5.0179, 5.0182, 5.0179, 5.0178, 5.0176, 5.0177,\n",
      "        5.0176, 5.0171, 5.0173, 5.0179, 5.0177, 5.0180, 5.0181, 5.0179, 5.0178,\n",
      "        5.0177, 5.0178, 5.0178], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.437068  [5518124/5599865]\n",
      "average delta from current occupancy tensor([5.4935, 5.4934, 5.4933, 5.4934, 5.4931, 5.4931, 5.4934, 5.4936, 5.4935,\n",
      "        5.4936, 5.4936, 5.4936, 5.4935, 5.4934, 5.4932, 5.4934, 5.4935, 5.4934,\n",
      "        5.4930, 5.4931, 5.4932, 5.4932, 5.4937, 5.4933, 5.4935, 5.4940, 5.4939,\n",
      "        5.4939, 5.4939, 5.4939, 5.4937, 5.4938, 5.4938, 5.4934, 5.4937, 5.4936,\n",
      "        5.4937, 5.4935, 5.4934, 5.4933, 5.4931, 5.4927, 5.4927, 5.4932, 5.4933,\n",
      "        5.4928, 5.4932, 5.4934, 5.4936, 5.4935, 5.4935, 5.4932, 5.4934, 5.4933,\n",
      "        5.4933, 5.4935, 5.4935, 5.4934, 5.4935, 5.4933, 5.4933, 5.4935, 5.4930,\n",
      "        5.4930, 5.4936, 5.4935, 5.4934, 5.4935, 5.4930, 5.4930, 5.4933, 5.4933,\n",
      "        5.4934, 5.4935, 5.4940, 5.4940, 5.4940, 5.4936, 5.4938, 5.4938, 5.4940,\n",
      "        5.4942, 5.4942, 5.4941, 5.4940, 5.4938, 5.4935, 5.4937, 5.4935, 5.4936,\n",
      "        5.4937, 5.4934, 5.4931, 5.4932, 5.4931, 5.4936, 5.4933, 5.4934, 5.4932,\n",
      "        5.4933, 5.4933, 5.4931, 5.4931, 5.4933, 5.4931, 5.4932, 5.4935, 5.4934,\n",
      "        5.4935, 5.4934, 5.4935, 5.4930, 5.4934, 5.4931, 5.4936, 5.4935, 5.4931,\n",
      "        5.4932, 5.4930, 5.4930], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.504707  [5530524/5599865]\n",
      "average delta from current occupancy tensor([5.3711, 5.3712, 5.3714, 5.3712, 5.3713, 5.3712, 5.3715, 5.3712, 5.3711,\n",
      "        5.3711, 5.3714, 5.3711, 5.3712, 5.3713, 5.3711, 5.3711, 5.3713, 5.3711,\n",
      "        5.3711, 5.3711, 5.3712, 5.3712, 5.3712, 5.3710, 5.3711, 5.3710, 5.3710,\n",
      "        5.3712, 5.3710, 5.3711, 5.3712, 5.3711, 5.3710, 5.3710, 5.3711, 5.3711,\n",
      "        5.3711, 5.3710, 5.3711, 5.3710, 5.3711, 5.3710, 5.3710, 5.3712, 5.3711,\n",
      "        5.3712, 5.3713, 5.3712, 5.3712, 5.3712, 5.3711, 5.3711, 5.3712, 5.3711,\n",
      "        5.3712, 5.3711, 5.3712, 5.3711, 5.3711, 5.3711, 5.3711, 5.3710, 5.3711,\n",
      "        5.3711, 5.3711, 5.3711, 5.3712, 5.3712, 5.3712, 5.3711, 5.3711, 5.3712,\n",
      "        5.3712, 5.3711, 5.3712, 5.3711, 5.3712, 5.3710, 5.3710, 5.3712, 5.3712,\n",
      "        5.3711, 5.3712, 5.3711, 5.3711, 5.3712, 5.3710, 5.3712, 5.3711, 5.3711,\n",
      "        5.3712, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3713, 5.3712, 5.3712,\n",
      "        5.3713, 5.3713, 5.3712, 5.3713, 5.3712, 5.3713, 5.3713, 5.3713, 5.3712,\n",
      "        5.3711, 5.3711, 5.3712, 5.3711, 5.3711, 5.3714, 5.3711, 5.3711, 5.3710,\n",
      "        5.3713, 5.3710, 5.3710], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.286847  [5542924/5599865]\n",
      "average delta from current occupancy tensor([5.1785, 5.1787, 5.1785, 5.1786, 5.1786, 5.1784, 5.1785, 5.1785, 5.1785,\n",
      "        5.1784, 5.1786, 5.1786, 5.1785, 5.1786, 5.1785, 5.1785, 5.1785, 5.1785,\n",
      "        5.1785, 5.1785, 5.1786, 5.1785, 5.1786, 5.1785, 5.1786, 5.1786, 5.1785,\n",
      "        5.1785, 5.1786, 5.1787, 5.1786, 5.1788, 5.1787, 5.1786, 5.1786, 5.1787,\n",
      "        5.1786, 5.1785, 5.1786, 5.1786, 5.1785, 5.1785, 5.1785, 5.1784, 5.1784,\n",
      "        5.1784, 5.1786, 5.1785, 5.1786, 5.1785, 5.1786, 5.1786, 5.1784, 5.1785,\n",
      "        5.1786, 5.1785, 5.1785, 5.1784, 5.1784, 5.1785, 5.1785, 5.1786, 5.1784,\n",
      "        5.1785, 5.1784, 5.1783, 5.1785, 5.1785, 5.1784, 5.1784, 5.1785, 5.1785,\n",
      "        5.1784, 5.1784, 5.1784, 5.1784, 5.1785, 5.1785, 5.1784, 5.1785, 5.1784,\n",
      "        5.1783, 5.1785, 5.1784, 5.1784, 5.1784, 5.1784, 5.1785, 5.1784, 5.1784,\n",
      "        5.1785, 5.1785, 5.1785, 5.1785, 5.1785, 5.1786, 5.1784, 5.1786, 5.1786,\n",
      "        5.1787, 5.1787, 5.1787, 5.1787, 5.1787, 5.1787, 5.1788, 5.1788, 5.1787,\n",
      "        5.1788, 5.1787, 5.1787, 5.1785, 5.1786, 5.1786, 5.1786, 5.1787, 5.1787,\n",
      "        5.1787, 5.1786, 5.1787], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.734447  [5555324/5599865]\n",
      "average delta from current occupancy tensor([4.8239, 4.8233, 4.8238, 4.8239, 4.8239, 4.8240, 4.8240, 4.8242, 4.8240,\n",
      "        4.8239, 4.8242, 4.8243, 4.8236, 4.8241, 4.8240, 4.8235, 4.8236, 4.8235,\n",
      "        4.8239, 4.8239, 4.8241, 4.8240, 4.8239, 4.8242, 4.8237, 4.8240, 4.8240,\n",
      "        4.8238, 4.8239, 4.8235, 4.8239, 4.8233, 4.8238, 4.8240, 4.8240, 4.8239,\n",
      "        4.8239, 4.8240, 4.8239, 4.8241, 4.8240, 4.8239, 4.8239, 4.8238, 4.8239,\n",
      "        4.8240, 4.8241, 4.8242, 4.8242, 4.8240, 4.8243, 4.8241, 4.8241, 4.8241,\n",
      "        4.8242, 4.8240, 4.8240, 4.8239, 4.8238, 4.8239, 4.8238, 4.8239, 4.8238,\n",
      "        4.8239, 4.8239, 4.8241, 4.8238, 4.8240, 4.8238, 4.8239, 4.8240, 4.8238,\n",
      "        4.8239, 4.8239, 4.8238, 4.8240, 4.8240, 4.8239, 4.8239, 4.8241, 4.8240,\n",
      "        4.8240, 4.8241, 4.8241, 4.8240, 4.8238, 4.8240, 4.8240, 4.8239, 4.8239,\n",
      "        4.8239, 4.8238, 4.8239, 4.8240, 4.8239, 4.8238, 4.8240, 4.8240, 4.8240,\n",
      "        4.8240, 4.8241, 4.8239, 4.8239, 4.8238, 4.8239, 4.8238, 4.8238, 4.8240,\n",
      "        4.8238, 4.8237, 4.8237, 4.8242, 4.8239, 4.8239, 4.8239, 4.8238, 4.8238,\n",
      "        4.8238, 4.8240, 4.8237], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.443007  [5567724/5599865]\n",
      "average delta from current occupancy tensor([5.5973, 5.5977, 5.5972, 5.5972, 5.5975, 5.5975, 5.5975, 5.5976, 5.5975,\n",
      "        5.5974, 5.5975, 5.5975, 5.5974, 5.5974, 5.5974, 5.5975, 5.5972, 5.5972,\n",
      "        5.5972, 5.5973, 5.5975, 5.5975, 5.5972, 5.5974, 5.5973, 5.5973, 5.5973,\n",
      "        5.5972, 5.5974, 5.5975, 5.5974, 5.5974, 5.5977, 5.5974, 5.5973, 5.5975,\n",
      "        5.5975, 5.5976, 5.5976, 5.5976, 5.5974, 5.5973, 5.5975, 5.5975, 5.5976,\n",
      "        5.5977, 5.5976, 5.5977, 5.5977, 5.5978, 5.5976, 5.5977, 5.5977, 5.5975,\n",
      "        5.5976, 5.5976, 5.5976, 5.5973, 5.5972, 5.5972, 5.5974, 5.5973, 5.5973,\n",
      "        5.5973, 5.5976, 5.5976, 5.5975, 5.5975, 5.5973, 5.5975, 5.5975, 5.5974,\n",
      "        5.5974, 5.5975, 5.5974, 5.5976, 5.5974, 5.5974, 5.5973, 5.5976, 5.5975,\n",
      "        5.5976, 5.5976, 5.5976, 5.5976, 5.5976, 5.5973, 5.5976, 5.5975, 5.5974,\n",
      "        5.5974, 5.5974, 5.5975, 5.5976, 5.5977, 5.5975, 5.5974, 5.5976, 5.5977,\n",
      "        5.5978, 5.5974, 5.5973, 5.5974, 5.5973, 5.5974, 5.5973, 5.5972, 5.5972,\n",
      "        5.5975, 5.5973, 5.5973, 5.5974, 5.5973, 5.5973, 5.5974, 5.5973, 5.5973,\n",
      "        5.5973, 5.5973, 5.5974], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.296351  [5580124/5599865]\n",
      "average delta from current occupancy tensor([5.3225, 5.3226, 5.3226, 5.3226, 5.3225, 5.3225, 5.3225, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3225, 5.3226, 5.3226, 5.3225, 5.3225, 5.3225, 5.3225, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3225, 5.3226, 5.3226, 5.3225, 5.3225, 5.3226,\n",
      "        5.3226, 5.3226, 5.3225, 5.3226, 5.3225, 5.3226, 5.3225, 5.3225, 5.3225,\n",
      "        5.3226, 5.3226, 5.3225, 5.3225, 5.3226, 5.3226, 5.3226, 5.3226, 5.3225,\n",
      "        5.3226, 5.3226, 5.3225, 5.3225, 5.3226, 5.3226, 5.3226, 5.3225, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3225, 5.3226, 5.3225, 5.3225, 5.3225,\n",
      "        5.3226, 5.3225, 5.3225, 5.3225, 5.3225, 5.3225, 5.3226, 5.3226, 5.3225,\n",
      "        5.3225, 5.3225, 5.3225, 5.3226, 5.3226, 5.3225, 5.3226, 5.3225, 5.3225,\n",
      "        5.3225, 5.3225, 5.3225], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.072306  [5592524/5599865]\n",
      "average delta from current occupancy tensor([5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Avg loss: 5.270467 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.879868  [  124/5599865]\n",
      "average delta from current occupancy tensor([4.6614, 4.6613, 4.6614, 4.6614, 4.6615, 4.6614, 4.6615, 4.6615, 4.6613,\n",
      "        4.6613, 4.6615, 4.6613, 4.6614, 4.6613, 4.6615, 4.6615, 4.6614, 4.6614,\n",
      "        4.6614, 4.6614, 4.6613, 4.6613, 4.6614, 4.6613, 4.6613, 4.6613, 4.6615,\n",
      "        4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6613,\n",
      "        4.6613, 4.6613, 4.6615, 4.6615, 4.6614, 4.6615, 4.6613, 4.6614, 4.6613,\n",
      "        4.6614, 4.6613, 4.6613, 4.6613, 4.6613, 4.6615, 4.6613, 4.6613, 4.6613,\n",
      "        4.6614, 4.6614, 4.6613, 4.6615, 4.6614, 4.6615, 4.6615, 4.6613, 4.6613,\n",
      "        4.6613, 4.6613, 4.6613, 4.6613, 4.6614, 4.6614, 4.6614, 4.6613, 4.6613,\n",
      "        4.6613, 4.6612, 4.6613, 4.6613, 4.6614, 4.6613, 4.6613, 4.6612, 4.6613,\n",
      "        4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6612, 4.6612, 4.6612, 4.6612,\n",
      "        4.6612, 4.6612, 4.6612, 4.6612, 4.6612, 4.6612, 4.6612, 4.6613, 4.6612,\n",
      "        4.6612, 4.6612, 4.6612, 4.6614, 4.6615, 4.6612, 4.6613, 4.6613, 4.6613,\n",
      "        4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6613, 4.6612, 4.6613, 4.6612,\n",
      "        4.6613, 4.6612, 4.6613], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.218496  [12524/5599865]\n",
      "average delta from current occupancy tensor([5.1453, 5.1453, 5.1453, 5.1455, 5.1453, 5.1451, 5.1453, 5.1452, 5.1454,\n",
      "        5.1452, 5.1454, 5.1453, 5.1455, 5.1453, 5.1452, 5.1452, 5.1454, 5.1454,\n",
      "        5.1456, 5.1455, 5.1455, 5.1455, 5.1455, 5.1454, 5.1454, 5.1455, 5.1454,\n",
      "        5.1454, 5.1455, 5.1452, 5.1452, 5.1451, 5.1451, 5.1451, 5.1451, 5.1453,\n",
      "        5.1453, 5.1455, 5.1455, 5.1455, 5.1455, 5.1456, 5.1455, 5.1454, 5.1452,\n",
      "        5.1454, 5.1452, 5.1453, 5.1453, 5.1453, 5.1454, 5.1454, 5.1453, 5.1454,\n",
      "        5.1454, 5.1454, 5.1454, 5.1454, 5.1454, 5.1452, 5.1454, 5.1453, 5.1453,\n",
      "        5.1453, 5.1452, 5.1454, 5.1453, 5.1455, 5.1453, 5.1455, 5.1453, 5.1454,\n",
      "        5.1453, 5.1452, 5.1453, 5.1452, 5.1455, 5.1454, 5.1452, 5.1452, 5.1454,\n",
      "        5.1453, 5.1454, 5.1454, 5.1453, 5.1453, 5.1453, 5.1452, 5.1452, 5.1453,\n",
      "        5.1452, 5.1452, 5.1453, 5.1453, 5.1453, 5.1453, 5.1454, 5.1453, 5.1453,\n",
      "        5.1452, 5.1452, 5.1452, 5.1454, 5.1454, 5.1453, 5.1453, 5.1453, 5.1453,\n",
      "        5.1452, 5.1452, 5.1452, 5.1453, 5.1454, 5.1454, 5.1453, 5.1454, 5.1453,\n",
      "        5.1454, 5.1452, 5.1452], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.653279  [24924/5599865]\n",
      "average delta from current occupancy tensor([4.7976, 4.7977, 4.7973, 4.7975, 4.7975, 4.7976, 4.7976, 4.7977, 4.7978,\n",
      "        4.7981, 4.7980, 4.7981, 4.7982, 4.7982, 4.7980, 4.7982, 4.7985, 4.7982,\n",
      "        4.7981, 4.7981, 4.7982, 4.7981, 4.7984, 4.7983, 4.7981, 4.7983, 4.7986,\n",
      "        4.7983, 4.7984, 4.7983, 4.7983, 4.7981, 4.7981, 4.7981, 4.7983, 4.7985,\n",
      "        4.7985, 4.7984, 4.7982, 4.7983, 4.7983, 4.7982, 4.7984, 4.7983, 4.7984,\n",
      "        4.7984, 4.7983, 4.7983, 4.7982, 4.7981, 4.7984, 4.7983, 4.7984, 4.7983,\n",
      "        4.7984, 4.7982, 4.7983, 4.7984, 4.7981, 4.7981, 4.7983, 4.7983, 4.7982,\n",
      "        4.7984, 4.7982, 4.7984, 4.7983, 4.7983, 4.7986, 4.7984, 4.7983, 4.7986,\n",
      "        4.7984, 4.7984, 4.7985, 4.7985, 4.7983, 4.7983, 4.7984, 4.7984, 4.7984,\n",
      "        4.7985, 4.7984, 4.7986, 4.7984, 4.7982, 4.7981, 4.7979, 4.7980, 4.7981,\n",
      "        4.7979, 4.7981, 4.7980, 4.7982, 4.7981, 4.7982, 4.7982, 4.7982, 4.7981,\n",
      "        4.7984, 4.7981, 4.7979, 4.7979, 4.7979, 4.7983, 4.7980, 4.7982, 4.7983,\n",
      "        4.7980, 4.7982, 4.7984, 4.7980, 4.7980, 4.7981, 4.7979, 4.7982, 4.7980,\n",
      "        4.7982, 4.7986, 4.7981], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.698899  [37324/5599865]\n",
      "average delta from current occupancy tensor([4.7279, 4.7279, 4.7278, 4.7279, 4.7278, 4.7278, 4.7278, 4.7277, 4.7278,\n",
      "        4.7277, 4.7277, 4.7277, 4.7277, 4.7278, 4.7276, 4.7276, 4.7276, 4.7276,\n",
      "        4.7276, 4.7276, 4.7277, 4.7276, 4.7275, 4.7276, 4.7276, 4.7277, 4.7277,\n",
      "        4.7276, 4.7278, 4.7277, 4.7276, 4.7276, 4.7276, 4.7273, 4.7274, 4.7274,\n",
      "        4.7275, 4.7276, 4.7275, 4.7275, 4.7276, 4.7276, 4.7277, 4.7276, 4.7277,\n",
      "        4.7276, 4.7276, 4.7278, 4.7277, 4.7273, 4.7276, 4.7278, 4.7277, 4.7275,\n",
      "        4.7277, 4.7275, 4.7276, 4.7276, 4.7276, 4.7277, 4.7274, 4.7275, 4.7275,\n",
      "        4.7275, 4.7273, 4.7273, 4.7273, 4.7273, 4.7273, 4.7273, 4.7275, 4.7275,\n",
      "        4.7274, 4.7276, 4.7275, 4.7276, 4.7277, 4.7275, 4.7274, 4.7274, 4.7275,\n",
      "        4.7275, 4.7276, 4.7276, 4.7275, 4.7278, 4.7278, 4.7278, 4.7278, 4.7278,\n",
      "        4.7276, 4.7277, 4.7278, 4.7277, 4.7277, 4.7277, 4.7277, 4.7278, 4.7275,\n",
      "        4.7276, 4.7276, 4.7275, 4.7278, 4.7272, 4.7277, 4.7272, 4.7278, 4.7277,\n",
      "        4.7274, 4.7277, 4.7276, 4.7274, 4.7275, 4.7276, 4.7271, 4.7276, 4.7275,\n",
      "        4.7271, 4.7274, 4.7272], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.957493  [49724/5599865]\n",
      "average delta from current occupancy tensor([5.1377, 5.1379, 5.1377, 5.1378, 5.1380, 5.1377, 5.1378, 5.1380, 5.1379,\n",
      "        5.1380, 5.1379, 5.1381, 5.1379, 5.1378, 5.1379, 5.1379, 5.1380, 5.1380,\n",
      "        5.1380, 5.1379, 5.1380, 5.1380, 5.1381, 5.1381, 5.1380, 5.1380, 5.1380,\n",
      "        5.1379, 5.1379, 5.1381, 5.1380, 5.1379, 5.1380, 5.1378, 5.1379, 5.1379,\n",
      "        5.1379, 5.1378, 5.1378, 5.1374, 5.1375, 5.1376, 5.1373, 5.1375, 5.1375,\n",
      "        5.1374, 5.1374, 5.1375, 5.1374, 5.1375, 5.1374, 5.1376, 5.1375, 5.1376,\n",
      "        5.1373, 5.1376, 5.1375, 5.1376, 5.1377, 5.1375, 5.1379, 5.1379, 5.1379,\n",
      "        5.1380, 5.1378, 5.1377, 5.1377, 5.1377, 5.1377, 5.1376, 5.1376, 5.1375,\n",
      "        5.1374, 5.1372, 5.1372, 5.1372, 5.1374, 5.1373, 5.1375, 5.1376, 5.1375,\n",
      "        5.1374, 5.1375, 5.1374, 5.1374, 5.1373, 5.1373, 5.1373, 5.1374, 5.1373,\n",
      "        5.1373, 5.1374, 5.1372, 5.1373, 5.1373, 5.1372, 5.1376, 5.1376, 5.1378,\n",
      "        5.1375, 5.1376, 5.1377, 5.1374, 5.1377, 5.1375, 5.1377, 5.1374, 5.1377,\n",
      "        5.1379, 5.1375, 5.1376, 5.1378, 5.1379, 5.1378, 5.1378, 5.1377, 5.1378,\n",
      "        5.1377, 5.1377, 5.1379], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.858365  [62124/5599865]\n",
      "average delta from current occupancy tensor([4.9477, 4.9481, 4.9480, 4.9480, 4.9478, 4.9476, 4.9477, 4.9477, 4.9477,\n",
      "        4.9478, 4.9476, 4.9479, 4.9476, 4.9474, 4.9474, 4.9474, 4.9474, 4.9472,\n",
      "        4.9475, 4.9474, 4.9475, 4.9475, 4.9476, 4.9475, 4.9479, 4.9480, 4.9476,\n",
      "        4.9477, 4.9477, 4.9479, 4.9479, 4.9478, 4.9480, 4.9478, 4.9477, 4.9477,\n",
      "        4.9476, 4.9472, 4.9473, 4.9472, 4.9471, 4.9475, 4.9471, 4.9473, 4.9472,\n",
      "        4.9472, 4.9472, 4.9472, 4.9472, 4.9470, 4.9474, 4.9471, 4.9472, 4.9477,\n",
      "        4.9472, 4.9478, 4.9473, 4.9474, 4.9480, 4.9474, 4.9471, 4.9472, 4.9472,\n",
      "        4.9475, 4.9472, 4.9471, 4.9469, 4.9473, 4.9477, 4.9480, 4.9477, 4.9475,\n",
      "        4.9470, 4.9474, 4.9474, 4.9471, 4.9473, 4.9471, 4.9471, 4.9474, 4.9470,\n",
      "        4.9472, 4.9471, 4.9471, 4.9471, 4.9470, 4.9468, 4.9468, 4.9468, 4.9470,\n",
      "        4.9469, 4.9471, 4.9469, 4.9467, 4.9470, 4.9466, 4.9470, 4.9469, 4.9470,\n",
      "        4.9468, 4.9468, 4.9469, 4.9473, 4.9466, 4.9469, 4.9466, 4.9469, 4.9469,\n",
      "        4.9472, 4.9470, 4.9469, 4.9472, 4.9472, 4.9470, 4.9470, 4.9468, 4.9469,\n",
      "        4.9469, 4.9468, 4.9469], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.261207  [74524/5599865]\n",
      "average delta from current occupancy tensor([5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0885, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0887, 5.0886, 5.0887, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0887, 5.0887, 5.0887,\n",
      "        5.0887, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0887, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0887, 5.0887, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0887, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886, 5.0886,\n",
      "        5.0886, 5.0886, 5.0886], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.553265  [86924/5599865]\n",
      "average delta from current occupancy tensor([5.4450, 5.4449, 5.4450, 5.4450, 5.4450, 5.4450, 5.4450, 5.4450, 5.4450,\n",
      "        5.4450, 5.4451, 5.4451, 5.4451, 5.4452, 5.4451, 5.4451, 5.4451, 5.4452,\n",
      "        5.4452, 5.4453, 5.4452, 5.4452, 5.4451, 5.4451, 5.4450, 5.4451, 5.4450,\n",
      "        5.4451, 5.4452, 5.4451, 5.4452, 5.4452, 5.4452, 5.4452, 5.4452, 5.4452,\n",
      "        5.4452, 5.4452, 5.4452, 5.4453, 5.4452, 5.4452, 5.4451, 5.4452, 5.4452,\n",
      "        5.4451, 5.4451, 5.4451, 5.4451, 5.4451, 5.4451, 5.4451, 5.4452, 5.4451,\n",
      "        5.4451, 5.4451, 5.4450, 5.4450, 5.4450, 5.4451, 5.4450, 5.4450, 5.4450,\n",
      "        5.4450, 5.4450, 5.4450, 5.4451, 5.4452, 5.4452, 5.4452, 5.4452, 5.4452,\n",
      "        5.4452, 5.4452, 5.4452, 5.4452, 5.4453, 5.4453, 5.4452, 5.4452, 5.4452,\n",
      "        5.4452, 5.4452, 5.4452, 5.4452, 5.4453, 5.4452, 5.4453, 5.4452, 5.4452,\n",
      "        5.4452, 5.4453, 5.4453, 5.4453, 5.4454, 5.4454, 5.4454, 5.4455, 5.4454,\n",
      "        5.4453, 5.4453, 5.4454, 5.4455, 5.4454, 5.4454, 5.4454, 5.4455, 5.4454,\n",
      "        5.4454, 5.4453, 5.4453, 5.4454, 5.4454, 5.4454, 5.4453, 5.4453, 5.4453,\n",
      "        5.4453, 5.4453, 5.4453], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.866453  [99324/5599865]\n",
      "average delta from current occupancy tensor([5.1503, 5.1502, 5.1501, 5.1502, 5.1503, 5.1503, 5.1502, 5.1502, 5.1502,\n",
      "        5.1504, 5.1504, 5.1504, 5.1504, 5.1505, 5.1504, 5.1504, 5.1506, 5.1506,\n",
      "        5.1506, 5.1510, 5.1504, 5.1506, 5.1504, 5.1507, 5.1505, 5.1505, 5.1503,\n",
      "        5.1502, 5.1501, 5.1503, 5.1502, 5.1502, 5.1501, 5.1500, 5.1501, 5.1501,\n",
      "        5.1501, 5.1501, 5.1502, 5.1503, 5.1502, 5.1502, 5.1502, 5.1505, 5.1503,\n",
      "        5.1503, 5.1504, 5.1504, 5.1506, 5.1505, 5.1505, 5.1503, 5.1504, 5.1503,\n",
      "        5.1502, 5.1502, 5.1502, 5.1502, 5.1501, 5.1502, 5.1502, 5.1500, 5.1502,\n",
      "        5.1501, 5.1502, 5.1501, 5.1503, 5.1504, 5.1506, 5.1510, 5.1504, 5.1505,\n",
      "        5.1505, 5.1508, 5.1505, 5.1506, 5.1511, 5.1511, 5.1510, 5.1509, 5.1507,\n",
      "        5.1508, 5.1505, 5.1510, 5.1512, 5.1512, 5.1508, 5.1512, 5.1508, 5.1507,\n",
      "        5.1508, 5.1514, 5.1514, 5.1511, 5.1511, 5.1510, 5.1508, 5.1505, 5.1511,\n",
      "        5.1513, 5.1511, 5.1510, 5.1506, 5.1510, 5.1509, 5.1507, 5.1505, 5.1507,\n",
      "        5.1511, 5.1514, 5.1515, 5.1516, 5.1515, 5.1516, 5.1516, 5.1515, 5.1514,\n",
      "        5.1514, 5.1514, 5.1514], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.996691  [111724/5599865]\n",
      "average delta from current occupancy tensor([5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0969, 5.0969, 5.0969, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0971, 5.0969, 5.0969, 5.0968, 5.0968, 5.0969, 5.0968,\n",
      "        5.0968, 5.0969, 5.0970, 5.0968, 5.0971, 5.0969, 5.0970, 5.0968, 5.0968,\n",
      "        5.0969, 5.0968, 5.0969, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968, 5.0968,\n",
      "        5.0968, 5.0968, 5.0968], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.595026  [124124/5599865]\n",
      "average delta from current occupancy tensor([5.1626, 5.1627, 5.1627, 5.1626, 5.1627, 5.1627, 5.1626, 5.1626, 5.1626,\n",
      "        5.1626, 5.1627, 5.1627, 5.1627, 5.1627, 5.1626, 5.1627, 5.1627, 5.1627,\n",
      "        5.1626, 5.1625, 5.1626, 5.1626, 5.1627, 5.1627, 5.1627, 5.1627, 5.1627,\n",
      "        5.1626, 5.1625, 5.1625, 5.1625, 5.1624, 5.1625, 5.1625, 5.1624, 5.1625,\n",
      "        5.1626, 5.1626, 5.1628, 5.1626, 5.1626, 5.1628, 5.1626, 5.1625, 5.1626,\n",
      "        5.1626, 5.1625, 5.1626, 5.1626, 5.1624, 5.1627, 5.1626, 5.1627, 5.1627,\n",
      "        5.1627, 5.1629, 5.1627, 5.1629, 5.1628, 5.1629, 5.1627, 5.1628, 5.1628,\n",
      "        5.1628, 5.1629, 5.1629, 5.1629, 5.1629, 5.1630, 5.1630, 5.1631, 5.1631,\n",
      "        5.1630, 5.1630, 5.1630, 5.1631, 5.1631, 5.1631, 5.1631, 5.1630, 5.1631,\n",
      "        5.1631, 5.1630, 5.1629, 5.1629, 5.1629, 5.1629, 5.1629, 5.1628, 5.1630,\n",
      "        5.1629, 5.1629, 5.1628, 5.1628, 5.1629, 5.1629, 5.1629, 5.1629, 5.1630,\n",
      "        5.1630, 5.1630, 5.1629, 5.1629, 5.1629, 5.1630, 5.1629, 5.1629, 5.1629,\n",
      "        5.1629, 5.1628, 5.1628, 5.1628, 5.1629, 5.1629, 5.1629, 5.1629, 5.1629,\n",
      "        5.1629, 5.1628, 5.1629], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.327979  [136524/5599865]\n",
      "average delta from current occupancy tensor([4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9759, 4.9759, 4.9760,\n",
      "        4.9759, 4.9759, 4.9759, 4.9758, 4.9759, 4.9759, 4.9759, 4.9759, 4.9759,\n",
      "        4.9759, 4.9760, 4.9758, 4.9759, 4.9760, 4.9759, 4.9759, 4.9759, 4.9760,\n",
      "        4.9760, 4.9760, 4.9760, 4.9759, 4.9759, 4.9758, 4.9760, 4.9759, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9759, 4.9758, 4.9758,\n",
      "        4.9758, 4.9759, 4.9759, 4.9760, 4.9760, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9757, 4.9757, 4.9758, 4.9757, 4.9757, 4.9757, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9758, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9758, 4.9757,\n",
      "        4.9756, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9756, 4.9757, 4.9757], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.505409  [148924/5599865]\n",
      "average delta from current occupancy tensor([4.4999, 4.5000, 4.5000, 4.4999, 4.4999, 4.5000, 4.5000, 4.4999, 4.5000,\n",
      "        4.5000, 4.4999, 4.4999, 4.5000, 4.5000, 4.5000, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.5000, 4.5000, 4.4999,\n",
      "        4.5001, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5001, 4.5000,\n",
      "        4.5000, 4.5000, 4.5001, 4.5000, 4.5001, 4.5000, 4.4999, 4.5000, 4.4999,\n",
      "        4.4999, 4.5000, 4.5000, 4.5000, 4.5002, 4.4999, 4.5000, 4.5000, 4.5002,\n",
      "        4.4999, 4.5000, 4.5000, 4.5000, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.5000, 4.4999, 4.5000, 4.5000, 4.5000,\n",
      "        4.5000, 4.4999, 4.5000, 4.5000, 4.5000, 4.5001, 4.5000, 4.5000, 4.5000,\n",
      "        4.5002, 4.5001, 4.5002, 4.5000, 4.5000, 4.5001, 4.5000, 4.5000, 4.4999,\n",
      "        4.5001, 4.5001, 4.5000, 4.5001, 4.5000, 4.5001, 4.5000, 4.4999, 4.5001,\n",
      "        4.5001, 4.5001, 4.5000, 4.5000, 4.5001, 4.5000, 4.5000, 4.5000, 4.5002,\n",
      "        4.5002, 4.5003, 4.5003, 4.5002, 4.5002, 4.5002, 4.5002, 4.5003, 4.5003,\n",
      "        4.5001, 4.5002, 4.5001], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.727242  [161324/5599865]\n",
      "average delta from current occupancy tensor([5.6779, 5.6778, 5.6778, 5.6778, 5.6779, 5.6778, 5.6778, 5.6778, 5.6779,\n",
      "        5.6779, 5.6779, 5.6779, 5.6779, 5.6780, 5.6779, 5.6779, 5.6779, 5.6779,\n",
      "        5.6780, 5.6779, 5.6779, 5.6780, 5.6779, 5.6780, 5.6780, 5.6780, 5.6780,\n",
      "        5.6781, 5.6781, 5.6780, 5.6779, 5.6778, 5.6780, 5.6780, 5.6779, 5.6780,\n",
      "        5.6779, 5.6779, 5.6779, 5.6779, 5.6779, 5.6779, 5.6780, 5.6779, 5.6780,\n",
      "        5.6782, 5.6782, 5.6781, 5.6782, 5.6780, 5.6782, 5.6782, 5.6782, 5.6781,\n",
      "        5.6781, 5.6781, 5.6781, 5.6780, 5.6781, 5.6782, 5.6781, 5.6781, 5.6781,\n",
      "        5.6781, 5.6781, 5.6780, 5.6780, 5.6781, 5.6781, 5.6781, 5.6781, 5.6780,\n",
      "        5.6780, 5.6780, 5.6780, 5.6780, 5.6781, 5.6781, 5.6781, 5.6780, 5.6781,\n",
      "        5.6780, 5.6780, 5.6780, 5.6781, 5.6781, 5.6781, 5.6780, 5.6781, 5.6781,\n",
      "        5.6781, 5.6781, 5.6781, 5.6781, 5.6781, 5.6781, 5.6782, 5.6780, 5.6781,\n",
      "        5.6781, 5.6781, 5.6781, 5.6781, 5.6781, 5.6781, 5.6780, 5.6781, 5.6780,\n",
      "        5.6779, 5.6780, 5.6780, 5.6780, 5.6780, 5.6780, 5.6780, 5.6781, 5.6781,\n",
      "        5.6781, 5.6781, 5.6781], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.520152  [173724/5599865]\n",
      "average delta from current occupancy tensor([4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7336, 4.7337, 4.7336, 4.7336, 4.7336, 4.7337, 4.7337, 4.7337, 4.7337,\n",
      "        4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7337, 4.7336, 4.7336,\n",
      "        4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7337, 4.7336,\n",
      "        4.7336, 4.7336, 4.7337, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336,\n",
      "        4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336, 4.7336,\n",
      "        4.7336, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335,\n",
      "        4.7335, 4.7335, 4.7335, 4.7334, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335,\n",
      "        4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335,\n",
      "        4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335,\n",
      "        4.7335, 4.7335, 4.7335, 4.7334, 4.7334, 4.7335, 4.7334, 4.7334, 4.7335,\n",
      "        4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335,\n",
      "        4.7334, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335, 4.7335,\n",
      "        4.7335, 4.7335, 4.7335], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.428283  [186124/5599865]\n",
      "average delta from current occupancy tensor([5.4195, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4196, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4195,\n",
      "        5.4195, 5.4194, 5.4194, 5.4194, 5.4194, 5.4195, 5.4194, 5.4194, 5.4194,\n",
      "        5.4195, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4195, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4196, 5.4195, 5.4198, 5.4197, 5.4198,\n",
      "        5.4198, 5.4198, 5.4200, 5.4201, 5.4202, 5.4198, 5.4198, 5.4198, 5.4199,\n",
      "        5.4198, 5.4199, 5.4200, 5.4199, 5.4199, 5.4198, 5.4198, 5.4201, 5.4203,\n",
      "        5.4202, 5.4202, 5.4202, 5.4202, 5.4203, 5.4201, 5.4199, 5.4202, 5.4200,\n",
      "        5.4202, 5.4202, 5.4202, 5.4204, 5.4204, 5.4200, 5.4203, 5.4204, 5.4201,\n",
      "        5.4200, 5.4201, 5.4202, 5.4204, 5.4201, 5.4201, 5.4201, 5.4204, 5.4205,\n",
      "        5.4208, 5.4207, 5.4207, 5.4206, 5.4204, 5.4205, 5.4205, 5.4204, 5.4203,\n",
      "        5.4202, 5.4201, 5.4203], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.887067  [198524/5599865]\n",
      "average delta from current occupancy tensor([4.8210, 4.8210, 4.8210, 4.8211, 4.8210, 4.8211, 4.8211, 4.8208, 4.8210,\n",
      "        4.8211, 4.8210, 4.8209, 4.8209, 4.8209, 4.8210, 4.8209, 4.8211, 4.8211,\n",
      "        4.8210, 4.8210, 4.8212, 4.8210, 4.8210, 4.8210, 4.8210, 4.8210, 4.8211,\n",
      "        4.8211, 4.8212, 4.8212, 4.8213, 4.8213, 4.8214, 4.8212, 4.8213, 4.8212,\n",
      "        4.8212, 4.8213, 4.8213, 4.8213, 4.8214, 4.8214, 4.8213, 4.8214, 4.8213,\n",
      "        4.8215, 4.8213, 4.8214, 4.8212, 4.8213, 4.8212, 4.8213, 4.8214, 4.8214,\n",
      "        4.8215, 4.8213, 4.8213, 4.8214, 4.8213, 4.8214, 4.8217, 4.8215, 4.8216,\n",
      "        4.8217, 4.8215, 4.8218, 4.8221, 4.8219, 4.8216, 4.8215, 4.8214, 4.8214,\n",
      "        4.8213, 4.8214, 4.8214, 4.8214, 4.8214, 4.8215, 4.8214, 4.8216, 4.8219,\n",
      "        4.8219, 4.8219, 4.8220, 4.8218, 4.8219, 4.8217, 4.8215, 4.8218, 4.8216,\n",
      "        4.8219, 4.8220, 4.8219, 4.8217, 4.8219, 4.8217, 4.8220, 4.8217, 4.8219,\n",
      "        4.8217, 4.8217, 4.8217, 4.8218, 4.8215, 4.8216, 4.8216, 4.8217, 4.8217,\n",
      "        4.8215, 4.8215, 4.8216, 4.8217, 4.8218, 4.8217, 4.8217, 4.8219, 4.8218,\n",
      "        4.8216, 4.8214, 4.8216], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.929316  [210924/5599865]\n",
      "average delta from current occupancy tensor([4.7156, 4.7157, 4.7158, 4.7160, 4.7154, 4.7157, 4.7157, 4.7152, 4.7158,\n",
      "        4.7159, 4.7157, 4.7157, 4.7157, 4.7158, 4.7160, 4.7157, 4.7157, 4.7153,\n",
      "        4.7157, 4.7159, 4.7156, 4.7159, 4.7159, 4.7160, 4.7159, 4.7160, 4.7159,\n",
      "        4.7159, 4.7154, 4.7154, 4.7153, 4.7154, 4.7158, 4.7159, 4.7159, 4.7156,\n",
      "        4.7159, 4.7158, 4.7158, 4.7158, 4.7154, 4.7154, 4.7157, 4.7152, 4.7158,\n",
      "        4.7155, 4.7157, 4.7155, 4.7157, 4.7157, 4.7156, 4.7159, 4.7156, 4.7159,\n",
      "        4.7156, 4.7157, 4.7158, 4.7156, 4.7158, 4.7155, 4.7156, 4.7154, 4.7156,\n",
      "        4.7156, 4.7156, 4.7157, 4.7155, 4.7155, 4.7156, 4.7158, 4.7154, 4.7157,\n",
      "        4.7158, 4.7158, 4.7156, 4.7157, 4.7156, 4.7156, 4.7158, 4.7154, 4.7152,\n",
      "        4.7152, 4.7153, 4.7154, 4.7154, 4.7153, 4.7155, 4.7157, 4.7155, 4.7155,\n",
      "        4.7155, 4.7155, 4.7155, 4.7153, 4.7151, 4.7151, 4.7151, 4.7150, 4.7153,\n",
      "        4.7151, 4.7151, 4.7152, 4.7153, 4.7154, 4.7153, 4.7152, 4.7151, 4.7152,\n",
      "        4.7156, 4.7156, 4.7155, 4.7152, 4.7151, 4.7150, 4.7150, 4.7150, 4.7150,\n",
      "        4.7152, 4.7155, 4.7151], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.651725  [223324/5599865]\n",
      "average delta from current occupancy tensor([5.3225, 5.3224, 5.3225, 5.3227, 5.3226, 5.3225, 5.3226, 5.3229, 5.3226,\n",
      "        5.3225, 5.3225, 5.3225, 5.3225, 5.3224, 5.3224, 5.3226, 5.3228, 5.3225,\n",
      "        5.3228, 5.3227, 5.3226, 5.3230, 5.3228, 5.3227, 5.3229, 5.3229, 5.3227,\n",
      "        5.3228, 5.3226, 5.3228, 5.3225, 5.3226, 5.3227, 5.3226, 5.3227, 5.3227,\n",
      "        5.3226, 5.3226, 5.3225, 5.3225, 5.3229, 5.3228, 5.3225, 5.3227, 5.3225,\n",
      "        5.3226, 5.3228, 5.3229, 5.3225, 5.3225, 5.3225, 5.3224, 5.3224, 5.3225,\n",
      "        5.3224, 5.3223, 5.3224, 5.3224, 5.3225, 5.3224, 5.3224, 5.3224, 5.3224,\n",
      "        5.3224, 5.3223, 5.3223, 5.3224, 5.3223, 5.3223, 5.3225, 5.3225, 5.3224,\n",
      "        5.3223, 5.3224, 5.3228, 5.3226, 5.3228, 5.3226, 5.3225, 5.3228, 5.3226,\n",
      "        5.3225, 5.3226, 5.3225, 5.3226, 5.3228, 5.3226, 5.3224, 5.3227, 5.3227,\n",
      "        5.3226, 5.3226, 5.3225, 5.3225, 5.3227, 5.3224, 5.3223, 5.3223, 5.3226,\n",
      "        5.3224, 5.3224, 5.3223, 5.3224, 5.3223, 5.3221, 5.3221, 5.3222, 5.3222,\n",
      "        5.3226, 5.3226, 5.3225, 5.3224, 5.3224, 5.3225, 5.3224, 5.3223, 5.3221,\n",
      "        5.3223, 5.3225, 5.3220], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.193621  [235724/5599865]\n",
      "average delta from current occupancy tensor([5.1855, 5.1856, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1856, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1856, 5.1855, 5.1859, 5.1858,\n",
      "        5.1859, 5.1856, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1856, 5.1858, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1856, 5.1855, 5.1855, 5.1855, 5.1857, 5.1857,\n",
      "        5.1858, 5.1858, 5.1857, 5.1859, 5.1859, 5.1860, 5.1862, 5.1862, 5.1861,\n",
      "        5.1862, 5.1863, 5.1863, 5.1864, 5.1863, 5.1860, 5.1862, 5.1862, 5.1862,\n",
      "        5.1862, 5.1862, 5.1862, 5.1863, 5.1863, 5.1862, 5.1861, 5.1862, 5.1862,\n",
      "        5.1863, 5.1863, 5.1862], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.515913  [248124/5599865]\n",
      "average delta from current occupancy tensor([5.4276, 5.4275, 5.4275, 5.4277, 5.4277, 5.4275, 5.4274, 5.4276, 5.4277,\n",
      "        5.4276, 5.4275, 5.4278, 5.4276, 5.4278, 5.4276, 5.4279, 5.4278, 5.4279,\n",
      "        5.4280, 5.4278, 5.4278, 5.4278, 5.4276, 5.4277, 5.4275, 5.4276, 5.4277,\n",
      "        5.4275, 5.4277, 5.4276, 5.4277, 5.4277, 5.4276, 5.4276, 5.4276, 5.4275,\n",
      "        5.4276, 5.4277, 5.4277, 5.4276, 5.4278, 5.4276, 5.4278, 5.4280, 5.4280,\n",
      "        5.4281, 5.4282, 5.4283, 5.4281, 5.4281, 5.4281, 5.4282, 5.4280, 5.4279,\n",
      "        5.4280, 5.4280, 5.4279, 5.4278, 5.4279, 5.4278, 5.4276, 5.4277, 5.4277,\n",
      "        5.4278, 5.4280, 5.4279, 5.4278, 5.4276, 5.4275, 5.4276, 5.4277, 5.4276,\n",
      "        5.4278, 5.4276, 5.4275, 5.4277, 5.4276, 5.4276, 5.4275, 5.4276, 5.4275,\n",
      "        5.4277, 5.4277, 5.4278, 5.4276, 5.4275, 5.4276, 5.4277, 5.4278, 5.4277,\n",
      "        5.4276, 5.4278, 5.4277, 5.4278, 5.4279, 5.4281, 5.4280, 5.4282, 5.4282,\n",
      "        5.4280, 5.4281, 5.4281, 5.4280, 5.4279, 5.4278, 5.4276, 5.4278, 5.4278,\n",
      "        5.4279, 5.4280, 5.4282, 5.4278, 5.4278, 5.4278, 5.4276, 5.4277, 5.4276,\n",
      "        5.4280, 5.4280, 5.4277], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.853147  [260524/5599865]\n",
      "average delta from current occupancy tensor([4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8548, 4.8547,\n",
      "        4.8547, 4.8547, 4.8547, 4.8548, 4.8548, 4.8548, 4.8548, 4.8547, 4.8547,\n",
      "        4.8547, 4.8548, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8546, 4.8546,\n",
      "        4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8547, 4.8546, 4.8546, 4.8546,\n",
      "        4.8545, 4.8545, 4.8545, 4.8545, 4.8546, 4.8546, 4.8546, 4.8545, 4.8545,\n",
      "        4.8545, 4.8545, 4.8545, 4.8545, 4.8545, 4.8545, 4.8546, 4.8546, 4.8546,\n",
      "        4.8547, 4.8547, 4.8546, 4.8546, 4.8546, 4.8546, 4.8547, 4.8546, 4.8546,\n",
      "        4.8546, 4.8545, 4.8545, 4.8545, 4.8545, 4.8545, 4.8546, 4.8545, 4.8546,\n",
      "        4.8547, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546,\n",
      "        4.8546, 4.8546, 4.8546, 4.8547, 4.8547, 4.8546, 4.8545, 4.8545, 4.8545,\n",
      "        4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8548, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8547, 4.8548, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8548, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8546, 4.8547], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.364860  [272924/5599865]\n",
      "average delta from current occupancy tensor([4.3461, 4.3459, 4.3460, 4.3460, 4.3464, 4.3462, 4.3462, 4.3458, 4.3460,\n",
      "        4.3460, 4.3460, 4.3461, 4.3461, 4.3461, 4.3461, 4.3460, 4.3458, 4.3459,\n",
      "        4.3458, 4.3457, 4.3459, 4.3459, 4.3458, 4.3460, 4.3458, 4.3460, 4.3458,\n",
      "        4.3460, 4.3458, 4.3460, 4.3460, 4.3461, 4.3461, 4.3459, 4.3458, 4.3458,\n",
      "        4.3457, 4.3456, 4.3456, 4.3458, 4.3459, 4.3458, 4.3459, 4.3455, 4.3456,\n",
      "        4.3455, 4.3456, 4.3456, 4.3456, 4.3455, 4.3456, 4.3459, 4.3459, 4.3459,\n",
      "        4.3461, 4.3460, 4.3460, 4.3460, 4.3461, 4.3460, 4.3461, 4.3459, 4.3458,\n",
      "        4.3458, 4.3457, 4.3457, 4.3457, 4.3459, 4.3459, 4.3460, 4.3460, 4.3461,\n",
      "        4.3462, 4.3461, 4.3461, 4.3460, 4.3461, 4.3461, 4.3459, 4.3459, 4.3457,\n",
      "        4.3458, 4.3459, 4.3460, 4.3460, 4.3460, 4.3458, 4.3457, 4.3457, 4.3458,\n",
      "        4.3459, 4.3460, 4.3460, 4.3460, 4.3460, 4.3461, 4.3461, 4.3462, 4.3459,\n",
      "        4.3461, 4.3460, 4.3460, 4.3459, 4.3460, 4.3460, 4.3458, 4.3459, 4.3458,\n",
      "        4.3459, 4.3460, 4.3458, 4.3459, 4.3461, 4.3461, 4.3460, 4.3459, 4.3460,\n",
      "        4.3460, 4.3458, 4.3459], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.958959  [285324/5599865]\n",
      "average delta from current occupancy tensor([4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9113, 4.9113, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9115, 4.9114, 4.9114, 4.9114, 4.9115, 4.9115, 4.9114, 4.9115, 4.9115,\n",
      "        4.9115, 4.9115, 4.9115, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9115, 4.9114, 4.9115, 4.9115, 4.9115, 4.9115, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9115, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9115, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.165524  [297724/5599865]\n",
      "average delta from current occupancy tensor([5.0808, 5.0808, 5.0808, 5.0807, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0807, 5.0807, 5.0807, 5.0808, 5.0807,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.764400  [310124/5599865]\n",
      "average delta from current occupancy tensor([5.3947, 5.3947, 5.3947, 5.3946, 5.3946, 5.3946, 5.3947, 5.3947, 5.3947,\n",
      "        5.3947, 5.3947, 5.3946, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947,\n",
      "        5.3947, 5.3947, 5.3947, 5.3946, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947,\n",
      "        5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947,\n",
      "        5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947,\n",
      "        5.3947, 5.3947, 5.3948, 5.3947, 5.3947, 5.3947, 5.3947, 5.3948, 5.3948,\n",
      "        5.3948, 5.3946, 5.3946, 5.3946, 5.3946, 5.3947, 5.3947, 5.3947, 5.3947,\n",
      "        5.3946, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3948, 5.3947, 5.3948,\n",
      "        5.3947, 5.3948, 5.3948, 5.3947, 5.3947, 5.3947, 5.3947, 5.3948, 5.3947,\n",
      "        5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3948, 5.3947, 5.3948, 5.3947,\n",
      "        5.3948, 5.3948, 5.3947, 5.3947, 5.3948, 5.3948, 5.3948, 5.3948, 5.3948,\n",
      "        5.3948, 5.3948, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3948,\n",
      "        5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3946, 5.3947,\n",
      "        5.3947, 5.3947, 5.3947], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.636453  [322524/5599865]\n",
      "average delta from current occupancy tensor([5.6214, 5.6213, 5.6213, 5.6213, 5.6212, 5.6213, 5.6212, 5.6214, 5.6213,\n",
      "        5.6212, 5.6212, 5.6212, 5.6212, 5.6213, 5.6214, 5.6213, 5.6214, 5.6214,\n",
      "        5.6214, 5.6212, 5.6214, 5.6213, 5.6214, 5.6214, 5.6214, 5.6214, 5.6214,\n",
      "        5.6213, 5.6214, 5.6213, 5.6214, 5.6212, 5.6213, 5.6212, 5.6212, 5.6212,\n",
      "        5.6212, 5.6212, 5.6212, 5.6211, 5.6211, 5.6212, 5.6212, 5.6211, 5.6211,\n",
      "        5.6211, 5.6212, 5.6211, 5.6212, 5.6212, 5.6210, 5.6212, 5.6213, 5.6212,\n",
      "        5.6213, 5.6212, 5.6213, 5.6212, 5.6213, 5.6213, 5.6212, 5.6212, 5.6213,\n",
      "        5.6213, 5.6213, 5.6212, 5.6213, 5.6212, 5.6212, 5.6213, 5.6213, 5.6213,\n",
      "        5.6213, 5.6213, 5.6212, 5.6212, 5.6213, 5.6212, 5.6211, 5.6211, 5.6212,\n",
      "        5.6211, 5.6211, 5.6211, 5.6211, 5.6212, 5.6211, 5.6211, 5.6212, 5.6210,\n",
      "        5.6210, 5.6211, 5.6211, 5.6211, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210,\n",
      "        5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6211,\n",
      "        5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210, 5.6210,\n",
      "        5.6210, 5.6210, 5.6210], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.603012  [334924/5599865]\n",
      "average delta from current occupancy tensor([4.6208, 4.6209, 4.6209, 4.6208, 4.6209, 4.6209, 4.6208, 4.6208, 4.6208,\n",
      "        4.6209, 4.6210, 4.6208, 4.6208, 4.6209, 4.6209, 4.6208, 4.6210, 4.6208,\n",
      "        4.6213, 4.6210, 4.6210, 4.6207, 4.6207, 4.6205, 4.6205, 4.6202, 4.6203,\n",
      "        4.6202, 4.6202, 4.6200, 4.6201, 4.6201, 4.6206, 4.6205, 4.6208, 4.6208,\n",
      "        4.6208, 4.6210, 4.6210, 4.6210, 4.6209, 4.6209, 4.6209, 4.6212, 4.6209,\n",
      "        4.6208, 4.6208, 4.6207, 4.6209, 4.6208, 4.6207, 4.6209, 4.6208, 4.6207,\n",
      "        4.6207, 4.6207, 4.6208, 4.6208, 4.6209, 4.6207, 4.6208, 4.6208, 4.6208,\n",
      "        4.6210, 4.6208, 4.6208, 4.6208, 4.6208, 4.6208, 4.6210, 4.6209, 4.6209,\n",
      "        4.6212, 4.6211, 4.6211, 4.6208, 4.6210, 4.6209, 4.6209, 4.6206, 4.6209,\n",
      "        4.6206, 4.6207, 4.6207, 4.6206, 4.6209, 4.6206, 4.6206, 4.6207, 4.6207,\n",
      "        4.6207, 4.6206, 4.6208, 4.6210, 4.6208, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6204, 4.6205, 4.6203, 4.6203, 4.6204, 4.6205, 4.6204, 4.6207, 4.6204,\n",
      "        4.6203, 4.6209, 4.6204, 4.6206, 4.6205, 4.6204, 4.6207, 4.6208, 4.6210,\n",
      "        4.6209, 4.6209, 4.6206], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.418004  [347324/5599865]\n",
      "average delta from current occupancy tensor([5.5046, 5.5046, 5.5046, 5.5048, 5.5047, 5.5046, 5.5046, 5.5047, 5.5045,\n",
      "        5.5045, 5.5046, 5.5047, 5.5047, 5.5047, 5.5042, 5.5045, 5.5045, 5.5045,\n",
      "        5.5045, 5.5044, 5.5046, 5.5047, 5.5046, 5.5043, 5.5044, 5.5047, 5.5045,\n",
      "        5.5045, 5.5048, 5.5046, 5.5047, 5.5047, 5.5046, 5.5044, 5.5044, 5.5045,\n",
      "        5.5044, 5.5044, 5.5043, 5.5045, 5.5044, 5.5046, 5.5044, 5.5045, 5.5045,\n",
      "        5.5046, 5.5045, 5.5045, 5.5045, 5.5045, 5.5046, 5.5046, 5.5046, 5.5044,\n",
      "        5.5046, 5.5044, 5.5044, 5.5043, 5.5043, 5.5043, 5.5044, 5.5045, 5.5043,\n",
      "        5.5043, 5.5042, 5.5041, 5.5042, 5.5043, 5.5043, 5.5042, 5.5045, 5.5043,\n",
      "        5.5045, 5.5044, 5.5044, 5.5045, 5.5045, 5.5044, 5.5047, 5.5048, 5.5046,\n",
      "        5.5046, 5.5045, 5.5045, 5.5045, 5.5043, 5.5043, 5.5044, 5.5043, 5.5045,\n",
      "        5.5044, 5.5045, 5.5045, 5.5046, 5.5045, 5.5045, 5.5047, 5.5048, 5.5048,\n",
      "        5.5046, 5.5049, 5.5048, 5.5049, 5.5047, 5.5047, 5.5045, 5.5045, 5.5048,\n",
      "        5.5046, 5.5047, 5.5046, 5.5048, 5.5046, 5.5049, 5.5047, 5.5048, 5.5047,\n",
      "        5.5047, 5.5045, 5.5047], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.643747  [359724/5599865]\n",
      "average delta from current occupancy tensor([4.6530, 4.6529, 4.6530, 4.6529, 4.6529, 4.6529, 4.6529, 4.6529, 4.6529,\n",
      "        4.6528, 4.6529, 4.6529, 4.6530, 4.6529, 4.6529, 4.6528, 4.6529, 4.6530,\n",
      "        4.6528, 4.6528, 4.6529, 4.6529, 4.6528, 4.6527, 4.6527, 4.6529, 4.6527,\n",
      "        4.6529, 4.6528, 4.6529, 4.6528, 4.6528, 4.6528, 4.6529, 4.6527, 4.6527,\n",
      "        4.6527, 4.6528, 4.6527, 4.6528, 4.6529, 4.6529, 4.6528, 4.6528, 4.6527,\n",
      "        4.6527, 4.6527, 4.6526, 4.6525, 4.6527, 4.6527, 4.6527, 4.6528, 4.6529,\n",
      "        4.6529, 4.6528, 4.6527, 4.6526, 4.6526, 4.6527, 4.6529, 4.6529, 4.6529,\n",
      "        4.6529, 4.6526, 4.6525, 4.6527, 4.6527, 4.6527, 4.6527, 4.6528, 4.6529,\n",
      "        4.6527, 4.6529, 4.6530, 4.6529, 4.6529, 4.6530, 4.6525, 4.6525, 4.6531,\n",
      "        4.6531, 4.6529, 4.6530, 4.6529, 4.6528, 4.6528, 4.6529, 4.6530, 4.6529,\n",
      "        4.6530, 4.6530, 4.6529, 4.6529, 4.6529, 4.6529, 4.6528, 4.6528, 4.6529,\n",
      "        4.6529, 4.6527, 4.6529, 4.6530, 4.6531, 4.6528, 4.6529, 4.6528, 4.6529,\n",
      "        4.6528, 4.6529, 4.6531, 4.6528, 4.6529, 4.6521, 4.6522, 4.6520, 4.6522,\n",
      "        4.6524, 4.6523, 4.6521], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.486737  [372124/5599865]\n",
      "average delta from current occupancy tensor([5.4758, 5.4758, 5.4759, 5.4759, 5.4759, 5.4759, 5.4759, 5.4758, 5.4758,\n",
      "        5.4760, 5.4758, 5.4759, 5.4759, 5.4759, 5.4759, 5.4758, 5.4758, 5.4758,\n",
      "        5.4759, 5.4759, 5.4760, 5.4760, 5.4760, 5.4760, 5.4758, 5.4759, 5.4760,\n",
      "        5.4758, 5.4758, 5.4759, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4759,\n",
      "        5.4758, 5.4759, 5.4758, 5.4758, 5.4758, 5.4758, 5.4759, 5.4760, 5.4758,\n",
      "        5.4758, 5.4758, 5.4758, 5.4758, 5.4760, 5.4759, 5.4758, 5.4758, 5.4758,\n",
      "        5.4758, 5.4759, 5.4760, 5.4759, 5.4759, 5.4759, 5.4758, 5.4758, 5.4758,\n",
      "        5.4758, 5.4758, 5.4759, 5.4758, 5.4758, 5.4759, 5.4760, 5.4758, 5.4758,\n",
      "        5.4758, 5.4758, 5.4758, 5.4758, 5.4759, 5.4759, 5.4759, 5.4758, 5.4758,\n",
      "        5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4759, 5.4759,\n",
      "        5.4759, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4759,\n",
      "        5.4758, 5.4758, 5.4759, 5.4758, 5.4760, 5.4760, 5.4758, 5.4758, 5.4759,\n",
      "        5.4758, 5.4759, 5.4758, 5.4758, 5.4758, 5.4758, 5.4758, 5.4759, 5.4758,\n",
      "        5.4758, 5.4758, 5.4758], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.914327  [384524/5599865]\n",
      "average delta from current occupancy tensor([4.8860, 4.8862, 4.8861, 4.8861, 4.8861, 4.8859, 4.8860, 4.8859, 4.8859,\n",
      "        4.8860, 4.8859, 4.8859, 4.8861, 4.8859, 4.8859, 4.8860, 4.8860, 4.8860,\n",
      "        4.8860, 4.8861, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860, 4.8859,\n",
      "        4.8859, 4.8858, 4.8859, 4.8859, 4.8859, 4.8859, 4.8859, 4.8859, 4.8859,\n",
      "        4.8860, 4.8859, 4.8860, 4.8859, 4.8858, 4.8859, 4.8859, 4.8859, 4.8860,\n",
      "        4.8860, 4.8860, 4.8861, 4.8861, 4.8861, 4.8860, 4.8862, 4.8860, 4.8860,\n",
      "        4.8860, 4.8860, 4.8861, 4.8860, 4.8860, 4.8861, 4.8860, 4.8860, 4.8860,\n",
      "        4.8861, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860,\n",
      "        4.8860, 4.8861, 4.8860, 4.8860, 4.8860, 4.8860, 4.8860, 4.8861, 4.8859,\n",
      "        4.8859, 4.8859, 4.8859, 4.8859, 4.8859, 4.8860, 4.8860, 4.8860, 4.8859,\n",
      "        4.8859, 4.8859, 4.8860, 4.8858, 4.8857, 4.8858, 4.8858, 4.8857, 4.8858,\n",
      "        4.8858, 4.8858, 4.8858, 4.8859, 4.8859, 4.8860, 4.8859, 4.8860, 4.8860,\n",
      "        4.8860, 4.8859, 4.8858, 4.8860, 4.8859, 4.8858, 4.8860, 4.8858, 4.8861,\n",
      "        4.8861, 4.8860, 4.8859], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.831915  [396924/5599865]\n",
      "average delta from current occupancy tensor([4.9032, 4.9031, 4.9032, 4.9031, 4.9031, 4.9031, 4.9030, 4.9030, 4.9030,\n",
      "        4.9031, 4.9031, 4.9031, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032, 4.9032,\n",
      "        4.9031, 4.9031, 4.9030, 4.9031, 4.9029, 4.9031, 4.9031, 4.9032, 4.9031,\n",
      "        4.9031, 4.9030, 4.9031, 4.9032, 4.9032, 4.9033, 4.9031, 4.9034, 4.9031,\n",
      "        4.9030, 4.9030, 4.9033, 4.9030, 4.9030, 4.9029, 4.9030, 4.9029, 4.9030,\n",
      "        4.9030, 4.9030, 4.9030, 4.9031, 4.9030, 4.9030, 4.9031, 4.9031, 4.9031,\n",
      "        4.9032, 4.9033, 4.9032, 4.9031, 4.9029, 4.9030, 4.9029, 4.9030, 4.9030,\n",
      "        4.9029, 4.9028, 4.9029, 4.9028, 4.9029, 4.9029, 4.9029, 4.9030, 4.9028,\n",
      "        4.9028, 4.9031, 4.9031, 4.9030, 4.9029, 4.9029, 4.9030, 4.9031, 4.9032,\n",
      "        4.9032, 4.9029, 4.9029, 4.9030, 4.9030, 4.9028, 4.9030, 4.9033, 4.9029,\n",
      "        4.9030, 4.9029, 4.9032, 4.9030, 4.9029, 4.9029, 4.9028, 4.9029, 4.9027,\n",
      "        4.9027, 4.9029, 4.9029, 4.9029, 4.9027, 4.9027, 4.9028, 4.9028, 4.9027,\n",
      "        4.9029, 4.9029, 4.9030, 4.9030, 4.9030, 4.9029, 4.9029, 4.9029, 4.9029,\n",
      "        4.9030, 4.9030, 4.9029], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.444963  [409324/5599865]\n",
      "average delta from current occupancy tensor([5.7872, 5.7875, 5.7874, 5.7873, 5.7873, 5.7872, 5.7874, 5.7872, 5.7872,\n",
      "        5.7874, 5.7872, 5.7873, 5.7874, 5.7877, 5.7878, 5.7878, 5.7878, 5.7875,\n",
      "        5.7874, 5.7875, 5.7874, 5.7875, 5.7878, 5.7876, 5.7879, 5.7877, 5.7877,\n",
      "        5.7876, 5.7876, 5.7877, 5.7874, 5.7878, 5.7878, 5.7880, 5.7880, 5.7878,\n",
      "        5.7880, 5.7880, 5.7881, 5.7879, 5.7879, 5.7878, 5.7878, 5.7877, 5.7877,\n",
      "        5.7880, 5.7879, 5.7881, 5.7880, 5.7883, 5.7883, 5.7881, 5.7881, 5.7880,\n",
      "        5.7880, 5.7880, 5.7882, 5.7884, 5.7880, 5.7879, 5.7878, 5.7877, 5.7880,\n",
      "        5.7880, 5.7882, 5.7886, 5.7884, 5.7880, 5.7879, 5.7881, 5.7878, 5.7881,\n",
      "        5.7880, 5.7874, 5.7875, 5.7876, 5.7875, 5.7879, 5.7878, 5.7878, 5.7879,\n",
      "        5.7878, 5.7878, 5.7880, 5.7881, 5.7880, 5.7880, 5.7878, 5.7876, 5.7877,\n",
      "        5.7877, 5.7879, 5.7880, 5.7878, 5.7879, 5.7880, 5.7881, 5.7881, 5.7882,\n",
      "        5.7880, 5.7881, 5.7879, 5.7882, 5.7884, 5.7885, 5.7886, 5.7884, 5.7885,\n",
      "        5.7885, 5.7886, 5.7885, 5.7888, 5.7885, 5.7885, 5.7884, 5.7883, 5.7883,\n",
      "        5.7882, 5.7882, 5.7882], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.713675  [421724/5599865]\n",
      "average delta from current occupancy tensor([4.6938, 4.6939, 4.6939, 4.6937, 4.6939, 4.6938, 4.6937, 4.6939, 4.6938,\n",
      "        4.6940, 4.6939, 4.6940, 4.6939, 4.6939, 4.6940, 4.6939, 4.6940, 4.6938,\n",
      "        4.6937, 4.6937, 4.6937, 4.6938, 4.6938, 4.6938, 4.6937, 4.6937, 4.6939,\n",
      "        4.6939, 4.6940, 4.6940, 4.6939, 4.6939, 4.6937, 4.6938, 4.6939, 4.6938,\n",
      "        4.6939, 4.6938, 4.6938, 4.6938, 4.6938, 4.6937, 4.6936, 4.6936, 4.6937,\n",
      "        4.6938, 4.6937, 4.6938, 4.6936, 4.6938, 4.6938, 4.6938, 4.6937, 4.6937,\n",
      "        4.6937, 4.6937, 4.6937, 4.6935, 4.6936, 4.6938, 4.6938, 4.6938, 4.6938,\n",
      "        4.6936, 4.6937, 4.6938, 4.6938, 4.6938, 4.6937, 4.6937, 4.6936, 4.6936,\n",
      "        4.6937, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936,\n",
      "        4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936,\n",
      "        4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936,\n",
      "        4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6936,\n",
      "        4.6936, 4.6936, 4.6936, 4.6936, 4.6936, 4.6935, 4.6936, 4.6936, 4.6936,\n",
      "        4.6936, 4.6936, 4.6936], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.225932  [434124/5599865]\n",
      "average delta from current occupancy tensor([5.1536, 5.1537, 5.1535, 5.1536, 5.1536, 5.1535, 5.1536, 5.1536, 5.1536,\n",
      "        5.1536, 5.1537, 5.1537, 5.1537, 5.1537, 5.1537, 5.1537, 5.1537, 5.1537,\n",
      "        5.1536, 5.1536, 5.1537, 5.1536, 5.1537, 5.1536, 5.1537, 5.1537, 5.1537,\n",
      "        5.1537, 5.1537, 5.1537, 5.1536, 5.1536, 5.1535, 5.1536, 5.1536, 5.1536,\n",
      "        5.1536, 5.1536, 5.1536, 5.1537, 5.1536, 5.1536, 5.1536, 5.1536, 5.1536,\n",
      "        5.1536, 5.1535, 5.1535, 5.1536, 5.1536, 5.1536, 5.1536, 5.1536, 5.1536,\n",
      "        5.1536, 5.1536, 5.1535, 5.1536, 5.1537, 5.1537, 5.1536, 5.1535, 5.1535,\n",
      "        5.1534, 5.1535, 5.1535, 5.1535, 5.1534, 5.1535, 5.1535, 5.1535, 5.1535,\n",
      "        5.1534, 5.1534, 5.1534, 5.1533, 5.1534, 5.1534, 5.1535, 5.1534, 5.1535,\n",
      "        5.1534, 5.1536, 5.1535, 5.1536, 5.1535, 5.1536, 5.1536, 5.1535, 5.1536,\n",
      "        5.1536, 5.1536, 5.1536, 5.1536, 5.1537, 5.1537, 5.1537, 5.1538, 5.1537,\n",
      "        5.1535, 5.1536, 5.1536, 5.1537, 5.1536, 5.1537, 5.1537, 5.1537, 5.1537,\n",
      "        5.1537, 5.1536, 5.1537, 5.1537, 5.1539, 5.1539, 5.1537, 5.1537, 5.1537,\n",
      "        5.1537, 5.1536, 5.1535], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.594044  [446524/5599865]\n",
      "average delta from current occupancy tensor([5.8472, 5.8472, 5.8473, 5.8474, 5.8474, 5.8473, 5.8473, 5.8473, 5.8473,\n",
      "        5.8473, 5.8472, 5.8472, 5.8473, 5.8472, 5.8472, 5.8472, 5.8473, 5.8472,\n",
      "        5.8471, 5.8472, 5.8473, 5.8473, 5.8474, 5.8473, 5.8473, 5.8474, 5.8472,\n",
      "        5.8472, 5.8473, 5.8473, 5.8473, 5.8472, 5.8472, 5.8471, 5.8472, 5.8472,\n",
      "        5.8471, 5.8471, 5.8471, 5.8472, 5.8471, 5.8472, 5.8472, 5.8471, 5.8471,\n",
      "        5.8471, 5.8472, 5.8472, 5.8472, 5.8472, 5.8472, 5.8472, 5.8472, 5.8472,\n",
      "        5.8472, 5.8472, 5.8472, 5.8471, 5.8472, 5.8472, 5.8471, 5.8472, 5.8471,\n",
      "        5.8472, 5.8472, 5.8472, 5.8471, 5.8471, 5.8471, 5.8472, 5.8471, 5.8473,\n",
      "        5.8472, 5.8472, 5.8473, 5.8472, 5.8472, 5.8473, 5.8472, 5.8472, 5.8472,\n",
      "        5.8472, 5.8472, 5.8471, 5.8472, 5.8472, 5.8473, 5.8472, 5.8472, 5.8473,\n",
      "        5.8472, 5.8472, 5.8472, 5.8472, 5.8473, 5.8473, 5.8472, 5.8472, 5.8472,\n",
      "        5.8472, 5.8471, 5.8472, 5.8472, 5.8472, 5.8471, 5.8471, 5.8471, 5.8472,\n",
      "        5.8472, 5.8472, 5.8472, 5.8473, 5.8472, 5.8472, 5.8472, 5.8472, 5.8472,\n",
      "        5.8472, 5.8472, 5.8472], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.432344  [458924/5599865]\n",
      "average delta from current occupancy tensor([5.4518, 5.4518, 5.4517, 5.4517, 5.4517, 5.4518, 5.4517, 5.4517, 5.4517,\n",
      "        5.4517, 5.4517, 5.4518, 5.4517, 5.4517, 5.4518, 5.4518, 5.4517, 5.4518,\n",
      "        5.4518, 5.4518, 5.4518, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4518,\n",
      "        5.4518, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517,\n",
      "        5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518,\n",
      "        5.4518, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517,\n",
      "        5.4517, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518,\n",
      "        5.4517, 5.4517, 5.4517, 5.4517, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518,\n",
      "        5.4518, 5.4518, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517,\n",
      "        5.4517, 5.4517, 5.4518, 5.4517, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518,\n",
      "        5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4517,\n",
      "        5.4518, 5.4518, 5.4517, 5.4517, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518,\n",
      "        5.4518, 5.4517, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518, 5.4518,\n",
      "        5.4517, 5.4518, 5.4518], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.440516  [471324/5599865]\n",
      "average delta from current occupancy tensor([4.3462, 4.3464, 4.3463, 4.3463, 4.3463, 4.3462, 4.3463, 4.3463, 4.3463,\n",
      "        4.3463, 4.3462, 4.3461, 4.3461, 4.3462, 4.3462, 4.3460, 4.3461, 4.3462,\n",
      "        4.3461, 4.3461, 4.3460, 4.3461, 4.3460, 4.3460, 4.3461, 4.3463, 4.3462,\n",
      "        4.3462, 4.3462, 4.3462, 4.3462, 4.3463, 4.3461, 4.3462, 4.3461, 4.3460,\n",
      "        4.3461, 4.3461, 4.3460, 4.3460, 4.3459, 4.3459, 4.3459, 4.3459, 4.3458,\n",
      "        4.3458, 4.3458, 4.3458, 4.3459, 4.3458, 4.3459, 4.3460, 4.3459, 4.3459,\n",
      "        4.3460, 4.3461, 4.3459, 4.3458, 4.3457, 4.3457, 4.3459, 4.3458, 4.3458,\n",
      "        4.3458, 4.3459, 4.3459, 4.3458, 4.3458, 4.3458, 4.3458, 4.3457, 4.3457,\n",
      "        4.3458, 4.3458, 4.3458, 4.3459, 4.3461, 4.3460, 4.3460, 4.3458, 4.3459,\n",
      "        4.3461, 4.3461, 4.3460, 4.3461, 4.3460, 4.3462, 4.3460, 4.3461, 4.3460,\n",
      "        4.3460, 4.3460, 4.3461, 4.3460, 4.3460, 4.3461, 4.3459, 4.3460, 4.3460,\n",
      "        4.3460, 4.3459, 4.3460, 4.3460, 4.3459, 4.3461, 4.3461, 4.3461, 4.3460,\n",
      "        4.3461, 4.3461, 4.3460, 4.3457, 4.3458, 4.3456, 4.3459, 4.3457, 4.3459,\n",
      "        4.3457, 4.3457, 4.3457], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.418781  [483724/5599865]\n",
      "average delta from current occupancy tensor([5.6702, 5.6702, 5.6701, 5.6701, 5.6701, 5.6700, 5.6701, 5.6700, 5.6700,\n",
      "        5.6700, 5.6699, 5.6699, 5.6700, 5.6700, 5.6700, 5.6700, 5.6700, 5.6701,\n",
      "        5.6700, 5.6699, 5.6700, 5.6700, 5.6699, 5.6700, 5.6701, 5.6700, 5.6701,\n",
      "        5.6701, 5.6700, 5.6700, 5.6701, 5.6701, 5.6700, 5.6700, 5.6701, 5.6701,\n",
      "        5.6701, 5.6702, 5.6702, 5.6701, 5.6702, 5.6702, 5.6702, 5.6701, 5.6700,\n",
      "        5.6702, 5.6702, 5.6700, 5.6700, 5.6701, 5.6701, 5.6702, 5.6703, 5.6703,\n",
      "        5.6701, 5.6701, 5.6701, 5.6702, 5.6703, 5.6701, 5.6701, 5.6702, 5.6702,\n",
      "        5.6702, 5.6701, 5.6703, 5.6702, 5.6702, 5.6702, 5.6702, 5.6702, 5.6702,\n",
      "        5.6701, 5.6700, 5.6700, 5.6702, 5.6702, 5.6701, 5.6701, 5.6701, 5.6701,\n",
      "        5.6701, 5.6701, 5.6702, 5.6701, 5.6700, 5.6700, 5.6700, 5.6700, 5.6700,\n",
      "        5.6698, 5.6699, 5.6699, 5.6698, 5.6699, 5.6697, 5.6698, 5.6699, 5.6699,\n",
      "        5.6699, 5.6698, 5.6700, 5.6700, 5.6700, 5.6698, 5.6699, 5.6700, 5.6700,\n",
      "        5.6700, 5.6698, 5.6700, 5.6702, 5.6700, 5.6700, 5.6700, 5.6701, 5.6699,\n",
      "        5.6700, 5.6701, 5.6701], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.705911  [496124/5599865]\n",
      "average delta from current occupancy tensor([5.6935, 5.6935, 5.6934, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6936,\n",
      "        5.6936, 5.6935, 5.6936, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935,\n",
      "        5.6935, 5.6935, 5.6935, 5.6936, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935,\n",
      "        5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6936, 5.6935, 5.6935, 5.6935,\n",
      "        5.6936, 5.6935, 5.6934, 5.6935, 5.6934, 5.6934, 5.6935, 5.6934, 5.6935,\n",
      "        5.6934, 5.6935, 5.6934, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935,\n",
      "        5.6934, 5.6934, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935,\n",
      "        5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935, 5.6935,\n",
      "        5.6934, 5.6935, 5.6935, 5.6935, 5.6935, 5.6934, 5.6934, 5.6934, 5.6934,\n",
      "        5.6934, 5.6934, 5.6936, 5.6936, 5.6934, 5.6935, 5.6935, 5.6935, 5.6934,\n",
      "        5.6935, 5.6934, 5.6935, 5.6935, 5.6935, 5.6936, 5.6934, 5.6934, 5.6935,\n",
      "        5.6934, 5.6934, 5.6935, 5.6935, 5.6935, 5.6935, 5.6934, 5.6935, 5.6935,\n",
      "        5.6935, 5.6934, 5.6935, 5.6935, 5.6934, 5.6935, 5.6934, 5.6935, 5.6935,\n",
      "        5.6934, 5.6935, 5.6934], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.054184  [508524/5599865]\n",
      "average delta from current occupancy tensor([5.1292, 5.1293, 5.1292, 5.1293, 5.1293, 5.1292, 5.1292, 5.1293, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1293, 5.1293, 5.1292, 5.1293, 5.1292, 5.1293, 5.1293,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1291, 5.1292, 5.1292, 5.1292, 5.1292, 5.1291, 5.1292, 5.1292,\n",
      "        5.1291, 5.1292, 5.1292, 5.1291, 5.1291, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1291, 5.1291, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292, 5.1292,\n",
      "        5.1292, 5.1292, 5.1292], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.414451  [520924/5599865]\n",
      "average delta from current occupancy tensor([5.3562, 5.3562, 5.3564, 5.3563, 5.3565, 5.3567, 5.3565, 5.3563, 5.3565,\n",
      "        5.3565, 5.3565, 5.3562, 5.3565, 5.3563, 5.3565, 5.3565, 5.3564, 5.3565,\n",
      "        5.3566, 5.3566, 5.3565, 5.3566, 5.3564, 5.3568, 5.3567, 5.3566, 5.3565,\n",
      "        5.3568, 5.3566, 5.3565, 5.3566, 5.3566, 5.3566, 5.3566, 5.3567, 5.3565,\n",
      "        5.3566, 5.3566, 5.3567, 5.3563, 5.3564, 5.3563, 5.3565, 5.3564, 5.3563,\n",
      "        5.3562, 5.3562, 5.3564, 5.3562, 5.3565, 5.3563, 5.3565, 5.3564, 5.3565,\n",
      "        5.3564, 5.3564, 5.3565, 5.3566, 5.3566, 5.3565, 5.3566, 5.3562, 5.3562,\n",
      "        5.3564, 5.3561, 5.3562, 5.3561, 5.3561, 5.3562, 5.3564, 5.3563, 5.3564,\n",
      "        5.3564, 5.3563, 5.3563, 5.3563, 5.3563, 5.3562, 5.3562, 5.3563, 5.3562,\n",
      "        5.3563, 5.3559, 5.3562, 5.3562, 5.3562, 5.3564, 5.3565, 5.3564, 5.3561,\n",
      "        5.3562, 5.3564, 5.3564, 5.3565, 5.3563, 5.3565, 5.3564, 5.3560, 5.3561,\n",
      "        5.3561, 5.3562, 5.3560, 5.3559, 5.3560, 5.3561, 5.3562, 5.3560, 5.3560,\n",
      "        5.3563, 5.3561, 5.3564, 5.3563, 5.3558, 5.3559, 5.3562, 5.3560, 5.3560,\n",
      "        5.3559, 5.3563, 5.3561], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.727134  [533324/5599865]\n",
      "average delta from current occupancy tensor([4.6783, 4.6784, 4.6783, 4.6784, 4.6781, 4.6780, 4.6782, 4.6784, 4.6783,\n",
      "        4.6783, 4.6783, 4.6784, 4.6782, 4.6784, 4.6784, 4.6783, 4.6785, 4.6784,\n",
      "        4.6783, 4.6782, 4.6782, 4.6782, 4.6783, 4.6781, 4.6781, 4.6781, 4.6781,\n",
      "        4.6780, 4.6780, 4.6781, 4.6779, 4.6779, 4.6779, 4.6779, 4.6778, 4.6778,\n",
      "        4.6778, 4.6778, 4.6778, 4.6781, 4.6781, 4.6780, 4.6779, 4.6779, 4.6780,\n",
      "        4.6781, 4.6781, 4.6780, 4.6780, 4.6780, 4.6779, 4.6779, 4.6779, 4.6779,\n",
      "        4.6778, 4.6777, 4.6777, 4.6777, 4.6777, 4.6777, 4.6778, 4.6779, 4.6779,\n",
      "        4.6777, 4.6780, 4.6781, 4.6781, 4.6780, 4.6781, 4.6780, 4.6780, 4.6781,\n",
      "        4.6780, 4.6781, 4.6782, 4.6782, 4.6782, 4.6783, 4.6783, 4.6784, 4.6784,\n",
      "        4.6784, 4.6786, 4.6786, 4.6786, 4.6786, 4.6785, 4.6785, 4.6785, 4.6785,\n",
      "        4.6786, 4.6784, 4.6784, 4.6783, 4.6784, 4.6784, 4.6784, 4.6786, 4.6787,\n",
      "        4.6786, 4.6786, 4.6787, 4.6787, 4.6786, 4.6786, 4.6786, 4.6786, 4.6786,\n",
      "        4.6785, 4.6786, 4.6784, 4.6785, 4.6788, 4.6787, 4.6786, 4.6786, 4.6787,\n",
      "        4.6787, 4.6786, 4.6787], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.318922  [545724/5599865]\n",
      "average delta from current occupancy tensor([5.0658, 5.0657, 5.0659, 5.0660, 5.0661, 5.0661, 5.0660, 5.0661, 5.0661,\n",
      "        5.0660, 5.0660, 5.0660, 5.0660, 5.0657, 5.0659, 5.0660, 5.0660, 5.0660,\n",
      "        5.0659, 5.0660, 5.0661, 5.0663, 5.0662, 5.0661, 5.0660, 5.0662, 5.0662,\n",
      "        5.0661, 5.0662, 5.0663, 5.0661, 5.0661, 5.0661, 5.0661, 5.0661, 5.0658,\n",
      "        5.0658, 5.0658, 5.0658, 5.0658, 5.0658, 5.0659, 5.0659, 5.0659, 5.0660,\n",
      "        5.0660, 5.0660, 5.0661, 5.0660, 5.0659, 5.0660, 5.0659, 5.0659, 5.0658,\n",
      "        5.0659, 5.0659, 5.0661, 5.0660, 5.0661, 5.0660, 5.0661, 5.0658, 5.0660,\n",
      "        5.0658, 5.0658, 5.0660, 5.0659, 5.0658, 5.0658, 5.0658, 5.0659, 5.0660,\n",
      "        5.0659, 5.0659, 5.0661, 5.0660, 5.0661, 5.0662, 5.0661, 5.0661, 5.0660,\n",
      "        5.0660, 5.0658, 5.0660, 5.0660, 5.0660, 5.0660, 5.0662, 5.0661, 5.0660,\n",
      "        5.0661, 5.0662, 5.0661, 5.0660, 5.0661, 5.0662, 5.0662, 5.0662, 5.0662,\n",
      "        5.0661, 5.0662, 5.0661, 5.0661, 5.0662, 5.0661, 5.0662, 5.0662, 5.0663,\n",
      "        5.0663, 5.0663, 5.0663, 5.0664, 5.0663, 5.0664, 5.0665, 5.0664, 5.0664,\n",
      "        5.0663, 5.0662, 5.0662], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.532920  [558124/5599865]\n",
      "average delta from current occupancy tensor([4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4998,\n",
      "        4.4998, 4.4998, 4.4998, 4.4999, 4.4999, 4.4998, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4998, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999, 4.4999,\n",
      "        4.4999, 4.4999, 4.4999], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.267155  [570524/5599865]\n",
      "average delta from current occupancy tensor([5.3946, 5.3946, 5.3945, 5.3945, 5.3946, 5.3946, 5.3946, 5.3945, 5.3945,\n",
      "        5.3945, 5.3946, 5.3945, 5.3946, 5.3946, 5.3945, 5.3946, 5.3947, 5.3947,\n",
      "        5.3947, 5.3946, 5.3946, 5.3946, 5.3947, 5.3946, 5.3946, 5.3946, 5.3946,\n",
      "        5.3946, 5.3945, 5.3946, 5.3946, 5.3946, 5.3945, 5.3945, 5.3946, 5.3945,\n",
      "        5.3945, 5.3945, 5.3945, 5.3945, 5.3945, 5.3945, 5.3945, 5.3946, 5.3946,\n",
      "        5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946,\n",
      "        5.3946, 5.3945, 5.3946, 5.3946, 5.3947, 5.3946, 5.3946, 5.3946, 5.3946,\n",
      "        5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3947, 5.3946, 5.3946,\n",
      "        5.3946, 5.3946, 5.3947, 5.3946, 5.3946, 5.3946, 5.3947, 5.3947, 5.3947,\n",
      "        5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3947, 5.3946,\n",
      "        5.3946, 5.3946, 5.3945, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946,\n",
      "        5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3946, 5.3947, 5.3946, 5.3946,\n",
      "        5.3947, 5.3946, 5.3947, 5.3946, 5.3945, 5.3946, 5.3946, 5.3946, 5.3946,\n",
      "        5.3947, 5.3946, 5.3946], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.189615  [582924/5599865]\n",
      "average delta from current occupancy tensor([5.2176, 5.2177, 5.2177, 5.2176, 5.2177, 5.2177, 5.2179, 5.2178, 5.2177,\n",
      "        5.2177, 5.2177, 5.2177, 5.2177, 5.2177, 5.2177, 5.2175, 5.2176, 5.2176,\n",
      "        5.2176, 5.2177, 5.2177, 5.2175, 5.2176, 5.2176, 5.2177, 5.2178, 5.2177,\n",
      "        5.2178, 5.2177, 5.2176, 5.2176, 5.2175, 5.2176, 5.2179, 5.2177, 5.2176,\n",
      "        5.2178, 5.2180, 5.2177, 5.2177, 5.2177, 5.2177, 5.2177, 5.2180, 5.2179,\n",
      "        5.2177, 5.2179, 5.2178, 5.2177, 5.2178, 5.2179, 5.2181, 5.2179, 5.2180,\n",
      "        5.2181, 5.2179, 5.2180, 5.2177, 5.2176, 5.2176, 5.2175, 5.2175, 5.2175,\n",
      "        5.2176, 5.2176, 5.2175, 5.2175, 5.2174, 5.2175, 5.2175, 5.2175, 5.2174,\n",
      "        5.2174, 5.2174, 5.2174, 5.2173, 5.2173, 5.2172, 5.2174, 5.2173, 5.2173,\n",
      "        5.2174, 5.2173, 5.2173, 5.2174, 5.2173, 5.2174, 5.2173, 5.2173, 5.2174,\n",
      "        5.2174, 5.2173, 5.2173, 5.2174, 5.2173, 5.2174, 5.2173, 5.2173, 5.2173,\n",
      "        5.2173, 5.2172, 5.2172, 5.2173, 5.2172, 5.2173, 5.2173, 5.2172, 5.2171,\n",
      "        5.2171, 5.2171, 5.2172, 5.2171, 5.2172, 5.2171, 5.2170, 5.2171, 5.2171,\n",
      "        5.2171, 5.2171, 5.2171], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.262779  [595324/5599865]\n",
      "average delta from current occupancy tensor([5.1779, 5.1778, 5.1779, 5.1777, 5.1780, 5.1780, 5.1780, 5.1780, 5.1778,\n",
      "        5.1778, 5.1780, 5.1780, 5.1778, 5.1779, 5.1778, 5.1781, 5.1781, 5.1780,\n",
      "        5.1781, 5.1780, 5.1780, 5.1783, 5.1781, 5.1781, 5.1781, 5.1778, 5.1779,\n",
      "        5.1778, 5.1781, 5.1782, 5.1782, 5.1783, 5.1781, 5.1780, 5.1782, 5.1781,\n",
      "        5.1780, 5.1780, 5.1779, 5.1780, 5.1780, 5.1781, 5.1782, 5.1783, 5.1782,\n",
      "        5.1780, 5.1780, 5.1780, 5.1780, 5.1779, 5.1779, 5.1780, 5.1779, 5.1780,\n",
      "        5.1781, 5.1781, 5.1779, 5.1779, 5.1781, 5.1781, 5.1781, 5.1781, 5.1782,\n",
      "        5.1782, 5.1779, 5.1780, 5.1781, 5.1780, 5.1781, 5.1781, 5.1782, 5.1782,\n",
      "        5.1781, 5.1781, 5.1780, 5.1780, 5.1780, 5.1779, 5.1780, 5.1781, 5.1780,\n",
      "        5.1780, 5.1780, 5.1781, 5.1780, 5.1779, 5.1779, 5.1781, 5.1782, 5.1782,\n",
      "        5.1781, 5.1781, 5.1782, 5.1782, 5.1782, 5.1782, 5.1782, 5.1782, 5.1782,\n",
      "        5.1781, 5.1780, 5.1781, 5.1782, 5.1782, 5.1783, 5.1782, 5.1780, 5.1779,\n",
      "        5.1779, 5.1779, 5.1781, 5.1779, 5.1781, 5.1780, 5.1780, 5.1782, 5.1782,\n",
      "        5.1782, 5.1781, 5.1782], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.226190  [607724/5599865]\n",
      "average delta from current occupancy tensor([5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4356, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355, 5.4355,\n",
      "        5.4355, 5.4355, 5.4355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.714101  [620124/5599865]\n",
      "average delta from current occupancy tensor([4.7024, 4.7024, 4.7025, 4.7024, 4.7025, 4.7024, 4.7024, 4.7024, 4.7024,\n",
      "        4.7024, 4.7024, 4.7025, 4.7025, 4.7024, 4.7024, 4.7024, 4.7024, 4.7024,\n",
      "        4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7024, 4.7024,\n",
      "        4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7024, 4.7023, 4.7023, 4.7023,\n",
      "        4.7022, 4.7022, 4.7022, 4.7023, 4.7022, 4.7023, 4.7022, 4.7023, 4.7023,\n",
      "        4.7023, 4.7023, 4.7022, 4.7023, 4.7022, 4.7022, 4.7022, 4.7022, 4.7022,\n",
      "        4.7022, 4.7022, 4.7022, 4.7022, 4.7022, 4.7022, 4.7022, 4.7022, 4.7022,\n",
      "        4.7022, 4.7021, 4.7021, 4.7021, 4.7020, 4.7021, 4.7021, 4.7021, 4.7021,\n",
      "        4.7021, 4.7022, 4.7022, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023,\n",
      "        4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7023, 4.7024,\n",
      "        4.7023, 4.7024, 4.7024, 4.7024, 4.7024, 4.7023, 4.7024, 4.7024, 4.7024,\n",
      "        4.7024, 4.7024, 4.7025, 4.7025, 4.7025, 4.7025, 4.7025, 4.7025, 4.7025,\n",
      "        4.7024, 4.7025, 4.7024, 4.7023, 4.7024, 4.7023, 4.7024, 4.7023, 4.7024,\n",
      "        4.7024, 4.7024, 4.7024], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.890474  [632524/5599865]\n",
      "average delta from current occupancy tensor([4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8468, 4.8468], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.877518  [644924/5599865]\n",
      "average delta from current occupancy tensor([4.8548, 4.8549, 4.8548, 4.8549, 4.8548, 4.8548, 4.8548, 4.8549, 4.8547,\n",
      "        4.8548, 4.8546, 4.8548, 4.8547, 4.8547, 4.8547, 4.8546, 4.8547, 4.8549,\n",
      "        4.8547, 4.8547, 4.8547, 4.8548, 4.8548, 4.8548, 4.8550, 4.8551, 4.8550,\n",
      "        4.8551, 4.8550, 4.8549, 4.8550, 4.8551, 4.8547, 4.8548, 4.8550, 4.8553,\n",
      "        4.8554, 4.8551, 4.8550, 4.8552, 4.8553, 4.8555, 4.8552, 4.8552, 4.8551,\n",
      "        4.8550, 4.8549, 4.8551, 4.8549, 4.8551, 4.8552, 4.8550, 4.8552, 4.8550,\n",
      "        4.8552, 4.8552, 4.8550, 4.8551, 4.8549, 4.8552, 4.8548, 4.8548, 4.8548,\n",
      "        4.8549, 4.8549, 4.8550, 4.8553, 4.8551, 4.8553, 4.8550, 4.8553, 4.8553,\n",
      "        4.8554, 4.8553, 4.8552, 4.8553, 4.8554, 4.8554, 4.8554, 4.8553, 4.8552,\n",
      "        4.8554, 4.8554, 4.8553, 4.8556, 4.8552, 4.8556, 4.8556, 4.8553, 4.8554,\n",
      "        4.8553, 4.8552, 4.8552, 4.8551, 4.8553, 4.8554, 4.8552, 4.8550, 4.8552,\n",
      "        4.8551, 4.8553, 4.8552, 4.8553, 4.8552, 4.8555, 4.8556, 4.8559, 4.8554,\n",
      "        4.8554, 4.8556, 4.8557, 4.8559, 4.8558, 4.8557, 4.8553, 4.8553, 4.8552,\n",
      "        4.8553, 4.8555, 4.8553], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.354300  [657324/5599865]\n",
      "average delta from current occupancy tensor([4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3146, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3146, 4.3145,\n",
      "        4.3145, 4.3146, 4.3148, 4.3146, 4.3145, 4.3145, 4.3147, 4.3148, 4.3148,\n",
      "        4.3146, 4.3145, 4.3145, 4.3145, 4.3147, 4.3148, 4.3148, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3146, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.445478  [669724/5599865]\n",
      "average delta from current occupancy tensor([4.6131, 4.6133, 4.6133, 4.6134, 4.6133, 4.6133, 4.6134, 4.6133, 4.6134,\n",
      "        4.6132, 4.6131, 4.6131, 4.6131, 4.6130, 4.6131, 4.6129, 4.6130, 4.6131,\n",
      "        4.6130, 4.6130, 4.6131, 4.6129, 4.6129, 4.6129, 4.6131, 4.6129, 4.6130,\n",
      "        4.6131, 4.6131, 4.6130, 4.6131, 4.6132, 4.6131, 4.6130, 4.6130, 4.6129,\n",
      "        4.6128, 4.6128, 4.6132, 4.6129, 4.6129, 4.6130, 4.6130, 4.6129, 4.6129,\n",
      "        4.6129, 4.6130, 4.6130, 4.6130, 4.6131, 4.6132, 4.6130, 4.6131, 4.6131,\n",
      "        4.6130, 4.6133, 4.6131, 4.6130, 4.6131, 4.6132, 4.6132, 4.6132, 4.6131,\n",
      "        4.6131, 4.6129, 4.6130, 4.6130, 4.6131, 4.6131, 4.6130, 4.6129, 4.6130,\n",
      "        4.6129, 4.6127, 4.6127, 4.6126, 4.6127, 4.6129, 4.6129, 4.6129, 4.6130,\n",
      "        4.6129, 4.6130, 4.6131, 4.6131, 4.6129, 4.6129, 4.6129, 4.6132, 4.6131,\n",
      "        4.6130, 4.6132, 4.6131, 4.6129, 4.6130, 4.6130, 4.6129, 4.6131, 4.6129,\n",
      "        4.6129, 4.6128, 4.6127, 4.6128, 4.6126, 4.6127, 4.6129, 4.6129, 4.6130,\n",
      "        4.6129, 4.6129, 4.6129, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6129, 4.6128], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.907998  [682124/5599865]\n",
      "average delta from current occupancy tensor([4.8397, 4.8396, 4.8396, 4.8398, 4.8396, 4.8396, 4.8396, 4.8396, 4.8397,\n",
      "        4.8396, 4.8396, 4.8394, 4.8396, 4.8398, 4.8398, 4.8398, 4.8398, 4.8399,\n",
      "        4.8399, 4.8398, 4.8398, 4.8398, 4.8397, 4.8400, 4.8397, 4.8397, 4.8399,\n",
      "        4.8396, 4.8399, 4.8398, 4.8396, 4.8397, 4.8399, 4.8396, 4.8393, 4.8393,\n",
      "        4.8395, 4.8395, 4.8397, 4.8398, 4.8398, 4.8395, 4.8397, 4.8397, 4.8395,\n",
      "        4.8395, 4.8398, 4.8399, 4.8398, 4.8397, 4.8397, 4.8398, 4.8398, 4.8398,\n",
      "        4.8395, 4.8397, 4.8397, 4.8394, 4.8399, 4.8393, 4.8396, 4.8397, 4.8395,\n",
      "        4.8398, 4.8395, 4.8394, 4.8397, 4.8399, 4.8396, 4.8398, 4.8398, 4.8398,\n",
      "        4.8399, 4.8397, 4.8398, 4.8397, 4.8397, 4.8399, 4.8398, 4.8397, 4.8398,\n",
      "        4.8397, 4.8398, 4.8398, 4.8395, 4.8396, 4.8399, 4.8400, 4.8399, 4.8399,\n",
      "        4.8400, 4.8400, 4.8399, 4.8399, 4.8401, 4.8400, 4.8401, 4.8400, 4.8401,\n",
      "        4.8401, 4.8399, 4.8400, 4.8400, 4.8398, 4.8401, 4.8402, 4.8397, 4.8401,\n",
      "        4.8398, 4.8401, 4.8398, 4.8401, 4.8401, 4.8400, 4.8399, 4.8398, 4.8400,\n",
      "        4.8397, 4.8400, 4.8400], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.522726  [694524/5599865]\n",
      "average delta from current occupancy tensor([5.3061, 5.3060, 5.3062, 5.3060, 5.3060, 5.3061, 5.3061, 5.3061, 5.3061,\n",
      "        5.3060, 5.3062, 5.3062, 5.3062, 5.3063, 5.3062, 5.3062, 5.3062, 5.3059,\n",
      "        5.3058, 5.3058, 5.3061, 5.3060, 5.3060, 5.3059, 5.3060, 5.3061, 5.3059,\n",
      "        5.3063, 5.3059, 5.3062, 5.3064, 5.3063, 5.3061, 5.3062, 5.3062, 5.3061,\n",
      "        5.3063, 5.3063, 5.3062, 5.3063, 5.3063, 5.3063, 5.3063, 5.3063, 5.3062,\n",
      "        5.3063, 5.3063, 5.3062, 5.3063, 5.3063, 5.3062, 5.3062, 5.3062, 5.3062,\n",
      "        5.3064, 5.3065, 5.3064, 5.3064, 5.3064, 5.3062, 5.3063, 5.3063, 5.3063,\n",
      "        5.3062, 5.3064, 5.3064, 5.3063, 5.3061, 5.3064, 5.3062, 5.3064, 5.3062,\n",
      "        5.3062, 5.3064, 5.3061, 5.3065, 5.3062, 5.3062, 5.3061, 5.3064, 5.3064,\n",
      "        5.3063, 5.3061, 5.3060, 5.3062, 5.3064, 5.3061, 5.3062, 5.3062, 5.3062,\n",
      "        5.3062, 5.3062, 5.3063, 5.3062, 5.3063, 5.3060, 5.3060, 5.3060, 5.3061,\n",
      "        5.3061, 5.3061, 5.3060, 5.3061, 5.3063, 5.3062, 5.3062, 5.3063, 5.3060,\n",
      "        5.3062, 5.3061, 5.3067, 5.3062, 5.3062, 5.3063, 5.3062, 5.3064, 5.3063,\n",
      "        5.3066, 5.3063, 5.3062], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.564599  [706924/5599865]\n",
      "average delta from current occupancy tensor([5.5808, 5.5808, 5.5808, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5810,\n",
      "        5.5808, 5.5807, 5.5809, 5.5809, 5.5808, 5.5808, 5.5808, 5.5809, 5.5808,\n",
      "        5.5808, 5.5809, 5.5808, 5.5808, 5.5808, 5.5809, 5.5808, 5.5808, 5.5808,\n",
      "        5.5808, 5.5807, 5.5808, 5.5808, 5.5810, 5.5809, 5.5808, 5.5807, 5.5807,\n",
      "        5.5808, 5.5808, 5.5808, 5.5808, 5.5808, 5.5808, 5.5808, 5.5807, 5.5808,\n",
      "        5.5808, 5.5809, 5.5810, 5.5809, 5.5808, 5.5810, 5.5809, 5.5808, 5.5810,\n",
      "        5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5808, 5.5809, 5.5809,\n",
      "        5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809,\n",
      "        5.5810, 5.5809, 5.5808, 5.5809, 5.5808, 5.5808, 5.5809, 5.5808, 5.5809,\n",
      "        5.5809, 5.5809, 5.5808, 5.5810, 5.5810, 5.5809, 5.5808, 5.5809, 5.5809,\n",
      "        5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5810,\n",
      "        5.5808, 5.5808, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809,\n",
      "        5.5809, 5.5808, 5.5808, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5808,\n",
      "        5.5809, 5.5809, 5.5810], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.706589  [719324/5599865]\n",
      "average delta from current occupancy tensor([4.6840, 4.6841, 4.6840, 4.6841, 4.6842, 4.6842, 4.6841, 4.6842, 4.6841,\n",
      "        4.6839, 4.6840, 4.6840, 4.6839, 4.6841, 4.6840, 4.6840, 4.6841, 4.6841,\n",
      "        4.6840, 4.6839, 4.6841, 4.6841, 4.6842, 4.6841, 4.6842, 4.6841, 4.6842,\n",
      "        4.6841, 4.6840, 4.6841, 4.6842, 4.6839, 4.6840, 4.6840, 4.6839, 4.6840,\n",
      "        4.6840, 4.6841, 4.6841, 4.6840, 4.6839, 4.6840, 4.6842, 4.6842, 4.6842,\n",
      "        4.6841, 4.6841, 4.6839, 4.6840, 4.6842, 4.6840, 4.6841, 4.6840, 4.6840,\n",
      "        4.6842, 4.6842, 4.6842, 4.6841, 4.6842, 4.6841, 4.6840, 4.6842, 4.6841,\n",
      "        4.6841, 4.6842, 4.6841, 4.6843, 4.6842, 4.6842, 4.6843, 4.6841, 4.6842,\n",
      "        4.6843, 4.6843, 4.6844, 4.6843, 4.6844, 4.6843, 4.6843, 4.6843, 4.6842,\n",
      "        4.6841, 4.6840, 4.6842, 4.6840, 4.6840, 4.6843, 4.6843, 4.6842, 4.6841,\n",
      "        4.6842, 4.6842, 4.6841, 4.6842, 4.6841, 4.6841, 4.6839, 4.6837, 4.6839,\n",
      "        4.6836, 4.6837, 4.6838, 4.6838, 4.6838, 4.6838, 4.6839, 4.6837, 4.6839,\n",
      "        4.6839, 4.6838, 4.6839, 4.6838, 4.6839, 4.6839, 4.6839, 4.6839, 4.6840,\n",
      "        4.6839, 4.6841, 4.6840], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.132729  [731724/5599865]\n",
      "average delta from current occupancy tensor([4.9452, 4.9446, 4.9452, 4.9446, 4.9442, 4.9443, 4.9444, 4.9442, 4.9445,\n",
      "        4.9452, 4.9446, 4.9451, 4.9453, 4.9448, 4.9450, 4.9448, 4.9441, 4.9444,\n",
      "        4.9444, 4.9449, 4.9441, 4.9444, 4.9440, 4.9442, 4.9441, 4.9446, 4.9439,\n",
      "        4.9443, 4.9445, 4.9442, 4.9438, 4.9445, 4.9442, 4.9443, 4.9451, 4.9442,\n",
      "        4.9442, 4.9437, 4.9438, 4.9443, 4.9446, 4.9441, 4.9438, 4.9438, 4.9438,\n",
      "        4.9444, 4.9445, 4.9445, 4.9440, 4.9436, 4.9444, 4.9437, 4.9438, 4.9441,\n",
      "        4.9436, 4.9437, 4.9437, 4.9435, 4.9436, 4.9436, 4.9438, 4.9436, 4.9437,\n",
      "        4.9436, 4.9437, 4.9437, 4.9437, 4.9437, 4.9438, 4.9437, 4.9437, 4.9437,\n",
      "        4.9436, 4.9437, 4.9437, 4.9436, 4.9437, 4.9438, 4.9436, 4.9436, 4.9436,\n",
      "        4.9438, 4.9437, 4.9437, 4.9438, 4.9441, 4.9437, 4.9437, 4.9438, 4.9438,\n",
      "        4.9439, 4.9438, 4.9438, 4.9438, 4.9437, 4.9437, 4.9446, 4.9451, 4.9446,\n",
      "        4.9456, 4.9448, 4.9442, 4.9449, 4.9446, 4.9447, 4.9444, 4.9449, 4.9441,\n",
      "        4.9439, 4.9438, 4.9437, 4.9439, 4.9439, 4.9442, 4.9440, 4.9439, 4.9438,\n",
      "        4.9439, 4.9439, 4.9440], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.133572  [744124/5599865]\n",
      "average delta from current occupancy tensor([5.0728, 5.0729, 5.0729, 5.0730, 5.0729, 5.0729, 5.0729, 5.0728, 5.0727,\n",
      "        5.0730, 5.0729, 5.0730, 5.0728, 5.0730, 5.0729, 5.0729, 5.0728, 5.0728,\n",
      "        5.0728, 5.0729, 5.0727, 5.0728, 5.0730, 5.0728, 5.0729, 5.0730, 5.0730,\n",
      "        5.0730, 5.0729, 5.0730, 5.0730, 5.0729, 5.0729, 5.0730, 5.0729, 5.0730,\n",
      "        5.0729, 5.0729, 5.0730, 5.0729, 5.0729, 5.0730, 5.0729, 5.0730, 5.0730,\n",
      "        5.0728, 5.0730, 5.0730, 5.0729, 5.0729, 5.0728, 5.0730, 5.0729, 5.0728,\n",
      "        5.0729, 5.0730, 5.0730, 5.0730, 5.0729, 5.0730, 5.0730, 5.0730, 5.0729,\n",
      "        5.0729, 5.0730, 5.0729, 5.0730, 5.0730, 5.0730, 5.0729, 5.0730, 5.0730,\n",
      "        5.0729, 5.0730, 5.0730, 5.0729, 5.0730, 5.0730, 5.0730, 5.0730, 5.0730,\n",
      "        5.0729, 5.0729, 5.0729, 5.0730, 5.0729, 5.0729, 5.0729, 5.0729, 5.0730,\n",
      "        5.0730, 5.0731, 5.0730, 5.0731, 5.0730, 5.0730, 5.0730, 5.0730, 5.0730,\n",
      "        5.0730, 5.0729, 5.0729, 5.0729, 5.0729, 5.0729, 5.0729, 5.0729, 5.0729,\n",
      "        5.0729, 5.0729, 5.0729, 5.0729, 5.0729, 5.0729, 5.0729, 5.0730, 5.0730,\n",
      "        5.0730, 5.0730, 5.0728], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.705883  [756524/5599865]\n",
      "average delta from current occupancy tensor([5.6541, 5.6538, 5.6535, 5.6536, 5.6536, 5.6537, 5.6538, 5.6539, 5.6541,\n",
      "        5.6541, 5.6541, 5.6540, 5.6539, 5.6538, 5.6538, 5.6539, 5.6537, 5.6537,\n",
      "        5.6536, 5.6535, 5.6537, 5.6536, 5.6536, 5.6536, 5.6536, 5.6539, 5.6538,\n",
      "        5.6537, 5.6538, 5.6538, 5.6537, 5.6537, 5.6537, 5.6538, 5.6539, 5.6539,\n",
      "        5.6538, 5.6539, 5.6538, 5.6540, 5.6540, 5.6539, 5.6539, 5.6539, 5.6540,\n",
      "        5.6539, 5.6537, 5.6538, 5.6539, 5.6539, 5.6539, 5.6539, 5.6540, 5.6537,\n",
      "        5.6537, 5.6535, 5.6536, 5.6538, 5.6539, 5.6538, 5.6538, 5.6539, 5.6539,\n",
      "        5.6537, 5.6537, 5.6536, 5.6536, 5.6536, 5.6537, 5.6537, 5.6535, 5.6535,\n",
      "        5.6535, 5.6536, 5.6539, 5.6537, 5.6540, 5.6538, 5.6538, 5.6537, 5.6538,\n",
      "        5.6536, 5.6536, 5.6538, 5.6538, 5.6537, 5.6535, 5.6536, 5.6536, 5.6536,\n",
      "        5.6541, 5.6539, 5.6539, 5.6538, 5.6539, 5.6537, 5.6536, 5.6538, 5.6538,\n",
      "        5.6538, 5.6538, 5.6538, 5.6538, 5.6538, 5.6538, 5.6539, 5.6539, 5.6536,\n",
      "        5.6536, 5.6539, 5.6535, 5.6535, 5.6536, 5.6540, 5.6541, 5.6539, 5.6536,\n",
      "        5.6538, 5.6538, 5.6538], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.818190  [768924/5599865]\n",
      "average delta from current occupancy tensor([4.8952, 4.8954, 4.8953, 4.8952, 4.8953, 4.8953, 4.8954, 4.8955, 4.8954,\n",
      "        4.8952, 4.8954, 4.8956, 4.8955, 4.8953, 4.8955, 4.8955, 4.8955, 4.8953,\n",
      "        4.8954, 4.8953, 4.8954, 4.8952, 4.8955, 4.8953, 4.8952, 4.8954, 4.8952,\n",
      "        4.8953, 4.8953, 4.8952, 4.8953, 4.8952, 4.8952, 4.8954, 4.8953, 4.8953,\n",
      "        4.8955, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8953,\n",
      "        4.8953, 4.8955, 4.8954, 4.8954, 4.8953, 4.8954, 4.8955, 4.8954, 4.8953,\n",
      "        4.8953, 4.8953, 4.8954, 4.8954, 4.8954, 4.8955, 4.8954, 4.8954, 4.8954,\n",
      "        4.8954, 4.8954, 4.8953, 4.8954, 4.8953, 4.8954, 4.8954, 4.8954, 4.8953,\n",
      "        4.8953, 4.8954, 4.8953, 4.8955, 4.8952, 4.8954, 4.8954, 4.8953, 4.8954,\n",
      "        4.8952, 4.8953, 4.8952, 4.8953, 4.8952, 4.8954, 4.8952, 4.8954, 4.8953,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8955, 4.8954,\n",
      "        4.8953, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8953, 4.8953,\n",
      "        4.8953, 4.8952, 4.8954, 4.8953, 4.8955, 4.8954, 4.8953, 4.8955, 4.8954,\n",
      "        4.8954, 4.8954, 4.8954], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.459335  [781324/5599865]\n",
      "average delta from current occupancy tensor([5.5989, 5.5989, 5.5988, 5.5991, 5.5992, 5.5991, 5.5993, 5.5991, 5.5990,\n",
      "        5.5990, 5.5991, 5.5991, 5.5992, 5.5989, 5.5988, 5.5990, 5.5990, 5.5990,\n",
      "        5.5990, 5.5989, 5.5991, 5.5991, 5.5990, 5.5990, 5.5988, 5.5989, 5.5990,\n",
      "        5.5988, 5.5989, 5.5987, 5.5988, 5.5989, 5.5990, 5.5991, 5.5991, 5.5990,\n",
      "        5.5987, 5.5987, 5.5987, 5.5989, 5.5989, 5.5986, 5.5989, 5.5988, 5.5988,\n",
      "        5.5988, 5.5987, 5.5987, 5.5987, 5.5987, 5.5988, 5.5987, 5.5986, 5.5987,\n",
      "        5.5988, 5.5988, 5.5988, 5.5988, 5.5989, 5.5988, 5.5987, 5.5991, 5.5989,\n",
      "        5.5986, 5.5988, 5.5988, 5.5987, 5.5988, 5.5986, 5.5986, 5.5987, 5.5986,\n",
      "        5.5987, 5.5985, 5.5987, 5.5987, 5.5987, 5.5988, 5.5988, 5.5987, 5.5989,\n",
      "        5.5988, 5.5987, 5.5988, 5.5987, 5.5987, 5.5987, 5.5989, 5.5986, 5.5990,\n",
      "        5.5987, 5.5988, 5.5988, 5.5989, 5.5988, 5.5988, 5.5988, 5.5990, 5.5988,\n",
      "        5.5990, 5.5990, 5.5989, 5.5989, 5.5987, 5.5987, 5.5986, 5.5985, 5.5987,\n",
      "        5.5989, 5.5988, 5.5987, 5.5984, 5.5987, 5.5989, 5.5988, 5.5990, 5.5988,\n",
      "        5.5990, 5.5988, 5.5988], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.380345  [793724/5599865]\n",
      "average delta from current occupancy tensor([5.3716, 5.3717, 5.3717, 5.3717, 5.3717, 5.3716, 5.3716, 5.3717, 5.3716,\n",
      "        5.3717, 5.3716, 5.3714, 5.3715, 5.3716, 5.3716, 5.3716, 5.3715, 5.3715,\n",
      "        5.3714, 5.3715, 5.3716, 5.3717, 5.3715, 5.3715, 5.3716, 5.3717, 5.3717,\n",
      "        5.3714, 5.3715, 5.3715, 5.3714, 5.3714, 5.3714, 5.3716, 5.3715, 5.3717,\n",
      "        5.3717, 5.3715, 5.3714, 5.3717, 5.3715, 5.3715, 5.3716, 5.3717, 5.3718,\n",
      "        5.3718, 5.3716, 5.3717, 5.3717, 5.3715, 5.3716, 5.3717, 5.3716, 5.3717,\n",
      "        5.3717, 5.3717, 5.3716, 5.3717, 5.3716, 5.3717, 5.3716, 5.3717, 5.3717,\n",
      "        5.3716, 5.3716, 5.3718, 5.3716, 5.3716, 5.3719, 5.3720, 5.3717, 5.3719,\n",
      "        5.3719, 5.3719, 5.3718, 5.3718, 5.3719, 5.3718, 5.3718, 5.3717, 5.3717,\n",
      "        5.3717, 5.3719, 5.3718, 5.3720, 5.3720, 5.3719, 5.3717, 5.3719, 5.3717,\n",
      "        5.3719, 5.3719, 5.3720, 5.3719, 5.3720, 5.3721, 5.3720, 5.3721, 5.3721,\n",
      "        5.3722, 5.3721, 5.3721, 5.3723, 5.3721, 5.3722, 5.3723, 5.3723, 5.3723,\n",
      "        5.3723, 5.3723, 5.3721, 5.3722, 5.3722, 5.3722, 5.3722, 5.3723, 5.3723,\n",
      "        5.3723, 5.3722, 5.3722], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.342292  [806124/5599865]\n",
      "average delta from current occupancy tensor([5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3386, 5.3385, 5.3385,\n",
      "        5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385,\n",
      "        5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385,\n",
      "        5.3385, 5.3385, 5.3385, 5.3386, 5.3385, 5.3385, 5.3385, 5.3386, 5.3386,\n",
      "        5.3386, 5.3385, 5.3385, 5.3386, 5.3386, 5.3386, 5.3385, 5.3385, 5.3385,\n",
      "        5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385, 5.3385,\n",
      "        5.3385, 5.3384, 5.3385, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384,\n",
      "        5.3385, 5.3384, 5.3385, 5.3384, 5.3385, 5.3385, 5.3385, 5.3384, 5.3384,\n",
      "        5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384,\n",
      "        5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384,\n",
      "        5.3384, 5.3384, 5.3384, 5.3383, 5.3383, 5.3383, 5.3383, 5.3383, 5.3384,\n",
      "        5.3383, 5.3384, 5.3383, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384, 5.3384,\n",
      "        5.3384, 5.3384, 5.3384, 5.3385, 5.3385, 5.3384, 5.3385, 5.3384, 5.3385,\n",
      "        5.3385, 5.3386, 5.3386], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.080603  [818524/5599865]\n",
      "average delta from current occupancy tensor([4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9758, 4.9758, 4.9757, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9758, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757,\n",
      "        4.9757, 4.9757, 4.9756, 4.9757, 4.9757, 4.9757, 4.9757, 4.9757, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9757, 4.9758, 4.9758, 4.9757, 4.9758,\n",
      "        4.9758, 4.9758, 4.9757], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.582556  [830924/5599865]\n",
      "average delta from current occupancy tensor([4.3148, 4.3145, 4.3145, 4.3147, 4.3146, 4.3145, 4.3145, 4.3145, 4.3145,\n",
      "        4.3145, 4.3145, 4.3145, 4.3146, 4.3146, 4.3146, 4.3145, 4.3147, 4.3145,\n",
      "        4.3146, 4.3145, 4.3146, 4.3148, 4.3146, 4.3146, 4.3147, 4.3146, 4.3147,\n",
      "        4.3145, 4.3147, 4.3146, 4.3145, 4.3145, 4.3146, 4.3146, 4.3146, 4.3146,\n",
      "        4.3146, 4.3146, 4.3147, 4.3146, 4.3146, 4.3146, 4.3146, 4.3146, 4.3146,\n",
      "        4.3145, 4.3146, 4.3146, 4.3145, 4.3146, 4.3145, 4.3146, 4.3146, 4.3145,\n",
      "        4.3147, 4.3148, 4.3148, 4.3148, 4.3148, 4.3147, 4.3147, 4.3147, 4.3147,\n",
      "        4.3147, 4.3148, 4.3147, 4.3147, 4.3145, 4.3146, 4.3147, 4.3148, 4.3147,\n",
      "        4.3148, 4.3149, 4.3146, 4.3147, 4.3147, 4.3147, 4.3147, 4.3149, 4.3149,\n",
      "        4.3149, 4.3150, 4.3151, 4.3152, 4.3152, 4.3150, 4.3148, 4.3147, 4.3147,\n",
      "        4.3148, 4.3148, 4.3149, 4.3147, 4.3147, 4.3147, 4.3146, 4.3148, 4.3148,\n",
      "        4.3148, 4.3149, 4.3148, 4.3149, 4.3149, 4.3150, 4.3149, 4.3149, 4.3148,\n",
      "        4.3151, 4.3148, 4.3149, 4.3149, 4.3148, 4.3149, 4.3149, 4.3148, 4.3150,\n",
      "        4.3148, 4.3147, 4.3147], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.959576  [843324/5599865]\n",
      "average delta from current occupancy tensor([4.9272, 4.9272, 4.9272, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271,\n",
      "        4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9270, 4.9270, 4.9271, 4.9271,\n",
      "        4.9270, 4.9271, 4.9270, 4.9271, 4.9270, 4.9271, 4.9271, 4.9269, 4.9269,\n",
      "        4.9270, 4.9271, 4.9271, 4.9271, 4.9270, 4.9271, 4.9271, 4.9271, 4.9271,\n",
      "        4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9272, 4.9271,\n",
      "        4.9271, 4.9272, 4.9272, 4.9272, 4.9272, 4.9273, 4.9273, 4.9273, 4.9273,\n",
      "        4.9272, 4.9273, 4.9273, 4.9272, 4.9272, 4.9272, 4.9272, 4.9272, 4.9273,\n",
      "        4.9272, 4.9272, 4.9272, 4.9272, 4.9272, 4.9272, 4.9271, 4.9272, 4.9271,\n",
      "        4.9271, 4.9271, 4.9271, 4.9272, 4.9272, 4.9271, 4.9271, 4.9272, 4.9271,\n",
      "        4.9272, 4.9271, 4.9271, 4.9272, 4.9272, 4.9272, 4.9272, 4.9271, 4.9271,\n",
      "        4.9271, 4.9272, 4.9271, 4.9272, 4.9271, 4.9271, 4.9270, 4.9271, 4.9270,\n",
      "        4.9270, 4.9270, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271, 4.9271,\n",
      "        4.9271, 4.9271, 4.9270, 4.9271, 4.9270, 4.9270, 4.9271, 4.9270, 4.9270,\n",
      "        4.9271, 4.9272, 4.9270], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.244308  [855724/5599865]\n",
      "average delta from current occupancy tensor([5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068,\n",
      "        5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068,\n",
      "        5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068,\n",
      "        5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3067, 5.3068,\n",
      "        5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068,\n",
      "        5.3068, 5.3067, 5.3068, 5.3068, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3067, 5.3068, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3066, 5.3067, 5.3067, 5.3066, 5.3067, 5.3066, 5.3066, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.574472  [868124/5599865]\n",
      "average delta from current occupancy tensor([5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4426, 5.4425, 5.4425, 5.4425,\n",
      "        5.4425, 5.4425, 5.4425, 5.4424, 5.4424, 5.4424, 5.4425, 5.4424, 5.4425,\n",
      "        5.4426, 5.4425, 5.4425, 5.4424, 5.4425, 5.4425, 5.4424, 5.4424, 5.4425,\n",
      "        5.4425, 5.4424, 5.4424, 5.4424, 5.4425, 5.4424, 5.4424, 5.4424, 5.4424,\n",
      "        5.4424, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425,\n",
      "        5.4424, 5.4425, 5.4425, 5.4425, 5.4425, 5.4423, 5.4424, 5.4424, 5.4424,\n",
      "        5.4423, 5.4424, 5.4425, 5.4424, 5.4424, 5.4423, 5.4423, 5.4423, 5.4423,\n",
      "        5.4423, 5.4423, 5.4423, 5.4424, 5.4423, 5.4423, 5.4424, 5.4423, 5.4426,\n",
      "        5.4426, 5.4423, 5.4425, 5.4426, 5.4425, 5.4427, 5.4425, 5.4423, 5.4424,\n",
      "        5.4423, 5.4423, 5.4425, 5.4426, 5.4425, 5.4425, 5.4423, 5.4424, 5.4426,\n",
      "        5.4425, 5.4424, 5.4426, 5.4426, 5.4426, 5.4426, 5.4426, 5.4426, 5.4424,\n",
      "        5.4425, 5.4425, 5.4424, 5.4424, 5.4425, 5.4426, 5.4424, 5.4425, 5.4426,\n",
      "        5.4426, 5.4425, 5.4424, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425, 5.4425,\n",
      "        5.4425, 5.4424, 5.4424], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.621910  [880524/5599865]\n",
      "average delta from current occupancy tensor([5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4033, 5.4032, 5.4033,\n",
      "        5.4032, 5.4033, 5.4033, 5.4034, 5.4033, 5.4033, 5.4034, 5.4034, 5.4033,\n",
      "        5.4033, 5.4032, 5.4033, 5.4033, 5.4033, 5.4032, 5.4034, 5.4032, 5.4034,\n",
      "        5.4033, 5.4034, 5.4033, 5.4033, 5.4034, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4034, 5.4035, 5.4032,\n",
      "        5.4038, 5.4038, 5.4038, 5.4038, 5.4038, 5.4038, 5.4037, 5.4035, 5.4037,\n",
      "        5.4035, 5.4036, 5.4035, 5.4035, 5.4036, 5.4035, 5.4034, 5.4034, 5.4037,\n",
      "        5.4036, 5.4036, 5.4036, 5.4038, 5.4035, 5.4035, 5.4035, 5.4037, 5.4034,\n",
      "        5.4039, 5.4032, 5.4034, 5.4035, 5.4035, 5.4034, 5.4037, 5.4033, 5.4036,\n",
      "        5.4032, 5.4036, 5.4034, 5.4039, 5.4037, 5.4035, 5.4032, 5.4034, 5.4038,\n",
      "        5.4032, 5.4032, 5.4035, 5.4034, 5.4037, 5.4035, 5.4038, 5.4036, 5.4035,\n",
      "        5.4035, 5.4037, 5.4035, 5.4036, 5.4036, 5.4033, 5.4037, 5.4036, 5.4038,\n",
      "        5.4035, 5.4037, 5.4038, 5.4038, 5.4037, 5.4034, 5.4034, 5.4033, 5.4033,\n",
      "        5.4032, 5.4032, 5.4032], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.919343  [892924/5599865]\n",
      "average delta from current occupancy tensor([4.9283, 4.9285, 4.9282, 4.9280, 4.9280, 4.9280, 4.9277, 4.9280, 4.9276,\n",
      "        4.9276, 4.9274, 4.9274, 4.9274, 4.9274, 4.9276, 4.9277, 4.9274, 4.9274,\n",
      "        4.9276, 4.9276, 4.9274, 4.9275, 4.9274, 4.9277, 4.9275, 4.9278, 4.9276,\n",
      "        4.9276, 4.9277, 4.9279, 4.9277, 4.9276, 4.9281, 4.9280, 4.9282, 4.9282,\n",
      "        4.9283, 4.9282, 4.9279, 4.9280, 4.9280, 4.9282, 4.9279, 4.9278, 4.9282,\n",
      "        4.9274, 4.9274, 4.9276, 4.9279, 4.9277, 4.9277, 4.9278, 4.9277, 4.9274,\n",
      "        4.9276, 4.9275, 4.9275, 4.9274, 4.9277, 4.9277, 4.9278, 4.9275, 4.9276,\n",
      "        4.9278, 4.9276, 4.9276, 4.9276, 4.9277, 4.9278, 4.9276, 4.9276, 4.9276,\n",
      "        4.9274, 4.9276, 4.9274, 4.9274, 4.9274, 4.9274, 4.9274, 4.9274, 4.9275,\n",
      "        4.9276, 4.9275, 4.9274, 4.9274, 4.9274, 4.9274, 4.9276, 4.9274, 4.9274,\n",
      "        4.9276, 4.9276, 4.9274, 4.9275, 4.9274, 4.9274, 4.9274, 4.9275, 4.9276,\n",
      "        4.9276, 4.9274, 4.9274, 4.9274, 4.9274, 4.9275, 4.9274, 4.9274, 4.9274,\n",
      "        4.9274, 4.9274, 4.9276, 4.9274, 4.9274, 4.9276, 4.9276, 4.9278, 4.9278,\n",
      "        4.9280, 4.9278, 4.9276], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.375337  [905324/5599865]\n",
      "average delta from current occupancy tensor([5.3873, 5.3873, 5.3874, 5.3873, 5.3873, 5.3872, 5.3872, 5.3872, 5.3873,\n",
      "        5.3872, 5.3873, 5.3873, 5.3872, 5.3872, 5.3873, 5.3873, 5.3873, 5.3875,\n",
      "        5.3873, 5.3874, 5.3875, 5.3875, 5.3876, 5.3874, 5.3873, 5.3875, 5.3875,\n",
      "        5.3874, 5.3875, 5.3876, 5.3874, 5.3874, 5.3874, 5.3875, 5.3873, 5.3874,\n",
      "        5.3873, 5.3874, 5.3875, 5.3874, 5.3875, 5.3875, 5.3875, 5.3876, 5.3875,\n",
      "        5.3875, 5.3875, 5.3874, 5.3876, 5.3875, 5.3875, 5.3875, 5.3874, 5.3874,\n",
      "        5.3876, 5.3876, 5.3876, 5.3875, 5.3874, 5.3874, 5.3876, 5.3876, 5.3876,\n",
      "        5.3877, 5.3875, 5.3875, 5.3877, 5.3876, 5.3876, 5.3876, 5.3877, 5.3875,\n",
      "        5.3874, 5.3875, 5.3874, 5.3875, 5.3875, 5.3874, 5.3875, 5.3876, 5.3876,\n",
      "        5.3876, 5.3874, 5.3874, 5.3874, 5.3874, 5.3875, 5.3875, 5.3875, 5.3875,\n",
      "        5.3874, 5.3873, 5.3873, 5.3874, 5.3875, 5.3874, 5.3875, 5.3874, 5.3875,\n",
      "        5.3874, 5.3875, 5.3876, 5.3876, 5.3876, 5.3876, 5.3875, 5.3875, 5.3876,\n",
      "        5.3875, 5.3875, 5.3876, 5.3875, 5.3875, 5.3875, 5.3876, 5.3877, 5.3876,\n",
      "        5.3876, 5.3875, 5.3874], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.754450  [917724/5599865]\n",
      "average delta from current occupancy tensor([4.7981, 4.7981, 4.7983, 4.7980, 4.7981, 4.7981, 4.7980, 4.7981, 4.7982,\n",
      "        4.7983, 4.7981, 4.7980, 4.7982, 4.7982, 4.7983, 4.7983, 4.7981, 4.7981,\n",
      "        4.7982, 4.7982, 4.7983, 4.7982, 4.7983, 4.7982, 4.7981, 4.7981, 4.7981,\n",
      "        4.7983, 4.7981, 4.7982, 4.7981, 4.7981, 4.7981, 4.7979, 4.7980, 4.7981,\n",
      "        4.7982, 4.7980, 4.7979, 4.7980, 4.7978, 4.7979, 4.7979, 4.7980, 4.7981,\n",
      "        4.7979, 4.7980, 4.7983, 4.7980, 4.7980, 4.7982, 4.7980, 4.7981, 4.7981,\n",
      "        4.7979, 4.7978, 4.7978, 4.7979, 4.7981, 4.7981, 4.7978, 4.7980, 4.7980,\n",
      "        4.7980, 4.7980, 4.7981, 4.7981, 4.7981, 4.7981, 4.7981, 4.7982, 4.7982,\n",
      "        4.7983, 4.7983, 4.7981, 4.7983, 4.7983, 4.7982, 4.7982, 4.7983, 4.7983,\n",
      "        4.7981, 4.7984, 4.7983, 4.7983, 4.7982, 4.7982, 4.7981, 4.7981, 4.7984,\n",
      "        4.7984, 4.7982, 4.7983, 4.7984, 4.7983, 4.7984, 4.7983, 4.7986, 4.7986,\n",
      "        4.7985, 4.7985, 4.7986, 4.7986, 4.7986, 4.7986, 4.7986, 4.7985, 4.7986,\n",
      "        4.7985, 4.7985, 4.7985, 4.7986, 4.7985, 4.7985, 4.7984, 4.7982, 4.7984,\n",
      "        4.7984, 4.7986, 4.7983], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.609546  [930124/5599865]\n",
      "average delta from current occupancy tensor([5.4832, 5.4832, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4833, 5.4833, 5.4832, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4834, 5.4834, 5.4833,\n",
      "        5.4833, 5.4833, 5.4834, 5.4833, 5.4834, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4834, 5.4833, 5.4834, 5.4833, 5.4833, 5.4834, 5.4833, 5.4833,\n",
      "        5.4833, 5.4833, 5.4834, 5.4833, 5.4833, 5.4833, 5.4834, 5.4834, 5.4833,\n",
      "        5.4833, 5.4834, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4832, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4834, 5.4833, 5.4834, 5.4833, 5.4833, 5.4833, 5.4833, 5.4834,\n",
      "        5.4834, 5.4834, 5.4834, 5.4834, 5.4834, 5.4834, 5.4833, 5.4833, 5.4833,\n",
      "        5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4833, 5.4834,\n",
      "        5.4833, 5.4834, 5.4834], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.596181  [942524/5599865]\n",
      "average delta from current occupancy tensor([4.6535, 4.6535, 4.6535, 4.6535, 4.6536, 4.6536, 4.6536, 4.6537, 4.6536,\n",
      "        4.6537, 4.6536, 4.6537, 4.6538, 4.6537, 4.6537, 4.6536, 4.6536, 4.6537,\n",
      "        4.6536, 4.6536, 4.6536, 4.6537, 4.6536, 4.6536, 4.6535, 4.6538, 4.6534,\n",
      "        4.6537, 4.6538, 4.6538, 4.6536, 4.6535, 4.6534, 4.6536, 4.6535, 4.6534,\n",
      "        4.6534, 4.6535, 4.6536, 4.6537, 4.6537, 4.6535, 4.6536, 4.6535, 4.6535,\n",
      "        4.6536, 4.6538, 4.6536, 4.6535, 4.6538, 4.6538, 4.6536, 4.6534, 4.6535,\n",
      "        4.6537, 4.6534, 4.6534, 4.6536, 4.6533, 4.6535, 4.6535, 4.6536, 4.6536,\n",
      "        4.6537, 4.6536, 4.6536, 4.6536, 4.6535, 4.6534, 4.6535, 4.6535, 4.6536,\n",
      "        4.6536, 4.6535, 4.6535, 4.6537, 4.6536, 4.6537, 4.6538, 4.6541, 4.6541,\n",
      "        4.6542, 4.6540, 4.6540, 4.6541, 4.6538, 4.6539, 4.6539, 4.6542, 4.6540,\n",
      "        4.6541, 4.6539, 4.6542, 4.6543, 4.6545, 4.6545, 4.6543, 4.6542, 4.6541,\n",
      "        4.6543, 4.6543, 4.6540, 4.6542, 4.6543, 4.6541, 4.6540, 4.6542, 4.6541,\n",
      "        4.6541, 4.6541, 4.6540, 4.6542, 4.6540, 4.6539, 4.6539, 4.6538, 4.6538,\n",
      "        4.6540, 4.6540, 4.6540], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.973161  [954924/5599865]\n",
      "average delta from current occupancy tensor([4.9046, 4.9046, 4.9043, 4.9044, 4.9040, 4.9040, 4.9049, 4.9047, 4.9049,\n",
      "        4.9047, 4.9051, 4.9043, 4.9044, 4.9050, 4.9044, 4.9044, 4.9047, 4.9043,\n",
      "        4.9046, 4.9047, 4.9047, 4.9043, 4.9046, 4.9046, 4.9050, 4.9047, 4.9050,\n",
      "        4.9046, 4.9046, 4.9046, 4.9049, 4.9047, 4.9049, 4.9048, 4.9049, 4.9051,\n",
      "        4.9049, 4.9050, 4.9052, 4.9051, 4.9048, 4.9051, 4.9051, 4.9049, 4.9047,\n",
      "        4.9052, 4.9049, 4.9051, 4.9055, 4.9049, 4.9051, 4.9048, 4.9052, 4.9052,\n",
      "        4.9049, 4.9054, 4.9055, 4.9046, 4.9053, 4.9048, 4.9048, 4.9048, 4.9049,\n",
      "        4.9046, 4.9047, 4.9049, 4.9046, 4.9050, 4.9052, 4.9052, 4.9052, 4.9048,\n",
      "        4.9049, 4.9049, 4.9050, 4.9046, 4.9050, 4.9048, 4.9046, 4.9046, 4.9045,\n",
      "        4.9046, 4.9046, 4.9047, 4.9043, 4.9048, 4.9049, 4.9046, 4.9049, 4.9048,\n",
      "        4.9041, 4.9043, 4.9040, 4.9042, 4.9042, 4.9041, 4.9043, 4.9044, 4.9043,\n",
      "        4.9041, 4.9043, 4.9043, 4.9042, 4.9039, 4.9043, 4.9041, 4.9039, 4.9040,\n",
      "        4.9040, 4.9039, 4.9042, 4.9040, 4.9044, 4.9042, 4.9042, 4.9044, 4.9044,\n",
      "        4.9043, 4.9041, 4.9044], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.472392  [967324/5599865]\n",
      "average delta from current occupancy tensor([4.4969, 4.4969, 4.4973, 4.4969, 4.4973, 4.4970, 4.4971, 4.4972, 4.4974,\n",
      "        4.4974, 4.4975, 4.4974, 4.4975, 4.4972, 4.4972, 4.4973, 4.4970, 4.4970,\n",
      "        4.4970, 4.4972, 4.4969, 4.4969, 4.4969, 4.4967, 4.4970, 4.4968, 4.4971,\n",
      "        4.4968, 4.4970, 4.4971, 4.4969, 4.4972, 4.4970, 4.4972, 4.4972, 4.4973,\n",
      "        4.4973, 4.4974, 4.4977, 4.4976, 4.4971, 4.4971, 4.4972, 4.4971, 4.4973,\n",
      "        4.4973, 4.4972, 4.4976, 4.4975, 4.4972, 4.4972, 4.4968, 4.4980, 4.4988,\n",
      "        4.4977, 4.4987, 4.4988, 4.4970, 4.4981, 4.4972, 4.4975, 4.4977, 4.4982,\n",
      "        4.4985, 4.4987, 4.4984, 4.4986, 4.4984, 4.4980, 4.4981, 4.4980, 4.4981,\n",
      "        4.4973, 4.4974, 4.4973, 4.4966, 4.4970, 4.4969, 4.4974, 4.4969, 4.4975,\n",
      "        4.4971, 4.4973, 4.4972, 4.4986, 4.4979, 4.4981, 4.4988, 4.4976, 4.4975,\n",
      "        4.4977, 4.4974, 4.4972, 4.4970, 4.4971, 4.4971, 4.4968, 4.4969, 4.4972,\n",
      "        4.4973, 4.4973, 4.4971, 4.4970, 4.4972, 4.4973, 4.4971, 4.4975, 4.4973,\n",
      "        4.4983, 4.4982, 4.4975, 4.4983, 4.4969, 4.4978, 4.4976, 4.4977, 4.4974,\n",
      "        4.4984, 4.4984, 4.4986], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.268785  [979724/5599865]\n",
      "average delta from current occupancy tensor([5.5748, 5.5750, 5.5749, 5.5750, 5.5748, 5.5748, 5.5747, 5.5745, 5.5744,\n",
      "        5.5743, 5.5746, 5.5744, 5.5743, 5.5745, 5.5744, 5.5743, 5.5745, 5.5745,\n",
      "        5.5745, 5.5743, 5.5745, 5.5744, 5.5743, 5.5743, 5.5741, 5.5745, 5.5743,\n",
      "        5.5745, 5.5744, 5.5743, 5.5742, 5.5740, 5.5742, 5.5742, 5.5741, 5.5740,\n",
      "        5.5740, 5.5736, 5.5735, 5.5736, 5.5739, 5.5742, 5.5741, 5.5742, 5.5742,\n",
      "        5.5741, 5.5741, 5.5738, 5.5739, 5.5741, 5.5739, 5.5743, 5.5735, 5.5730,\n",
      "        5.5738, 5.5733, 5.5733, 5.5741, 5.5735, 5.5740, 5.5739, 5.5739, 5.5736,\n",
      "        5.5733, 5.5736, 5.5734, 5.5734, 5.5733, 5.5736, 5.5735, 5.5736, 5.5736,\n",
      "        5.5741, 5.5742, 5.5742, 5.5746, 5.5745, 5.5747, 5.5743, 5.5745, 5.5742,\n",
      "        5.5745, 5.5744, 5.5742, 5.5735, 5.5737, 5.5736, 5.5733, 5.5741, 5.5745,\n",
      "        5.5744, 5.5744, 5.5746, 5.5749, 5.5747, 5.5747, 5.5748, 5.5747, 5.5746,\n",
      "        5.5745, 5.5745, 5.5747, 5.5749, 5.5749, 5.5748, 5.5750, 5.5747, 5.5749,\n",
      "        5.5743, 5.5746, 5.5749, 5.5744, 5.5752, 5.5747, 5.5747, 5.5747, 5.5750,\n",
      "        5.5743, 5.5741, 5.5740], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.483189  [992124/5599865]\n",
      "average delta from current occupancy tensor([5.4702, 5.4705, 5.4704, 5.4705, 5.4702, 5.4704, 5.4703, 5.4702, 5.4700,\n",
      "        5.4700, 5.4702, 5.4701, 5.4701, 5.4703, 5.4702, 5.4700, 5.4701, 5.4699,\n",
      "        5.4699, 5.4701, 5.4700, 5.4701, 5.4698, 5.4699, 5.4703, 5.4701, 5.4702,\n",
      "        5.4701, 5.4699, 5.4700, 5.4701, 5.4702, 5.4702, 5.4698, 5.4700, 5.4703,\n",
      "        5.4703, 5.4707, 5.4706, 5.4707, 5.4704, 5.4704, 5.4703, 5.4702, 5.4703,\n",
      "        5.4703, 5.4702, 5.4704, 5.4705, 5.4704, 5.4707, 5.4703, 5.4708, 5.4708,\n",
      "        5.4709, 5.4710, 5.4710, 5.4708, 5.4710, 5.4709, 5.4709, 5.4709, 5.4710,\n",
      "        5.4711, 5.4711, 5.4711, 5.4711, 5.4713, 5.4713, 5.4710, 5.4710, 5.4711,\n",
      "        5.4707, 5.4706, 5.4705, 5.4709, 5.4709, 5.4709, 5.4704, 5.4707, 5.4704,\n",
      "        5.4705, 5.4706, 5.4705, 5.4711, 5.4708, 5.4708, 5.4710, 5.4704, 5.4708,\n",
      "        5.4707, 5.4706, 5.4707, 5.4707, 5.4707, 5.4708, 5.4707, 5.4706, 5.4705,\n",
      "        5.4704, 5.4704, 5.4706, 5.4708, 5.4708, 5.4707, 5.4709, 5.4708, 5.4709,\n",
      "        5.4704, 5.4706, 5.4708, 5.4704, 5.4712, 5.4707, 5.4707, 5.4708, 5.4711,\n",
      "        5.4706, 5.4704, 5.4706], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.189636  [1004524/5599865]\n",
      "average delta from current occupancy tensor([5.2136, 5.2142, 5.2136, 5.2141, 5.2132, 5.2133, 5.2134, 5.2129, 5.2126,\n",
      "        5.2128, 5.2130, 5.2134, 5.2133, 5.2134, 5.2129, 5.2126, 5.2130, 5.2127,\n",
      "        5.2124, 5.2129, 5.2128, 5.2131, 5.2126, 5.2123, 5.2131, 5.2132, 5.2134,\n",
      "        5.2131, 5.2129, 5.2132, 5.2135, 5.2140, 5.2140, 5.2132, 5.2135, 5.2141,\n",
      "        5.2142, 5.2149, 5.2147, 5.2152, 5.2142, 5.2142, 5.2139, 5.2138, 5.2141,\n",
      "        5.2143, 5.2141, 5.2144, 5.2149, 5.2147, 5.2155, 5.2145, 5.2154, 5.2153,\n",
      "        5.2158, 5.2160, 5.2157, 5.2152, 5.2154, 5.2155, 5.2154, 5.2156, 5.2160,\n",
      "        5.2164, 5.2161, 5.2158, 5.2159, 5.2160, 5.2160, 5.2155, 5.2155, 5.2155,\n",
      "        5.2150, 5.2146, 5.2146, 5.2157, 5.2156, 5.2158, 5.2149, 5.2153, 5.2149,\n",
      "        5.2148, 5.2147, 5.2146, 5.2156, 5.2150, 5.2150, 5.2152, 5.2142, 5.2153,\n",
      "        5.2151, 5.2154, 5.2154, 5.2152, 5.2156, 5.2155, 5.2153, 5.2149, 5.2147,\n",
      "        5.2145, 5.2144, 5.2153, 5.2156, 5.2158, 5.2156, 5.2156, 5.2157, 5.2163,\n",
      "        5.2155, 5.2158, 5.2159, 5.2154, 5.2167, 5.2161, 5.2157, 5.2161, 5.2166,\n",
      "        5.2159, 5.2154, 5.2158], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.978709  [1016924/5599865]\n",
      "average delta from current occupancy tensor([4.7186, 4.7185, 4.7185, 4.7185, 4.7186, 4.7184, 4.7184, 4.7184, 4.7184,\n",
      "        4.7184, 4.7185, 4.7185, 4.7185, 4.7185, 4.7185, 4.7186, 4.7185, 4.7185,\n",
      "        4.7185, 4.7185, 4.7184, 4.7184, 4.7184, 4.7184, 4.7185, 4.7185, 4.7186,\n",
      "        4.7186, 4.7185, 4.7186, 4.7185, 4.7185, 4.7186, 4.7187, 4.7186, 4.7185,\n",
      "        4.7185, 4.7183, 4.7184, 4.7185, 4.7186, 4.7185, 4.7185, 4.7185, 4.7187,\n",
      "        4.7187, 4.7187, 4.7186, 4.7184, 4.7183, 4.7183, 4.7185, 4.7181, 4.7178,\n",
      "        4.7177, 4.7181, 4.7180, 4.7177, 4.7178, 4.7182, 4.7181, 4.7182, 4.7177,\n",
      "        4.7181, 4.7184, 4.7184, 4.7182, 4.7184, 4.7182, 4.7182, 4.7183, 4.7182,\n",
      "        4.7184, 4.7183, 4.7184, 4.7182, 4.7182, 4.7180, 4.7182, 4.7182, 4.7181,\n",
      "        4.7183, 4.7183, 4.7184, 4.7178, 4.7181, 4.7182, 4.7183, 4.7184, 4.7184,\n",
      "        4.7183, 4.7182, 4.7182, 4.7182, 4.7182, 4.7181, 4.7181, 4.7183, 4.7182,\n",
      "        4.7183, 4.7184, 4.7182, 4.7181, 4.7179, 4.7180, 4.7178, 4.7179, 4.7177,\n",
      "        4.7180, 4.7180, 4.7180, 4.7179, 4.7178, 4.7181, 4.7178, 4.7180, 4.7183,\n",
      "        4.7182, 4.7183, 4.7182], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.173126  [1029324/5599865]\n",
      "average delta from current occupancy tensor([5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.004048  [1041724/5599865]\n",
      "average delta from current occupancy tensor([4.9510, 4.9511, 4.9511, 4.9512, 4.9511, 4.9513, 4.9514, 4.9512, 4.9512,\n",
      "        4.9511, 4.9510, 4.9510, 4.9512, 4.9511, 4.9511, 4.9511, 4.9509, 4.9511,\n",
      "        4.9512, 4.9512, 4.9509, 4.9511, 4.9506, 4.9506, 4.9506, 4.9508, 4.9507,\n",
      "        4.9506, 4.9509, 4.9508, 4.9505, 4.9505, 4.9505, 4.9506, 4.9505, 4.9506,\n",
      "        4.9507, 4.9508, 4.9509, 4.9507, 4.9504, 4.9507, 4.9508, 4.9504, 4.9504,\n",
      "        4.9504, 4.9507, 4.9505, 4.9509, 4.9508, 4.9509, 4.9507, 4.9507, 4.9510,\n",
      "        4.9507, 4.9508, 4.9509, 4.9508, 4.9507, 4.9507, 4.9507, 4.9507, 4.9509,\n",
      "        4.9506, 4.9508, 4.9507, 4.9508, 4.9508, 4.9508, 4.9506, 4.9505, 4.9504,\n",
      "        4.9506, 4.9506, 4.9506, 4.9507, 4.9506, 4.9504, 4.9505, 4.9505, 4.9505,\n",
      "        4.9505, 4.9504, 4.9508, 4.9505, 4.9506, 4.9505, 4.9505, 4.9507, 4.9507,\n",
      "        4.9506, 4.9510, 4.9506, 4.9509, 4.9510, 4.9511, 4.9510, 4.9510, 4.9510,\n",
      "        4.9506, 4.9508, 4.9510, 4.9509, 4.9507, 4.9509, 4.9510, 4.9511, 4.9508,\n",
      "        4.9508, 4.9509, 4.9510, 4.9511, 4.9510, 4.9511, 4.9510, 4.9510, 4.9512,\n",
      "        4.9508, 4.9508, 4.9510], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.825468  [1054124/5599865]\n",
      "average delta from current occupancy tensor([4.7638, 4.7639, 4.7638, 4.7637, 4.7638, 4.7638, 4.7637, 4.7638, 4.7637,\n",
      "        4.7637, 4.7638, 4.7637, 4.7637, 4.7637, 4.7637, 4.7636, 4.7637, 4.7636,\n",
      "        4.7637, 4.7637, 4.7636, 4.7637, 4.7638, 4.7638, 4.7639, 4.7638, 4.7638,\n",
      "        4.7638, 4.7637, 4.7636, 4.7636, 4.7637, 4.7638, 4.7638, 4.7638, 4.7637,\n",
      "        4.7637, 4.7636, 4.7638, 4.7637, 4.7638, 4.7636, 4.7638, 4.7637, 4.7637,\n",
      "        4.7636, 4.7638, 4.7638, 4.7637, 4.7638, 4.7637, 4.7639, 4.7638, 4.7639,\n",
      "        4.7637, 4.7638, 4.7638, 4.7637, 4.7637, 4.7637, 4.7637, 4.7637, 4.7637,\n",
      "        4.7636, 4.7637, 4.7637, 4.7637, 4.7637, 4.7637, 4.7637, 4.7637, 4.7637,\n",
      "        4.7637, 4.7637, 4.7637, 4.7637, 4.7637, 4.7638, 4.7638, 4.7639, 4.7638,\n",
      "        4.7638, 4.7638, 4.7638, 4.7639, 4.7639, 4.7640, 4.7640, 4.7639, 4.7640,\n",
      "        4.7640, 4.7640, 4.7640, 4.7640, 4.7639, 4.7639, 4.7639, 4.7639, 4.7638,\n",
      "        4.7639, 4.7639, 4.7638, 4.7638, 4.7638, 4.7638, 4.7638, 4.7638, 4.7637,\n",
      "        4.7638, 4.7638, 4.7639, 4.7638, 4.7636, 4.7637, 4.7639, 4.7636, 4.7638,\n",
      "        4.7638, 4.7638, 4.7638], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.696918  [1066524/5599865]\n",
      "average delta from current occupancy tensor([4.6776, 4.6778, 4.6778, 4.6778, 4.6778, 4.6778, 4.6777, 4.6776, 4.6775,\n",
      "        4.6775, 4.6778, 4.6778, 4.6775, 4.6775, 4.6777, 4.6777, 4.6778, 4.6776,\n",
      "        4.6777, 4.6777, 4.6776, 4.6775, 4.6776, 4.6777, 4.6778, 4.6777, 4.6778,\n",
      "        4.6776, 4.6776, 4.6776, 4.6776, 4.6776, 4.6776, 4.6775, 4.6775, 4.6777,\n",
      "        4.6778, 4.6776, 4.6778, 4.6781, 4.6778, 4.6780, 4.6779, 4.6780, 4.6780,\n",
      "        4.6778, 4.6778, 4.6779, 4.6778, 4.6779, 4.6780, 4.6779, 4.6779, 4.6781,\n",
      "        4.6780, 4.6781, 4.6781, 4.6780, 4.6779, 4.6779, 4.6781, 4.6779, 4.6780,\n",
      "        4.6779, 4.6780, 4.6780, 4.6779, 4.6780, 4.6781, 4.6783, 4.6779, 4.6783,\n",
      "        4.6782, 4.6782, 4.6782, 4.6781, 4.6781, 4.6780, 4.6780, 4.6781, 4.6780,\n",
      "        4.6780, 4.6781, 4.6780, 4.6781, 4.6781, 4.6781, 4.6782, 4.6783, 4.6781,\n",
      "        4.6780, 4.6781, 4.6780, 4.6780, 4.6780, 4.6780, 4.6781, 4.6781, 4.6781,\n",
      "        4.6779, 4.6780, 4.6780, 4.6779, 4.6779, 4.6778, 4.6779, 4.6778, 4.6777,\n",
      "        4.6777, 4.6776, 4.6775, 4.6777, 4.6777, 4.6778, 4.6779, 4.6778, 4.6778,\n",
      "        4.6776, 4.6777, 4.6777], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.180392  [1078924/5599865]\n",
      "average delta from current occupancy tensor([5.1411, 5.1412, 5.1412, 5.1411, 5.1413, 5.1413, 5.1409, 5.1411, 5.1407,\n",
      "        5.1409, 5.1412, 5.1409, 5.1400, 5.1400, 5.1407, 5.1405, 5.1405, 5.1404,\n",
      "        5.1406, 5.1407, 5.1408, 5.1411, 5.1413, 5.1411, 5.1409, 5.1402, 5.1400,\n",
      "        5.1400, 5.1406, 5.1401, 5.1396, 5.1393, 5.1395, 5.1399, 5.1399, 5.1403,\n",
      "        5.1406, 5.1404, 5.1401, 5.1403, 5.1404, 5.1404, 5.1403, 5.1402, 5.1399,\n",
      "        5.1402, 5.1403, 5.1398, 5.1398, 5.1398, 5.1398, 5.1399, 5.1397, 5.1396,\n",
      "        5.1397, 5.1398, 5.1397, 5.1398, 5.1395, 5.1396, 5.1394, 5.1390, 5.1395,\n",
      "        5.1399, 5.1400, 5.1403, 5.1402, 5.1399, 5.1397, 5.1391, 5.1394, 5.1387,\n",
      "        5.1396, 5.1400, 5.1395, 5.1400, 5.1399, 5.1397, 5.1397, 5.1400, 5.1393,\n",
      "        5.1389, 5.1393, 5.1391, 5.1391, 5.1392, 5.1387, 5.1393, 5.1394, 5.1390,\n",
      "        5.1388, 5.1386, 5.1385, 5.1388, 5.1387, 5.1385, 5.1385, 5.1384, 5.1387,\n",
      "        5.1389, 5.1388, 5.1391, 5.1397, 5.1397, 5.1394, 5.1394, 5.1397, 5.1396,\n",
      "        5.1392, 5.1391, 5.1390, 5.1395, 5.1395, 5.1401, 5.1398, 5.1397, 5.1398,\n",
      "        5.1399, 5.1400, 5.1395], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.263025  [1091324/5599865]\n",
      "average delta from current occupancy tensor([5.1948, 5.1950, 5.1952, 5.1951, 5.1953, 5.1952, 5.1952, 5.1952, 5.1957,\n",
      "        5.1955, 5.1952, 5.1957, 5.1955, 5.1952, 5.1959, 5.1952, 5.1952, 5.1952,\n",
      "        5.1950, 5.1952, 5.1952, 5.1952, 5.1952, 5.1955, 5.1952, 5.1956, 5.1952,\n",
      "        5.1951, 5.1952, 5.1955, 5.1955, 5.1957, 5.1959, 5.1954, 5.1956, 5.1955,\n",
      "        5.1954, 5.1957, 5.1956, 5.1954, 5.1956, 5.1956, 5.1958, 5.1959, 5.1959,\n",
      "        5.1961, 5.1960, 5.1958, 5.1960, 5.1956, 5.1958, 5.1957, 5.1958, 5.1955,\n",
      "        5.1954, 5.1953, 5.1953, 5.1951, 5.1950, 5.1952, 5.1945, 5.1950, 5.1951,\n",
      "        5.1954, 5.1952, 5.1947, 5.1948, 5.1949, 5.1948, 5.1942, 5.1953, 5.1946,\n",
      "        5.1950, 5.1947, 5.1950, 5.1948, 5.1951, 5.1954, 5.1953, 5.1951, 5.1953,\n",
      "        5.1945, 5.1951, 5.1944, 5.1941, 5.1943, 5.1947, 5.1942, 5.1944, 5.1946,\n",
      "        5.1948, 5.1950, 5.1946, 5.1943, 5.1945, 5.1947, 5.1944, 5.1946, 5.1953,\n",
      "        5.1953, 5.1953, 5.1954, 5.1949, 5.1949, 5.1953, 5.1956, 5.1951, 5.1953,\n",
      "        5.1946, 5.1946, 5.1948, 5.1954, 5.1952, 5.1952, 5.1949, 5.1945, 5.1941,\n",
      "        5.1943, 5.1944, 5.1951], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.864859  [1103724/5599865]\n",
      "average delta from current occupancy tensor([5.0242, 5.0242, 5.0242, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0244, 5.0244, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0242, 5.0243, 5.0243, 5.0243, 5.0243, 5.0244, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0244, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0244, 5.0244, 5.0243, 5.0244, 5.0243, 5.0243, 5.0244, 5.0243, 5.0244,\n",
      "        5.0244, 5.0244, 5.0244, 5.0243, 5.0244, 5.0244, 5.0244, 5.0244, 5.0244,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.006111  [1116124/5599865]\n",
      "average delta from current occupancy tensor([3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9915,\n",
      "        3.9915, 3.9915, 3.9915, 3.9914, 3.9914, 3.9915, 3.9914, 3.9915, 3.9915,\n",
      "        3.9915, 3.9915, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914,\n",
      "        3.9914, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9914,\n",
      "        3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9914, 3.9915,\n",
      "        3.9915, 3.9915, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914, 3.9914,\n",
      "        3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915,\n",
      "        3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915,\n",
      "        3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915,\n",
      "        3.9914, 3.9915, 3.9915, 3.9915, 3.9914, 3.9914, 3.9914, 3.9915, 3.9914,\n",
      "        3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9914, 3.9914,\n",
      "        3.9915, 3.9915, 3.9914, 3.9914, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915,\n",
      "        3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915, 3.9915,\n",
      "        3.9915, 3.9915, 3.9915], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.998696  [1128524/5599865]\n",
      "average delta from current occupancy tensor([4.6780, 4.6779, 4.6779, 4.6780, 4.6780, 4.6781, 4.6781, 4.6781, 4.6782,\n",
      "        4.6782, 4.6782, 4.6783, 4.6783, 4.6781, 4.6783, 4.6780, 4.6783, 4.6783,\n",
      "        4.6783, 4.6783, 4.6781, 4.6781, 4.6780, 4.6780, 4.6780, 4.6780, 4.6780,\n",
      "        4.6780, 4.6781, 4.6783, 4.6782, 4.6783, 4.6782, 4.6783, 4.6782, 4.6780,\n",
      "        4.6783, 4.6781, 4.6780, 4.6781, 4.6782, 4.6782, 4.6781, 4.6781, 4.6782,\n",
      "        4.6781, 4.6781, 4.6782, 4.6781, 4.6780, 4.6780, 4.6782, 4.6782, 4.6782,\n",
      "        4.6782, 4.6780, 4.6780, 4.6780, 4.6780, 4.6780, 4.6779, 4.6780, 4.6780,\n",
      "        4.6780, 4.6779, 4.6779, 4.6779, 4.6778, 4.6779, 4.6780, 4.6780, 4.6781,\n",
      "        4.6780, 4.6780, 4.6780, 4.6781, 4.6780, 4.6780, 4.6781, 4.6781, 4.6781,\n",
      "        4.6781, 4.6780, 4.6780, 4.6781, 4.6779, 4.6779, 4.6780, 4.6780, 4.6781,\n",
      "        4.6780, 4.6779, 4.6780, 4.6779, 4.6779, 4.6779, 4.6779, 4.6779, 4.6779,\n",
      "        4.6779, 4.6779, 4.6779, 4.6780, 4.6780, 4.6781, 4.6780, 4.6780, 4.6782,\n",
      "        4.6782, 4.6781, 4.6781, 4.6782, 4.6782, 4.6780, 4.6780, 4.6781, 4.6783,\n",
      "        4.6780, 4.6780, 4.6780], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.513749  [1140924/5599865]\n",
      "average delta from current occupancy tensor([5.6204, 5.6204, 5.6207, 5.6206, 5.6204, 5.6207, 5.6205, 5.6205, 5.6206,\n",
      "        5.6204, 5.6204, 5.6205, 5.6204, 5.6204, 5.6204, 5.6203, 5.6202, 5.6201,\n",
      "        5.6200, 5.6200, 5.6201, 5.6201, 5.6201, 5.6199, 5.6200, 5.6197, 5.6200,\n",
      "        5.6199, 5.6198, 5.6198, 5.6198, 5.6199, 5.6199, 5.6199, 5.6200, 5.6200,\n",
      "        5.6200, 5.6200, 5.6200, 5.6202, 5.6200, 5.6201, 5.6201, 5.6201, 5.6201,\n",
      "        5.6202, 5.6202, 5.6202, 5.6202, 5.6204, 5.6202, 5.6201, 5.6202, 5.6203,\n",
      "        5.6203, 5.6203, 5.6201, 5.6202, 5.6201, 5.6201, 5.6200, 5.6202, 5.6201,\n",
      "        5.6199, 5.6200, 5.6200, 5.6202, 5.6202, 5.6201, 5.6200, 5.6199, 5.6200,\n",
      "        5.6200, 5.6199, 5.6199, 5.6199, 5.6200, 5.6200, 5.6199, 5.6199, 5.6199,\n",
      "        5.6199, 5.6198, 5.6198, 5.6199, 5.6198, 5.6199, 5.6198, 5.6198, 5.6197,\n",
      "        5.6200, 5.6197, 5.6198, 5.6198, 5.6202, 5.6202, 5.6198, 5.6198, 5.6201,\n",
      "        5.6199, 5.6199, 5.6198, 5.6200, 5.6199, 5.6201, 5.6202, 5.6200, 5.6205,\n",
      "        5.6204, 5.6204, 5.6203, 5.6201, 5.6202, 5.6200, 5.6201, 5.6201, 5.6202,\n",
      "        5.6199, 5.6200, 5.6200], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.498248  [1153324/5599865]\n",
      "average delta from current occupancy tensor([4.4433, 4.4433, 4.4432, 4.4432, 4.4432, 4.4432, 4.4432, 4.4432, 4.4432,\n",
      "        4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433,\n",
      "        4.4433, 4.4434, 4.4434, 4.4433, 4.4433, 4.4434, 4.4434, 4.4433, 4.4434,\n",
      "        4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433, 4.4433,\n",
      "        4.4433, 4.4433, 4.4434, 4.4434, 4.4434, 4.4434, 4.4433, 4.4434, 4.4434,\n",
      "        4.4434, 4.4434, 4.4433, 4.4434, 4.4434, 4.4434, 4.4433, 4.4434, 4.4434,\n",
      "        4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434,\n",
      "        4.4433, 4.4434, 4.4433, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4433,\n",
      "        4.4434, 4.4433, 4.4433, 4.4433, 4.4434, 4.4433, 4.4434, 4.4434, 4.4434,\n",
      "        4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4433, 4.4434, 4.4433, 4.4433,\n",
      "        4.4434, 4.4434, 4.4433, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434,\n",
      "        4.4434, 4.4434, 4.4433, 4.4433, 4.4433, 4.4434, 4.4434, 4.4434, 4.4434,\n",
      "        4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4434, 4.4433,\n",
      "        4.4434, 4.4433, 4.4433], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.631051  [1165724/5599865]\n",
      "average delta from current occupancy tensor([4.6380, 4.6380, 4.6381, 4.6381, 4.6379, 4.6381, 4.6380, 4.6380, 4.6381,\n",
      "        4.6378, 4.6380, 4.6381, 4.6380, 4.6377, 4.6380, 4.6379, 4.6381, 4.6381,\n",
      "        4.6382, 4.6380, 4.6379, 4.6380, 4.6380, 4.6377, 4.6379, 4.6379, 4.6380,\n",
      "        4.6381, 4.6381, 4.6381, 4.6381, 4.6382, 4.6381, 4.6380, 4.6379, 4.6378,\n",
      "        4.6380, 4.6378, 4.6378, 4.6377, 4.6377, 4.6378, 4.6378, 4.6378, 4.6379,\n",
      "        4.6378, 4.6377, 4.6378, 4.6376, 4.6375, 4.6376, 4.6374, 4.6375, 4.6377,\n",
      "        4.6379, 4.6378, 4.6375, 4.6375, 4.6375, 4.6376, 4.6376, 4.6375, 4.6373,\n",
      "        4.6375, 4.6373, 4.6374, 4.6374, 4.6375, 4.6376, 4.6376, 4.6378, 4.6373,\n",
      "        4.6375, 4.6373, 4.6374, 4.6376, 4.6377, 4.6377, 4.6374, 4.6377, 4.6379,\n",
      "        4.6376, 4.6374, 4.6376, 4.6375, 4.6378, 4.6376, 4.6375, 4.6375, 4.6375,\n",
      "        4.6377, 4.6375, 4.6375, 4.6376, 4.6377, 4.6376, 4.6374, 4.6376, 4.6379,\n",
      "        4.6378, 4.6377, 4.6378, 4.6379, 4.6381, 4.6379, 4.6381, 4.6379, 4.6382,\n",
      "        4.6380, 4.6382, 4.6379, 4.6379, 4.6378, 4.6379, 4.6380, 4.6380, 4.6380,\n",
      "        4.6379, 4.6380, 4.6380], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.509043  [1178124/5599865]\n",
      "average delta from current occupancy tensor([5.2267, 5.2268, 5.2265, 5.2265, 5.2265, 5.2263, 5.2262, 5.2263, 5.2262,\n",
      "        5.2264, 5.2263, 5.2262, 5.2265, 5.2265, 5.2264, 5.2264, 5.2264, 5.2263,\n",
      "        5.2265, 5.2264, 5.2265, 5.2266, 5.2266, 5.2264, 5.2267, 5.2267, 5.2264,\n",
      "        5.2263, 5.2264, 5.2263, 5.2263, 5.2262, 5.2265, 5.2264, 5.2263, 5.2262,\n",
      "        5.2261, 5.2260, 5.2261, 5.2262, 5.2263, 5.2264, 5.2264, 5.2267, 5.2265,\n",
      "        5.2265, 5.2263, 5.2262, 5.2266, 5.2266, 5.2266, 5.2265, 5.2266, 5.2265,\n",
      "        5.2266, 5.2262, 5.2265, 5.2266, 5.2267, 5.2269, 5.2266, 5.2269, 5.2270,\n",
      "        5.2269, 5.2270, 5.2271, 5.2270, 5.2269, 5.2268, 5.2269, 5.2268, 5.2271,\n",
      "        5.2270, 5.2271, 5.2269, 5.2268, 5.2270, 5.2270, 5.2271, 5.2270, 5.2269,\n",
      "        5.2269, 5.2270, 5.2270, 5.2269, 5.2262, 5.2267, 5.2270, 5.2268, 5.2268,\n",
      "        5.2262, 5.2270, 5.2269, 5.2267, 5.2269, 5.2269, 5.2270, 5.2270, 5.2272,\n",
      "        5.2268, 5.2269, 5.2269, 5.2270, 5.2268, 5.2269, 5.2268, 5.2268, 5.2269,\n",
      "        5.2268, 5.2269, 5.2264, 5.2267, 5.2268, 5.2266, 5.2266, 5.2267, 5.2265,\n",
      "        5.2265, 5.2265, 5.2266], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.504078  [1190524/5599865]\n",
      "average delta from current occupancy tensor([5.3148, 5.3147, 5.3147, 5.3148, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3148, 5.3148,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3148, 5.3148,\n",
      "        5.3148, 5.3147, 5.3147], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.471398  [1202924/5599865]\n",
      "average delta from current occupancy tensor([5.4038, 5.4038, 5.4036, 5.4037, 5.4037, 5.4038, 5.4039, 5.4037, 5.4037,\n",
      "        5.4036, 5.4037, 5.4037, 5.4036, 5.4037, 5.4038, 5.4037, 5.4036, 5.4037,\n",
      "        5.4037, 5.4038, 5.4038, 5.4037, 5.4037, 5.4038, 5.4038, 5.4038, 5.4038,\n",
      "        5.4036, 5.4037, 5.4036, 5.4036, 5.4037, 5.4038, 5.4038, 5.4037, 5.4037,\n",
      "        5.4038, 5.4036, 5.4035, 5.4036, 5.4034, 5.4035, 5.4033, 5.4033, 5.4035,\n",
      "        5.4033, 5.4035, 5.4035, 5.4036, 5.4036, 5.4033, 5.4034, 5.4036, 5.4034,\n",
      "        5.4036, 5.4035, 5.4036, 5.4032, 5.4036, 5.4034, 5.4034, 5.4037, 5.4036,\n",
      "        5.4036, 5.4038, 5.4036, 5.4035, 5.4034, 5.4036, 5.4036, 5.4036, 5.4036,\n",
      "        5.4035, 5.4035, 5.4034, 5.4034, 5.4033, 5.4034, 5.4034, 5.4034, 5.4035,\n",
      "        5.4035, 5.4035, 5.4034, 5.4034, 5.4035, 5.4035, 5.4037, 5.4032, 5.4034,\n",
      "        5.4035, 5.4036, 5.4036, 5.4034, 5.4034, 5.4035, 5.4035, 5.4035, 5.4034,\n",
      "        5.4034, 5.4033, 5.4033, 5.4034, 5.4034, 5.4036, 5.4036, 5.4034, 5.4034,\n",
      "        5.4035, 5.4036, 5.4036, 5.4038, 5.4039, 5.4038, 5.4039, 5.4037, 5.4038,\n",
      "        5.4038, 5.4039, 5.4039], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.717309  [1215324/5599865]\n",
      "average delta from current occupancy tensor([5.5002, 5.5001, 5.5001, 5.5001, 5.5001, 5.5001, 5.5001, 5.5001, 5.5001,\n",
      "        5.5002, 5.5001, 5.5002, 5.5001, 5.5001, 5.5001, 5.5001, 5.5001, 5.5001,\n",
      "        5.5001, 5.5001, 5.5002, 5.5001, 5.5001, 5.5002, 5.5003, 5.5001, 5.5002,\n",
      "        5.5002, 5.5002, 5.5002, 5.5001, 5.5002, 5.5002, 5.5002, 5.5002, 5.5002,\n",
      "        5.5002, 5.5002, 5.5003, 5.5002, 5.5003, 5.5003, 5.5003, 5.5002, 5.5002,\n",
      "        5.5001, 5.5002, 5.5003, 5.5002, 5.5001, 5.5001, 5.5001, 5.5002, 5.5001,\n",
      "        5.5002, 5.5000, 5.5000, 5.5000, 5.5001, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5001, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5002, 5.5001,\n",
      "        5.5001, 5.5001, 5.5001, 5.5001, 5.5001, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5001, 5.5000,\n",
      "        5.5001, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5001, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5001,\n",
      "        5.5001, 5.5001, 5.5001, 5.5001, 5.5000, 5.5000, 5.5001, 5.5000, 5.5000,\n",
      "        5.5000, 5.5000, 5.5000], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.135666  [1227724/5599865]\n",
      "average delta from current occupancy tensor([5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127,\n",
      "        5.1126, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127,\n",
      "        5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1126, 5.1127, 5.1127,\n",
      "        5.1127, 5.1126, 5.1127, 5.1127, 5.1126, 5.1127, 5.1127, 5.1127, 5.1127,\n",
      "        5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127,\n",
      "        5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127,\n",
      "        5.1126, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1126, 5.1126,\n",
      "        5.1126, 5.1127, 5.1126, 5.1126, 5.1127, 5.1126, 5.1126, 5.1126, 5.1126,\n",
      "        5.1125, 5.1126, 5.1126, 5.1126, 5.1126, 5.1127, 5.1127, 5.1127, 5.1127,\n",
      "        5.1126, 5.1127, 5.1126, 5.1126, 5.1127, 5.1125, 5.1125, 5.1125, 5.1125,\n",
      "        5.1125, 5.1126, 5.1125, 5.1127, 5.1126, 5.1127, 5.1126, 5.1127, 5.1126,\n",
      "        5.1126, 5.1126, 5.1126, 5.1126, 5.1126, 5.1126, 5.1126, 5.1126, 5.1127,\n",
      "        5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1126,\n",
      "        5.1127, 5.1127, 5.1127], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.077721  [1240124/5599865]\n",
      "average delta from current occupancy tensor([5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4114, 5.4113, 5.4114, 5.4113,\n",
      "        5.4114, 5.4113, 5.4113, 5.4115, 5.4114, 5.4113, 5.4115, 5.4114, 5.4113,\n",
      "        5.4113, 5.4114, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4113, 5.4114, 5.4114, 5.4113, 5.4113, 5.4113, 5.4113, 5.4113,\n",
      "        5.4113, 5.4114, 5.4114], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.771724  [1252524/5599865]\n",
      "average delta from current occupancy tensor([4.8227, 4.8227, 4.8227, 4.8227, 4.8226, 4.8227, 4.8227, 4.8227, 4.8227,\n",
      "        4.8227, 4.8228, 4.8227, 4.8227, 4.8226, 4.8227, 4.8227, 4.8226, 4.8227,\n",
      "        4.8226, 4.8227, 4.8227, 4.8227, 4.8227, 4.8228, 4.8228, 4.8228, 4.8227,\n",
      "        4.8227, 4.8228, 4.8228, 4.8228, 4.8228, 4.8229, 4.8228, 4.8228, 4.8228,\n",
      "        4.8228, 4.8228, 4.8228, 4.8228, 4.8228, 4.8228, 4.8229, 4.8228, 4.8228,\n",
      "        4.8227, 4.8227, 4.8227, 4.8228, 4.8228, 4.8227, 4.8226, 4.8226, 4.8226,\n",
      "        4.8227, 4.8227, 4.8226, 4.8226, 4.8226, 4.8227, 4.8227, 4.8227, 4.8226,\n",
      "        4.8227, 4.8228, 4.8228, 4.8228, 4.8228, 4.8229, 4.8228, 4.8230, 4.8227,\n",
      "        4.8228, 4.8228, 4.8228, 4.8227, 4.8228, 4.8227, 4.8227, 4.8227, 4.8228,\n",
      "        4.8226, 4.8228, 4.8227, 4.8227, 4.8226, 4.8227, 4.8227, 4.8227, 4.8226,\n",
      "        4.8226, 4.8227, 4.8226, 4.8226, 4.8226, 4.8226, 4.8226, 4.8227, 4.8226,\n",
      "        4.8228, 4.8226, 4.8226, 4.8226, 4.8226, 4.8226, 4.8226, 4.8226, 4.8227,\n",
      "        4.8228, 4.8226, 4.8226, 4.8227, 4.8227, 4.8227, 4.8227, 4.8227, 4.8228,\n",
      "        4.8228, 4.8228, 4.8228], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.584015  [1264924/5599865]\n",
      "average delta from current occupancy tensor([6.0643, 6.0643, 6.0642, 6.0643, 6.0643, 6.0642, 6.0644, 6.0644, 6.0642,\n",
      "        6.0642, 6.0643, 6.0641, 6.0641, 6.0637, 6.0641, 6.0643, 6.0641, 6.0643,\n",
      "        6.0640, 6.0640, 6.0643, 6.0642, 6.0641, 6.0643, 6.0644, 6.0644, 6.0643,\n",
      "        6.0641, 6.0644, 6.0644, 6.0643, 6.0644, 6.0643, 6.0643, 6.0645, 6.0646,\n",
      "        6.0642, 6.0642, 6.0643, 6.0644, 6.0645, 6.0642, 6.0642, 6.0643, 6.0644,\n",
      "        6.0644, 6.0644, 6.0642, 6.0642, 6.0642, 6.0641, 6.0638, 6.0637, 6.0637,\n",
      "        6.0639, 6.0638, 6.0638, 6.0637, 6.0636, 6.0639, 6.0638, 6.0640, 6.0640,\n",
      "        6.0640, 6.0640, 6.0643, 6.0639, 6.0639, 6.0643, 6.0640, 6.0641, 6.0641,\n",
      "        6.0635, 6.0636, 6.0643, 6.0641, 6.0639, 6.0639, 6.0641, 6.0640, 6.0635,\n",
      "        6.0638, 6.0637, 6.0638, 6.0641, 6.0638, 6.0638, 6.0640, 6.0642, 6.0641,\n",
      "        6.0642, 6.0641, 6.0641, 6.0642, 6.0643, 6.0647, 6.0645, 6.0645, 6.0646,\n",
      "        6.0646, 6.0646, 6.0648, 6.0647, 6.0648, 6.0646, 6.0645, 6.0644, 6.0645,\n",
      "        6.0644, 6.0645, 6.0646, 6.0643, 6.0644, 6.0644, 6.0643, 6.0643, 6.0642,\n",
      "        6.0645, 6.0644, 6.0643], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.255798  [1277324/5599865]\n",
      "average delta from current occupancy tensor([5.2583, 5.2583, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584,\n",
      "        5.2584, 5.2584, 5.2583, 5.2583, 5.2583, 5.2583, 5.2582, 5.2583, 5.2582,\n",
      "        5.2582, 5.2582, 5.2582, 5.2582, 5.2582, 5.2582, 5.2582, 5.2582, 5.2583,\n",
      "        5.2582, 5.2582, 5.2583, 5.2582, 5.2581, 5.2581, 5.2582, 5.2582, 5.2581,\n",
      "        5.2581, 5.2582, 5.2582, 5.2582, 5.2582, 5.2582, 5.2582, 5.2583, 5.2583,\n",
      "        5.2582, 5.2583, 5.2583, 5.2582, 5.2583, 5.2582, 5.2584, 5.2584, 5.2584,\n",
      "        5.2583, 5.2584, 5.2583, 5.2584, 5.2583, 5.2583, 5.2583, 5.2582, 5.2582,\n",
      "        5.2582, 5.2582, 5.2582, 5.2583, 5.2583, 5.2582, 5.2583, 5.2583, 5.2583,\n",
      "        5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2583, 5.2584, 5.2584,\n",
      "        5.2584, 5.2585, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584,\n",
      "        5.2584, 5.2584, 5.2584, 5.2583, 5.2584, 5.2584, 5.2583, 5.2583, 5.2584,\n",
      "        5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2584, 5.2583, 5.2583, 5.2583,\n",
      "        5.2583, 5.2582, 5.2582, 5.2582, 5.2583, 5.2583, 5.2583, 5.2582, 5.2582,\n",
      "        5.2583, 5.2582, 5.2582], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.246270  [1289724/5599865]\n",
      "average delta from current occupancy tensor([5.3954, 5.3954, 5.3953, 5.3954, 5.3953, 5.3953, 5.3953, 5.3953, 5.3953,\n",
      "        5.3953, 5.3953, 5.3953, 5.3953, 5.3953, 5.3953, 5.3954, 5.3953, 5.3953,\n",
      "        5.3954, 5.3953, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3953, 5.3953, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3953, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3953, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3953, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3953, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954, 5.3954,\n",
      "        5.3954, 5.3954, 5.3954], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.912271  [1302124/5599865]\n",
      "average delta from current occupancy tensor([4.8310, 4.8309, 4.8308, 4.8310, 4.8310, 4.8310, 4.8309, 4.8308, 4.8310,\n",
      "        4.8309, 4.8308, 4.8311, 4.8310, 4.8309, 4.8309, 4.8310, 4.8312, 4.8312,\n",
      "        4.8311, 4.8313, 4.8313, 4.8313, 4.8313, 4.8313, 4.8315, 4.8313, 4.8314,\n",
      "        4.8315, 4.8315, 4.8314, 4.8316, 4.8316, 4.8316, 4.8317, 4.8316, 4.8317,\n",
      "        4.8316, 4.8313, 4.8313, 4.8315, 4.8315, 4.8316, 4.8315, 4.8314, 4.8314,\n",
      "        4.8316, 4.8315, 4.8314, 4.8316, 4.8314, 4.8314, 4.8315, 4.8316, 4.8314,\n",
      "        4.8313, 4.8312, 4.8312, 4.8311, 4.8313, 4.8312, 4.8312, 4.8310, 4.8314,\n",
      "        4.8312, 4.8312, 4.8312, 4.8313, 4.8313, 4.8311, 4.8313, 4.8311, 4.8312,\n",
      "        4.8312, 4.8312, 4.8310, 4.8310, 4.8312, 4.8312, 4.8312, 4.8313, 4.8311,\n",
      "        4.8311, 4.8311, 4.8311, 4.8313, 4.8311, 4.8312, 4.8311, 4.8311, 4.8310,\n",
      "        4.8310, 4.8311, 4.8311, 4.8314, 4.8313, 4.8313, 4.8313, 4.8315, 4.8315,\n",
      "        4.8314, 4.8312, 4.8315, 4.8313, 4.8312, 4.8312, 4.8314, 4.8312, 4.8313,\n",
      "        4.8313, 4.8313, 4.8314, 4.8314, 4.8315, 4.8313, 4.8315, 4.8316, 4.8315,\n",
      "        4.8317, 4.8316, 4.8318], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.570440  [1314524/5599865]\n",
      "average delta from current occupancy tensor([5.6952, 5.6953, 5.6954, 5.6952, 5.6950, 5.6949, 5.6948, 5.6949, 5.6947,\n",
      "        5.6949, 5.6950, 5.6947, 5.6946, 5.6945, 5.6945, 5.6943, 5.6944, 5.6943,\n",
      "        5.6941, 5.6947, 5.6943, 5.6943, 5.6942, 5.6946, 5.6944, 5.6943, 5.6947,\n",
      "        5.6946, 5.6953, 5.6951, 5.6950, 5.6948, 5.6949, 5.6950, 5.6945, 5.6945,\n",
      "        5.6944, 5.6946, 5.6947, 5.6946, 5.6948, 5.6948, 5.6948, 5.6950, 5.6949,\n",
      "        5.6947, 5.6949, 5.6948, 5.6946, 5.6945, 5.6946, 5.6952, 5.6951, 5.6944,\n",
      "        5.6945, 5.6944, 5.6946, 5.6945, 5.6943, 5.6943, 5.6945, 5.6945, 5.6948,\n",
      "        5.6948, 5.6945, 5.6944, 5.6948, 5.6947, 5.6947, 5.6952, 5.6950, 5.6947,\n",
      "        5.6947, 5.6945, 5.6945, 5.6945, 5.6945, 5.6946, 5.6945, 5.6947, 5.6944,\n",
      "        5.6945, 5.6947, 5.6943, 5.6948, 5.6945, 5.6944, 5.6946, 5.6944, 5.6947,\n",
      "        5.6949, 5.6949, 5.6952, 5.6954, 5.6955, 5.6955, 5.6953, 5.6950, 5.6951,\n",
      "        5.6952, 5.6949, 5.6953, 5.6951, 5.6950, 5.6949, 5.6950, 5.6948, 5.6949,\n",
      "        5.6946, 5.6947, 5.6946, 5.6949, 5.6948, 5.6947, 5.6947, 5.6949, 5.6950,\n",
      "        5.6953, 5.6949, 5.6951], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.913743  [1326924/5599865]\n",
      "average delta from current occupancy tensor([5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323, 5.0323,\n",
      "        5.0323, 5.0323, 5.0323], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.967073  [1339324/5599865]\n",
      "average delta from current occupancy tensor([5.0808, 5.0808, 5.0808, 5.0809, 5.0809, 5.0809, 5.0809, 5.0808, 5.0809,\n",
      "        5.0808, 5.0809, 5.0808, 5.0808, 5.0809, 5.0809, 5.0808, 5.0808, 5.0809,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0809,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0809, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0807, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0808, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0808, 5.0808, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0808,\n",
      "        5.0808, 5.0807, 5.0807, 5.0807, 5.0808, 5.0808, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0806, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807, 5.0807,\n",
      "        5.0807, 5.0807, 5.0808], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.589316  [1351724/5599865]\n",
      "average delta from current occupancy tensor([4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5719,\n",
      "        4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718,\n",
      "        4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5718, 4.5719, 4.5718, 4.5718,\n",
      "        4.5718, 4.5718, 4.5719, 4.5719, 4.5719, 4.5718, 4.5719, 4.5719, 4.5719,\n",
      "        4.5719, 4.5719, 4.5719, 4.5718, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719,\n",
      "        4.5719, 4.5719, 4.5720, 4.5719, 4.5720, 4.5719, 4.5719, 4.5719, 4.5718,\n",
      "        4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5718, 4.5718, 4.5718, 4.5719,\n",
      "        4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5718, 4.5719,\n",
      "        4.5718, 4.5721, 4.5720, 4.5719, 4.5719, 4.5719, 4.5719, 4.5720, 4.5719,\n",
      "        4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5720, 4.5720,\n",
      "        4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5718, 4.5719,\n",
      "        4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719,\n",
      "        4.5719, 4.5719, 4.5720, 4.5720, 4.5719, 4.5719, 4.5719, 4.5719, 4.5719,\n",
      "        4.5719, 4.5719, 4.5719], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.262274  [1364124/5599865]\n",
      "average delta from current occupancy tensor([5.2743, 5.2744, 5.2744, 5.2744, 5.2744, 5.2744, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2742, 5.2743, 5.2743, 5.2743, 5.2743, 5.2744,\n",
      "        5.2742, 5.2743, 5.2744, 5.2744, 5.2746, 5.2746, 5.2747, 5.2747, 5.2747,\n",
      "        5.2747, 5.2746, 5.2746, 5.2747, 5.2747, 5.2746, 5.2748, 5.2747, 5.2747,\n",
      "        5.2746, 5.2746, 5.2745, 5.2744, 5.2744, 5.2744, 5.2743, 5.2744, 5.2743,\n",
      "        5.2744, 5.2744, 5.2746, 5.2745, 5.2745, 5.2744, 5.2743, 5.2743, 5.2744,\n",
      "        5.2744, 5.2743, 5.2743, 5.2744, 5.2743, 5.2744, 5.2743, 5.2743, 5.2743,\n",
      "        5.2744, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2745, 5.2744, 5.2744,\n",
      "        5.2744, 5.2743, 5.2743, 5.2744, 5.2744, 5.2744, 5.2744, 5.2743, 5.2744,\n",
      "        5.2744, 5.2744, 5.2743, 5.2743, 5.2743, 5.2744, 5.2743, 5.2744, 5.2744,\n",
      "        5.2744, 5.2745, 5.2744, 5.2744, 5.2744, 5.2745, 5.2744, 5.2744, 5.2744,\n",
      "        5.2744, 5.2744, 5.2745, 5.2744, 5.2744, 5.2744, 5.2745, 5.2744, 5.2745,\n",
      "        5.2745, 5.2744, 5.2744, 5.2745, 5.2744, 5.2745, 5.2744, 5.2745, 5.2745,\n",
      "        5.2745, 5.2745, 5.2745], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.033566  [1376524/5599865]\n",
      "average delta from current occupancy tensor([5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0646,\n",
      "        5.0645, 5.0646, 5.0646, 5.0645, 5.0645, 5.0645, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0645, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.115122  [1388924/5599865]\n",
      "average delta from current occupancy tensor([5.2912, 5.2910, 5.2911, 5.2912, 5.2908, 5.2909, 5.2910, 5.2911, 5.2910,\n",
      "        5.2910, 5.2911, 5.2913, 5.2910, 5.2911, 5.2910, 5.2913, 5.2912, 5.2907,\n",
      "        5.2913, 5.2910, 5.2911, 5.2912, 5.2911, 5.2911, 5.2909, 5.2908, 5.2909,\n",
      "        5.2910, 5.2909, 5.2908, 5.2906, 5.2905, 5.2910, 5.2911, 5.2909, 5.2912,\n",
      "        5.2909, 5.2908, 5.2909, 5.2909, 5.2908, 5.2909, 5.2909, 5.2909, 5.2908,\n",
      "        5.2908, 5.2906, 5.2910, 5.2908, 5.2904, 5.2909, 5.2908, 5.2909, 5.2909,\n",
      "        5.2910, 5.2911, 5.2910, 5.2909, 5.2910, 5.2911, 5.2908, 5.2908, 5.2909,\n",
      "        5.2911, 5.2909, 5.2910, 5.2910, 5.2910, 5.2909, 5.2909, 5.2910, 5.2910,\n",
      "        5.2905, 5.2908, 5.2908, 5.2907, 5.2906, 5.2905, 5.2904, 5.2905, 5.2905,\n",
      "        5.2908, 5.2905, 5.2907, 5.2909, 5.2907, 5.2905, 5.2910, 5.2907, 5.2908,\n",
      "        5.2907, 5.2904, 5.2907, 5.2905, 5.2905, 5.2906, 5.2905, 5.2908, 5.2906,\n",
      "        5.2909, 5.2909, 5.2907, 5.2910, 5.2907, 5.2908, 5.2908, 5.2907, 5.2908,\n",
      "        5.2907, 5.2910, 5.2910, 5.2909, 5.2909, 5.2912, 5.2912, 5.2908, 5.2908,\n",
      "        5.2909, 5.2911, 5.2909], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.802315  [1401324/5599865]\n",
      "average delta from current occupancy tensor([4.9356, 4.9356, 4.9355, 4.9354, 4.9357, 4.9357, 4.9356, 4.9356, 4.9357,\n",
      "        4.9356, 4.9356, 4.9355, 4.9356, 4.9356, 4.9357, 4.9357, 4.9356, 4.9356,\n",
      "        4.9358, 4.9355, 4.9357, 4.9355, 4.9354, 4.9355, 4.9354, 4.9354, 4.9356,\n",
      "        4.9355, 4.9358, 4.9359, 4.9359, 4.9357, 4.9359, 4.9358, 4.9357, 4.9358,\n",
      "        4.9357, 4.9358, 4.9360, 4.9359, 4.9359, 4.9358, 4.9358, 4.9356, 4.9358,\n",
      "        4.9359, 4.9357, 4.9356, 4.9357, 4.9356, 4.9357, 4.9357, 4.9356, 4.9357,\n",
      "        4.9358, 4.9360, 4.9359, 4.9355, 4.9358, 4.9359, 4.9357, 4.9356, 4.9356,\n",
      "        4.9356, 4.9355, 4.9356, 4.9357, 4.9357, 4.9357, 4.9359, 4.9357, 4.9358,\n",
      "        4.9358, 4.9359, 4.9357, 4.9357, 4.9356, 4.9358, 4.9357, 4.9354, 4.9355,\n",
      "        4.9354, 4.9353, 4.9359, 4.9358, 4.9359, 4.9357, 4.9358, 4.9357, 4.9355,\n",
      "        4.9353, 4.9352, 4.9355, 4.9353, 4.9353, 4.9356, 4.9354, 4.9354, 4.9356,\n",
      "        4.9352, 4.9357, 4.9356, 4.9356, 4.9357, 4.9355, 4.9357, 4.9355, 4.9355,\n",
      "        4.9356, 4.9356, 4.9355, 4.9356, 4.9355, 4.9352, 4.9355, 4.9356, 4.9356,\n",
      "        4.9357, 4.9358, 4.9355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.678905  [1413724/5599865]\n",
      "average delta from current occupancy tensor([4.6856, 4.6857, 4.6857, 4.6857, 4.6856, 4.6857, 4.6861, 4.6861, 4.6862,\n",
      "        4.6860, 4.6858, 4.6858, 4.6860, 4.6858, 4.6859, 4.6858, 4.6858, 4.6856,\n",
      "        4.6858, 4.6856, 4.6859, 4.6855, 4.6857, 4.6857, 4.6860, 4.6856, 4.6858,\n",
      "        4.6855, 4.6857, 4.6856, 4.6857, 4.6858, 4.6858, 4.6855, 4.6857, 4.6855,\n",
      "        4.6855, 4.6855, 4.6855, 4.6857, 4.6858, 4.6856, 4.6856, 4.6858, 4.6856,\n",
      "        4.6856, 4.6856, 4.6857, 4.6859, 4.6861, 4.6861, 4.6861, 4.6862, 4.6863,\n",
      "        4.6858, 4.6861, 4.6858, 4.6857, 4.6861, 4.6863, 4.6859, 4.6862, 4.6857,\n",
      "        4.6864, 4.6859, 4.6856, 4.6860, 4.6861, 4.6859, 4.6862, 4.6859, 4.6864,\n",
      "        4.6863, 4.6861, 4.6862, 4.6857, 4.6856, 4.6860, 4.6857, 4.6855, 4.6855,\n",
      "        4.6855, 4.6857, 4.6857, 4.6857, 4.6858, 4.6855, 4.6857, 4.6856, 4.6855,\n",
      "        4.6856, 4.6855, 4.6856, 4.6855, 4.6856, 4.6856, 4.6856, 4.6857, 4.6856,\n",
      "        4.6855, 4.6856, 4.6855, 4.6856, 4.6857, 4.6856, 4.6855, 4.6856, 4.6856,\n",
      "        4.6855, 4.6855, 4.6856, 4.6856, 4.6855, 4.6856, 4.6855, 4.6856, 4.6855,\n",
      "        4.6855, 4.6855, 4.6856], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.405972  [1426124/5599865]\n",
      "average delta from current occupancy tensor([5.4116, 5.4119, 5.4117, 5.4116, 5.4118, 5.4117, 5.4118, 5.4118, 5.4118,\n",
      "        5.4117, 5.4116, 5.4116, 5.4116, 5.4117, 5.4117, 5.4118, 5.4117, 5.4118,\n",
      "        5.4117, 5.4117, 5.4118, 5.4118, 5.4116, 5.4118, 5.4118, 5.4118, 5.4118,\n",
      "        5.4118, 5.4117, 5.4117, 5.4117, 5.4117, 5.4118, 5.4117, 5.4117, 5.4118,\n",
      "        5.4117, 5.4115, 5.4116, 5.4117, 5.4118, 5.4117, 5.4117, 5.4118, 5.4118,\n",
      "        5.4116, 5.4116, 5.4117, 5.4115, 5.4115, 5.4117, 5.4116, 5.4116, 5.4115,\n",
      "        5.4115, 5.4114, 5.4115, 5.4116, 5.4116, 5.4116, 5.4116, 5.4115, 5.4116,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4116, 5.4116, 5.4116, 5.4116,\n",
      "        5.4115, 5.4115, 5.4115, 5.4116, 5.4116, 5.4116, 5.4116, 5.4116, 5.4115,\n",
      "        5.4115, 5.4115, 5.4116, 5.4116, 5.4116, 5.4116, 5.4116, 5.4116, 5.4116,\n",
      "        5.4115, 5.4114, 5.4114, 5.4115, 5.4114, 5.4114, 5.4114, 5.4115, 5.4114,\n",
      "        5.4115, 5.4114, 5.4115, 5.4115, 5.4114, 5.4114, 5.4115, 5.4114, 5.4114,\n",
      "        5.4114, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4116, 5.4114, 5.4114,\n",
      "        5.4115, 5.4116, 5.4115], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.477098  [1438524/5599865]\n",
      "average delta from current occupancy tensor([4.4259, 4.4261, 4.4262, 4.4259, 4.4263, 4.4259, 4.4263, 4.4261, 4.4262,\n",
      "        4.4261, 4.4260, 4.4260, 4.4263, 4.4264, 4.4263, 4.4263, 4.4264, 4.4264,\n",
      "        4.4264, 4.4267, 4.4267, 4.4267, 4.4265, 4.4268, 4.4269, 4.4268, 4.4269,\n",
      "        4.4271, 4.4270, 4.4268, 4.4269, 4.4269, 4.4269, 4.4269, 4.4268, 4.4272,\n",
      "        4.4266, 4.4265, 4.4266, 4.4267, 4.4270, 4.4267, 4.4270, 4.4269, 4.4270,\n",
      "        4.4269, 4.4270, 4.4270, 4.4268, 4.4269, 4.4271, 4.4266, 4.4267, 4.4267,\n",
      "        4.4267, 4.4268, 4.4267, 4.4267, 4.4266, 4.4267, 4.4267, 4.4265, 4.4265,\n",
      "        4.4267, 4.4266, 4.4267, 4.4268, 4.4268, 4.4267, 4.4267, 4.4267, 4.4266,\n",
      "        4.4267, 4.4267, 4.4267, 4.4268, 4.4266, 4.4266, 4.4267, 4.4266, 4.4266,\n",
      "        4.4265, 4.4265, 4.4267, 4.4266, 4.4267, 4.4267, 4.4266, 4.4267, 4.4266,\n",
      "        4.4268, 4.4268, 4.4270, 4.4268, 4.4268, 4.4268, 4.4268, 4.4268, 4.4268,\n",
      "        4.4267, 4.4268, 4.4268, 4.4268, 4.4268, 4.4267, 4.4268, 4.4268, 4.4267,\n",
      "        4.4267, 4.4266, 4.4267, 4.4266, 4.4266, 4.4267, 4.4267, 4.4267, 4.4267,\n",
      "        4.4267, 4.4267, 4.4268], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.063267  [1450924/5599865]\n",
      "average delta from current occupancy tensor([5.0400, 5.0401, 5.0403, 5.0400, 5.0402, 5.0399, 5.0401, 5.0401, 5.0401,\n",
      "        5.0399, 5.0399, 5.0399, 5.0401, 5.0400, 5.0399, 5.0399, 5.0401, 5.0400,\n",
      "        5.0400, 5.0401, 5.0401, 5.0402, 5.0401, 5.0404, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0401, 5.0403, 5.0402, 5.0403, 5.0404, 5.0402, 5.0403,\n",
      "        5.0402, 5.0401, 5.0401, 5.0402, 5.0403, 5.0404, 5.0403, 5.0403, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0404, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0402, 5.0403, 5.0403, 5.0403, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0402, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0403,\n",
      "        5.0403, 5.0403, 5.0403, 5.0403, 5.0403, 5.0404, 5.0404, 5.0403, 5.0403,\n",
      "        5.0403, 5.0403, 5.0402, 5.0402, 5.0403, 5.0403, 5.0403, 5.0403, 5.0402,\n",
      "        5.0402, 5.0402, 5.0401], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.297307  [1463324/5599865]\n",
      "average delta from current occupancy tensor([5.5030, 5.5030, 5.5029, 5.5027, 5.5031, 5.5025, 5.5029, 5.5027, 5.5026,\n",
      "        5.5023, 5.5025, 5.5023, 5.5028, 5.5026, 5.5024, 5.5024, 5.5029, 5.5028,\n",
      "        5.5026, 5.5028, 5.5028, 5.5029, 5.5027, 5.5023, 5.5024, 5.5026, 5.5028,\n",
      "        5.5028, 5.5027, 5.5028, 5.5027, 5.5030, 5.5025, 5.5024, 5.5029, 5.5025,\n",
      "        5.5030, 5.5028, 5.5026, 5.5032, 5.5030, 5.5029, 5.5032, 5.5030, 5.5030,\n",
      "        5.5030, 5.5030, 5.5031, 5.5031, 5.5028, 5.5029, 5.5029, 5.5029, 5.5031,\n",
      "        5.5031, 5.5032, 5.5031, 5.5031, 5.5034, 5.5033, 5.5033, 5.5031, 5.5032,\n",
      "        5.5031, 5.5030, 5.5031, 5.5030, 5.5032, 5.5032, 5.5031, 5.5031, 5.5031,\n",
      "        5.5032, 5.5032, 5.5030, 5.5032, 5.5034, 5.5033, 5.5032, 5.5032, 5.5031,\n",
      "        5.5030, 5.5026, 5.5031, 5.5030, 5.5030, 5.5029, 5.5026, 5.5026, 5.5027,\n",
      "        5.5026, 5.5025, 5.5029, 5.5027, 5.5025, 5.5022, 5.5026, 5.5023, 5.5025,\n",
      "        5.5026, 5.5024, 5.5022, 5.5022, 5.5023, 5.5019, 5.5021, 5.5021, 5.5022,\n",
      "        5.5023, 5.5025, 5.5024, 5.5025, 5.5021, 5.5025, 5.5022, 5.5026, 5.5024,\n",
      "        5.5025, 5.5024, 5.5025], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.043729  [1475724/5599865]\n",
      "average delta from current occupancy tensor([5.1130, 5.1130, 5.1130, 5.1131, 5.1130, 5.1131, 5.1130, 5.1131, 5.1131,\n",
      "        5.1131, 5.1131, 5.1131, 5.1130, 5.1131, 5.1131, 5.1131, 5.1130, 5.1131,\n",
      "        5.1131, 5.1131, 5.1132, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1131,\n",
      "        5.1131, 5.1131, 5.1131, 5.1131, 5.1130, 5.1131, 5.1130, 5.1131, 5.1131,\n",
      "        5.1130, 5.1131, 5.1130, 5.1131, 5.1131, 5.1131, 5.1131, 5.1131, 5.1130,\n",
      "        5.1131, 5.1130, 5.1131, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1131,\n",
      "        5.1131, 5.1131, 5.1132, 5.1131, 5.1131, 5.1131, 5.1132, 5.1131, 5.1131,\n",
      "        5.1131, 5.1130, 5.1131, 5.1131, 5.1131, 5.1132, 5.1130, 5.1131, 5.1131,\n",
      "        5.1130, 5.1131, 5.1131, 5.1131, 5.1131, 5.1131, 5.1131, 5.1131, 5.1131,\n",
      "        5.1131, 5.1131, 5.1130, 5.1130, 5.1131, 5.1130, 5.1130, 5.1130, 5.1131,\n",
      "        5.1131, 5.1131, 5.1130, 5.1130, 5.1131, 5.1130, 5.1130, 5.1131, 5.1130,\n",
      "        5.1131, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130,\n",
      "        5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1130, 5.1131, 5.1131, 5.1130,\n",
      "        5.1130, 5.1130, 5.1131], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.858100  [1488124/5599865]\n",
      "average delta from current occupancy tensor([4.7904, 4.7904, 4.7906, 4.7907, 4.7904, 4.7906, 4.7907, 4.7905, 4.7907,\n",
      "        4.7906, 4.7903, 4.7904, 4.7907, 4.7907, 4.7905, 4.7905, 4.7906, 4.7904,\n",
      "        4.7906, 4.7906, 4.7904, 4.7905, 4.7905, 4.7905, 4.7905, 4.7903, 4.7907,\n",
      "        4.7907, 4.7907, 4.7907, 4.7909, 4.7903, 4.7907, 4.7908, 4.7909, 4.7908,\n",
      "        4.7906, 4.7909, 4.7906, 4.7908, 4.7906, 4.7906, 4.7908, 4.7908, 4.7903,\n",
      "        4.7903, 4.7903, 4.7903, 4.7904, 4.7904, 4.7903, 4.7903, 4.7906, 4.7907,\n",
      "        4.7907, 4.7907, 4.7907, 4.7905, 4.7904, 4.7905, 4.7906, 4.7905, 4.7907,\n",
      "        4.7906, 4.7907, 4.7905, 4.7907, 4.7904, 4.7904, 4.7905, 4.7907, 4.7906,\n",
      "        4.7905, 4.7906, 4.7906, 4.7905, 4.7907, 4.7907, 4.7907, 4.7908, 4.7908,\n",
      "        4.7906, 4.7906, 4.7905, 4.7907, 4.7907, 4.7907, 4.7907, 4.7906, 4.7907,\n",
      "        4.7906, 4.7905, 4.7905, 4.7904, 4.7906, 4.7906, 4.7904, 4.7904, 4.7905,\n",
      "        4.7906, 4.7904, 4.7906, 4.7904, 4.7904, 4.7906, 4.7905, 4.7908, 4.7905,\n",
      "        4.7906, 4.7905, 4.7904, 4.7905, 4.7904, 4.7905, 4.7905, 4.7905, 4.7905,\n",
      "        4.7907, 4.7905, 4.7905], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.959911  [1500524/5599865]\n",
      "average delta from current occupancy tensor([5.0646, 5.0645, 5.0645, 5.0646, 5.0645, 5.0646, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0646, 5.0647, 5.0645, 5.0646, 5.0646, 5.0645,\n",
      "        5.0645, 5.0646, 5.0647, 5.0646, 5.0646, 5.0645, 5.0645, 5.0646, 5.0646,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0645, 5.0645, 5.0646, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0646, 5.0646, 5.0645, 5.0645, 5.0646, 5.0645, 5.0646, 5.0646, 5.0646,\n",
      "        5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.712996  [1512924/5599865]\n",
      "average delta from current occupancy tensor([4.4428, 4.4428, 4.4430, 4.4427, 4.4430, 4.4430, 4.4428, 4.4428, 4.4428,\n",
      "        4.4432, 4.4430, 4.4434, 4.4430, 4.4433, 4.4432, 4.4433, 4.4433, 4.4430,\n",
      "        4.4434, 4.4430, 4.4434, 4.4433, 4.4429, 4.4431, 4.4431, 4.4434, 4.4433,\n",
      "        4.4431, 4.4433, 4.4432, 4.4431, 4.4433, 4.4434, 4.4432, 4.4434, 4.4433,\n",
      "        4.4433, 4.4433, 4.4433, 4.4433, 4.4430, 4.4433, 4.4431, 4.4431, 4.4433,\n",
      "        4.4433, 4.4434, 4.4433, 4.4434, 4.4433, 4.4434, 4.4433, 4.4433, 4.4434,\n",
      "        4.4433, 4.4430, 4.4434, 4.4434, 4.4432, 4.4434, 4.4430, 4.4432, 4.4434,\n",
      "        4.4428, 4.4430, 4.4430, 4.4433, 4.4433, 4.4431, 4.4434, 4.4434, 4.4434,\n",
      "        4.4433, 4.4434, 4.4433, 4.4432, 4.4433, 4.4433, 4.4432, 4.4434, 4.4434,\n",
      "        4.4434, 4.4433, 4.4434, 4.4434, 4.4434, 4.4433, 4.4434, 4.4433, 4.4433,\n",
      "        4.4433, 4.4434, 4.4434, 4.4433, 4.4434, 4.4434, 4.4434, 4.4433, 4.4434,\n",
      "        4.4434, 4.4433, 4.4433, 4.4433, 4.4432, 4.4434, 4.4433, 4.4433, 4.4432,\n",
      "        4.4432, 4.4432, 4.4432, 4.4432, 4.4431, 4.4433, 4.4434, 4.4434, 4.4434,\n",
      "        4.4434, 4.4434, 4.4432], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.799784  [1525324/5599865]\n",
      "average delta from current occupancy tensor([4.5810, 4.5809, 4.5810, 4.5808, 4.5809, 4.5811, 4.5811, 4.5810, 4.5811,\n",
      "        4.5811, 4.5811, 4.5811, 4.5810, 4.5811, 4.5811, 4.5811, 4.5811, 4.5812,\n",
      "        4.5811, 4.5811, 4.5812, 4.5813, 4.5811, 4.5811, 4.5812, 4.5812, 4.5812,\n",
      "        4.5813, 4.5812, 4.5812, 4.5811, 4.5812, 4.5812, 4.5810, 4.5810, 4.5811,\n",
      "        4.5810, 4.5811, 4.5811, 4.5811, 4.5812, 4.5813, 4.5812, 4.5812, 4.5812,\n",
      "        4.5812, 4.5811, 4.5812, 4.5811, 4.5811, 4.5812, 4.5811, 4.5811, 4.5811,\n",
      "        4.5811, 4.5810, 4.5811, 4.5810, 4.5811, 4.5811, 4.5811, 4.5811, 4.5811,\n",
      "        4.5810, 4.5810, 4.5810, 4.5811, 4.5810, 4.5811, 4.5811, 4.5810, 4.5810,\n",
      "        4.5810, 4.5810, 4.5809, 4.5810, 4.5810, 4.5810, 4.5810, 4.5810, 4.5810,\n",
      "        4.5809, 4.5810, 4.5810, 4.5810, 4.5809, 4.5810, 4.5810, 4.5810, 4.5810,\n",
      "        4.5811, 4.5811, 4.5811, 4.5810, 4.5811, 4.5810, 4.5811, 4.5811, 4.5811,\n",
      "        4.5811, 4.5810, 4.5810, 4.5811, 4.5810, 4.5810, 4.5810, 4.5810, 4.5810,\n",
      "        4.5810, 4.5810, 4.5810, 4.5811, 4.5810, 4.5811, 4.5811, 4.5811, 4.5811,\n",
      "        4.5812, 4.5810, 4.5810], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.986444  [1537724/5599865]\n",
      "average delta from current occupancy tensor([5.0558, 5.0558, 5.0558, 5.0558, 5.0559, 5.0559, 5.0558, 5.0558, 5.0559,\n",
      "        5.0558, 5.0558, 5.0558, 5.0557, 5.0558, 5.0557, 5.0557, 5.0558, 5.0556,\n",
      "        5.0557, 5.0556, 5.0556, 5.0556, 5.0556, 5.0555, 5.0556, 5.0556, 5.0556,\n",
      "        5.0557, 5.0555, 5.0558, 5.0558, 5.0557, 5.0556, 5.0558, 5.0558, 5.0557,\n",
      "        5.0558, 5.0557, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0557, 5.0558,\n",
      "        5.0558, 5.0556, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558,\n",
      "        5.0557, 5.0557, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558,\n",
      "        5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0557, 5.0558, 5.0558,\n",
      "        5.0558, 5.0558, 5.0558, 5.0558, 5.0558, 5.0557, 5.0558, 5.0558, 5.0558,\n",
      "        5.0558, 5.0558, 5.0558, 5.0559, 5.0559, 5.0558, 5.0558, 5.0558, 5.0558,\n",
      "        5.0558, 5.0557, 5.0557, 5.0557, 5.0557, 5.0557, 5.0557, 5.0557, 5.0556,\n",
      "        5.0556, 5.0556, 5.0556, 5.0553, 5.0556, 5.0556, 5.0556, 5.0555, 5.0556,\n",
      "        5.0556, 5.0555, 5.0556, 5.0553, 5.0555, 5.0553, 5.0554, 5.0554, 5.0556,\n",
      "        5.0554, 5.0556, 5.0556], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.487799  [1550124/5599865]\n",
      "average delta from current occupancy tensor([5.5662, 5.5660, 5.5660, 5.5661, 5.5658, 5.5659, 5.5659, 5.5660, 5.5660,\n",
      "        5.5660, 5.5661, 5.5661, 5.5662, 5.5662, 5.5661, 5.5661, 5.5660, 5.5663,\n",
      "        5.5661, 5.5663, 5.5663, 5.5665, 5.5663, 5.5664, 5.5663, 5.5665, 5.5665,\n",
      "        5.5664, 5.5664, 5.5662, 5.5663, 5.5664, 5.5665, 5.5662, 5.5663, 5.5664,\n",
      "        5.5663, 5.5662, 5.5661, 5.5663, 5.5663, 5.5663, 5.5663, 5.5665, 5.5664,\n",
      "        5.5664, 5.5668, 5.5666, 5.5665, 5.5665, 5.5666, 5.5664, 5.5663, 5.5664,\n",
      "        5.5664, 5.5664, 5.5665, 5.5665, 5.5666, 5.5668, 5.5667, 5.5667, 5.5666,\n",
      "        5.5666, 5.5666, 5.5665, 5.5666, 5.5667, 5.5668, 5.5669, 5.5669, 5.5668,\n",
      "        5.5669, 5.5667, 5.5667, 5.5665, 5.5665, 5.5667, 5.5668, 5.5667, 5.5668,\n",
      "        5.5667, 5.5668, 5.5668, 5.5666, 5.5665, 5.5665, 5.5665, 5.5666, 5.5666,\n",
      "        5.5665, 5.5666, 5.5667, 5.5666, 5.5667, 5.5666, 5.5666, 5.5666, 5.5666,\n",
      "        5.5667, 5.5669, 5.5670, 5.5671, 5.5670, 5.5668, 5.5671, 5.5671, 5.5672,\n",
      "        5.5671, 5.5673, 5.5672, 5.5675, 5.5674, 5.5676, 5.5675, 5.5674, 5.5673,\n",
      "        5.5676, 5.5675, 5.5674], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.776619  [1562524/5599865]\n",
      "average delta from current occupancy tensor([5.6616, 5.6617, 5.6617, 5.6617, 5.6617, 5.6617, 5.6617, 5.6617, 5.6617,\n",
      "        5.6616, 5.6616, 5.6616, 5.6616, 5.6616, 5.6616, 5.6615, 5.6616, 5.6615,\n",
      "        5.6615, 5.6616, 5.6616, 5.6616, 5.6616, 5.6615, 5.6616, 5.6615, 5.6615,\n",
      "        5.6615, 5.6615, 5.6615, 5.6615, 5.6616, 5.6615, 5.6615, 5.6614, 5.6615,\n",
      "        5.6615, 5.6615, 5.6616, 5.6615, 5.6616, 5.6615, 5.6615, 5.6614, 5.6615,\n",
      "        5.6615, 5.6613, 5.6614, 5.6615, 5.6615, 5.6615, 5.6614, 5.6615, 5.6615,\n",
      "        5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614,\n",
      "        5.6615, 5.6615, 5.6616, 5.6614, 5.6614, 5.6614, 5.6613, 5.6614, 5.6613,\n",
      "        5.6613, 5.6614, 5.6614, 5.6613, 5.6613, 5.6614, 5.6613, 5.6613, 5.6613,\n",
      "        5.6613, 5.6614, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613, 5.6613,\n",
      "        5.6613, 5.6613, 5.6614, 5.6613, 5.6614, 5.6613, 5.6613, 5.6613, 5.6614,\n",
      "        5.6614, 5.6613, 5.6613, 5.6615, 5.6614, 5.6613, 5.6615, 5.6614, 5.6615,\n",
      "        5.6614, 5.6615, 5.6614, 5.6615, 5.6615, 5.6616, 5.6616, 5.6615, 5.6614,\n",
      "        5.6616, 5.6616, 5.6616], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.378942  [1574924/5599865]\n",
      "average delta from current occupancy tensor([5.2119, 5.2120, 5.2120, 5.2121, 5.2124, 5.2123, 5.2121, 5.2120, 5.2121,\n",
      "        5.2119, 5.2118, 5.2117, 5.2118, 5.2118, 5.2116, 5.2115, 5.2115, 5.2113,\n",
      "        5.2113, 5.2117, 5.2117, 5.2118, 5.2118, 5.2116, 5.2117, 5.2116, 5.2112,\n",
      "        5.2111, 5.2113, 5.2113, 5.2114, 5.2115, 5.2113, 5.2112, 5.2110, 5.2109,\n",
      "        5.2111, 5.2110, 5.2110, 5.2110, 5.2111, 5.2112, 5.2110, 5.2110, 5.2111,\n",
      "        5.2109, 5.2117, 5.2110, 5.2111, 5.2110, 5.2111, 5.2110, 5.2112, 5.2112,\n",
      "        5.2112, 5.2111, 5.2112, 5.2114, 5.2113, 5.2115, 5.2113, 5.2115, 5.2112,\n",
      "        5.2110, 5.2113, 5.2115, 5.2112, 5.2115, 5.2117, 5.2120, 5.2122, 5.2121,\n",
      "        5.2124, 5.2123, 5.2123, 5.2121, 5.2123, 5.2124, 5.2121, 5.2122, 5.2122,\n",
      "        5.2119, 5.2119, 5.2119, 5.2120, 5.2118, 5.2118, 5.2118, 5.2118, 5.2117,\n",
      "        5.2116, 5.2116, 5.2117, 5.2115, 5.2117, 5.2114, 5.2111, 5.2112, 5.2113,\n",
      "        5.2113, 5.2112, 5.2110, 5.2110, 5.2112, 5.2111, 5.2110, 5.2107, 5.2109,\n",
      "        5.2110, 5.2109, 5.2109, 5.2106, 5.2105, 5.2109, 5.2106, 5.2109, 5.2109,\n",
      "        5.2109, 5.2108, 5.2106], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.386666  [1587324/5599865]\n",
      "average delta from current occupancy tensor([5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3146, 5.3146, 5.3145,\n",
      "        5.3146, 5.3146, 5.3146, 5.3146, 5.3145, 5.3146, 5.3146, 5.3146, 5.3146,\n",
      "        5.3146, 5.3146, 5.3146, 5.3146, 5.3146, 5.3145, 5.3145, 5.3146, 5.3146,\n",
      "        5.3146, 5.3146, 5.3145, 5.3146, 5.3146, 5.3146, 5.3146, 5.3146, 5.3145,\n",
      "        5.3145, 5.3145, 5.3146, 5.3146, 5.3146, 5.3146, 5.3145, 5.3146, 5.3146,\n",
      "        5.3146, 5.3145, 5.3146, 5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3146, 5.3145,\n",
      "        5.3146, 5.3145, 5.3146, 5.3145, 5.3146, 5.3145, 5.3145, 5.3146, 5.3145,\n",
      "        5.3146, 5.3145, 5.3145, 5.3146, 5.3146, 5.3146, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3146, 5.3146, 5.3146, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3146, 5.3146, 5.3147, 5.3147, 5.3147, 5.3146,\n",
      "        5.3147, 5.3146, 5.3146, 5.3146, 5.3146, 5.3146, 5.3146, 5.3145, 5.3146,\n",
      "        5.3145, 5.3145, 5.3145, 5.3146, 5.3146, 5.3146, 5.3146, 5.3146, 5.3146,\n",
      "        5.3145, 5.3146, 5.3146], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.544951  [1599724/5599865]\n",
      "average delta from current occupancy tensor([5.8064, 5.8064, 5.8065, 5.8065, 5.8064, 5.8064, 5.8064, 5.8064, 5.8065,\n",
      "        5.8065, 5.8064, 5.8064, 5.8064, 5.8065, 5.8064, 5.8064, 5.8065, 5.8064,\n",
      "        5.8065, 5.8064, 5.8064, 5.8065, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064,\n",
      "        5.8065, 5.8065, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8065, 5.8064,\n",
      "        5.8064, 5.8064, 5.8065, 5.8064, 5.8065, 5.8065, 5.8064, 5.8064, 5.8064,\n",
      "        5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064,\n",
      "        5.8064, 5.8065, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8065, 5.8064,\n",
      "        5.8065, 5.8064, 5.8064, 5.8065, 5.8064, 5.8065, 5.8064, 5.8064, 5.8064,\n",
      "        5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064,\n",
      "        5.8064, 5.8064, 5.8064, 5.8064, 5.8065, 5.8064, 5.8065, 5.8064, 5.8064,\n",
      "        5.8065, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064, 5.8065,\n",
      "        5.8064, 5.8064, 5.8065, 5.8065, 5.8064, 5.8064, 5.8064, 5.8064, 5.8064,\n",
      "        5.8064, 5.8064, 5.8064, 5.8064, 5.8065, 5.8065, 5.8064, 5.8064, 5.8064,\n",
      "        5.8064, 5.8064, 5.8064], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.538748  [1612124/5599865]\n",
      "average delta from current occupancy tensor([4.5487, 4.5488, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5488, 4.5487, 4.5487,\n",
      "        4.5486, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5488, 4.5488, 4.5487, 4.5488, 4.5488, 4.5487, 4.5488, 4.5487,\n",
      "        4.5488, 4.5488, 4.5488, 4.5488, 4.5488, 4.5488, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487, 4.5487, 4.5488, 4.5488, 4.5488, 4.5487, 4.5487,\n",
      "        4.5488, 4.5488, 4.5488, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5488, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5486, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487, 4.5487,\n",
      "        4.5487, 4.5487, 4.5487], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.042793  [1624524/5599865]\n",
      "average delta from current occupancy tensor([4.9762, 4.9762, 4.9766, 4.9763, 4.9766, 4.9764, 4.9762, 4.9767, 4.9764,\n",
      "        4.9768, 4.9765, 4.9766, 4.9767, 4.9764, 4.9766, 4.9763, 4.9766, 4.9766,\n",
      "        4.9770, 4.9765, 4.9767, 4.9770, 4.9763, 4.9767, 4.9766, 4.9767, 4.9765,\n",
      "        4.9765, 4.9761, 4.9768, 4.9760, 4.9762, 4.9765, 4.9767, 4.9763, 4.9765,\n",
      "        4.9762, 4.9761, 4.9760, 4.9764, 4.9765, 4.9764, 4.9766, 4.9766, 4.9762,\n",
      "        4.9765, 4.9766, 4.9764, 4.9767, 4.9765, 4.9763, 4.9763, 4.9761, 4.9765,\n",
      "        4.9766, 4.9760, 4.9761, 4.9763, 4.9761, 4.9762, 4.9766, 4.9764, 4.9762,\n",
      "        4.9766, 4.9766, 4.9766, 4.9765, 4.9767, 4.9766, 4.9767, 4.9769, 4.9769,\n",
      "        4.9768, 4.9768, 4.9769, 4.9770, 4.9768, 4.9769, 4.9769, 4.9769, 4.9770,\n",
      "        4.9768, 4.9770, 4.9770, 4.9769, 4.9769, 4.9768, 4.9768, 4.9767, 4.9769,\n",
      "        4.9767, 4.9770, 4.9772, 4.9770, 4.9771, 4.9770, 4.9769, 4.9771, 4.9770,\n",
      "        4.9769, 4.9767, 4.9768, 4.9766, 4.9766, 4.9769, 4.9769, 4.9771, 4.9769,\n",
      "        4.9770, 4.9770, 4.9770, 4.9771, 4.9771, 4.9770, 4.9770, 4.9768, 4.9770,\n",
      "        4.9770, 4.9768, 4.9769], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.251729  [1636924/5599865]\n",
      "average delta from current occupancy tensor([5.2083, 5.2084, 5.2080, 5.2082, 5.2075, 5.2084, 5.2084, 5.2077, 5.2085,\n",
      "        5.2074, 5.2079, 5.2079, 5.2080, 5.2087, 5.2084, 5.2087, 5.2080, 5.2077,\n",
      "        5.2077, 5.2082, 5.2081, 5.2080, 5.2087, 5.2082, 5.2080, 5.2079, 5.2082,\n",
      "        5.2078, 5.2079, 5.2076, 5.2082, 5.2079, 5.2080, 5.2081, 5.2083, 5.2083,\n",
      "        5.2084, 5.2084, 5.2086, 5.2085, 5.2083, 5.2082, 5.2085, 5.2087, 5.2086,\n",
      "        5.2085, 5.2084, 5.2087, 5.2083, 5.2086, 5.2085, 5.2083, 5.2082, 5.2083,\n",
      "        5.2083, 5.2084, 5.2085, 5.2086, 5.2086, 5.2083, 5.2081, 5.2084, 5.2084,\n",
      "        5.2082, 5.2084, 5.2081, 5.2079, 5.2078, 5.2077, 5.2075, 5.2074, 5.2073,\n",
      "        5.2073, 5.2069, 5.2072, 5.2070, 5.2074, 5.2073, 5.2072, 5.2073, 5.2073,\n",
      "        5.2074, 5.2074, 5.2072, 5.2075, 5.2075, 5.2077, 5.2077, 5.2081, 5.2079,\n",
      "        5.2081, 5.2074, 5.2075, 5.2076, 5.2077, 5.2080, 5.2078, 5.2077, 5.2079,\n",
      "        5.2085, 5.2080, 5.2080, 5.2082, 5.2082, 5.2077, 5.2077, 5.2079, 5.2077,\n",
      "        5.2078, 5.2075, 5.2075, 5.2077, 5.2076, 5.2079, 5.2077, 5.2079, 5.2080,\n",
      "        5.2080, 5.2082, 5.2081], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.499110  [1649324/5599865]\n",
      "average delta from current occupancy tensor([4.4677, 4.4676, 4.4675, 4.4675, 4.4674, 4.4677, 4.4677, 4.4674, 4.4676,\n",
      "        4.4676, 4.4676, 4.4675, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674,\n",
      "        4.4673, 4.4674, 4.4674, 4.4674, 4.4674, 4.4675, 4.4674, 4.4674, 4.4674,\n",
      "        4.4674, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674, 4.4675, 4.4675, 4.4673,\n",
      "        4.4674, 4.4674, 4.4673, 4.4673, 4.4673, 4.4673, 4.4674, 4.4674, 4.4673,\n",
      "        4.4675, 4.4674, 4.4674, 4.4675, 4.4674, 4.4675, 4.4675, 4.4675, 4.4674,\n",
      "        4.4676, 4.4675, 4.4675, 4.4676, 4.4675, 4.4676, 4.4677, 4.4676, 4.4674,\n",
      "        4.4675, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674, 4.4674,\n",
      "        4.4674, 4.4675, 4.4674, 4.4674, 4.4675, 4.4675, 4.4675, 4.4675, 4.4675,\n",
      "        4.4675, 4.4675, 4.4675, 4.4674, 4.4675, 4.4675, 4.4675, 4.4673, 4.4672,\n",
      "        4.4672, 4.4673, 4.4673, 4.4673, 4.4673, 4.4674, 4.4674, 4.4674, 4.4673,\n",
      "        4.4673, 4.4672, 4.4672, 4.4673, 4.4673, 4.4673, 4.4674, 4.4674, 4.4675,\n",
      "        4.4676, 4.4673, 4.4673, 4.4675, 4.4675, 4.4676, 4.4675, 4.4675, 4.4675,\n",
      "        4.4674, 4.4675, 4.4675], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.378416  [1661724/5599865]\n",
      "average delta from current occupancy tensor([5.4600, 5.4600, 5.4600, 5.4601, 5.4600, 5.4601, 5.4600, 5.4600, 5.4599,\n",
      "        5.4600, 5.4600, 5.4600, 5.4599, 5.4600, 5.4599, 5.4600, 5.4600, 5.4599,\n",
      "        5.4599, 5.4600, 5.4599, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4601, 5.4600, 5.4601, 5.4600, 5.4600, 5.4599, 5.4599, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600, 5.4601, 5.4601, 5.4600,\n",
      "        5.4601, 5.4601, 5.4601, 5.4601, 5.4600, 5.4601, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4600, 5.4600, 5.4601, 5.4602, 5.4602, 5.4600, 5.4604, 5.4600,\n",
      "        5.4603, 5.4600, 5.4600, 5.4602, 5.4600, 5.4601, 5.4601, 5.4601, 5.4600,\n",
      "        5.4599, 5.4599, 5.4600, 5.4598, 5.4600, 5.4600, 5.4600, 5.4600, 5.4600,\n",
      "        5.4600, 5.4599, 5.4600, 5.4600, 5.4599, 5.4600, 5.4601, 5.4601, 5.4601,\n",
      "        5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4602, 5.4601, 5.4602,\n",
      "        5.4601, 5.4602, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601, 5.4601,\n",
      "        5.4601, 5.4601, 5.4601, 5.4602, 5.4602, 5.4603, 5.4603, 5.4603, 5.4602,\n",
      "        5.4602, 5.4602, 5.4603], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.111182  [1674124/5599865]\n",
      "average delta from current occupancy tensor([5.0437, 5.0436, 5.0436, 5.0435, 5.0435, 5.0434, 5.0437, 5.0436, 5.0436,\n",
      "        5.0438, 5.0439, 5.0437, 5.0437, 5.0437, 5.0439, 5.0440, 5.0440, 5.0439,\n",
      "        5.0440, 5.0442, 5.0441, 5.0440, 5.0441, 5.0441, 5.0438, 5.0438, 5.0437,\n",
      "        5.0439, 5.0436, 5.0437, 5.0436, 5.0439, 5.0437, 5.0436, 5.0437, 5.0439,\n",
      "        5.0439, 5.0440, 5.0440, 5.0440, 5.0439, 5.0440, 5.0442, 5.0443, 5.0442,\n",
      "        5.0442, 5.0439, 5.0443, 5.0441, 5.0440, 5.0439, 5.0443, 5.0443, 5.0443,\n",
      "        5.0444, 5.0441, 5.0446, 5.0444, 5.0444, 5.0443, 5.0441, 5.0440, 5.0443,\n",
      "        5.0442, 5.0440, 5.0442, 5.0441, 5.0439, 5.0439, 5.0438, 5.0438, 5.0438,\n",
      "        5.0438, 5.0439, 5.0439, 5.0438, 5.0439, 5.0439, 5.0438, 5.0439, 5.0439,\n",
      "        5.0440, 5.0439, 5.0440, 5.0439, 5.0439, 5.0439, 5.0438, 5.0438, 5.0439,\n",
      "        5.0439, 5.0441, 5.0439, 5.0441, 5.0440, 5.0438, 5.0440, 5.0440, 5.0440,\n",
      "        5.0444, 5.0442, 5.0444, 5.0442, 5.0445, 5.0444, 5.0444, 5.0442, 5.0443,\n",
      "        5.0443, 5.0443, 5.0444, 5.0443, 5.0443, 5.0443, 5.0442, 5.0440, 5.0443,\n",
      "        5.0440, 5.0443, 5.0442], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.617759  [1686524/5599865]\n",
      "average delta from current occupancy tensor([4.5561, 4.5560, 4.5561, 4.5561, 4.5561, 4.5560, 4.5561, 4.5559, 4.5559,\n",
      "        4.5559, 4.5559, 4.5559, 4.5558, 4.5559, 4.5558, 4.5558, 4.5558, 4.5558,\n",
      "        4.5558, 4.5559, 4.5559, 4.5558, 4.5558, 4.5559, 4.5558, 4.5558, 4.5559,\n",
      "        4.5559, 4.5560, 4.5560, 4.5559, 4.5559, 4.5559, 4.5561, 4.5561, 4.5560,\n",
      "        4.5560, 4.5559, 4.5559, 4.5559, 4.5561, 4.5559, 4.5559, 4.5559, 4.5559,\n",
      "        4.5559, 4.5560, 4.5559, 4.5559, 4.5560, 4.5560, 4.5559, 4.5559, 4.5559,\n",
      "        4.5559, 4.5559, 4.5559, 4.5559, 4.5559, 4.5560, 4.5561, 4.5560, 4.5559,\n",
      "        4.5559, 4.5559, 4.5559, 4.5559, 4.5558, 4.5558, 4.5560, 4.5559, 4.5559,\n",
      "        4.5559, 4.5559, 4.5560, 4.5560, 4.5559, 4.5560, 4.5560, 4.5559, 4.5559,\n",
      "        4.5559, 4.5559, 4.5559, 4.5559, 4.5560, 4.5560, 4.5560, 4.5560, 4.5559,\n",
      "        4.5561, 4.5560, 4.5560, 4.5560, 4.5560, 4.5560, 4.5559, 4.5559, 4.5560,\n",
      "        4.5559, 4.5559, 4.5559, 4.5559, 4.5559, 4.5559, 4.5559, 4.5559, 4.5559,\n",
      "        4.5559, 4.5559, 4.5559, 4.5560, 4.5560, 4.5560, 4.5561, 4.5561, 4.5560,\n",
      "        4.5561, 4.5561, 4.5561], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.753796  [1698924/5599865]\n",
      "average delta from current occupancy tensor([4.8709, 4.8709, 4.8709, 4.8709, 4.8708, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8710, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8710, 4.8710, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8710, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8710, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8710, 4.8710, 4.8709, 4.8709, 4.8710, 4.8709, 4.8709,\n",
      "        4.8710, 4.8710, 4.8710, 4.8709, 4.8710, 4.8709, 4.8709, 4.8709, 4.8710,\n",
      "        4.8709, 4.8709, 4.8710, 4.8710, 4.8710, 4.8709, 4.8710, 4.8709, 4.8710,\n",
      "        4.8710, 4.8710, 4.8710, 4.8709, 4.8710, 4.8710, 4.8710, 4.8710, 4.8710,\n",
      "        4.8710, 4.8710, 4.8709, 4.8710, 4.8709, 4.8710, 4.8710, 4.8710, 4.8710,\n",
      "        4.8709, 4.8710, 4.8709, 4.8710, 4.8709, 4.8709, 4.8710, 4.8709, 4.8710,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8710, 4.8709, 4.8710, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8710, 4.8710, 4.8709, 4.8709, 4.8710,\n",
      "        4.8709, 4.8709, 4.8709], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.132305  [1711324/5599865]\n",
      "average delta from current occupancy tensor([5.1611, 5.1612, 5.1611, 5.1612, 5.1612, 5.1611, 5.1612, 5.1612, 5.1612,\n",
      "        5.1611, 5.1612, 5.1612, 5.1612, 5.1613, 5.1613, 5.1613, 5.1613, 5.1612,\n",
      "        5.1612, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1614, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1612,\n",
      "        5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1611, 5.1612,\n",
      "        5.1612, 5.1612, 5.1612, 5.1611, 5.1611, 5.1612, 5.1611, 5.1611, 5.1611,\n",
      "        5.1611, 5.1611, 5.1611, 5.1611, 5.1610, 5.1610, 5.1611, 5.1611, 5.1612,\n",
      "        5.1611, 5.1611, 5.1611, 5.1612, 5.1612, 5.1611, 5.1611, 5.1611, 5.1611,\n",
      "        5.1611, 5.1612, 5.1612, 5.1611, 5.1611, 5.1611, 5.1612, 5.1612, 5.1612,\n",
      "        5.1611, 5.1612, 5.1612, 5.1612, 5.1612, 5.1611, 5.1611, 5.1611, 5.1612,\n",
      "        5.1613, 5.1612, 5.1612, 5.1611, 5.1612, 5.1611, 5.1612, 5.1611, 5.1611,\n",
      "        5.1612, 5.1611, 5.1611, 5.1610, 5.1611, 5.1611, 5.1612, 5.1611, 5.1611,\n",
      "        5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1612, 5.1614, 5.1614, 5.1612,\n",
      "        5.1614, 5.1613, 5.1613], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.256776  [1723724/5599865]\n",
      "average delta from current occupancy tensor([5.1855, 5.1860, 5.1858, 5.1858, 5.1859, 5.1855, 5.1855, 5.1856, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1856, 5.1858, 5.1855, 5.1856, 5.1857, 5.1856,\n",
      "        5.1857, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1854, 5.1855, 5.1856,\n",
      "        5.1855, 5.1854, 5.1855, 5.1854, 5.1855, 5.1857, 5.1856, 5.1855, 5.1856,\n",
      "        5.1855, 5.1860, 5.1858, 5.1857, 5.1859, 5.1857, 5.1855, 5.1856, 5.1857,\n",
      "        5.1855, 5.1856, 5.1856, 5.1857, 5.1856, 5.1856, 5.1856, 5.1856, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1854, 5.1855,\n",
      "        5.1854, 5.1854, 5.1855, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1855,\n",
      "        5.1855, 5.1855, 5.1856, 5.1855, 5.1855, 5.1858, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1856, 5.1855, 5.1855, 5.1855, 5.1856, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1856, 5.1856, 5.1857, 5.1855, 5.1855,\n",
      "        5.1855, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1855, 5.1855, 5.1854,\n",
      "        5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854,\n",
      "        5.1854, 5.1854, 5.1854], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.068820  [1736124/5599865]\n",
      "average delta from current occupancy tensor([5.0803, 5.0802, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0802, 5.0803,\n",
      "        5.0803, 5.0802, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803,\n",
      "        5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803,\n",
      "        5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803,\n",
      "        5.0803, 5.0803, 5.0803, 5.0804, 5.0804, 5.0804, 5.0804, 5.0803, 5.0804,\n",
      "        5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0804,\n",
      "        5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803,\n",
      "        5.0803, 5.0803, 5.0803, 5.0803, 5.0804, 5.0804, 5.0804, 5.0804, 5.0803,\n",
      "        5.0803, 5.0803, 5.0804, 5.0804, 5.0804, 5.0804, 5.0803, 5.0804, 5.0803,\n",
      "        5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0803, 5.0804, 5.0804,\n",
      "        5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0803, 5.0804,\n",
      "        5.0803, 5.0804, 5.0805, 5.0804, 5.0805, 5.0804, 5.0803, 5.0804, 5.0803,\n",
      "        5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0804, 5.0804,\n",
      "        5.0804, 5.0805, 5.0805], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.214312  [1748524/5599865]\n",
      "average delta from current occupancy tensor([5.6455, 5.6455, 5.6455, 5.6456, 5.6455, 5.6455, 5.6455, 5.6454, 5.6455,\n",
      "        5.6454, 5.6454, 5.6455, 5.6454, 5.6454, 5.6455, 5.6455, 5.6454, 5.6455,\n",
      "        5.6454, 5.6455, 5.6455, 5.6454, 5.6454, 5.6454, 5.6455, 5.6455, 5.6455,\n",
      "        5.6455, 5.6455, 5.6454, 5.6455, 5.6455, 5.6455, 5.6455, 5.6455, 5.6455,\n",
      "        5.6455, 5.6455, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454,\n",
      "        5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6454,\n",
      "        5.6453, 5.6454, 5.6455, 5.6455, 5.6455, 5.6455, 5.6455, 5.6454, 5.6455,\n",
      "        5.6455, 5.6455, 5.6454, 5.6454, 5.6455, 5.6454, 5.6454, 5.6454, 5.6454,\n",
      "        5.6453, 5.6454, 5.6455, 5.6454, 5.6454, 5.6455, 5.6454, 5.6454, 5.6454,\n",
      "        5.6454, 5.6454, 5.6453, 5.6454, 5.6454, 5.6454, 5.6454, 5.6453, 5.6453,\n",
      "        5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6453, 5.6453, 5.6454, 5.6454,\n",
      "        5.6454, 5.6454, 5.6454, 5.6454, 5.6454, 5.6455, 5.6455, 5.6455, 5.6455,\n",
      "        5.6455, 5.6455, 5.6455, 5.6455, 5.6455, 5.6455, 5.6455, 5.6454, 5.6455,\n",
      "        5.6455, 5.6455, 5.6455], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.030508  [1760924/5599865]\n",
      "average delta from current occupancy tensor([5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9755, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756, 5.9756,\n",
      "        5.9756, 5.9756, 5.9756], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.064657  [1773324/5599865]\n",
      "average delta from current occupancy tensor([5.0489, 5.0489, 5.0488, 5.0489, 5.0488, 5.0488, 5.0488, 5.0488, 5.0489,\n",
      "        5.0489, 5.0490, 5.0490, 5.0490, 5.0490, 5.0490, 5.0490, 5.0491, 5.0491,\n",
      "        5.0490, 5.0491, 5.0491, 5.0491, 5.0490, 5.0491, 5.0490, 5.0490, 5.0490,\n",
      "        5.0490, 5.0490, 5.0490, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491,\n",
      "        5.0491, 5.0491, 5.0490, 5.0490, 5.0490, 5.0490, 5.0490, 5.0490, 5.0490,\n",
      "        5.0490, 5.0490, 5.0490, 5.0490, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491,\n",
      "        5.0491, 5.0491, 5.0490, 5.0490, 5.0491, 5.0491, 5.0492, 5.0492, 5.0492,\n",
      "        5.0492, 5.0491, 5.0491, 5.0491, 5.0490, 5.0491, 5.0491, 5.0491, 5.0491,\n",
      "        5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0492, 5.0491, 5.0492,\n",
      "        5.0491, 5.0491, 5.0492, 5.0492, 5.0491, 5.0491, 5.0491, 5.0493, 5.0492,\n",
      "        5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0490,\n",
      "        5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0491, 5.0490,\n",
      "        5.0492, 5.0491, 5.0491, 5.0491, 5.0492, 5.0491, 5.0490, 5.0491, 5.0490,\n",
      "        5.0491, 5.0490, 5.0491], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.242342  [1785724/5599865]\n",
      "average delta from current occupancy tensor([4.3627, 4.3628, 4.3628, 4.3629, 4.3628, 4.3628, 4.3628, 4.3629, 4.3627,\n",
      "        4.3627, 4.3627, 4.3629, 4.3628, 4.3628, 4.3629, 4.3628, 4.3627, 4.3628,\n",
      "        4.3628, 4.3628, 4.3628, 4.3628, 4.3628, 4.3627, 4.3628, 4.3629, 4.3629,\n",
      "        4.3631, 4.3629, 4.3631, 4.3629, 4.3630, 4.3633, 4.3631, 4.3629, 4.3630,\n",
      "        4.3628, 4.3628, 4.3630, 4.3628, 4.3627, 4.3627, 4.3627, 4.3626, 4.3626,\n",
      "        4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626,\n",
      "        4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3627, 4.3626, 4.3627,\n",
      "        4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3627, 4.3626, 4.3627, 4.3626,\n",
      "        4.3626, 4.3628, 4.3628, 4.3629, 4.3630, 4.3628, 4.3628, 4.3627, 4.3629,\n",
      "        4.3631, 4.3629, 4.3628, 4.3630, 4.3628, 4.3628, 4.3627, 4.3629, 4.3628,\n",
      "        4.3627, 4.3627, 4.3627, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626, 4.3626,\n",
      "        4.3626, 4.3626, 4.3626, 4.3625, 4.3625, 4.3626, 4.3626, 4.3627, 4.3626,\n",
      "        4.3627, 4.3626, 4.3626, 4.3626, 4.3627, 4.3627, 4.3627, 4.3627, 4.3626,\n",
      "        4.3626, 4.3626, 4.3626], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.266471  [1798124/5599865]\n",
      "average delta from current occupancy tensor([5.2502, 5.2501, 5.2501, 5.2501, 5.2501, 5.2500, 5.2501, 5.2501, 5.2500,\n",
      "        5.2501, 5.2500, 5.2500, 5.2502, 5.2502, 5.2500, 5.2500, 5.2500, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501, 5.2501, 5.2500, 5.2501, 5.2500, 5.2503, 5.2503,\n",
      "        5.2503, 5.2505, 5.2500, 5.2502, 5.2502, 5.2500, 5.2501, 5.2502, 5.2500,\n",
      "        5.2503, 5.2501, 5.2500, 5.2502, 5.2501, 5.2501, 5.2500, 5.2502, 5.2505,\n",
      "        5.2504, 5.2501, 5.2504, 5.2503, 5.2504, 5.2504, 5.2503, 5.2505, 5.2503,\n",
      "        5.2506, 5.2506, 5.2504, 5.2504, 5.2504, 5.2505, 5.2506, 5.2506, 5.2503,\n",
      "        5.2503, 5.2504, 5.2504, 5.2505, 5.2504, 5.2500, 5.2502, 5.2501, 5.2503,\n",
      "        5.2503, 5.2500, 5.2500, 5.2501, 5.2501, 5.2501, 5.2500, 5.2501, 5.2501,\n",
      "        5.2501, 5.2503, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2501, 5.2502,\n",
      "        5.2502, 5.2501, 5.2500, 5.2503, 5.2503, 5.2501, 5.2500, 5.2500, 5.2501,\n",
      "        5.2501, 5.2501, 5.2500, 5.2501, 5.2501, 5.2501, 5.2500, 5.2501, 5.2500,\n",
      "        5.2502, 5.2501, 5.2501, 5.2501, 5.2500, 5.2501, 5.2501, 5.2501, 5.2501,\n",
      "        5.2501, 5.2501, 5.2501], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.954537  [1810524/5599865]\n",
      "average delta from current occupancy tensor([5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0405,\n",
      "        5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0403, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0403, 5.0404, 5.0404, 5.0403,\n",
      "        5.0404, 5.0404, 5.0403, 5.0404, 5.0404, 5.0404, 5.0403, 5.0404, 5.0404,\n",
      "        5.0404, 5.0403, 5.0404, 5.0404, 5.0403, 5.0404, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0405, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404,\n",
      "        5.0403, 5.0405, 5.0403, 5.0404, 5.0403, 5.0403, 5.0404, 5.0404, 5.0406,\n",
      "        5.0405, 5.0404, 5.0404, 5.0405, 5.0405, 5.0404, 5.0403, 5.0404, 5.0403,\n",
      "        5.0404, 5.0404, 5.0404, 5.0406, 5.0405, 5.0406, 5.0404, 5.0404, 5.0404,\n",
      "        5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0404, 5.0405,\n",
      "        5.0404, 5.0404, 5.0404], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.292064  [1822924/5599865]\n",
      "average delta from current occupancy tensor([4.4167, 4.4165, 4.4167, 4.4169, 4.4171, 4.4170, 4.4166, 4.4167, 4.4171,\n",
      "        4.4163, 4.4163, 4.4167, 4.4164, 4.4163, 4.4167, 4.4167, 4.4167, 4.4165,\n",
      "        4.4169, 4.4167, 4.4166, 4.4167, 4.4170, 4.4170, 4.4170, 4.4168, 4.4171,\n",
      "        4.4170, 4.4166, 4.4166, 4.4164, 4.4167, 4.4161, 4.4160, 4.4161, 4.4161,\n",
      "        4.4159, 4.4159, 4.4161, 4.4162, 4.4161, 4.4159, 4.4163, 4.4165, 4.4168,\n",
      "        4.4168, 4.4167, 4.4165, 4.4164, 4.4166, 4.4166, 4.4162, 4.4161, 4.4159,\n",
      "        4.4160, 4.4163, 4.4162, 4.4159, 4.4153, 4.4155, 4.4156, 4.4152, 4.4153,\n",
      "        4.4157, 4.4154, 4.4157, 4.4151, 4.4153, 4.4154, 4.4150, 4.4151, 4.4151,\n",
      "        4.4156, 4.4155, 4.4153, 4.4155, 4.4154, 4.4153, 4.4155, 4.4156, 4.4156,\n",
      "        4.4161, 4.4160, 4.4164, 4.4162, 4.4164, 4.4162, 4.4160, 4.4162, 4.4162,\n",
      "        4.4162, 4.4162, 4.4160, 4.4161, 4.4158, 4.4159, 4.4155, 4.4159, 4.4157,\n",
      "        4.4158, 4.4159, 4.4158, 4.4161, 4.4159, 4.4159, 4.4155, 4.4158, 4.4157,\n",
      "        4.4160, 4.4161, 4.4163, 4.4155, 4.4154, 4.4154, 4.4159, 4.4162, 4.4165,\n",
      "        4.4158, 4.4157, 4.4161], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.874633  [1835324/5599865]\n",
      "average delta from current occupancy tensor([5.9275, 5.9275, 5.9275, 5.9275, 5.9274, 5.9275, 5.9274, 5.9275, 5.9274,\n",
      "        5.9277, 5.9277, 5.9278, 5.9278, 5.9279, 5.9277, 5.9277, 5.9277, 5.9277,\n",
      "        5.9277, 5.9277, 5.9277, 5.9277, 5.9277, 5.9276, 5.9276, 5.9277, 5.9277,\n",
      "        5.9277, 5.9277, 5.9276, 5.9278, 5.9279, 5.9279, 5.9280, 5.9281, 5.9281,\n",
      "        5.9281, 5.9280, 5.9280, 5.9279, 5.9279, 5.9278, 5.9277, 5.9278, 5.9280,\n",
      "        5.9280, 5.9281, 5.9278, 5.9279, 5.9279, 5.9278, 5.9278, 5.9277, 5.9278,\n",
      "        5.9277, 5.9277, 5.9277, 5.9278, 5.9278, 5.9278, 5.9277, 5.9275, 5.9276,\n",
      "        5.9276, 5.9276, 5.9276, 5.9277, 5.9278, 5.9277, 5.9276, 5.9276, 5.9277,\n",
      "        5.9278, 5.9277, 5.9278, 5.9279, 5.9277, 5.9279, 5.9280, 5.9280, 5.9279,\n",
      "        5.9277, 5.9277, 5.9278, 5.9277, 5.9277, 5.9277, 5.9276, 5.9276, 5.9276,\n",
      "        5.9275, 5.9275, 5.9275, 5.9274, 5.9275, 5.9274, 5.9274, 5.9274, 5.9274,\n",
      "        5.9274, 5.9274, 5.9274, 5.9274, 5.9274, 5.9274, 5.9274, 5.9275, 5.9274,\n",
      "        5.9274, 5.9275, 5.9275, 5.9277, 5.9275, 5.9277, 5.9276, 5.9275, 5.9275,\n",
      "        5.9276, 5.9277, 5.9277], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.585173  [1847724/5599865]\n",
      "average delta from current occupancy tensor([5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306, 5.3306,\n",
      "        5.3306, 5.3306, 5.3306], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.921879  [1860124/5599865]\n",
      "average delta from current occupancy tensor([4.9282, 4.9282, 4.9282, 4.9282, 4.9282, 4.9282, 4.9280, 4.9281, 4.9282,\n",
      "        4.9284, 4.9282, 4.9282, 4.9282, 4.9281, 4.9282, 4.9281, 4.9281, 4.9281,\n",
      "        4.9282, 4.9283, 4.9283, 4.9282, 4.9283, 4.9282, 4.9281, 4.9282, 4.9283,\n",
      "        4.9281, 4.9281, 4.9280, 4.9279, 4.9281, 4.9281, 4.9283, 4.9283, 4.9282,\n",
      "        4.9282, 4.9283, 4.9280, 4.9282, 4.9281, 4.9280, 4.9280, 4.9280, 4.9281,\n",
      "        4.9280, 4.9280, 4.9279, 4.9281, 4.9278, 4.9278, 4.9280, 4.9279, 4.9280,\n",
      "        4.9280, 4.9278, 4.9280, 4.9278, 4.9280, 4.9279, 4.9280, 4.9281, 4.9281,\n",
      "        4.9279, 4.9278, 4.9279, 4.9279, 4.9281, 4.9282, 4.9282, 4.9282, 4.9282,\n",
      "        4.9281, 4.9284, 4.9285, 4.9283, 4.9285, 4.9284, 4.9284, 4.9283, 4.9283,\n",
      "        4.9282, 4.9282, 4.9282, 4.9281, 4.9282, 4.9280, 4.9281, 4.9280, 4.9280,\n",
      "        4.9278, 4.9278, 4.9280, 4.9280, 4.9279, 4.9279, 4.9280, 4.9279, 4.9279,\n",
      "        4.9277, 4.9280, 4.9279, 4.9280, 4.9280, 4.9280, 4.9280, 4.9279, 4.9280,\n",
      "        4.9280, 4.9279, 4.9280, 4.9281, 4.9282, 4.9281, 4.9282, 4.9280, 4.9280,\n",
      "        4.9281, 4.9282, 4.9282], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.043379  [1872524/5599865]\n",
      "average delta from current occupancy tensor([4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952, 4.8952,\n",
      "        4.8952, 4.8952, 4.8952], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.678316  [1884924/5599865]\n",
      "average delta from current occupancy tensor([4.5645, 4.5644, 4.5645, 4.5644, 4.5648, 4.5645, 4.5645, 4.5643, 4.5644,\n",
      "        4.5645, 4.5645, 4.5647, 4.5646, 4.5644, 4.5644, 4.5645, 4.5643, 4.5644,\n",
      "        4.5643, 4.5643, 4.5643, 4.5644, 4.5643, 4.5644, 4.5643, 4.5644, 4.5642,\n",
      "        4.5642, 4.5643, 4.5642, 4.5642, 4.5642, 4.5643, 4.5642, 4.5643, 4.5643,\n",
      "        4.5643, 4.5643, 4.5643, 4.5643, 4.5644, 4.5644, 4.5643, 4.5643, 4.5643,\n",
      "        4.5644, 4.5645, 4.5643, 4.5644, 4.5644, 4.5644, 4.5644, 4.5645, 4.5644,\n",
      "        4.5644, 4.5646, 4.5645, 4.5644, 4.5644, 4.5643, 4.5643, 4.5645, 4.5644,\n",
      "        4.5642, 4.5643, 4.5643, 4.5644, 4.5643, 4.5642, 4.5642, 4.5643, 4.5642,\n",
      "        4.5643, 4.5643, 4.5643, 4.5643, 4.5643, 4.5643, 4.5644, 4.5643, 4.5643,\n",
      "        4.5644, 4.5644, 4.5644, 4.5644, 4.5643, 4.5644, 4.5643, 4.5644, 4.5643,\n",
      "        4.5644, 4.5643, 4.5644, 4.5644, 4.5644, 4.5649, 4.5646, 4.5647, 4.5649,\n",
      "        4.5646, 4.5644, 4.5645, 4.5644, 4.5645, 4.5647, 4.5649, 4.5647, 4.5645,\n",
      "        4.5646, 4.5645, 4.5647, 4.5646, 4.5646, 4.5646, 4.5645, 4.5645, 4.5644,\n",
      "        4.5644, 4.5645, 4.5643], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.081859  [1897324/5599865]\n",
      "average delta from current occupancy tensor([4.9362, 4.9360, 4.9361, 4.9361, 4.9361, 4.9361, 4.9361, 4.9360, 4.9361,\n",
      "        4.9361, 4.9361, 4.9361, 4.9361, 4.9361, 4.9361, 4.9360, 4.9360, 4.9360,\n",
      "        4.9360, 4.9361, 4.9361, 4.9361, 4.9361, 4.9361, 4.9360, 4.9360, 4.9360,\n",
      "        4.9359, 4.9359, 4.9360, 4.9360, 4.9360, 4.9360, 4.9360, 4.9360, 4.9360,\n",
      "        4.9359, 4.9360, 4.9360, 4.9359, 4.9360, 4.9359, 4.9360, 4.9360, 4.9360,\n",
      "        4.9360, 4.9361, 4.9361, 4.9361, 4.9359, 4.9360, 4.9359, 4.9360, 4.9361,\n",
      "        4.9362, 4.9360, 4.9360, 4.9360, 4.9361, 4.9362, 4.9361, 4.9360, 4.9361,\n",
      "        4.9360, 4.9360, 4.9360, 4.9361, 4.9361, 4.9361, 4.9362, 4.9362, 4.9361,\n",
      "        4.9361, 4.9361, 4.9361, 4.9361, 4.9361, 4.9362, 4.9361, 4.9361, 4.9361,\n",
      "        4.9360, 4.9360, 4.9360, 4.9360, 4.9360, 4.9360, 4.9360, 4.9360, 4.9361,\n",
      "        4.9360, 4.9360, 4.9361, 4.9361, 4.9361, 4.9360, 4.9361, 4.9360, 4.9361,\n",
      "        4.9360, 4.9359, 4.9359, 4.9359, 4.9360, 4.9359, 4.9359, 4.9359, 4.9359,\n",
      "        4.9359, 4.9359, 4.9359, 4.9359, 4.9359, 4.9359, 4.9358, 4.9359, 4.9359,\n",
      "        4.9360, 4.9359, 4.9359], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.443215  [1909724/5599865]\n",
      "average delta from current occupancy tensor([5.5084, 5.5084, 5.5085, 5.5084, 5.5083, 5.5084, 5.5083, 5.5084, 5.5084,\n",
      "        5.5084, 5.5083, 5.5084, 5.5084, 5.5085, 5.5084, 5.5084, 5.5084, 5.5084,\n",
      "        5.5084, 5.5083, 5.5084, 5.5083, 5.5083, 5.5083, 5.5083, 5.5084, 5.5084,\n",
      "        5.5084, 5.5084, 5.5084, 5.5085, 5.5085, 5.5085, 5.5085, 5.5085, 5.5085,\n",
      "        5.5085, 5.5084, 5.5085, 5.5084, 5.5084, 5.5084, 5.5084, 5.5084, 5.5084,\n",
      "        5.5084, 5.5084, 5.5084, 5.5084, 5.5085, 5.5084, 5.5085, 5.5085, 5.5084,\n",
      "        5.5084, 5.5085, 5.5085, 5.5085, 5.5085, 5.5086, 5.5085, 5.5086, 5.5086,\n",
      "        5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086,\n",
      "        5.5086, 5.5086, 5.5086, 5.5086, 5.5087, 5.5087, 5.5086, 5.5086, 5.5086,\n",
      "        5.5086, 5.5087, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086,\n",
      "        5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5087, 5.5086, 5.5086,\n",
      "        5.5086, 5.5086, 5.5086, 5.5086, 5.5086, 5.5085, 5.5086, 5.5086, 5.5085,\n",
      "        5.5085, 5.5085, 5.5086, 5.5085, 5.5085, 5.5086, 5.5085, 5.5085, 5.5085,\n",
      "        5.5085, 5.5085, 5.5084], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.658742  [1922124/5599865]\n",
      "average delta from current occupancy tensor([4.6933, 4.6933, 4.6933, 4.6932, 4.6932, 4.6934, 4.6935, 4.6932, 4.6932,\n",
      "        4.6932, 4.6932, 4.6932, 4.6933, 4.6932, 4.6932, 4.6931, 4.6931, 4.6934,\n",
      "        4.6933, 4.6934, 4.6934, 4.6934, 4.6934, 4.6934, 4.6934, 4.6932, 4.6933,\n",
      "        4.6933, 4.6929, 4.6933, 4.6929, 4.6930, 4.6930, 4.6930, 4.6931, 4.6930,\n",
      "        4.6930, 4.6930, 4.6930, 4.6929, 4.6930, 4.6930, 4.6934, 4.6933, 4.6932,\n",
      "        4.6933, 4.6932, 4.6930, 4.6930, 4.6930, 4.6930, 4.6930, 4.6930, 4.6930,\n",
      "        4.6930, 4.6931, 4.6930, 4.6931, 4.6930, 4.6932, 4.6932, 4.6932, 4.6932,\n",
      "        4.6931, 4.6931, 4.6931, 4.6931, 4.6931, 4.6931, 4.6932, 4.6932, 4.6932,\n",
      "        4.6934, 4.6933, 4.6933, 4.6934, 4.6933, 4.6932, 4.6933, 4.6932, 4.6933,\n",
      "        4.6933, 4.6933, 4.6932, 4.6933, 4.6932, 4.6931, 4.6934, 4.6932, 4.6932,\n",
      "        4.6931, 4.6933, 4.6932, 4.6933, 4.6932, 4.6933, 4.6933, 4.6933, 4.6931,\n",
      "        4.6931, 4.6930, 4.6931, 4.6931, 4.6930, 4.6930, 4.6930, 4.6930, 4.6930,\n",
      "        4.6930, 4.6929, 4.6930, 4.6930, 4.6930, 4.6929, 4.6930, 4.6930, 4.6932,\n",
      "        4.6930, 4.6931, 4.6931], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.499882  [1934524/5599865]\n",
      "average delta from current occupancy tensor([5.3471, 5.3472, 5.3474, 5.3474, 5.3474, 5.3475, 5.3475, 5.3474, 5.3474,\n",
      "        5.3472, 5.3473, 5.3475, 5.3475, 5.3475, 5.3474, 5.3474, 5.3474, 5.3475,\n",
      "        5.3474, 5.3475, 5.3476, 5.3475, 5.3476, 5.3476, 5.3475, 5.3475, 5.3474,\n",
      "        5.3472, 5.3472, 5.3474, 5.3475, 5.3474, 5.3474, 5.3473, 5.3473, 5.3474,\n",
      "        5.3473, 5.3474, 5.3473, 5.3472, 5.3474, 5.3474, 5.3473, 5.3473, 5.3473,\n",
      "        5.3472, 5.3472, 5.3474, 5.3475, 5.3475, 5.3474, 5.3473, 5.3472, 5.3471,\n",
      "        5.3472, 5.3472, 5.3473, 5.3472, 5.3473, 5.3473, 5.3473, 5.3473, 5.3472,\n",
      "        5.3473, 5.3473, 5.3473, 5.3473, 5.3473, 5.3471, 5.3470, 5.3470, 5.3471,\n",
      "        5.3471, 5.3470, 5.3471, 5.3471, 5.3471, 5.3471, 5.3471, 5.3470, 5.3472,\n",
      "        5.3471, 5.3471, 5.3470, 5.3470, 5.3470, 5.3472, 5.3471, 5.3472, 5.3472,\n",
      "        5.3473, 5.3470, 5.3472, 5.3471, 5.3471, 5.3470, 5.3470, 5.3470, 5.3472,\n",
      "        5.3474, 5.3472, 5.3471, 5.3473, 5.3471, 5.3473, 5.3476, 5.3473, 5.3473,\n",
      "        5.3474, 5.3474, 5.3475, 5.3475, 5.3475, 5.3474, 5.3473, 5.3475, 5.3473,\n",
      "        5.3475, 5.3474, 5.3473], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.070118  [1946924/5599865]\n",
      "average delta from current occupancy tensor([5.0563, 5.0562, 5.0561, 5.0562, 5.0561, 5.0562, 5.0563, 5.0562, 5.0561,\n",
      "        5.0561, 5.0561, 5.0560, 5.0561, 5.0563, 5.0562, 5.0562, 5.0563, 5.0564,\n",
      "        5.0562, 5.0563, 5.0564, 5.0563, 5.0564, 5.0564, 5.0564, 5.0563, 5.0562,\n",
      "        5.0564, 5.0563, 5.0563, 5.0563, 5.0562, 5.0563, 5.0563, 5.0563, 5.0563,\n",
      "        5.0563, 5.0563, 5.0563, 5.0564, 5.0563, 5.0563, 5.0563, 5.0564, 5.0564,\n",
      "        5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0565, 5.0566, 5.0566,\n",
      "        5.0565, 5.0566, 5.0567, 5.0566, 5.0566, 5.0565, 5.0564, 5.0565, 5.0565,\n",
      "        5.0565, 5.0565, 5.0564, 5.0566, 5.0564, 5.0565, 5.0564, 5.0564, 5.0564,\n",
      "        5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564,\n",
      "        5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564, 5.0564,\n",
      "        5.0564, 5.0564, 5.0564, 5.0563, 5.0564, 5.0563, 5.0563, 5.0563, 5.0563,\n",
      "        5.0564, 5.0564, 5.0564, 5.0562, 5.0563, 5.0562, 5.0561, 5.0562, 5.0562,\n",
      "        5.0562, 5.0563, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0563,\n",
      "        5.0563, 5.0562, 5.0562], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.534667  [1959324/5599865]\n",
      "average delta from current occupancy tensor([4.5403, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5403, 4.5404, 4.5404,\n",
      "        4.5404, 4.5405, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404,\n",
      "        4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404,\n",
      "        4.5403, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404,\n",
      "        4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404,\n",
      "        4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404, 4.5404,\n",
      "        4.5403, 4.5404, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5404,\n",
      "        4.5403, 4.5403, 4.5403, 4.5404, 4.5404, 4.5404, 4.5403, 4.5403, 4.5403,\n",
      "        4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403,\n",
      "        4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5404, 4.5404,\n",
      "        4.5404, 4.5403, 4.5404, 4.5404, 4.5403, 4.5404, 4.5404, 4.5404, 4.5404,\n",
      "        4.5404, 4.5404, 4.5404, 4.5404, 4.5403, 4.5404, 4.5403, 4.5404, 4.5404,\n",
      "        4.5404, 4.5404, 4.5404, 4.5404, 4.5403, 4.5403, 4.5404, 4.5404, 4.5404,\n",
      "        4.5404, 4.5404, 4.5404], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.954692  [1971724/5599865]\n",
      "average delta from current occupancy tensor([4.9664, 4.9660, 4.9664, 4.9666, 4.9663, 4.9657, 4.9665, 4.9667, 4.9662,\n",
      "        4.9666, 4.9659, 4.9662, 4.9663, 4.9667, 4.9666, 4.9666, 4.9660, 4.9663,\n",
      "        4.9657, 4.9655, 4.9648, 4.9646, 4.9644, 4.9645, 4.9644, 4.9646, 4.9650,\n",
      "        4.9650, 4.9645, 4.9644, 4.9647, 4.9642, 4.9643, 4.9643, 4.9644, 4.9643,\n",
      "        4.9644, 4.9645, 4.9643, 4.9643, 4.9644, 4.9641, 4.9644, 4.9647, 4.9647,\n",
      "        4.9648, 4.9653, 4.9649, 4.9652, 4.9649, 4.9647, 4.9650, 4.9649, 4.9652,\n",
      "        4.9646, 4.9653, 4.9654, 4.9655, 4.9649, 4.9649, 4.9662, 4.9659, 4.9658,\n",
      "        4.9661, 4.9658, 4.9658, 4.9663, 4.9661, 4.9658, 4.9661, 4.9661, 4.9659,\n",
      "        4.9653, 4.9652, 4.9652, 4.9648, 4.9649, 4.9653, 4.9661, 4.9657, 4.9661,\n",
      "        4.9658, 4.9658, 4.9659, 4.9658, 4.9655, 4.9665, 4.9667, 4.9671, 4.9666,\n",
      "        4.9667, 4.9661, 4.9655, 4.9660, 4.9655, 4.9656, 4.9659, 4.9653, 4.9666,\n",
      "        4.9657, 4.9663, 4.9661, 4.9659, 4.9669, 4.9666, 4.9665, 4.9664, 4.9666,\n",
      "        4.9668, 4.9663, 4.9667, 4.9667, 4.9666, 4.9665, 4.9665, 4.9666, 4.9669,\n",
      "        4.9668, 4.9670, 4.9666], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.734161  [1984124/5599865]\n",
      "average delta from current occupancy tensor([4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8548, 4.8548, 4.8548], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.834363  [1996524/5599865]\n",
      "average delta from current occupancy tensor([4.7905, 4.7906, 4.7906, 4.7905, 4.7905, 4.7906, 4.7906, 4.7906, 4.7906,\n",
      "        4.7907, 4.7906, 4.7906, 4.7906, 4.7906, 4.7905, 4.7905, 4.7905, 4.7905,\n",
      "        4.7906, 4.7905, 4.7906, 4.7905, 4.7905, 4.7904, 4.7903, 4.7904, 4.7904,\n",
      "        4.7903, 4.7903, 4.7903, 4.7903, 4.7904, 4.7904, 4.7903, 4.7904, 4.7904,\n",
      "        4.7904, 4.7903, 4.7903, 4.7904, 4.7904, 4.7904, 4.7904, 4.7905, 4.7906,\n",
      "        4.7906, 4.7906, 4.7906, 4.7906, 4.7907, 4.7906, 4.7907, 4.7906, 4.7907,\n",
      "        4.7906, 4.7906, 4.7907, 4.7906, 4.7907, 4.7908, 4.7908, 4.7908, 4.7907,\n",
      "        4.7907, 4.7906, 4.7906, 4.7905, 4.7906, 4.7906, 4.7907, 4.7907, 4.7906,\n",
      "        4.7907, 4.7907, 4.7908, 4.7908, 4.7908, 4.7908, 4.7908, 4.7908, 4.7908,\n",
      "        4.7908, 4.7908, 4.7908, 4.7908, 4.7906, 4.7906, 4.7905, 4.7906, 4.7906,\n",
      "        4.7907, 4.7906, 4.7906, 4.7906, 4.7905, 4.7906, 4.7906, 4.7907, 4.7906,\n",
      "        4.7905, 4.7905, 4.7906, 4.7907, 4.7906, 4.7907, 4.7906, 4.7906, 4.7907,\n",
      "        4.7906, 4.7905, 4.7905, 4.7904, 4.7905, 4.7905, 4.7904, 4.7903, 4.7904,\n",
      "        4.7904, 4.7903, 4.7904], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.803324  [2008924/5599865]\n",
      "average delta from current occupancy tensor([4.6854, 4.6857, 4.6857, 4.6857, 4.6858, 4.6854, 4.6858, 4.6855, 4.6855,\n",
      "        4.6856, 4.6857, 4.6857, 4.6854, 4.6853, 4.6854, 4.6855, 4.6856, 4.6856,\n",
      "        4.6857, 4.6858, 4.6857, 4.6854, 4.6855, 4.6855, 4.6854, 4.6856, 4.6856,\n",
      "        4.6856, 4.6857, 4.6856, 4.6856, 4.6856, 4.6856, 4.6855, 4.6856, 4.6856,\n",
      "        4.6857, 4.6855, 4.6855, 4.6856, 4.6854, 4.6855, 4.6856, 4.6855, 4.6856,\n",
      "        4.6855, 4.6856, 4.6857, 4.6856, 4.6857, 4.6856, 4.6855, 4.6857, 4.6856,\n",
      "        4.6856, 4.6857, 4.6855, 4.6856, 4.6855, 4.6855, 4.6855, 4.6855, 4.6855,\n",
      "        4.6857, 4.6855, 4.6858, 4.6855, 4.6856, 4.6856, 4.6855, 4.6858, 4.6856,\n",
      "        4.6857, 4.6856, 4.6857, 4.6855, 4.6855, 4.6856, 4.6856, 4.6856, 4.6855,\n",
      "        4.6856, 4.6858, 4.6856, 4.6858, 4.6858, 4.6855, 4.6855, 4.6858, 4.6858,\n",
      "        4.6858, 4.6859, 4.6857, 4.6855, 4.6856, 4.6857, 4.6858, 4.6856, 4.6856,\n",
      "        4.6856, 4.6855, 4.6856, 4.6857, 4.6856, 4.6856, 4.6858, 4.6857, 4.6857,\n",
      "        4.6856, 4.6856, 4.6857, 4.6853, 4.6855, 4.6854, 4.6856, 4.6854, 4.6854,\n",
      "        4.6852, 4.6852, 4.6855], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.653658  [2021324/5599865]\n",
      "average delta from current occupancy tensor([5.5094, 5.5094, 5.5094, 5.5095, 5.5095, 5.5094, 5.5094, 5.5093, 5.5092,\n",
      "        5.5093, 5.5091, 5.5091, 5.5091, 5.5093, 5.5091, 5.5093, 5.5092, 5.5093,\n",
      "        5.5094, 5.5094, 5.5093, 5.5093, 5.5093, 5.5091, 5.5093, 5.5092, 5.5091,\n",
      "        5.5091, 5.5091, 5.5091, 5.5092, 5.5091, 5.5092, 5.5091, 5.5090, 5.5091,\n",
      "        5.5093, 5.5092, 5.5091, 5.5091, 5.5091, 5.5094, 5.5093, 5.5094, 5.5091,\n",
      "        5.5091, 5.5093, 5.5091, 5.5091, 5.5091, 5.5093, 5.5093, 5.5091, 5.5095,\n",
      "        5.5095, 5.5095, 5.5093, 5.5092, 5.5093, 5.5093, 5.5095, 5.5095, 5.5096,\n",
      "        5.5095, 5.5095, 5.5095, 5.5094, 5.5095, 5.5094, 5.5095, 5.5095, 5.5095,\n",
      "        5.5095, 5.5095, 5.5094, 5.5095, 5.5094, 5.5095, 5.5095, 5.5095, 5.5094,\n",
      "        5.5093, 5.5096, 5.5094, 5.5095, 5.5095, 5.5095, 5.5096, 5.5095, 5.5095,\n",
      "        5.5095, 5.5094, 5.5092, 5.5091, 5.5091, 5.5091, 5.5092, 5.5091, 5.5092,\n",
      "        5.5093, 5.5094, 5.5091, 5.5093, 5.5091, 5.5092, 5.5095, 5.5096, 5.5095,\n",
      "        5.5095, 5.5095, 5.5095, 5.5096, 5.5096, 5.5095, 5.5096, 5.5095, 5.5095,\n",
      "        5.5095, 5.5094, 5.5095], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.072136  [2033724/5599865]\n",
      "average delta from current occupancy tensor([5.0238, 5.0238, 5.0238, 5.0239, 5.0239, 5.0238, 5.0238, 5.0238, 5.0238,\n",
      "        5.0238, 5.0237, 5.0237, 5.0237, 5.0238, 5.0237, 5.0240, 5.0240, 5.0237,\n",
      "        5.0236, 5.0237, 5.0238, 5.0238, 5.0238, 5.0240, 5.0239, 5.0239, 5.0238,\n",
      "        5.0240, 5.0239, 5.0238, 5.0238, 5.0237, 5.0238, 5.0236, 5.0236, 5.0237,\n",
      "        5.0238, 5.0237, 5.0237, 5.0236, 5.0237, 5.0237, 5.0238, 5.0239, 5.0237,\n",
      "        5.0237, 5.0238, 5.0238, 5.0238, 5.0238, 5.0238, 5.0238, 5.0237, 5.0239,\n",
      "        5.0238, 5.0238, 5.0237, 5.0237, 5.0237, 5.0237, 5.0237, 5.0237, 5.0238,\n",
      "        5.0237, 5.0237, 5.0237, 5.0238, 5.0239, 5.0238, 5.0239, 5.0238, 5.0238,\n",
      "        5.0239, 5.0239, 5.0238, 5.0240, 5.0238, 5.0239, 5.0239, 5.0238, 5.0237,\n",
      "        5.0237, 5.0239, 5.0237, 5.0239, 5.0238, 5.0239, 5.0239, 5.0239, 5.0239,\n",
      "        5.0238, 5.0239, 5.0237, 5.0237, 5.0237, 5.0237, 5.0238, 5.0237, 5.0237,\n",
      "        5.0238, 5.0238, 5.0237, 5.0239, 5.0237, 5.0237, 5.0236, 5.0236, 5.0236,\n",
      "        5.0237, 5.0237, 5.0238, 5.0238, 5.0238, 5.0237, 5.0239, 5.0238, 5.0238,\n",
      "        5.0237, 5.0237, 5.0237], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.335733  [2046124/5599865]\n",
      "average delta from current occupancy tensor([4.2666, 4.2666, 4.2665, 4.2666, 4.2667, 4.2665, 4.2666, 4.2666, 4.2666,\n",
      "        4.2666, 4.2665, 4.2665, 4.2667, 4.2668, 4.2667, 4.2667, 4.2667, 4.2669,\n",
      "        4.2667, 4.2668, 4.2668, 4.2668, 4.2668, 4.2667, 4.2668, 4.2667, 4.2667,\n",
      "        4.2667, 4.2666, 4.2667, 4.2667, 4.2667, 4.2668, 4.2666, 4.2666, 4.2668,\n",
      "        4.2668, 4.2667, 4.2665, 4.2665, 4.2666, 4.2666, 4.2666, 4.2665, 4.2667,\n",
      "        4.2667, 4.2666, 4.2666, 4.2666, 4.2666, 4.2667, 4.2665, 4.2666, 4.2666,\n",
      "        4.2665, 4.2666, 4.2667, 4.2666, 4.2666, 4.2666, 4.2665, 4.2665, 4.2665,\n",
      "        4.2666, 4.2665, 4.2665, 4.2665, 4.2664, 4.2666, 4.2665, 4.2665, 4.2664,\n",
      "        4.2664, 4.2664, 4.2665, 4.2664, 4.2666, 4.2664, 4.2664, 4.2665, 4.2666,\n",
      "        4.2667, 4.2666, 4.2667, 4.2666, 4.2666, 4.2666, 4.2666, 4.2666, 4.2666,\n",
      "        4.2666, 4.2664, 4.2666, 4.2667, 4.2666, 4.2667, 4.2666, 4.2667, 4.2665,\n",
      "        4.2666, 4.2666, 4.2665, 4.2666, 4.2666, 4.2666, 4.2667, 4.2667, 4.2667,\n",
      "        4.2667, 4.2668, 4.2667, 4.2667, 4.2667, 4.2667, 4.2667, 4.2667, 4.2667,\n",
      "        4.2668, 4.2667, 4.2666], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.056986  [2058524/5599865]\n",
      "average delta from current occupancy tensor([5.2098, 5.2098, 5.2099, 5.2098, 5.2098, 5.2098, 5.2098, 5.2099, 5.2098,\n",
      "        5.2099, 5.2098, 5.2098, 5.2098, 5.2099, 5.2099, 5.2099, 5.2099, 5.2098,\n",
      "        5.2099, 5.2099, 5.2098, 5.2098, 5.2099, 5.2099, 5.2098, 5.2099, 5.2099,\n",
      "        5.2099, 5.2098, 5.2097, 5.2098, 5.2098, 5.2098, 5.2098, 5.2099, 5.2099,\n",
      "        5.2099, 5.2099, 5.2100, 5.2099, 5.2097, 5.2098, 5.2099, 5.2098, 5.2099,\n",
      "        5.2098, 5.2098, 5.2098, 5.2099, 5.2098, 5.2100, 5.2101, 5.2100, 5.2099,\n",
      "        5.2099, 5.2098, 5.2098, 5.2098, 5.2100, 5.2100, 5.2098, 5.2098, 5.2098,\n",
      "        5.2099, 5.2099, 5.2098, 5.2099, 5.2099, 5.2098, 5.2100, 5.2100, 5.2100,\n",
      "        5.2100, 5.2100, 5.2100, 5.2100, 5.2100, 5.2099, 5.2098, 5.2100, 5.2100,\n",
      "        5.2100, 5.2100, 5.2099, 5.2099, 5.2099, 5.2098, 5.2098, 5.2098, 5.2098,\n",
      "        5.2099, 5.2098, 5.2098, 5.2097, 5.2098, 5.2097, 5.2098, 5.2097, 5.2097,\n",
      "        5.2097, 5.2097, 5.2097, 5.2098, 5.2098, 5.2097, 5.2098, 5.2097, 5.2098,\n",
      "        5.2097, 5.2098, 5.2098, 5.2098, 5.2097, 5.2098, 5.2098, 5.2098, 5.2098,\n",
      "        5.2097, 5.2097, 5.2098], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.795787  [2070924/5599865]\n",
      "average delta from current occupancy tensor([4.6799, 4.6801, 4.6803, 4.6804, 4.6803, 4.6802, 4.6804, 4.6806, 4.6804,\n",
      "        4.6806, 4.6806, 4.6809, 4.6809, 4.6813, 4.6809, 4.6812, 4.6812, 4.6810,\n",
      "        4.6811, 4.6811, 4.6811, 4.6810, 4.6808, 4.6805, 4.6804, 4.6804, 4.6801,\n",
      "        4.6805, 4.6798, 4.6803, 4.6796, 4.6794, 4.6795, 4.6794, 4.6794, 4.6798,\n",
      "        4.6801, 4.6803, 4.6803, 4.6803, 4.6805, 4.6798, 4.6800, 4.6800, 4.6797,\n",
      "        4.6799, 4.6799, 4.6799, 4.6804, 4.6804, 4.6806, 4.6805, 4.6802, 4.6801,\n",
      "        4.6804, 4.6801, 4.6800, 4.6801, 4.6804, 4.6805, 4.6805, 4.6808, 4.6808,\n",
      "        4.6810, 4.6811, 4.6805, 4.6807, 4.6806, 4.6804, 4.6806, 4.6806, 4.6806,\n",
      "        4.6808, 4.6806, 4.6806, 4.6807, 4.6809, 4.6804, 4.6806, 4.6808, 4.6808,\n",
      "        4.6806, 4.6811, 4.6812, 4.6810, 4.6809, 4.6812, 4.6811, 4.6814, 4.6816,\n",
      "        4.6813, 4.6810, 4.6811, 4.6813, 4.6818, 4.6817, 4.6814, 4.6815, 4.6815,\n",
      "        4.6816, 4.6816, 4.6817, 4.6817, 4.6818, 4.6819, 4.6819, 4.6821, 4.6818,\n",
      "        4.6818, 4.6818, 4.6819, 4.6819, 4.6821, 4.6819, 4.6817, 4.6817, 4.6813,\n",
      "        4.6813, 4.6818, 4.6817], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.506035  [2083324/5599865]\n",
      "average delta from current occupancy tensor([4.7085, 4.7085, 4.7085, 4.7085, 4.7085, 4.7085, 4.7085, 4.7085, 4.7086,\n",
      "        4.7085, 4.7086, 4.7085, 4.7085, 4.7085, 4.7085, 4.7085, 4.7085, 4.7085,\n",
      "        4.7086, 4.7085, 4.7085, 4.7086, 4.7085, 4.7086, 4.7086, 4.7086, 4.7086,\n",
      "        4.7087, 4.7086, 4.7086, 4.7087, 4.7086, 4.7086, 4.7086, 4.7087, 4.7087,\n",
      "        4.7087, 4.7086, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087,\n",
      "        4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7086,\n",
      "        4.7087, 4.7086, 4.7087, 4.7086, 4.7086, 4.7086, 4.7087, 4.7087, 4.7087,\n",
      "        4.7086, 4.7087, 4.7087, 4.7086, 4.7087, 4.7087, 4.7087, 4.7086, 4.7086,\n",
      "        4.7086, 4.7087, 4.7086, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087,\n",
      "        4.7087, 4.7087, 4.7087, 4.7088, 4.7088, 4.7087, 4.7088, 4.7088, 4.7088,\n",
      "        4.7087, 4.7087, 4.7087, 4.7088, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087,\n",
      "        4.7087, 4.7087, 4.7087, 4.7086, 4.7087, 4.7087, 4.7087, 4.7087, 4.7087,\n",
      "        4.7086, 4.7087, 4.7086, 4.7086, 4.7086, 4.7086, 4.7086, 4.7086, 4.7087,\n",
      "        4.7086, 4.7086, 4.7086], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.432150  [2095724/5599865]\n",
      "average delta from current occupancy tensor([5.5579, 5.5578, 5.5578, 5.5578, 5.5577, 5.5578, 5.5579, 5.5579, 5.5579,\n",
      "        5.5579, 5.5579, 5.5579, 5.5580, 5.5580, 5.5580, 5.5580, 5.5579, 5.5579,\n",
      "        5.5579, 5.5580, 5.5579, 5.5580, 5.5580, 5.5579, 5.5579, 5.5580, 5.5580,\n",
      "        5.5578, 5.5579, 5.5579, 5.5578, 5.5579, 5.5578, 5.5578, 5.5578, 5.5578,\n",
      "        5.5578, 5.5578, 5.5577, 5.5578, 5.5577, 5.5578, 5.5578, 5.5577, 5.5577,\n",
      "        5.5578, 5.5577, 5.5577, 5.5578, 5.5577, 5.5577, 5.5576, 5.5576, 5.5577,\n",
      "        5.5577, 5.5577, 5.5576, 5.5576, 5.5576, 5.5576, 5.5576, 5.5575, 5.5575,\n",
      "        5.5576, 5.5576, 5.5576, 5.5576, 5.5576, 5.5576, 5.5576, 5.5577, 5.5577,\n",
      "        5.5577, 5.5577, 5.5577, 5.5577, 5.5578, 5.5578, 5.5577, 5.5577, 5.5577,\n",
      "        5.5576, 5.5577, 5.5577, 5.5576, 5.5575, 5.5576, 5.5576, 5.5576, 5.5575,\n",
      "        5.5575, 5.5575, 5.5576, 5.5575, 5.5576, 5.5575, 5.5575, 5.5575, 5.5575,\n",
      "        5.5575, 5.5575, 5.5576, 5.5577, 5.5576, 5.5576, 5.5576, 5.5576, 5.5577,\n",
      "        5.5578, 5.5578, 5.5578, 5.5578, 5.5578, 5.5578, 5.5577, 5.5577, 5.5577,\n",
      "        5.5577, 5.5577, 5.5577], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.774762  [2108124/5599865]\n",
      "average delta from current occupancy tensor([4.6458, 4.6461, 4.6460, 4.6459, 4.6460, 4.6459, 4.6461, 4.6461, 4.6459,\n",
      "        4.6459, 4.6459, 4.6458, 4.6462, 4.6463, 4.6466, 4.6464, 4.6461, 4.6462,\n",
      "        4.6462, 4.6464, 4.6463, 4.6463, 4.6466, 4.6462, 4.6465, 4.6462, 4.6463,\n",
      "        4.6460, 4.6461, 4.6461, 4.6458, 4.6460, 4.6459, 4.6460, 4.6460, 4.6459,\n",
      "        4.6460, 4.6460, 4.6460, 4.6461, 4.6459, 4.6460, 4.6459, 4.6461, 4.6460,\n",
      "        4.6461, 4.6459, 4.6463, 4.6461, 4.6462, 4.6463, 4.6461, 4.6460, 4.6462,\n",
      "        4.6462, 4.6461, 4.6463, 4.6463, 4.6459, 4.6458, 4.6460, 4.6460, 4.6459,\n",
      "        4.6460, 4.6458, 4.6460, 4.6463, 4.6460, 4.6460, 4.6459, 4.6462, 4.6463,\n",
      "        4.6463, 4.6460, 4.6458, 4.6461, 4.6459, 4.6460, 4.6459, 4.6456, 4.6457,\n",
      "        4.6459, 4.6459, 4.6458, 4.6460, 4.6457, 4.6457, 4.6458, 4.6459, 4.6459,\n",
      "        4.6459, 4.6459, 4.6461, 4.6460, 4.6459, 4.6462, 4.6461, 4.6463, 4.6463,\n",
      "        4.6462, 4.6462, 4.6461, 4.6460, 4.6459, 4.6459, 4.6460, 4.6459, 4.6459,\n",
      "        4.6463, 4.6468, 4.6467, 4.6464, 4.6464, 4.6462, 4.6464, 4.6462, 4.6460,\n",
      "        4.6460, 4.6459, 4.6458], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.453186  [2120524/5599865]\n",
      "average delta from current occupancy tensor([4.3709, 4.3709, 4.3709, 4.3709, 4.3709, 4.3709, 4.3709, 4.3709, 4.3709,\n",
      "        4.3709, 4.3709, 4.3709, 4.3709, 4.3709, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3709, 4.3708, 4.3708, 4.3708, 4.3708, 4.3709, 4.3708, 4.3708, 4.3708,\n",
      "        4.3709, 4.3708, 4.3709, 4.3708, 4.3709, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3709, 4.3708, 4.3708, 4.3709, 4.3708,\n",
      "        4.3708, 4.3709, 4.3708, 4.3708, 4.3709, 4.3709, 4.3708, 4.3709, 4.3709,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708, 4.3708,\n",
      "        4.3708, 4.3708, 4.3708], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.016546  [2132924/5599865]\n",
      "average delta from current occupancy tensor([4.8953, 4.8954, 4.8953, 4.8954, 4.8955, 4.8955, 4.8956, 4.8954, 4.8955,\n",
      "        4.8956, 4.8954, 4.8957, 4.8954, 4.8952, 4.8955, 4.8953, 4.8954, 4.8952,\n",
      "        4.8955, 4.8954, 4.8953, 4.8953, 4.8955, 4.8957, 4.8958, 4.8959, 4.8954,\n",
      "        4.8956, 4.8953, 4.8952, 4.8958, 4.8952, 4.8956, 4.8958, 4.8952, 4.8957,\n",
      "        4.8953, 4.8957, 4.8955, 4.8954, 4.8954, 4.8955, 4.8953, 4.8955, 4.8954,\n",
      "        4.8954, 4.8955, 4.8956, 4.8955, 4.8956, 4.8956, 4.8955, 4.8954, 4.8952,\n",
      "        4.8952, 4.8953, 4.8953, 4.8952, 4.8957, 4.8952, 4.8957, 4.8953, 4.8955,\n",
      "        4.8955, 4.8955, 4.8956, 4.8959, 4.8959, 4.8959, 4.8959, 4.8962, 4.8959,\n",
      "        4.8960, 4.8961, 4.8959, 4.8961, 4.8962, 4.8963, 4.8961, 4.8959, 4.8963,\n",
      "        4.8959, 4.8962, 4.8965, 4.8961, 4.8962, 4.8962, 4.8963, 4.8960, 4.8965,\n",
      "        4.8965, 4.8965, 4.8968, 4.8962, 4.8962, 4.8965, 4.8968, 4.8961, 4.8967,\n",
      "        4.8964, 4.8966, 4.8964, 4.8966, 4.8963, 4.8962, 4.8957, 4.8960, 4.8962,\n",
      "        4.8958, 4.8960, 4.8961, 4.8961, 4.8957, 4.8958, 4.8962, 4.8963, 4.8963,\n",
      "        4.8962, 4.8964, 4.8960], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.883575  [2145324/5599865]\n",
      "average delta from current occupancy tensor([5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339, 5.7339,\n",
      "        5.7339, 5.7339, 5.7339], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.103307  [2157724/5599865]\n",
      "average delta from current occupancy tensor([5.0010, 5.0010, 5.0010, 5.0010, 5.0011, 5.0011, 5.0010, 5.0011, 5.0011,\n",
      "        5.0010, 5.0011, 5.0011, 5.0011, 5.0011, 5.0011, 5.0011, 5.0011, 5.0012,\n",
      "        5.0011, 5.0012, 5.0011, 5.0011, 5.0011, 5.0010, 5.0010, 5.0011, 5.0011,\n",
      "        5.0011, 5.0011, 5.0011, 5.0011, 5.0010, 5.0010, 5.0010, 5.0010, 5.0011,\n",
      "        5.0011, 5.0011, 5.0011, 5.0012, 5.0011, 5.0010, 5.0010, 5.0011, 5.0011,\n",
      "        5.0010, 5.0010, 5.0010, 5.0012, 5.0011, 5.0011, 5.0011, 5.0011, 5.0011,\n",
      "        5.0011, 5.0010, 5.0010, 5.0010, 5.0010, 5.0010, 5.0010, 5.0010, 5.0011,\n",
      "        5.0011, 5.0010, 5.0010, 5.0010, 5.0011, 5.0010, 5.0010, 5.0010, 5.0010,\n",
      "        5.0011, 5.0010, 5.0010, 5.0010, 5.0010, 5.0009, 5.0011, 5.0009, 5.0009,\n",
      "        5.0009, 5.0010, 5.0010, 5.0009, 5.0009, 5.0010, 5.0010, 5.0010, 5.0010,\n",
      "        5.0010, 5.0010, 5.0011, 5.0010, 5.0010, 5.0010, 5.0010, 5.0011, 5.0010,\n",
      "        5.0009, 5.0009, 5.0010, 5.0010, 5.0010, 5.0010, 5.0009, 5.0009, 5.0010,\n",
      "        5.0010, 5.0010, 5.0010, 5.0008, 5.0008, 5.0008, 5.0008, 5.0009, 5.0010,\n",
      "        5.0009, 5.0009, 5.0009], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.498225  [2170124/5599865]\n",
      "average delta from current occupancy tensor([4.3963, 4.3961, 4.3961, 4.3962, 4.3962, 4.3961, 4.3961, 4.3961, 4.3958,\n",
      "        4.3960, 4.3960, 4.3961, 4.3960, 4.3960, 4.3961, 4.3961, 4.3963, 4.3964,\n",
      "        4.3964, 4.3963, 4.3962, 4.3962, 4.3963, 4.3961, 4.3962, 4.3960, 4.3958,\n",
      "        4.3958, 4.3959, 4.3957, 4.3961, 4.3962, 4.3957, 4.3957, 4.3961, 4.3961,\n",
      "        4.3960, 4.3962, 4.3962, 4.3963, 4.3962, 4.3957, 4.3960, 4.3961, 4.3960,\n",
      "        4.3962, 4.3961, 4.3961, 4.3962, 4.3963, 4.3961, 4.3960, 4.3961, 4.3960,\n",
      "        4.3959, 4.3959, 4.3959, 4.3958, 4.3960, 4.3960, 4.3959, 4.3961, 4.3961,\n",
      "        4.3960, 4.3960, 4.3960, 4.3959, 4.3958, 4.3954, 4.3954, 4.3959, 4.3960,\n",
      "        4.3957, 4.3960, 4.3959, 4.3960, 4.3955, 4.3958, 4.3959, 4.3955, 4.3959,\n",
      "        4.3956, 4.3959, 4.3957, 4.3955, 4.3956, 4.3959, 4.3960, 4.3960, 4.3961,\n",
      "        4.3959, 4.3960, 4.3960, 4.3960, 4.3961, 4.3960, 4.3961, 4.3962, 4.3961,\n",
      "        4.3959, 4.3959, 4.3959, 4.3960, 4.3960, 4.3960, 4.3959, 4.3959, 4.3961,\n",
      "        4.3961, 4.3960, 4.3960, 4.3959, 4.3959, 4.3960, 4.3958, 4.3959, 4.3958,\n",
      "        4.3960, 4.3959, 4.3959], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.784838  [2182524/5599865]\n",
      "average delta from current occupancy tensor([4.5252, 4.5251, 4.5252, 4.5253, 4.5254, 4.5251, 4.5254, 4.5253, 4.5257,\n",
      "        4.5255, 4.5254, 4.5255, 4.5258, 4.5257, 4.5255, 4.5254, 4.5254, 4.5254,\n",
      "        4.5254, 4.5255, 4.5254, 4.5254, 4.5254, 4.5254, 4.5253, 4.5257, 4.5259,\n",
      "        4.5259, 4.5258, 4.5259, 4.5256, 4.5253, 4.5259, 4.5258, 4.5254, 4.5251,\n",
      "        4.5253, 4.5252, 4.5252, 4.5252, 4.5253, 4.5259, 4.5256, 4.5255, 4.5254,\n",
      "        4.5255, 4.5255, 4.5253, 4.5255, 4.5256, 4.5252, 4.5255, 4.5254, 4.5255,\n",
      "        4.5260, 4.5260, 4.5259, 4.5259, 4.5258, 4.5259, 4.5257, 4.5257, 4.5257,\n",
      "        4.5260, 4.5259, 4.5261, 4.5261, 4.5264, 4.5265, 4.5265, 4.5261, 4.5261,\n",
      "        4.5263, 4.5259, 4.5260, 4.5259, 4.5265, 4.5265, 4.5262, 4.5265, 4.5264,\n",
      "        4.5265, 4.5261, 4.5263, 4.5264, 4.5263, 4.5262, 4.5260, 4.5260, 4.5260,\n",
      "        4.5258, 4.5261, 4.5261, 4.5260, 4.5261, 4.5260, 4.5259, 4.5260, 4.5261,\n",
      "        4.5263, 4.5260, 4.5262, 4.5261, 4.5260, 4.5259, 4.5261, 4.5261, 4.5258,\n",
      "        4.5260, 4.5262, 4.5263, 4.5263, 4.5266, 4.5263, 4.5266, 4.5263, 4.5262,\n",
      "        4.5262, 4.5266, 4.5266], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.369614  [2194924/5599865]\n",
      "average delta from current occupancy tensor([4.2932, 4.2932, 4.2932, 4.2933, 4.2931, 4.2933, 4.2930, 4.2933, 4.2933,\n",
      "        4.2930, 4.2930, 4.2929, 4.2932, 4.2931, 4.2928, 4.2932, 4.2931, 4.2931,\n",
      "        4.2931, 4.2930, 4.2931, 4.2931, 4.2931, 4.2929, 4.2929, 4.2924, 4.2929,\n",
      "        4.2928, 4.2926, 4.2928, 4.2929, 4.2929, 4.2929, 4.2927, 4.2929, 4.2931,\n",
      "        4.2928, 4.2930, 4.2930, 4.2930, 4.2928, 4.2926, 4.2929, 4.2930, 4.2932,\n",
      "        4.2931, 4.2930, 4.2928, 4.2928, 4.2926, 4.2928, 4.2926, 4.2926, 4.2926,\n",
      "        4.2922, 4.2923, 4.2922, 4.2919, 4.2922, 4.2924, 4.2924, 4.2927, 4.2926,\n",
      "        4.2923, 4.2924, 4.2923, 4.2923, 4.2926, 4.2925, 4.2925, 4.2924, 4.2925,\n",
      "        4.2927, 4.2922, 4.2922, 4.2923, 4.2927, 4.2929, 4.2925, 4.2927, 4.2928,\n",
      "        4.2929, 4.2925, 4.2926, 4.2928, 4.2926, 4.2925, 4.2922, 4.2921, 4.2921,\n",
      "        4.2921, 4.2925, 4.2924, 4.2924, 4.2925, 4.2923, 4.2923, 4.2924, 4.2926,\n",
      "        4.2928, 4.2925, 4.2926, 4.2926, 4.2923, 4.2925, 4.2923, 4.2922, 4.2928,\n",
      "        4.2921, 4.2924, 4.2925, 4.2925, 4.2929, 4.2926, 4.2929, 4.2926, 4.2926,\n",
      "        4.2923, 4.2928, 4.2929], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.237335  [2207324/5599865]\n",
      "average delta from current occupancy tensor([5.1045, 5.1046, 5.1046, 5.1046, 5.1046, 5.1045, 5.1046, 5.1046, 5.1046,\n",
      "        5.1045, 5.1045, 5.1045, 5.1045, 5.1044, 5.1046, 5.1044, 5.1046, 5.1045,\n",
      "        5.1045, 5.1046, 5.1045, 5.1045, 5.1044, 5.1046, 5.1045, 5.1045, 5.1046,\n",
      "        5.1045, 5.1046, 5.1046, 5.1045, 5.1045, 5.1045, 5.1045, 5.1046, 5.1045,\n",
      "        5.1046, 5.1046, 5.1045, 5.1046, 5.1046, 5.1044, 5.1045, 5.1046, 5.1046,\n",
      "        5.1044, 5.1046, 5.1046, 5.1046, 5.1046, 5.1045, 5.1047, 5.1046, 5.1046,\n",
      "        5.1045, 5.1047, 5.1045, 5.1045, 5.1045, 5.1046, 5.1046, 5.1046, 5.1044,\n",
      "        5.1046, 5.1044, 5.1046, 5.1045, 5.1044, 5.1044, 5.1046, 5.1045, 5.1046,\n",
      "        5.1045, 5.1045, 5.1045, 5.1046, 5.1045, 5.1046, 5.1046, 5.1045, 5.1046,\n",
      "        5.1045, 5.1045, 5.1045, 5.1046, 5.1045, 5.1045, 5.1045, 5.1045, 5.1045,\n",
      "        5.1045, 5.1045, 5.1046, 5.1044, 5.1046, 5.1045, 5.1045, 5.1045, 5.1046,\n",
      "        5.1046, 5.1046, 5.1047, 5.1046, 5.1045, 5.1046, 5.1045, 5.1045, 5.1044,\n",
      "        5.1045, 5.1045, 5.1046, 5.1045, 5.1044, 5.1046, 5.1044, 5.1046, 5.1045,\n",
      "        5.1044, 5.1045, 5.1045], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.185473  [2219724/5599865]\n",
      "average delta from current occupancy tensor([4.2089, 4.2088, 4.2089, 4.2088, 4.2089, 4.2089, 4.2090, 4.2089, 4.2090,\n",
      "        4.2090, 4.2090, 4.2089, 4.2091, 4.2087, 4.2091, 4.2090, 4.2089, 4.2090,\n",
      "        4.2091, 4.2089, 4.2089, 4.2088, 4.2088, 4.2089, 4.2089, 4.2087, 4.2088,\n",
      "        4.2085, 4.2089, 4.2088, 4.2085, 4.2085, 4.2087, 4.2085, 4.2085, 4.2084,\n",
      "        4.2085, 4.2087, 4.2090, 4.2089, 4.2089, 4.2086, 4.2086, 4.2087, 4.2087,\n",
      "        4.2088, 4.2087, 4.2087, 4.2088, 4.2089, 4.2089, 4.2089, 4.2089, 4.2087,\n",
      "        4.2087, 4.2087, 4.2085, 4.2087, 4.2086, 4.2088, 4.2089, 4.2085, 4.2085,\n",
      "        4.2084, 4.2083, 4.2085, 4.2086, 4.2085, 4.2083, 4.2086, 4.2085, 4.2085,\n",
      "        4.2088, 4.2086, 4.2086, 4.2083, 4.2087, 4.2086, 4.2087, 4.2087, 4.2084,\n",
      "        4.2086, 4.2084, 4.2084, 4.2087, 4.2083, 4.2084, 4.2084, 4.2084, 4.2084,\n",
      "        4.2085, 4.2086, 4.2086, 4.2085, 4.2088, 4.2086, 4.2086, 4.2086, 4.2088,\n",
      "        4.2087, 4.2087, 4.2087, 4.2087, 4.2085, 4.2087, 4.2087, 4.2087, 4.2086,\n",
      "        4.2088, 4.2089, 4.2090, 4.2088, 4.2085, 4.2086, 4.2082, 4.2083, 4.2085,\n",
      "        4.2080, 4.2084, 4.2084], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.717845  [2232124/5599865]\n",
      "average delta from current occupancy tensor([4.6130, 4.6130, 4.6129, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6129, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6129, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130, 4.6130,\n",
      "        4.6131, 4.6130, 4.6130], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.352868  [2244524/5599865]\n",
      "average delta from current occupancy tensor([5.3147, 5.3147, 5.3148, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3148, 5.3148,\n",
      "        5.3148, 5.3147, 5.3147, 5.3147, 5.3148, 5.3147, 5.3148, 5.3148, 5.3147,\n",
      "        5.3148, 5.3147, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148,\n",
      "        5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148,\n",
      "        5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148,\n",
      "        5.3148, 5.3148, 5.3148, 5.3147, 5.3148, 5.3148, 5.3148, 5.3148, 5.3148,\n",
      "        5.3148, 5.3148, 5.3148, 5.3148, 5.3148, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3148,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147, 5.3147, 5.3147, 5.3148, 5.3147, 5.3147, 5.3147,\n",
      "        5.3147, 5.3147, 5.3147], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.928861  [2256924/5599865]\n",
      "average delta from current occupancy tensor([4.8550, 4.8552, 4.8552, 4.8550, 4.8551, 4.8553, 4.8552, 4.8551, 4.8550,\n",
      "        4.8552, 4.8552, 4.8552, 4.8551, 4.8550, 4.8549, 4.8549, 4.8549, 4.8551,\n",
      "        4.8551, 4.8550, 4.8550, 4.8551, 4.8551, 4.8551, 4.8555, 4.8552, 4.8552,\n",
      "        4.8553, 4.8552, 4.8553, 4.8552, 4.8552, 4.8550, 4.8550, 4.8550, 4.8551,\n",
      "        4.8551, 4.8551, 4.8552, 4.8552, 4.8552, 4.8552, 4.8552, 4.8553, 4.8553,\n",
      "        4.8553, 4.8555, 4.8553, 4.8552, 4.8551, 4.8554, 4.8551, 4.8551, 4.8549,\n",
      "        4.8552, 4.8552, 4.8551, 4.8550, 4.8550, 4.8550, 4.8551, 4.8551, 4.8552,\n",
      "        4.8552, 4.8552, 4.8552, 4.8554, 4.8552, 4.8552, 4.8551, 4.8550, 4.8550,\n",
      "        4.8551, 4.8551, 4.8552, 4.8552, 4.8553, 4.8552, 4.8553, 4.8553, 4.8552,\n",
      "        4.8553, 4.8554, 4.8552, 4.8552, 4.8552, 4.8550, 4.8551, 4.8551, 4.8552,\n",
      "        4.8551, 4.8552, 4.8552, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8547, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8550,\n",
      "        4.8548, 4.8551, 4.8551, 4.8549, 4.8551, 4.8551, 4.8552, 4.8552, 4.8551,\n",
      "        4.8552, 4.8551, 4.8553], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.330284  [2269324/5599865]\n",
      "average delta from current occupancy tensor([5.2743, 5.2744, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2744, 5.2743, 5.2745,\n",
      "        5.2744, 5.2744, 5.2745, 5.2746, 5.2746, 5.2746, 5.2747, 5.2746, 5.2746,\n",
      "        5.2747, 5.2746, 5.2747, 5.2746, 5.2746, 5.2746, 5.2745, 5.2745, 5.2746,\n",
      "        5.2747, 5.2746, 5.2746, 5.2747, 5.2746, 5.2747, 5.2747, 5.2747, 5.2746,\n",
      "        5.2746, 5.2746, 5.2746, 5.2746, 5.2746, 5.2745, 5.2746, 5.2745, 5.2745,\n",
      "        5.2746, 5.2746, 5.2746, 5.2745, 5.2745, 5.2746, 5.2745, 5.2746, 5.2746,\n",
      "        5.2746, 5.2746, 5.2746, 5.2746, 5.2746, 5.2746, 5.2746, 5.2746, 5.2746,\n",
      "        5.2746, 5.2745, 5.2746, 5.2746, 5.2746, 5.2746, 5.2747, 5.2747, 5.2747,\n",
      "        5.2747, 5.2747, 5.2747, 5.2747, 5.2747, 5.2747, 5.2747, 5.2748, 5.2748,\n",
      "        5.2748, 5.2749, 5.2749, 5.2748, 5.2749, 5.2748, 5.2748, 5.2748, 5.2749,\n",
      "        5.2749, 5.2749, 5.2749, 5.2749, 5.2748, 5.2749, 5.2748, 5.2748, 5.2749,\n",
      "        5.2749, 5.2750, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749,\n",
      "        5.2749, 5.2748, 5.2748], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.135086  [2281724/5599865]\n",
      "average delta from current occupancy tensor([4.1214, 4.1214, 4.1213, 4.1215, 4.1215, 4.1213, 4.1214, 4.1213, 4.1214,\n",
      "        4.1212, 4.1213, 4.1214, 4.1212, 4.1214, 4.1214, 4.1214, 4.1214, 4.1214,\n",
      "        4.1215, 4.1214, 4.1213, 4.1213, 4.1213, 4.1214, 4.1214, 4.1214, 4.1215,\n",
      "        4.1214, 4.1215, 4.1215, 4.1216, 4.1214, 4.1215, 4.1214, 4.1216, 4.1215,\n",
      "        4.1216, 4.1217, 4.1215, 4.1216, 4.1216, 4.1216, 4.1217, 4.1216, 4.1216,\n",
      "        4.1217, 4.1217, 4.1219, 4.1218, 4.1217, 4.1215, 4.1216, 4.1216, 4.1216,\n",
      "        4.1215, 4.1215, 4.1214, 4.1212, 4.1214, 4.1215, 4.1215, 4.1215, 4.1216,\n",
      "        4.1216, 4.1216, 4.1216, 4.1215, 4.1213, 4.1213, 4.1214, 4.1213, 4.1212,\n",
      "        4.1214, 4.1210, 4.1213, 4.1213, 4.1214, 4.1215, 4.1215, 4.1214, 4.1214,\n",
      "        4.1215, 4.1214, 4.1214, 4.1214, 4.1212, 4.1214, 4.1213, 4.1213, 4.1214,\n",
      "        4.1214, 4.1211, 4.1210, 4.1213, 4.1213, 4.1213, 4.1213, 4.1213, 4.1212,\n",
      "        4.1210, 4.1210, 4.1212, 4.1214, 4.1213, 4.1212, 4.1213, 4.1213, 4.1214,\n",
      "        4.1212, 4.1213, 4.1215, 4.1215, 4.1215, 4.1216, 4.1215, 4.1216, 4.1214,\n",
      "        4.1215, 4.1215, 4.1214], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.621904  [2294124/5599865]\n",
      "average delta from current occupancy tensor([5.4514, 5.4514, 5.4514, 5.4513, 5.4514, 5.4515, 5.4514, 5.4515, 5.4515,\n",
      "        5.4514, 5.4514, 5.4514, 5.4514, 5.4514, 5.4515, 5.4514, 5.4514, 5.4513,\n",
      "        5.4514, 5.4515, 5.4515, 5.4514, 5.4515, 5.4515, 5.4515, 5.4514, 5.4514,\n",
      "        5.4514, 5.4514, 5.4514, 5.4514, 5.4515, 5.4515, 5.4515, 5.4514, 5.4514,\n",
      "        5.4515, 5.4515, 5.4514, 5.4514, 5.4515, 5.4514, 5.4514, 5.4514, 5.4513,\n",
      "        5.4514, 5.4513, 5.4514, 5.4514, 5.4514, 5.4514, 5.4514, 5.4514, 5.4514,\n",
      "        5.4514, 5.4513, 5.4513, 5.4513, 5.4514, 5.4514, 5.4514, 5.4514, 5.4514,\n",
      "        5.4514, 5.4513, 5.4514, 5.4513, 5.4514, 5.4514, 5.4514, 5.4513, 5.4514,\n",
      "        5.4514, 5.4514, 5.4513, 5.4514, 5.4513, 5.4513, 5.4515, 5.4514, 5.4514,\n",
      "        5.4514, 5.4514, 5.4514, 5.4514, 5.4513, 5.4514, 5.4514, 5.4514, 5.4514,\n",
      "        5.4514, 5.4514, 5.4514, 5.4515, 5.4514, 5.4513, 5.4513, 5.4513, 5.4514,\n",
      "        5.4514, 5.4514, 5.4513, 5.4514, 5.4513, 5.4514, 5.4513, 5.4513, 5.4513,\n",
      "        5.4513, 5.4514, 5.4514, 5.4514, 5.4514, 5.4513, 5.4513, 5.4515, 5.4514,\n",
      "        5.4513, 5.4515, 5.4514], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.584374  [2306524/5599865]\n",
      "average delta from current occupancy tensor([4.7740, 4.7740, 4.7741, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740,\n",
      "        4.7740, 4.7740, 4.7739, 4.7740, 4.7740, 4.7740, 4.7739, 4.7740, 4.7739,\n",
      "        4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740,\n",
      "        4.7740, 4.7740, 4.7741, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740,\n",
      "        4.7740, 4.7740, 4.7740, 4.7741, 4.7741, 4.7740, 4.7740, 4.7740, 4.7740,\n",
      "        4.7740, 4.7741, 4.7740, 4.7740, 4.7741, 4.7740, 4.7741, 4.7741, 4.7741,\n",
      "        4.7740, 4.7740, 4.7740, 4.7740, 4.7741, 4.7741, 4.7740, 4.7740, 4.7740,\n",
      "        4.7740, 4.7740, 4.7741, 4.7741, 4.7741, 4.7741, 4.7741, 4.7741, 4.7741,\n",
      "        4.7741, 4.7741, 4.7741, 4.7740, 4.7740, 4.7741, 4.7741, 4.7740, 4.7741,\n",
      "        4.7741, 4.7740, 4.7741, 4.7741, 4.7740, 4.7740, 4.7740, 4.7740, 4.7741,\n",
      "        4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740,\n",
      "        4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7740, 4.7739, 4.7739, 4.7740,\n",
      "        4.7740, 4.7739, 4.7739, 4.7740, 4.7739, 4.7739, 4.7739, 4.7740, 4.7740,\n",
      "        4.7740, 4.7740, 4.7740], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.390315  [2318924/5599865]\n",
      "average delta from current occupancy tensor([5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.429469  [2331324/5599865]\n",
      "average delta from current occupancy tensor([5.3536, 5.3536, 5.3536, 5.3535, 5.3535, 5.3536, 5.3536, 5.3536, 5.3537,\n",
      "        5.3537, 5.3537, 5.3537, 5.3536, 5.3536, 5.3536, 5.3536, 5.3536, 5.3537,\n",
      "        5.3537, 5.3537, 5.3537, 5.3536, 5.3536, 5.3537, 5.3537, 5.3537, 5.3537,\n",
      "        5.3538, 5.3537, 5.3537, 5.3536, 5.3537, 5.3536, 5.3537, 5.3537, 5.3537,\n",
      "        5.3537, 5.3537, 5.3537, 5.3536, 5.3537, 5.3537, 5.3537, 5.3536, 5.3537,\n",
      "        5.3537, 5.3536, 5.3537, 5.3537, 5.3536, 5.3537, 5.3537, 5.3536, 5.3537,\n",
      "        5.3537, 5.3536, 5.3536, 5.3536, 5.3536, 5.3536, 5.3536, 5.3536, 5.3535,\n",
      "        5.3535, 5.3536, 5.3535, 5.3536, 5.3536, 5.3536, 5.3536, 5.3536, 5.3536,\n",
      "        5.3536, 5.3536, 5.3537, 5.3536, 5.3536, 5.3536, 5.3537, 5.3537, 5.3537,\n",
      "        5.3537, 5.3537, 5.3538, 5.3537, 5.3537, 5.3538, 5.3538, 5.3537, 5.3537,\n",
      "        5.3538, 5.3537, 5.3537, 5.3537, 5.3537, 5.3537, 5.3537, 5.3536, 5.3537,\n",
      "        5.3537, 5.3537, 5.3538, 5.3537, 5.3538, 5.3538, 5.3538, 5.3538, 5.3538,\n",
      "        5.3538, 5.3538, 5.3538, 5.3537, 5.3537, 5.3538, 5.3538, 5.3538, 5.3539,\n",
      "        5.3538, 5.3538, 5.3538], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.968456  [2343724/5599865]\n",
      "average delta from current occupancy tensor([4.8188, 4.8186, 4.8186, 4.8183, 4.8184, 4.8185, 4.8186, 4.8187, 4.8189,\n",
      "        4.8189, 4.8189, 4.8188, 4.8188, 4.8186, 4.8188, 4.8187, 4.8187, 4.8189,\n",
      "        4.8191, 4.8190, 4.8190, 4.8190, 4.8192, 4.8193, 4.8191, 4.8190, 4.8192,\n",
      "        4.8193, 4.8191, 4.8192, 4.8192, 4.8191, 4.8190, 4.8191, 4.8192, 4.8191,\n",
      "        4.8191, 4.8191, 4.8190, 4.8189, 4.8190, 4.8190, 4.8190, 4.8190, 4.8191,\n",
      "        4.8190, 4.8190, 4.8191, 4.8191, 4.8192, 4.8191, 4.8191, 4.8191, 4.8192,\n",
      "        4.8192, 4.8191, 4.8191, 4.8191, 4.8190, 4.8189, 4.8189, 4.8189, 4.8189,\n",
      "        4.8187, 4.8188, 4.8187, 4.8188, 4.8189, 4.8188, 4.8188, 4.8188, 4.8188,\n",
      "        4.8188, 4.8190, 4.8190, 4.8188, 4.8189, 4.8190, 4.8191, 4.8189, 4.8190,\n",
      "        4.8190, 4.8190, 4.8192, 4.8192, 4.8191, 4.8191, 4.8191, 4.8191, 4.8188,\n",
      "        4.8190, 4.8190, 4.8190, 4.8189, 4.8189, 4.8190, 4.8189, 4.8190, 4.8191,\n",
      "        4.8193, 4.8194, 4.8193, 4.8193, 4.8196, 4.8196, 4.8198, 4.8198, 4.8197,\n",
      "        4.8197, 4.8196, 4.8196, 4.8197, 4.8195, 4.8195, 4.8197, 4.8196, 4.8196,\n",
      "        4.8194, 4.8194, 4.8194], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.418396  [2356124/5599865]\n",
      "average delta from current occupancy tensor([5.3601, 5.3600, 5.3600, 5.3597, 5.3596, 5.3596, 5.3599, 5.3600, 5.3600,\n",
      "        5.3600, 5.3600, 5.3599, 5.3599, 5.3597, 5.3599, 5.3599, 5.3599, 5.3602,\n",
      "        5.3603, 5.3603, 5.3602, 5.3602, 5.3605, 5.3607, 5.3604, 5.3604, 5.3605,\n",
      "        5.3607, 5.3605, 5.3606, 5.3606, 5.3605, 5.3605, 5.3605, 5.3606, 5.3604,\n",
      "        5.3604, 5.3603, 5.3602, 5.3600, 5.3600, 5.3602, 5.3601, 5.3601, 5.3602,\n",
      "        5.3601, 5.3600, 5.3603, 5.3604, 5.3605, 5.3606, 5.3605, 5.3605, 5.3605,\n",
      "        5.3603, 5.3604, 5.3603, 5.3603, 5.3602, 5.3602, 5.3602, 5.3604, 5.3604,\n",
      "        5.3603, 5.3604, 5.3602, 5.3603, 5.3605, 5.3604, 5.3604, 5.3604, 5.3603,\n",
      "        5.3603, 5.3604, 5.3605, 5.3603, 5.3603, 5.3605, 5.3605, 5.3604, 5.3605,\n",
      "        5.3605, 5.3604, 5.3605, 5.3606, 5.3605, 5.3606, 5.3606, 5.3605, 5.3603,\n",
      "        5.3605, 5.3605, 5.3605, 5.3604, 5.3605, 5.3606, 5.3605, 5.3605, 5.3606,\n",
      "        5.3608, 5.3609, 5.3607, 5.3608, 5.3610, 5.3611, 5.3612, 5.3613, 5.3613,\n",
      "        5.3614, 5.3613, 5.3613, 5.3615, 5.3614, 5.3614, 5.3616, 5.3616, 5.3615,\n",
      "        5.3613, 5.3614, 5.3616], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.228889  [2368524/5599865]\n",
      "average delta from current occupancy tensor([5.2261, 5.2261, 5.2261, 5.2260, 5.2261, 5.2261, 5.2260, 5.2261, 5.2261,\n",
      "        5.2261, 5.2262, 5.2260, 5.2260, 5.2260, 5.2260, 5.2260, 5.2260, 5.2261,\n",
      "        5.2260, 5.2261, 5.2262, 5.2262, 5.2261, 5.2261, 5.2260, 5.2262, 5.2262,\n",
      "        5.2261, 5.2262, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261,\n",
      "        5.2262, 5.2262, 5.2261, 5.2261, 5.2262, 5.2261, 5.2261, 5.2261, 5.2261,\n",
      "        5.2261, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261, 5.2261,\n",
      "        5.2260, 5.2261, 5.2260, 5.2260, 5.2260, 5.2261, 5.2261, 5.2261, 5.2261,\n",
      "        5.2261, 5.2262, 5.2261, 5.2260, 5.2260, 5.2261, 5.2261, 5.2260, 5.2260,\n",
      "        5.2260, 5.2261, 5.2261, 5.2261, 5.2261, 5.2260, 5.2260, 5.2262, 5.2261,\n",
      "        5.2261, 5.2260, 5.2260, 5.2260, 5.2260, 5.2260, 5.2260, 5.2261, 5.2260,\n",
      "        5.2260, 5.2260, 5.2260, 5.2261, 5.2260, 5.2260, 5.2260, 5.2259, 5.2261,\n",
      "        5.2260, 5.2260, 5.2260, 5.2261, 5.2260, 5.2260, 5.2260, 5.2260, 5.2261,\n",
      "        5.2262, 5.2261, 5.2261, 5.2261, 5.2262, 5.2261, 5.2261, 5.2261, 5.2261,\n",
      "        5.2261, 5.2260, 5.2261], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.880310  [2380924/5599865]\n",
      "average delta from current occupancy tensor([5.0411, 5.0412, 5.0410, 5.0410, 5.0409, 5.0408, 5.0408, 5.0409, 5.0409,\n",
      "        5.0409, 5.0408, 5.0410, 5.0410, 5.0409, 5.0411, 5.0409, 5.0410, 5.0409,\n",
      "        5.0410, 5.0410, 5.0409, 5.0410, 5.0410, 5.0408, 5.0410, 5.0410, 5.0412,\n",
      "        5.0408, 5.0411, 5.0409, 5.0410, 5.0410, 5.0409, 5.0409, 5.0409, 5.0410,\n",
      "        5.0413, 5.0412, 5.0411, 5.0411, 5.0413, 5.0411, 5.0410, 5.0413, 5.0411,\n",
      "        5.0413, 5.0414, 5.0411, 5.0412, 5.0413, 5.0413, 5.0410, 5.0409, 5.0411,\n",
      "        5.0411, 5.0410, 5.0410, 5.0410, 5.0410, 5.0410, 5.0409, 5.0411, 5.0410,\n",
      "        5.0411, 5.0410, 5.0413, 5.0411, 5.0411, 5.0411, 5.0413, 5.0411, 5.0410,\n",
      "        5.0411, 5.0412, 5.0413, 5.0412, 5.0412, 5.0411, 5.0411, 5.0415, 5.0411,\n",
      "        5.0410, 5.0410, 5.0411, 5.0412, 5.0409, 5.0408, 5.0407, 5.0408, 5.0408,\n",
      "        5.0409, 5.0407, 5.0410, 5.0409, 5.0409, 5.0409, 5.0408, 5.0409, 5.0409,\n",
      "        5.0409, 5.0408, 5.0408, 5.0409, 5.0412, 5.0413, 5.0413, 5.0413, 5.0413,\n",
      "        5.0413, 5.0414, 5.0414, 5.0413, 5.0414, 5.0413, 5.0412, 5.0414, 5.0414,\n",
      "        5.0414, 5.0414, 5.0413], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.599897  [2393324/5599865]\n",
      "average delta from current occupancy tensor([5.5324, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323,\n",
      "        5.5323, 5.5324, 5.5323, 5.5324, 5.5324, 5.5324, 5.5323, 5.5324, 5.5325,\n",
      "        5.5324, 5.5323, 5.5323, 5.5324, 5.5324, 5.5323, 5.5324, 5.5323, 5.5323,\n",
      "        5.5324, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323,\n",
      "        5.5323, 5.5324, 5.5324, 5.5324, 5.5323, 5.5323, 5.5324, 5.5324, 5.5323,\n",
      "        5.5323, 5.5323, 5.5324, 5.5323, 5.5324, 5.5324, 5.5324, 5.5324, 5.5325,\n",
      "        5.5325, 5.5325, 5.5325, 5.5324, 5.5325, 5.5325, 5.5324, 5.5324, 5.5324,\n",
      "        5.5324, 5.5324, 5.5324, 5.5325, 5.5324, 5.5324, 5.5324, 5.5324, 5.5324,\n",
      "        5.5324, 5.5324, 5.5324, 5.5323, 5.5324, 5.5323, 5.5323, 5.5323, 5.5323,\n",
      "        5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323,\n",
      "        5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323, 5.5323,\n",
      "        5.5323, 5.5323, 5.5323, 5.5324, 5.5324, 5.5324, 5.5324, 5.5324, 5.5323,\n",
      "        5.5323, 5.5324, 5.5324, 5.5325, 5.5323, 5.5324, 5.5323, 5.5325, 5.5323,\n",
      "        5.5323, 5.5324, 5.5324], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.785419  [2405724/5599865]\n",
      "average delta from current occupancy tensor([4.6277, 4.6274, 4.6277, 4.6276, 4.6276, 4.6276, 4.6277, 4.6277, 4.6276,\n",
      "        4.6278, 4.6278, 4.6277, 4.6277, 4.6275, 4.6276, 4.6276, 4.6277, 4.6277,\n",
      "        4.6276, 4.6277, 4.6275, 4.6276, 4.6276, 4.6276, 4.6277, 4.6276, 4.6277,\n",
      "        4.6278, 4.6276, 4.6277, 4.6277, 4.6275, 4.6275, 4.6276, 4.6276, 4.6275,\n",
      "        4.6276, 4.6276, 4.6275, 4.6274, 4.6277, 4.6275, 4.6276, 4.6274, 4.6276,\n",
      "        4.6277, 4.6277, 4.6275, 4.6276, 4.6277, 4.6275, 4.6277, 4.6276, 4.6276,\n",
      "        4.6277, 4.6276, 4.6275, 4.6278, 4.6277, 4.6277, 4.6277, 4.6278, 4.6276,\n",
      "        4.6276, 4.6275, 4.6277, 4.6276, 4.6275, 4.6275, 4.6276, 4.6276, 4.6276,\n",
      "        4.6276, 4.6277, 4.6277, 4.6276, 4.6275, 4.6276, 4.6276, 4.6278, 4.6278,\n",
      "        4.6278, 4.6279, 4.6277, 4.6277, 4.6279, 4.6279, 4.6278, 4.6278, 4.6278,\n",
      "        4.6278, 4.6278, 4.6279, 4.6278, 4.6279, 4.6280, 4.6279, 4.6279, 4.6279,\n",
      "        4.6277, 4.6276, 4.6277, 4.6277, 4.6279, 4.6279, 4.6279, 4.6277, 4.6278,\n",
      "        4.6277, 4.6278, 4.6278, 4.6279, 4.6279, 4.6279, 4.6281, 4.6278, 4.6277,\n",
      "        4.6278, 4.6279, 4.6276], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.808558  [2418124/5599865]\n",
      "average delta from current occupancy tensor([5.6735, 5.6739, 5.6733, 5.6735, 5.6738, 5.6734, 5.6733, 5.6729, 5.6732,\n",
      "        5.6735, 5.6732, 5.6733, 5.6736, 5.6736, 5.6731, 5.6731, 5.6727, 5.6728,\n",
      "        5.6729, 5.6727, 5.6728, 5.6728, 5.6729, 5.6729, 5.6734, 5.6733, 5.6733,\n",
      "        5.6736, 5.6732, 5.6735, 5.6730, 5.6729, 5.6730, 5.6728, 5.6725, 5.6725,\n",
      "        5.6731, 5.6733, 5.6725, 5.6726, 5.6730, 5.6732, 5.6733, 5.6728, 5.6732,\n",
      "        5.6729, 5.6732, 5.6727, 5.6735, 5.6735, 5.6736, 5.6734, 5.6734, 5.6730,\n",
      "        5.6732, 5.6733, 5.6732, 5.6734, 5.6732, 5.6732, 5.6731, 5.6732, 5.6730,\n",
      "        5.6730, 5.6726, 5.6727, 5.6726, 5.6725, 5.6722, 5.6723, 5.6725, 5.6722,\n",
      "        5.6724, 5.6727, 5.6727, 5.6730, 5.6729, 5.6727, 5.6728, 5.6728, 5.6728,\n",
      "        5.6728, 5.6728, 5.6727, 5.6725, 5.6726, 5.6726, 5.6726, 5.6726, 5.6728,\n",
      "        5.6726, 5.6726, 5.6728, 5.6724, 5.6723, 5.6722, 5.6721, 5.6723, 5.6723,\n",
      "        5.6722, 5.6721, 5.6723, 5.6725, 5.6727, 5.6725, 5.6726, 5.6726, 5.6724,\n",
      "        5.6725, 5.6724, 5.6725, 5.6729, 5.6729, 5.6730, 5.6732, 5.6728, 5.6727,\n",
      "        5.6727, 5.6724, 5.6724], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.942910  [2430524/5599865]\n",
      "average delta from current occupancy tensor([4.9114, 4.9114, 4.9114, 4.9113, 4.9113, 4.9113, 4.9114, 4.9113, 4.9113,\n",
      "        4.9113, 4.9114, 4.9114, 4.9113, 4.9113, 4.9114, 4.9114, 4.9115, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9114,\n",
      "        4.9114, 4.9113, 4.9114, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113,\n",
      "        4.9113, 4.9112, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113,\n",
      "        4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9114, 4.9114, 4.9114, 4.9113,\n",
      "        4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9114, 4.9113, 4.9113, 4.9114,\n",
      "        4.9113, 4.9113, 4.9114, 4.9113, 4.9113, 4.9114, 4.9113, 4.9113, 4.9113,\n",
      "        4.9114, 4.9113, 4.9113, 4.9113, 4.9113, 4.9114, 4.9113, 4.9114, 4.9113,\n",
      "        4.9113, 4.9113, 4.9113, 4.9114, 4.9113, 4.9113, 4.9113, 4.9113, 4.9113,\n",
      "        4.9113, 4.9113, 4.9113, 4.9113, 4.9113, 4.9114, 4.9113, 4.9113, 4.9114,\n",
      "        4.9114, 4.9114, 4.9114, 4.9114, 4.9113, 4.9114, 4.9114, 4.9114, 4.9114,\n",
      "        4.9113, 4.9113, 4.9114, 4.9113, 4.9114, 4.9113, 4.9113, 4.9114, 4.9114,\n",
      "        4.9113, 4.9114, 4.9113], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.178021  [2442924/5599865]\n",
      "average delta from current occupancy tensor([5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3146, 5.3146, 5.3145, 5.3145, 5.3145, 5.3145, 5.3146, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145, 5.3145,\n",
      "        5.3145, 5.3145, 5.3145], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.186379  [2455324/5599865]\n",
      "average delta from current occupancy tensor([5.0322, 5.0322, 5.0324, 5.0325, 5.0324, 5.0328, 5.0322, 5.0322, 5.0322,\n",
      "        5.0322, 5.0321, 5.0323, 5.0324, 5.0321, 5.0321, 5.0322, 5.0321, 5.0320,\n",
      "        5.0319, 5.0319, 5.0319, 5.0318, 5.0320, 5.0320, 5.0324, 5.0320, 5.0319,\n",
      "        5.0322, 5.0322, 5.0324, 5.0319, 5.0321, 5.0319, 5.0320, 5.0320, 5.0318,\n",
      "        5.0319, 5.0320, 5.0321, 5.0322, 5.0319, 5.0320, 5.0320, 5.0320, 5.0322,\n",
      "        5.0322, 5.0320, 5.0317, 5.0318, 5.0318, 5.0319, 5.0319, 5.0318, 5.0320,\n",
      "        5.0321, 5.0321, 5.0321, 5.0320, 5.0322, 5.0322, 5.0321, 5.0320, 5.0321,\n",
      "        5.0320, 5.0320, 5.0320, 5.0320, 5.0321, 5.0321, 5.0322, 5.0320, 5.0319,\n",
      "        5.0322, 5.0320, 5.0320, 5.0320, 5.0320, 5.0320, 5.0320, 5.0319, 5.0322,\n",
      "        5.0321, 5.0322, 5.0323, 5.0325, 5.0321, 5.0321, 5.0320, 5.0325, 5.0321,\n",
      "        5.0321, 5.0323, 5.0324, 5.0323, 5.0326, 5.0322, 5.0322, 5.0321, 5.0322,\n",
      "        5.0322, 5.0322, 5.0321, 5.0321, 5.0319, 5.0322, 5.0323, 5.0321, 5.0321,\n",
      "        5.0321, 5.0322, 5.0323, 5.0325, 5.0325, 5.0326, 5.0327, 5.0330, 5.0326,\n",
      "        5.0327, 5.0326, 5.0326], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.200091  [2467724/5599865]\n",
      "average delta from current occupancy tensor([5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4200, 5.4201, 5.4200,\n",
      "        5.4200, 5.4200, 5.4200, 5.4200, 5.4201, 5.4200, 5.4200, 5.4201, 5.4200,\n",
      "        5.4200, 5.4200, 5.4200, 5.4201, 5.4201, 5.4201, 5.4202, 5.4201, 5.4201,\n",
      "        5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201,\n",
      "        5.4202, 5.4202, 5.4201, 5.4201, 5.4201, 5.4201, 5.4202, 5.4201, 5.4202,\n",
      "        5.4201, 5.4202, 5.4202, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4200, 5.4200, 5.4200, 5.4200, 5.4201, 5.4201, 5.4201, 5.4200,\n",
      "        5.4201, 5.4201, 5.4200, 5.4201, 5.4200, 5.4201, 5.4201, 5.4200, 5.4200,\n",
      "        5.4200, 5.4200, 5.4200, 5.4199, 5.4199, 5.4200, 5.4200, 5.4200, 5.4200,\n",
      "        5.4200, 5.4200, 5.4200, 5.4199, 5.4199, 5.4199, 5.4199, 5.4200, 5.4199,\n",
      "        5.4199, 5.4199, 5.4200, 5.4200, 5.4200, 5.4199, 5.4199, 5.4199, 5.4200,\n",
      "        5.4200, 5.4200, 5.4199, 5.4200, 5.4199, 5.4200, 5.4200, 5.4201, 5.4199,\n",
      "        5.4199, 5.4199, 5.4200], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.839442  [2480124/5599865]\n",
      "average delta from current occupancy tensor([5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0243,\n",
      "        5.0242, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242,\n",
      "        5.0243, 5.0242, 5.0243, 5.0243, 5.0243, 5.0242, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243,\n",
      "        5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242, 5.0242,\n",
      "        5.0242, 5.0243, 5.0242, 5.0242, 5.0242, 5.0242, 5.0242, 5.0243, 5.0242,\n",
      "        5.0242, 5.0242, 5.0242], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.086646  [2492524/5599865]\n",
      "average delta from current occupancy tensor([5.1054, 5.1053, 5.1058, 5.1059, 5.1054, 5.1053, 5.1057, 5.1061, 5.1060,\n",
      "        5.1058, 5.1056, 5.1057, 5.1058, 5.1061, 5.1057, 5.1058, 5.1060, 5.1062,\n",
      "        5.1062, 5.1061, 5.1062, 5.1063, 5.1063, 5.1060, 5.1063, 5.1060, 5.1061,\n",
      "        5.1063, 5.1062, 5.1062, 5.1063, 5.1062, 5.1063, 5.1060, 5.1060, 5.1061,\n",
      "        5.1061, 5.1057, 5.1059, 5.1058, 5.1053, 5.1054, 5.1054, 5.1057, 5.1055,\n",
      "        5.1058, 5.1057, 5.1059, 5.1059, 5.1057, 5.1055, 5.1055, 5.1054, 5.1051,\n",
      "        5.1052, 5.1057, 5.1055, 5.1054, 5.1055, 5.1052, 5.1051, 5.1050, 5.1051,\n",
      "        5.1051, 5.1054, 5.1050, 5.1051, 5.1054, 5.1055, 5.1052, 5.1053, 5.1052,\n",
      "        5.1053, 5.1051, 5.1049, 5.1057, 5.1051, 5.1052, 5.1055, 5.1061, 5.1058,\n",
      "        5.1056, 5.1055, 5.1054, 5.1054, 5.1057, 5.1057, 5.1054, 5.1055, 5.1054,\n",
      "        5.1055, 5.1056, 5.1053, 5.1054, 5.1055, 5.1052, 5.1054, 5.1056, 5.1053,\n",
      "        5.1051, 5.1052, 5.1052, 5.1052, 5.1053, 5.1050, 5.1052, 5.1053, 5.1052,\n",
      "        5.1055, 5.1055, 5.1056, 5.1053, 5.1059, 5.1051, 5.1056, 5.1054, 5.1059,\n",
      "        5.1055, 5.1058, 5.1057], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.988532  [2504924/5599865]\n",
      "average delta from current occupancy tensor([5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.903031  [2517324/5599865]\n",
      "average delta from current occupancy tensor([4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.411685  [2529724/5599865]\n",
      "average delta from current occupancy tensor([5.5422, 5.5421, 5.5421, 5.5421, 5.5421, 5.5419, 5.5419, 5.5420, 5.5420,\n",
      "        5.5421, 5.5422, 5.5422, 5.5422, 5.5424, 5.5426, 5.5424, 5.5422, 5.5425,\n",
      "        5.5424, 5.5422, 5.5424, 5.5424, 5.5427, 5.5426, 5.5426, 5.5427, 5.5424,\n",
      "        5.5424, 5.5422, 5.5422, 5.5422, 5.5422, 5.5420, 5.5419, 5.5417, 5.5418,\n",
      "        5.5417, 5.5417, 5.5420, 5.5418, 5.5420, 5.5421, 5.5419, 5.5416, 5.5417,\n",
      "        5.5420, 5.5416, 5.5415, 5.5417, 5.5418, 5.5417, 5.5418, 5.5417, 5.5417,\n",
      "        5.5416, 5.5420, 5.5417, 5.5416, 5.5418, 5.5418, 5.5416, 5.5417, 5.5416,\n",
      "        5.5415, 5.5417, 5.5415, 5.5416, 5.5418, 5.5421, 5.5420, 5.5417, 5.5417,\n",
      "        5.5419, 5.5420, 5.5418, 5.5418, 5.5419, 5.5420, 5.5419, 5.5419, 5.5424,\n",
      "        5.5423, 5.5420, 5.5419, 5.5420, 5.5425, 5.5422, 5.5417, 5.5422, 5.5424,\n",
      "        5.5420, 5.5421, 5.5422, 5.5420, 5.5418, 5.5421, 5.5420, 5.5419, 5.5418,\n",
      "        5.5418, 5.5419, 5.5418, 5.5418, 5.5418, 5.5419, 5.5419, 5.5421, 5.5423,\n",
      "        5.5423, 5.5423, 5.5425, 5.5425, 5.5421, 5.5426, 5.5422, 5.5421, 5.5420,\n",
      "        5.5422, 5.5419, 5.5419], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.182125  [2542124/5599865]\n",
      "average delta from current occupancy tensor([5.1217, 5.1217, 5.1216, 5.1218, 5.1217, 5.1217, 5.1217, 5.1217, 5.1217,\n",
      "        5.1216, 5.1216, 5.1216, 5.1216, 5.1217, 5.1216, 5.1217, 5.1216, 5.1217,\n",
      "        5.1216, 5.1217, 5.1216, 5.1217, 5.1217, 5.1215, 5.1215, 5.1215, 5.1215,\n",
      "        5.1215, 5.1215, 5.1216, 5.1216, 5.1215, 5.1217, 5.1217, 5.1217, 5.1217,\n",
      "        5.1217, 5.1217, 5.1217, 5.1217, 5.1217, 5.1218, 5.1217, 5.1217, 5.1217,\n",
      "        5.1215, 5.1217, 5.1217, 5.1217, 5.1216, 5.1217, 5.1217, 5.1216, 5.1216,\n",
      "        5.1217, 5.1215, 5.1216, 5.1216, 5.1216, 5.1215, 5.1216, 5.1217, 5.1216,\n",
      "        5.1217, 5.1217, 5.1217, 5.1218, 5.1217, 5.1216, 5.1216, 5.1218, 5.1218,\n",
      "        5.1216, 5.1218, 5.1218, 5.1217, 5.1217, 5.1216, 5.1216, 5.1216, 5.1217,\n",
      "        5.1219, 5.1218, 5.1217, 5.1216, 5.1217, 5.1215, 5.1217, 5.1215, 5.1215,\n",
      "        5.1217, 5.1216, 5.1215, 5.1217, 5.1217, 5.1216, 5.1216, 5.1217, 5.1217,\n",
      "        5.1218, 5.1217, 5.1217, 5.1216, 5.1217, 5.1216, 5.1216, 5.1217, 5.1216,\n",
      "        5.1217, 5.1216, 5.1217, 5.1216, 5.1216, 5.1216, 5.1216, 5.1216, 5.1216,\n",
      "        5.1217, 5.1216, 5.1217], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.261580  [2554524/5599865]\n",
      "average delta from current occupancy tensor([5.2334, 5.2334, 5.2334, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333,\n",
      "        5.2333, 5.2334, 5.2334, 5.2334, 5.2333, 5.2334, 5.2333, 5.2334, 5.2333,\n",
      "        5.2334, 5.2333, 5.2334, 5.2333, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334,\n",
      "        5.2334, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2332, 5.2332, 5.2332,\n",
      "        5.2332, 5.2332, 5.2332, 5.2331, 5.2332, 5.2331, 5.2332, 5.2332, 5.2332,\n",
      "        5.2332, 5.2331, 5.2331, 5.2331, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332,\n",
      "        5.2332, 5.2332, 5.2333, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332,\n",
      "        5.2332, 5.2332, 5.2331, 5.2331, 5.2332, 5.2332, 5.2333, 5.2332, 5.2332,\n",
      "        5.2333, 5.2332, 5.2332, 5.2332, 5.2332, 5.2333, 5.2333, 5.2333, 5.2333,\n",
      "        5.2332, 5.2333, 5.2333, 5.2334, 5.2333, 5.2333, 5.2333, 5.2334, 5.2333,\n",
      "        5.2333, 5.2334, 5.2334, 5.2333, 5.2332, 5.2333, 5.2333, 5.2332, 5.2333,\n",
      "        5.2332, 5.2333, 5.2333, 5.2332, 5.2332, 5.2333, 5.2333, 5.2333, 5.2333,\n",
      "        5.2333, 5.2333, 5.2333, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334, 5.2334,\n",
      "        5.2334, 5.2334, 5.2334], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.131255  [2566924/5599865]\n",
      "average delta from current occupancy tensor([5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068, 5.3068,\n",
      "        5.3068, 5.3067, 5.3067, 5.3068, 5.3067, 5.3067, 5.3067, 5.3068, 5.3067,\n",
      "        5.3068, 5.3067, 5.3067, 5.3068, 5.3067, 5.3068, 5.3068, 5.3067, 5.3067,\n",
      "        5.3068, 5.3068, 5.3067, 5.3068, 5.3068, 5.3068, 5.3068, 5.3067, 5.3066,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3068, 5.3067, 5.3067, 5.3066, 5.3068, 5.3067, 5.3067, 5.3067, 5.3068,\n",
      "        5.3067, 5.3068, 5.3068, 5.3067, 5.3067, 5.3068, 5.3067, 5.3067, 5.3068,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3068, 5.3068, 5.3068, 5.3068, 5.3067,\n",
      "        5.3068, 5.3068, 5.3067, 5.3067, 5.3067, 5.3068, 5.3068, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3066, 5.3066, 5.3067, 5.3067,\n",
      "        5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067, 5.3068, 5.3067, 5.3068,\n",
      "        5.3068, 5.3068, 5.3069, 5.3068, 5.3068, 5.3067, 5.3068, 5.3068, 5.3068,\n",
      "        5.3067, 5.3067, 5.3067, 5.3068, 5.3067, 5.3067, 5.3067, 5.3067, 5.3067,\n",
      "        5.3068, 5.3067, 5.3067], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.476519  [2579324/5599865]\n",
      "average delta from current occupancy tensor([5.2744, 5.2745, 5.2744, 5.2744, 5.2745, 5.2746, 5.2745, 5.2744, 5.2745,\n",
      "        5.2745, 5.2745, 5.2744, 5.2744, 5.2743, 5.2744, 5.2744, 5.2743, 5.2743,\n",
      "        5.2742, 5.2743, 5.2742, 5.2743, 5.2742, 5.2743, 5.2744, 5.2742, 5.2743,\n",
      "        5.2744, 5.2743, 5.2744, 5.2743, 5.2742, 5.2743, 5.2743, 5.2742, 5.2742,\n",
      "        5.2743, 5.2744, 5.2742, 5.2743, 5.2742, 5.2743, 5.2742, 5.2742, 5.2743,\n",
      "        5.2742, 5.2742, 5.2743, 5.2742, 5.2743, 5.2743, 5.2742, 5.2743, 5.2744,\n",
      "        5.2745, 5.2744, 5.2744, 5.2744, 5.2743, 5.2744, 5.2744, 5.2744, 5.2744,\n",
      "        5.2744, 5.2745, 5.2744, 5.2744, 5.2743, 5.2742, 5.2743, 5.2745, 5.2743,\n",
      "        5.2742, 5.2743, 5.2743, 5.2742, 5.2744, 5.2744, 5.2743, 5.2744, 5.2744,\n",
      "        5.2742, 5.2743, 5.2742, 5.2743, 5.2743, 5.2742, 5.2744, 5.2744, 5.2744,\n",
      "        5.2745, 5.2744, 5.2744, 5.2746, 5.2745, 5.2745, 5.2745, 5.2745, 5.2745,\n",
      "        5.2745, 5.2746, 5.2744, 5.2744, 5.2743, 5.2744, 5.2744, 5.2745, 5.2744,\n",
      "        5.2744, 5.2742, 5.2745, 5.2744, 5.2744, 5.2743, 5.2744, 5.2744, 5.2745,\n",
      "        5.2744, 5.2743, 5.2744], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.376616  [2591724/5599865]\n",
      "average delta from current occupancy tensor([5.4917, 5.4920, 5.4917, 5.4920, 5.4917, 5.4921, 5.4923, 5.4919, 5.4918,\n",
      "        5.4922, 5.4920, 5.4920, 5.4919, 5.4916, 5.4921, 5.4918, 5.4920, 5.4919,\n",
      "        5.4920, 5.4919, 5.4917, 5.4917, 5.4921, 5.4923, 5.4920, 5.4921, 5.4922,\n",
      "        5.4919, 5.4923, 5.4921, 5.4922, 5.4920, 5.4919, 5.4920, 5.4919, 5.4918,\n",
      "        5.4919, 5.4919, 5.4919, 5.4915, 5.4917, 5.4918, 5.4919, 5.4916, 5.4913,\n",
      "        5.4916, 5.4918, 5.4919, 5.4917, 5.4918, 5.4919, 5.4917, 5.4919, 5.4917,\n",
      "        5.4914, 5.4918, 5.4918, 5.4919, 5.4918, 5.4918, 5.4921, 5.4920, 5.4922,\n",
      "        5.4919, 5.4920, 5.4922, 5.4923, 5.4924, 5.4924, 5.4921, 5.4924, 5.4922,\n",
      "        5.4922, 5.4917, 5.4915, 5.4922, 5.4920, 5.4918, 5.4918, 5.4921, 5.4920,\n",
      "        5.4918, 5.4920, 5.4923, 5.4922, 5.4922, 5.4923, 5.4918, 5.4923, 5.4921,\n",
      "        5.4923, 5.4923, 5.4921, 5.4920, 5.4922, 5.4920, 5.4921, 5.4919, 5.4921,\n",
      "        5.4920, 5.4920, 5.4921, 5.4919, 5.4916, 5.4916, 5.4915, 5.4915, 5.4914,\n",
      "        5.4919, 5.4919, 5.4922, 5.4918, 5.4917, 5.4919, 5.4918, 5.4916, 5.4917,\n",
      "        5.4916, 5.4917, 5.4915], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.209388  [2604124/5599865]\n",
      "average delta from current occupancy tensor([5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129, 5.1129,\n",
      "        5.1129, 5.1129, 5.1129], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.095154  [2616524/5599865]\n",
      "average delta from current occupancy tensor([5.0080, 5.0079, 5.0080, 5.0079, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0080, 5.0081, 5.0081, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0079, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0080, 5.0080, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079,\n",
      "        5.0080, 5.0080, 5.0079, 5.0079, 5.0080, 5.0079, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0080, 5.0079, 5.0079, 5.0079, 5.0079, 5.0080, 5.0080,\n",
      "        5.0081, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0079,\n",
      "        5.0079, 5.0079, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0081,\n",
      "        5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0082, 5.0080, 5.0083, 5.0080, 5.0080, 5.0081, 5.0081,\n",
      "        5.0080, 5.0081, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0081, 5.0081, 5.0080, 5.0080, 5.0080, 5.0080, 5.0079,\n",
      "        5.0080, 5.0080, 5.0080, 5.0079, 5.0080, 5.0079, 5.0080, 5.0079, 5.0079,\n",
      "        5.0079, 5.0079, 5.0079], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.760526  [2628924/5599865]\n",
      "average delta from current occupancy tensor([4.8546, 4.8547, 4.8547, 4.8547, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546,\n",
      "        4.8547, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8547,\n",
      "        4.8546, 4.8546, 4.8546, 4.8546, 4.8548, 4.8549, 4.8547, 4.8547, 4.8547,\n",
      "        4.8548, 4.8548, 4.8549, 4.8547, 4.8547, 4.8547, 4.8549, 4.8548, 4.8548,\n",
      "        4.8546, 4.8547, 4.8548, 4.8546, 4.8547, 4.8546, 4.8547, 4.8547, 4.8547,\n",
      "        4.8546, 4.8546, 4.8547, 4.8549, 4.8548, 4.8549, 4.8549, 4.8547, 4.8548,\n",
      "        4.8548, 4.8547, 4.8546, 4.8547, 4.8547, 4.8547, 4.8546, 4.8546, 4.8547,\n",
      "        4.8547, 4.8548, 4.8548, 4.8547, 4.8546, 4.8546, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8546, 4.8547, 4.8547, 4.8547, 4.8546, 4.8546, 4.8545, 4.8546,\n",
      "        4.8546, 4.8546, 4.8548, 4.8546, 4.8547, 4.8547, 4.8546, 4.8546, 4.8546,\n",
      "        4.8546, 4.8547, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546, 4.8545,\n",
      "        4.8545, 4.8546, 4.8545, 4.8545, 4.8545, 4.8546, 4.8545, 4.8545, 4.8546,\n",
      "        4.8545, 4.8545, 4.8546, 4.8546, 4.8547, 4.8548, 4.8545, 4.8548, 4.8545,\n",
      "        4.8547, 4.8549, 4.8546], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.990155  [2641324/5599865]\n",
      "average delta from current occupancy tensor([5.9801, 5.9800, 5.9799, 5.9799, 5.9802, 5.9803, 5.9802, 5.9804, 5.9803,\n",
      "        5.9798, 5.9800, 5.9802, 5.9803, 5.9804, 5.9803, 5.9803, 5.9801, 5.9801,\n",
      "        5.9804, 5.9802, 5.9803, 5.9802, 5.9798, 5.9808, 5.9799, 5.9800, 5.9799,\n",
      "        5.9798, 5.9802, 5.9807, 5.9800, 5.9799, 5.9797, 5.9805, 5.9796, 5.9803,\n",
      "        5.9804, 5.9802, 5.9803, 5.9805, 5.9804, 5.9807, 5.9802, 5.9802, 5.9800,\n",
      "        5.9802, 5.9800, 5.9799, 5.9803, 5.9798, 5.9802, 5.9803, 5.9795, 5.9795,\n",
      "        5.9799, 5.9797, 5.9799, 5.9795, 5.9796, 5.9799, 5.9797, 5.9802, 5.9798,\n",
      "        5.9799, 5.9797, 5.9799, 5.9797, 5.9801, 5.9800, 5.9798, 5.9800, 5.9799,\n",
      "        5.9800, 5.9801, 5.9796, 5.9798, 5.9795, 5.9802, 5.9803, 5.9805, 5.9803,\n",
      "        5.9801, 5.9802, 5.9799, 5.9802, 5.9799, 5.9800, 5.9801, 5.9799, 5.9800,\n",
      "        5.9800, 5.9797, 5.9799, 5.9795, 5.9796, 5.9799, 5.9800, 5.9800, 5.9799,\n",
      "        5.9797, 5.9799, 5.9803, 5.9803, 5.9805, 5.9798, 5.9801, 5.9801, 5.9797,\n",
      "        5.9800, 5.9801, 5.9793, 5.9796, 5.9792, 5.9795, 5.9798, 5.9798, 5.9798,\n",
      "        5.9794, 5.9800, 5.9796], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.244208  [2653724/5599865]\n",
      "average delta from current occupancy tensor([5.0889, 5.0889, 5.0889, 5.0889, 5.0890, 5.0889, 5.0890, 5.0890, 5.0890,\n",
      "        5.0890, 5.0890, 5.0890, 5.0889, 5.0889, 5.0889, 5.0888, 5.0890, 5.0890,\n",
      "        5.0887, 5.0889, 5.0890, 5.0890, 5.0891, 5.0888, 5.0890, 5.0890, 5.0890,\n",
      "        5.0890, 5.0890, 5.0890, 5.0890, 5.0890, 5.0890, 5.0890, 5.0890, 5.0890,\n",
      "        5.0890, 5.0889, 5.0889, 5.0890, 5.0889, 5.0889, 5.0889, 5.0890, 5.0890,\n",
      "        5.0889, 5.0889, 5.0889, 5.0889, 5.0889, 5.0889, 5.0889, 5.0889, 5.0889,\n",
      "        5.0889, 5.0888, 5.0889, 5.0889, 5.0890, 5.0888, 5.0888, 5.0889, 5.0889,\n",
      "        5.0889, 5.0887, 5.0889, 5.0889, 5.0890, 5.0890, 5.0890, 5.0890, 5.0890,\n",
      "        5.0890, 5.0890, 5.0888, 5.0889, 5.0887, 5.0889, 5.0890, 5.0888, 5.0889,\n",
      "        5.0889, 5.0889, 5.0889, 5.0890, 5.0889, 5.0889, 5.0890, 5.0889, 5.0890,\n",
      "        5.0889, 5.0890, 5.0890, 5.0889, 5.0890, 5.0890, 5.0889, 5.0890, 5.0889,\n",
      "        5.0889, 5.0888, 5.0889, 5.0888, 5.0890, 5.0889, 5.0889, 5.0889, 5.0890,\n",
      "        5.0890, 5.0890, 5.0888, 5.0891, 5.0891, 5.0890, 5.0891, 5.0891, 5.0890,\n",
      "        5.0891, 5.0890, 5.0891], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.911593  [2666124/5599865]\n",
      "average delta from current occupancy tensor([5.0483, 5.0483, 5.0481, 5.0483, 5.0483, 5.0483, 5.0482, 5.0481, 5.0482,\n",
      "        5.0483, 5.0482, 5.0482, 5.0484, 5.0483, 5.0484, 5.0483, 5.0483, 5.0483,\n",
      "        5.0484, 5.0484, 5.0483, 5.0482, 5.0483, 5.0484, 5.0483, 5.0482, 5.0483,\n",
      "        5.0483, 5.0483, 5.0483, 5.0483, 5.0482, 5.0483, 5.0483, 5.0484, 5.0483,\n",
      "        5.0483, 5.0483, 5.0483, 5.0483, 5.0482, 5.0484, 5.0484, 5.0483, 5.0483,\n",
      "        5.0483, 5.0483, 5.0484, 5.0484, 5.0483, 5.0483, 5.0483, 5.0484, 5.0484,\n",
      "        5.0483, 5.0483, 5.0483, 5.0483, 5.0483, 5.0482, 5.0483, 5.0482, 5.0483,\n",
      "        5.0483, 5.0483, 5.0482, 5.0483, 5.0483, 5.0483, 5.0483, 5.0483, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0483, 5.0484, 5.0484, 5.0484, 5.0483, 5.0484,\n",
      "        5.0484, 5.0484, 5.0485, 5.0485, 5.0485, 5.0485, 5.0485, 5.0485, 5.0485,\n",
      "        5.0484, 5.0485, 5.0484, 5.0484, 5.0485, 5.0485, 5.0484, 5.0484, 5.0483,\n",
      "        5.0485, 5.0485, 5.0484, 5.0484, 5.0483, 5.0484, 5.0484, 5.0483, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484, 5.0484,\n",
      "        5.0484, 5.0484, 5.0484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.668560  [2678524/5599865]\n",
      "average delta from current occupancy tensor([4.6114, 4.6113, 4.6117, 4.6113, 4.6113, 4.6114, 4.6113, 4.6113, 4.6112,\n",
      "        4.6113, 4.6112, 4.6113, 4.6112, 4.6113, 4.6113, 4.6113, 4.6113, 4.6113,\n",
      "        4.6114, 4.6116, 4.6116, 4.6116, 4.6116, 4.6117, 4.6115, 4.6116, 4.6114,\n",
      "        4.6114, 4.6115, 4.6115, 4.6115, 4.6119, 4.6113, 4.6113, 4.6113, 4.6114,\n",
      "        4.6114, 4.6113, 4.6112, 4.6112, 4.6112, 4.6112, 4.6112, 4.6113, 4.6113,\n",
      "        4.6113, 4.6114, 4.6115, 4.6119, 4.6120, 4.6116, 4.6116, 4.6117, 4.6120,\n",
      "        4.6117, 4.6120, 4.6119, 4.6114, 4.6118, 4.6117, 4.6118, 4.6118, 4.6118,\n",
      "        4.6119, 4.6119, 4.6119, 4.6120, 4.6121, 4.6122, 4.6119, 4.6116, 4.6119,\n",
      "        4.6116, 4.6116, 4.6120, 4.6116, 4.6115, 4.6115, 4.6114, 4.6116, 4.6116,\n",
      "        4.6115, 4.6116, 4.6120, 4.6120, 4.6116, 4.6115, 4.6119, 4.6119, 4.6118,\n",
      "        4.6114, 4.6120, 4.6114, 4.6117, 4.6117, 4.6118, 4.6117, 4.6113, 4.6114,\n",
      "        4.6120, 4.6119, 4.6119, 4.6122, 4.6116, 4.6121, 4.6123, 4.6116, 4.6115,\n",
      "        4.6116, 4.6116, 4.6119, 4.6117, 4.6117, 4.6117, 4.6118, 4.6119, 4.6122,\n",
      "        4.6120, 4.6123, 4.6118], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.043609  [2690924/5599865]\n",
      "average delta from current occupancy tensor([4.0575, 4.0574, 4.0571, 4.0574, 4.0573, 4.0572, 4.0573, 4.0570, 4.0572,\n",
      "        4.0571, 4.0576, 4.0571, 4.0575, 4.0574, 4.0573, 4.0572, 4.0573, 4.0572,\n",
      "        4.0572, 4.0569, 4.0573, 4.0568, 4.0574, 4.0574, 4.0578, 4.0575, 4.0577,\n",
      "        4.0578, 4.0575, 4.0574, 4.0568, 4.0569, 4.0578, 4.0577, 4.0577, 4.0577,\n",
      "        4.0577, 4.0571, 4.0579, 4.0574, 4.0573, 4.0575, 4.0573, 4.0573, 4.0572,\n",
      "        4.0574, 4.0573, 4.0571, 4.0574, 4.0575, 4.0573, 4.0572, 4.0574, 4.0574,\n",
      "        4.0573, 4.0575, 4.0574, 4.0570, 4.0576, 4.0572, 4.0573, 4.0573, 4.0575,\n",
      "        4.0571, 4.0570, 4.0570, 4.0573, 4.0575, 4.0578, 4.0579, 4.0580, 4.0581,\n",
      "        4.0581, 4.0580, 4.0580, 4.0578, 4.0579, 4.0576, 4.0576, 4.0577, 4.0578,\n",
      "        4.0577, 4.0581, 4.0582, 4.0583, 4.0581, 4.0579, 4.0581, 4.0584, 4.0583,\n",
      "        4.0579, 4.0580, 4.0577, 4.0581, 4.0579, 4.0580, 4.0579, 4.0580, 4.0581,\n",
      "        4.0579, 4.0579, 4.0579, 4.0581, 4.0578, 4.0579, 4.0582, 4.0578, 4.0577,\n",
      "        4.0576, 4.0577, 4.0579, 4.0578, 4.0580, 4.0578, 4.0579, 4.0578, 4.0583,\n",
      "        4.0582, 4.0579, 4.0577], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.326474  [2703324/5599865]\n",
      "average delta from current occupancy tensor([5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2742, 5.2743,\n",
      "        5.2742, 5.2743, 5.2743, 5.2743, 5.2743, 5.2742, 5.2742, 5.2742, 5.2742,\n",
      "        5.2742, 5.2743, 5.2742, 5.2742, 5.2742, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743, 5.2743,\n",
      "        5.2743, 5.2743, 5.2743], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.218874  [2715724/5599865]\n",
      "average delta from current occupancy tensor([5.5158, 5.5157, 5.5158, 5.5156, 5.5156, 5.5157, 5.5157, 5.5155, 5.5157,\n",
      "        5.5159, 5.5158, 5.5158, 5.5158, 5.5158, 5.5159, 5.5159, 5.5159, 5.5159,\n",
      "        5.5158, 5.5158, 5.5157, 5.5160, 5.5158, 5.5158, 5.5159, 5.5159, 5.5160,\n",
      "        5.5160, 5.5160, 5.5160, 5.5160, 5.5160, 5.5159, 5.5158, 5.5159, 5.5159,\n",
      "        5.5159, 5.5160, 5.5160, 5.5161, 5.5161, 5.5160, 5.5160, 5.5160, 5.5161,\n",
      "        5.5161, 5.5161, 5.5161, 5.5162, 5.5161, 5.5161, 5.5161, 5.5161, 5.5161,\n",
      "        5.5161, 5.5160, 5.5160, 5.5159, 5.5158, 5.5158, 5.5159, 5.5159, 5.5158,\n",
      "        5.5158, 5.5156, 5.5157, 5.5157, 5.5159, 5.5159, 5.5159, 5.5159, 5.5159,\n",
      "        5.5160, 5.5159, 5.5159, 5.5159, 5.5158, 5.5159, 5.5160, 5.5158, 5.5159,\n",
      "        5.5157, 5.5158, 5.5157, 5.5157, 5.5156, 5.5157, 5.5156, 5.5156, 5.5155,\n",
      "        5.5156, 5.5155, 5.5157, 5.5157, 5.5157, 5.5157, 5.5157, 5.5157, 5.5157,\n",
      "        5.5156, 5.5156, 5.5156, 5.5155, 5.5157, 5.5158, 5.5157, 5.5157, 5.5157,\n",
      "        5.5157, 5.5158, 5.5159, 5.5158, 5.5158, 5.5159, 5.5158, 5.5159, 5.5159,\n",
      "        5.5158, 5.5158, 5.5157], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.261572  [2728124/5599865]\n",
      "average delta from current occupancy tensor([5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824,\n",
      "        5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824,\n",
      "        5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824,\n",
      "        5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2823, 5.2824, 5.2824, 5.2824,\n",
      "        5.2824, 5.2823, 5.2824, 5.2824, 5.2823, 5.2824, 5.2824, 5.2823, 5.2824,\n",
      "        5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824,\n",
      "        5.2823, 5.2824, 5.2823, 5.2823, 5.2824, 5.2824, 5.2824, 5.2823, 5.2824,\n",
      "        5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2824, 5.2823, 5.2824, 5.2824,\n",
      "        5.2824, 5.2824, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823,\n",
      "        5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823,\n",
      "        5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2824, 5.2823,\n",
      "        5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823,\n",
      "        5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823, 5.2823,\n",
      "        5.2823, 5.2823, 5.2823], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.959801  [2740524/5599865]\n",
      "average delta from current occupancy tensor([4.8864, 4.8864, 4.8863, 4.8863, 4.8864, 4.8864, 4.8863, 4.8864, 4.8863,\n",
      "        4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863,\n",
      "        4.8863, 4.8863, 4.8863, 4.8863, 4.8864, 4.8863, 4.8863, 4.8863, 4.8863,\n",
      "        4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8864, 4.8863,\n",
      "        4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863,\n",
      "        4.8862, 4.8863, 4.8862, 4.8863, 4.8862, 4.8862, 4.8863, 4.8863, 4.8862,\n",
      "        4.8862, 4.8862, 4.8863, 4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8863,\n",
      "        4.8862, 4.8862, 4.8863, 4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8863,\n",
      "        4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8863, 4.8863, 4.8863, 4.8863,\n",
      "        4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8862,\n",
      "        4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8863, 4.8862, 4.8862, 4.8862,\n",
      "        4.8862, 4.8862, 4.8862, 4.8862, 4.8863, 4.8863, 4.8862, 4.8862, 4.8862,\n",
      "        4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8862, 4.8862,\n",
      "        4.8862, 4.8863, 4.8862], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.088561  [2752924/5599865]\n",
      "average delta from current occupancy tensor([5.1055, 5.1055, 5.1055, 5.1056, 5.1055, 5.1055, 5.1056, 5.1056, 5.1056,\n",
      "        5.1056, 5.1056, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055,\n",
      "        5.1055, 5.1055, 5.1055, 5.1054, 5.1054, 5.1054, 5.1054, 5.1055, 5.1054,\n",
      "        5.1054, 5.1054, 5.1054, 5.1055, 5.1054, 5.1055, 5.1055, 5.1054, 5.1054,\n",
      "        5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1055,\n",
      "        5.1055, 5.1055, 5.1054, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055,\n",
      "        5.1055, 5.1054, 5.1054, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055,\n",
      "        5.1055, 5.1055, 5.1054, 5.1054, 5.1055, 5.1055, 5.1054, 5.1054, 5.1054,\n",
      "        5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054,\n",
      "        5.1054, 5.1055, 5.1055, 5.1054, 5.1054, 5.1054, 5.1055, 5.1055, 5.1055,\n",
      "        5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055,\n",
      "        5.1055, 5.1055, 5.1055, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054,\n",
      "        5.1054, 5.1054, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1056, 5.1055,\n",
      "        5.1055, 5.1055, 5.1055], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.118132  [2765324/5599865]\n",
      "average delta from current occupancy tensor([5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661, 5.2661,\n",
      "        5.2661, 5.2661, 5.2661], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.398835  [2777724/5599865]\n",
      "average delta from current occupancy tensor([5.4331, 5.4331, 5.4330, 5.4330, 5.4329, 5.4331, 5.4330, 5.4331, 5.4330,\n",
      "        5.4329, 5.4329, 5.4329, 5.4329, 5.4328, 5.4328, 5.4327, 5.4328, 5.4328,\n",
      "        5.4329, 5.4328, 5.4327, 5.4329, 5.4329, 5.4332, 5.4331, 5.4332, 5.4331,\n",
      "        5.4330, 5.4330, 5.4330, 5.4327, 5.4327, 5.4327, 5.4327, 5.4327, 5.4324,\n",
      "        5.4326, 5.4326, 5.4327, 5.4328, 5.4330, 5.4327, 5.4329, 5.4328, 5.4327,\n",
      "        5.4328, 5.4327, 5.4326, 5.4326, 5.4327, 5.4327, 5.4328, 5.4327, 5.4327,\n",
      "        5.4326, 5.4326, 5.4327, 5.4327, 5.4329, 5.4328, 5.4328, 5.4328, 5.4329,\n",
      "        5.4327, 5.4326, 5.4326, 5.4328, 5.4326, 5.4328, 5.4327, 5.4326, 5.4327,\n",
      "        5.4327, 5.4327, 5.4326, 5.4324, 5.4324, 5.4324, 5.4325, 5.4325, 5.4326,\n",
      "        5.4326, 5.4326, 5.4327, 5.4328, 5.4327, 5.4327, 5.4325, 5.4325, 5.4325,\n",
      "        5.4325, 5.4325, 5.4325, 5.4326, 5.4325, 5.4327, 5.4325, 5.4324, 5.4323,\n",
      "        5.4324, 5.4325, 5.4324, 5.4323, 5.4324, 5.4325, 5.4326, 5.4326, 5.4325,\n",
      "        5.4324, 5.4323, 5.4325, 5.4323, 5.4322, 5.4323, 5.4323, 5.4324, 5.4324,\n",
      "        5.4326, 5.4324, 5.4326], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.174068  [2790124/5599865]\n",
      "average delta from current occupancy tensor([5.1950, 5.1952, 5.1952, 5.1952, 5.1953, 5.1951, 5.1952, 5.1951, 5.1953,\n",
      "        5.1953, 5.1956, 5.1956, 5.1957, 5.1957, 5.1957, 5.1957, 5.1955, 5.1956,\n",
      "        5.1954, 5.1957, 5.1958, 5.1956, 5.1957, 5.1951, 5.1951, 5.1951, 5.1955,\n",
      "        5.1957, 5.1959, 5.1960, 5.1963, 5.1963, 5.1962, 5.1963, 5.1966, 5.1969,\n",
      "        5.1964, 5.1962, 5.1962, 5.1960, 5.1960, 5.1963, 5.1959, 5.1961, 5.1963,\n",
      "        5.1960, 5.1962, 5.1966, 5.1965, 5.1962, 5.1962, 5.1961, 5.1964, 5.1963,\n",
      "        5.1962, 5.1964, 5.1961, 5.1962, 5.1958, 5.1957, 5.1959, 5.1959, 5.1961,\n",
      "        5.1961, 5.1963, 5.1963, 5.1961, 5.1964, 5.1961, 5.1961, 5.1960, 5.1959,\n",
      "        5.1958, 5.1960, 5.1961, 5.1963, 5.1963, 5.1963, 5.1963, 5.1961, 5.1958,\n",
      "        5.1958, 5.1956, 5.1955, 5.1956, 5.1957, 5.1959, 5.1961, 5.1959, 5.1957,\n",
      "        5.1961, 5.1961, 5.1961, 5.1960, 5.1961, 5.1959, 5.1960, 5.1959, 5.1960,\n",
      "        5.1960, 5.1958, 5.1958, 5.1960, 5.1958, 5.1957, 5.1957, 5.1956, 5.1956,\n",
      "        5.1959, 5.1957, 5.1955, 5.1956, 5.1955, 5.1953, 5.1955, 5.1953, 5.1956,\n",
      "        5.1953, 5.1955, 5.1954], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.316232  [2802524/5599865]\n",
      "average delta from current occupancy tensor([5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0726,\n",
      "        5.0726, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0727, 5.0726,\n",
      "        5.0727, 5.0727, 5.0727, 5.0726, 5.0726, 5.0727, 5.0727, 5.0727, 5.0726,\n",
      "        5.0727, 5.0726, 5.0726, 5.0727, 5.0727, 5.0726, 5.0726, 5.0727, 5.0729,\n",
      "        5.0727, 5.0726, 5.0726, 5.0726, 5.0726, 5.0726, 5.0726, 5.0726, 5.0726,\n",
      "        5.0726, 5.0726, 5.0727, 5.0727, 5.0726, 5.0726, 5.0727, 5.0727, 5.0726,\n",
      "        5.0727, 5.0726, 5.0726, 5.0726, 5.0727, 5.0727, 5.0727, 5.0727, 5.0726,\n",
      "        5.0726, 5.0727, 5.0727, 5.0726, 5.0726, 5.0726, 5.0727, 5.0726, 5.0727,\n",
      "        5.0727, 5.0726, 5.0726, 5.0726, 5.0727, 5.0726, 5.0726, 5.0727, 5.0728,\n",
      "        5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0729, 5.0728, 5.0728, 5.0728,\n",
      "        5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728,\n",
      "        5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728,\n",
      "        5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728, 5.0728,\n",
      "        5.0728, 5.0728, 5.0728], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.782917  [2814924/5599865]\n",
      "average delta from current occupancy tensor([4.8634, 4.8633, 4.8628, 4.8630, 4.8632, 4.8633, 4.8631, 4.8629, 4.8635,\n",
      "        4.8634, 4.8634, 4.8632, 4.8634, 4.8635, 4.8634, 4.8632, 4.8638, 4.8634,\n",
      "        4.8632, 4.8632, 4.8633, 4.8634, 4.8629, 4.8631, 4.8635, 4.8637, 4.8637,\n",
      "        4.8637, 4.8634, 4.8639, 4.8636, 4.8642, 4.8640, 4.8640, 4.8640, 4.8641,\n",
      "        4.8640, 4.8634, 4.8633, 4.8633, 4.8629, 4.8632, 4.8637, 4.8636, 4.8638,\n",
      "        4.8631, 4.8637, 4.8637, 4.8637, 4.8637, 4.8634, 4.8635, 4.8638, 4.8635,\n",
      "        4.8641, 4.8641, 4.8638, 4.8640, 4.8637, 4.8640, 4.8639, 4.8639, 4.8634,\n",
      "        4.8638, 4.8641, 4.8644, 4.8639, 4.8644, 4.8639, 4.8640, 4.8640, 4.8641,\n",
      "        4.8639, 4.8641, 4.8641, 4.8637, 4.8638, 4.8640, 4.8637, 4.8637, 4.8635,\n",
      "        4.8639, 4.8636, 4.8634, 4.8633, 4.8635, 4.8638, 4.8636, 4.8636, 4.8635,\n",
      "        4.8633, 4.8634, 4.8638, 4.8640, 4.8642, 4.8643, 4.8643, 4.8644, 4.8641,\n",
      "        4.8642, 4.8640, 4.8639, 4.8641, 4.8641, 4.8636, 4.8636, 4.8636, 4.8632,\n",
      "        4.8633, 4.8632, 4.8630, 4.8625, 4.8628, 4.8628, 4.8630, 4.8627, 4.8626,\n",
      "        4.8625, 4.8628, 4.8629], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.428233  [2827324/5599865]\n",
      "average delta from current occupancy tensor([5.4619, 5.4621, 5.4620, 5.4622, 5.4622, 5.4622, 5.4622, 5.4622, 5.4622,\n",
      "        5.4621, 5.4621, 5.4622, 5.4621, 5.4623, 5.4622, 5.4620, 5.4620, 5.4619,\n",
      "        5.4619, 5.4620, 5.4619, 5.4621, 5.4619, 5.4619, 5.4620, 5.4620, 5.4622,\n",
      "        5.4621, 5.4623, 5.4622, 5.4623, 5.4623, 5.4621, 5.4621, 5.4619, 5.4620,\n",
      "        5.4621, 5.4624, 5.4622, 5.4622, 5.4624, 5.4627, 5.4623, 5.4622, 5.4622,\n",
      "        5.4623, 5.4622, 5.4623, 5.4625, 5.4624, 5.4624, 5.4620, 5.4623, 5.4622,\n",
      "        5.4623, 5.4623, 5.4622, 5.4624, 5.4623, 5.4623, 5.4622, 5.4624, 5.4623,\n",
      "        5.4623, 5.4622, 5.4621, 5.4620, 5.4621, 5.4621, 5.4620, 5.4620, 5.4620,\n",
      "        5.4621, 5.4620, 5.4622, 5.4621, 5.4622, 5.4619, 5.4621, 5.4620, 5.4622,\n",
      "        5.4623, 5.4621, 5.4620, 5.4620, 5.4619, 5.4619, 5.4621, 5.4620, 5.4621,\n",
      "        5.4622, 5.4622, 5.4622, 5.4622, 5.4623, 5.4620, 5.4620, 5.4620, 5.4620,\n",
      "        5.4620, 5.4620, 5.4619, 5.4620, 5.4619, 5.4619, 5.4621, 5.4621, 5.4622,\n",
      "        5.4622, 5.4623, 5.4623, 5.4624, 5.4623, 5.4624, 5.4623, 5.4624, 5.4623,\n",
      "        5.4623, 5.4623, 5.4621], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.677276  [2839724/5599865]\n",
      "average delta from current occupancy tensor([5.5410, 5.5410, 5.5409, 5.5409, 5.5408, 5.5408, 5.5408, 5.5407, 5.5407,\n",
      "        5.5407, 5.5407, 5.5410, 5.5408, 5.5410, 5.5408, 5.5412, 5.5412, 5.5413,\n",
      "        5.5411, 5.5412, 5.5412, 5.5411, 5.5411, 5.5411, 5.5411, 5.5410, 5.5409,\n",
      "        5.5408, 5.5412, 5.5411, 5.5410, 5.5411, 5.5411, 5.5409, 5.5408, 5.5408,\n",
      "        5.5408, 5.5409, 5.5409, 5.5408, 5.5410, 5.5411, 5.5408, 5.5408, 5.5408,\n",
      "        5.5407, 5.5409, 5.5408, 5.5410, 5.5409, 5.5409, 5.5409, 5.5408, 5.5408,\n",
      "        5.5408, 5.5408, 5.5409, 5.5411, 5.5410, 5.5410, 5.5411, 5.5411, 5.5411,\n",
      "        5.5412, 5.5411, 5.5411, 5.5411, 5.5411, 5.5410, 5.5410, 5.5409, 5.5411,\n",
      "        5.5411, 5.5410, 5.5410, 5.5409, 5.5408, 5.5410, 5.5409, 5.5410, 5.5408,\n",
      "        5.5408, 5.5410, 5.5411, 5.5411, 5.5412, 5.5412, 5.5409, 5.5410, 5.5411,\n",
      "        5.5411, 5.5411, 5.5410, 5.5410, 5.5411, 5.5409, 5.5410, 5.5411, 5.5411,\n",
      "        5.5412, 5.5411, 5.5411, 5.5411, 5.5410, 5.5411, 5.5412, 5.5412, 5.5413,\n",
      "        5.5414, 5.5415, 5.5416, 5.5417, 5.5416, 5.5416, 5.5415, 5.5415, 5.5414,\n",
      "        5.5414, 5.5414, 5.5413], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.595052  [2852124/5599865]\n",
      "average delta from current occupancy tensor([6.5916, 6.5916, 6.5924, 6.5920, 6.5918, 6.5914, 6.5911, 6.5916, 6.5915,\n",
      "        6.5909, 6.5911, 6.5907, 6.5909, 6.5921, 6.5909, 6.5909, 6.5907, 6.5919,\n",
      "        6.5906, 6.5904, 6.5914, 6.5912, 6.5911, 6.5920, 6.5921, 6.5920, 6.5920,\n",
      "        6.5918, 6.5922, 6.5923, 6.5921, 6.5923, 6.5923, 6.5923, 6.5924, 6.5921,\n",
      "        6.5919, 6.5918, 6.5913, 6.5914, 6.5914, 6.5917, 6.5918, 6.5916, 6.5915,\n",
      "        6.5918, 6.5916, 6.5914, 6.5918, 6.5918, 6.5917, 6.5917, 6.5920, 6.5920,\n",
      "        6.5917, 6.5917, 6.5918, 6.5918, 6.5917, 6.5918, 6.5919, 6.5920, 6.5921,\n",
      "        6.5922, 6.5922, 6.5920, 6.5921, 6.5919, 6.5921, 6.5925, 6.5922, 6.5923,\n",
      "        6.5921, 6.5921, 6.5925, 6.5923, 6.5917, 6.5922, 6.5920, 6.5924, 6.5918,\n",
      "        6.5908, 6.5925, 6.5928, 6.5924, 6.5922, 6.5925, 6.5926, 6.5922, 6.5924,\n",
      "        6.5926, 6.5926, 6.5925, 6.5924, 6.5923, 6.5921, 6.5927, 6.5922, 6.5929,\n",
      "        6.5930, 6.5928, 6.5929, 6.5927, 6.5922, 6.5926, 6.5927, 6.5926, 6.5927,\n",
      "        6.5925, 6.5910, 6.5917, 6.5916, 6.5912, 6.5916, 6.5915, 6.5922, 6.5922,\n",
      "        6.5925, 6.5922, 6.5925], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.555859  [2864524/5599865]\n",
      "average delta from current occupancy tensor([5.5655, 5.5655, 5.5654, 5.5654, 5.5653, 5.5654, 5.5652, 5.5653, 5.5653,\n",
      "        5.5652, 5.5652, 5.5650, 5.5652, 5.5654, 5.5653, 5.5652, 5.5648, 5.5655,\n",
      "        5.5649, 5.5649, 5.5654, 5.5652, 5.5653, 5.5653, 5.5652, 5.5652, 5.5652,\n",
      "        5.5651, 5.5652, 5.5653, 5.5653, 5.5652, 5.5652, 5.5653, 5.5653, 5.5653,\n",
      "        5.5653, 5.5653, 5.5653, 5.5653, 5.5654, 5.5653, 5.5653, 5.5652, 5.5652,\n",
      "        5.5653, 5.5651, 5.5652, 5.5651, 5.5650, 5.5651, 5.5651, 5.5650, 5.5651,\n",
      "        5.5651, 5.5651, 5.5651, 5.5651, 5.5652, 5.5652, 5.5652, 5.5652, 5.5652,\n",
      "        5.5651, 5.5651, 5.5652, 5.5652, 5.5652, 5.5652, 5.5651, 5.5652, 5.5651,\n",
      "        5.5653, 5.5653, 5.5653, 5.5655, 5.5654, 5.5653, 5.5652, 5.5652, 5.5652,\n",
      "        5.5651, 5.5651, 5.5651, 5.5652, 5.5651, 5.5651, 5.5650, 5.5651, 5.5652,\n",
      "        5.5652, 5.5653, 5.5653, 5.5652, 5.5653, 5.5652, 5.5652, 5.5653, 5.5652,\n",
      "        5.5652, 5.5653, 5.5652, 5.5652, 5.5652, 5.5651, 5.5651, 5.5652, 5.5651,\n",
      "        5.5651, 5.5652, 5.5652, 5.5652, 5.5653, 5.5652, 5.5653, 5.5653, 5.5654,\n",
      "        5.5653, 5.5653, 5.5652], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.392847  [2876924/5599865]\n",
      "average delta from current occupancy tensor([4.5395, 4.5396, 4.5397, 4.5397, 4.5393, 4.5396, 4.5394, 4.5392, 4.5392,\n",
      "        4.5392, 4.5392, 4.5397, 4.5393, 4.5393, 4.5394, 4.5394, 4.5394, 4.5397,\n",
      "        4.5393, 4.5395, 4.5396, 4.5393, 4.5396, 4.5396, 4.5392, 4.5394, 4.5392,\n",
      "        4.5391, 4.5390, 4.5391, 4.5393, 4.5394, 4.5394, 4.5391, 4.5390, 4.5392,\n",
      "        4.5391, 4.5392, 4.5395, 4.5391, 4.5394, 4.5395, 4.5395, 4.5395, 4.5396,\n",
      "        4.5397, 4.5396, 4.5396, 4.5394, 4.5396, 4.5394, 4.5395, 4.5395, 4.5394,\n",
      "        4.5393, 4.5393, 4.5395, 4.5396, 4.5395, 4.5395, 4.5395, 4.5393, 4.5394,\n",
      "        4.5395, 4.5396, 4.5392, 4.5393, 4.5392, 4.5392, 4.5394, 4.5393, 4.5396,\n",
      "        4.5395, 4.5394, 4.5393, 4.5395, 4.5395, 4.5393, 4.5393, 4.5395, 4.5396,\n",
      "        4.5395, 4.5392, 4.5393, 4.5395, 4.5395, 4.5394, 4.5393, 4.5395, 4.5393,\n",
      "        4.5392, 4.5392, 4.5392, 4.5393, 4.5391, 4.5394, 4.5396, 4.5395, 4.5396,\n",
      "        4.5395, 4.5394, 4.5394, 4.5392, 4.5393, 4.5392, 4.5392, 4.5390, 4.5392,\n",
      "        4.5392, 4.5393, 4.5393, 4.5394, 4.5394, 4.5394, 4.5395, 4.5395, 4.5394,\n",
      "        4.5395, 4.5395, 4.5394], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.842986  [2889324/5599865]\n",
      "average delta from current occupancy tensor([4.9921, 4.9921, 4.9921, 4.9923, 4.9923, 4.9923, 4.9923, 4.9924, 4.9923,\n",
      "        4.9922, 4.9922, 4.9922, 4.9923, 4.9922, 4.9923, 4.9923, 4.9923, 4.9923,\n",
      "        4.9922, 4.9922, 4.9922, 4.9923, 4.9923, 4.9923, 4.9924, 4.9923, 4.9924,\n",
      "        4.9923, 4.9923, 4.9923, 4.9924, 4.9925, 4.9924, 4.9924, 4.9923, 4.9924,\n",
      "        4.9922, 4.9923, 4.9923, 4.9923, 4.9923, 4.9924, 4.9923, 4.9923, 4.9922,\n",
      "        4.9922, 4.9923, 4.9923, 4.9922, 4.9922, 4.9923, 4.9921, 4.9921, 4.9923,\n",
      "        4.9922, 4.9923, 4.9922, 4.9923, 4.9922, 4.9921, 4.9922, 4.9921, 4.9922,\n",
      "        4.9922, 4.9921, 4.9922, 4.9922, 4.9922, 4.9922, 4.9922, 4.9922, 4.9922,\n",
      "        4.9922, 4.9922, 4.9922, 4.9921, 4.9921, 4.9922, 4.9923, 4.9922, 4.9924,\n",
      "        4.9922, 4.9923, 4.9922, 4.9923, 4.9923, 4.9922, 4.9923, 4.9923, 4.9922,\n",
      "        4.9922, 4.9923, 4.9922, 4.9923, 4.9922, 4.9922, 4.9924, 4.9924, 4.9924,\n",
      "        4.9924, 4.9923, 4.9922, 4.9923, 4.9923, 4.9923, 4.9923, 4.9923, 4.9923,\n",
      "        4.9923, 4.9922, 4.9924, 4.9923, 4.9923, 4.9923, 4.9924, 4.9923, 4.9924,\n",
      "        4.9924, 4.9926, 4.9925], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.476224  [2901724/5599865]\n",
      "average delta from current occupancy tensor([5.7026, 5.7024, 5.7024, 5.7026, 5.7027, 5.7025, 5.7024, 5.7025, 5.7024,\n",
      "        5.7024, 5.7024, 5.7025, 5.7023, 5.7024, 5.7023, 5.7024, 5.7024, 5.7022,\n",
      "        5.7022, 5.7024, 5.7022, 5.7025, 5.7023, 5.7023, 5.7023, 5.7023, 5.7024,\n",
      "        5.7024, 5.7024, 5.7025, 5.7025, 5.7025, 5.7024, 5.7026, 5.7025, 5.7026,\n",
      "        5.7025, 5.7024, 5.7025, 5.7024, 5.7025, 5.7026, 5.7024, 5.7025, 5.7025,\n",
      "        5.7026, 5.7025, 5.7026, 5.7025, 5.7024, 5.7024, 5.7022, 5.7023, 5.7023,\n",
      "        5.7021, 5.7023, 5.7023, 5.7022, 5.7023, 5.7024, 5.7024, 5.7026, 5.7022,\n",
      "        5.7024, 5.7022, 5.7022, 5.7020, 5.7023, 5.7021, 5.7019, 5.7020, 5.7022,\n",
      "        5.7023, 5.7025, 5.7022, 5.7024, 5.7023, 5.7024, 5.7023, 5.7022, 5.7023,\n",
      "        5.7024, 5.7022, 5.7023, 5.7024, 5.7024, 5.7023, 5.7022, 5.7023, 5.7022,\n",
      "        5.7023, 5.7024, 5.7023, 5.7022, 5.7022, 5.7019, 5.7020, 5.7020, 5.7021,\n",
      "        5.7020, 5.7021, 5.7020, 5.7021, 5.7020, 5.7021, 5.7021, 5.7021, 5.7021,\n",
      "        5.7022, 5.7021, 5.7021, 5.7022, 5.7021, 5.7023, 5.7022, 5.7022, 5.7022,\n",
      "        5.7023, 5.7021, 5.7024], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.498694  [2914124/5599865]\n",
      "average delta from current occupancy tensor([5.4196, 5.4196, 5.4197, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195, 5.4195,\n",
      "        5.4195, 5.4196, 5.4196, 5.4196, 5.4195, 5.4195, 5.4196, 5.4197, 5.4199,\n",
      "        5.4198, 5.4196, 5.4199, 5.4195, 5.4198, 5.4198, 5.4198, 5.4196, 5.4195,\n",
      "        5.4195, 5.4196, 5.4196, 5.4196, 5.4195, 5.4198, 5.4196, 5.4198, 5.4196,\n",
      "        5.4198, 5.4201, 5.4198, 5.4199, 5.4197, 5.4198, 5.4198, 5.4197, 5.4197,\n",
      "        5.4197, 5.4197, 5.4198, 5.4198, 5.4201, 5.4201, 5.4199, 5.4202, 5.4202,\n",
      "        5.4198, 5.4200, 5.4200, 5.4201, 5.4200, 5.4198, 5.4199, 5.4196, 5.4201,\n",
      "        5.4197, 5.4199, 5.4200, 5.4196, 5.4198, 5.4199, 5.4197, 5.4199, 5.4200,\n",
      "        5.4199, 5.4197, 5.4201, 5.4197, 5.4202, 5.4201, 5.4202, 5.4202, 5.4201,\n",
      "        5.4199, 5.4201, 5.4202, 5.4199, 5.4199, 5.4200, 5.4199, 5.4199, 5.4202,\n",
      "        5.4199, 5.4197, 5.4196, 5.4198, 5.4199, 5.4201, 5.4201, 5.4199, 5.4199,\n",
      "        5.4201, 5.4200, 5.4202, 5.4202, 5.4201, 5.4200, 5.4201, 5.4202, 5.4199,\n",
      "        5.4199, 5.4199, 5.4199, 5.4200, 5.4200, 5.4199, 5.4198, 5.4199, 5.4196,\n",
      "        5.4198, 5.4200, 5.4200], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.980779  [2926524/5599865]\n",
      "average delta from current occupancy tensor([5.1458, 5.1458, 5.1459, 5.1458, 5.1457, 5.1457, 5.1457, 5.1458, 5.1455,\n",
      "        5.1457, 5.1457, 5.1458, 5.1456, 5.1456, 5.1457, 5.1456, 5.1456, 5.1455,\n",
      "        5.1456, 5.1454, 5.1456, 5.1457, 5.1456, 5.1455, 5.1456, 5.1453, 5.1452,\n",
      "        5.1454, 5.1453, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452, 5.1452,\n",
      "        5.1453, 5.1454, 5.1452, 5.1455, 5.1452, 5.1455, 5.1454, 5.1453, 5.1455,\n",
      "        5.1456, 5.1455, 5.1455, 5.1456, 5.1455, 5.1458, 5.1455, 5.1459, 5.1458,\n",
      "        5.1457, 5.1460, 5.1459, 5.1459, 5.1460, 5.1460, 5.1458, 5.1459, 5.1461,\n",
      "        5.1456, 5.1460, 5.1458, 5.1460, 5.1460, 5.1461, 5.1461, 5.1461, 5.1461,\n",
      "        5.1460, 5.1459, 5.1459, 5.1455, 5.1459, 5.1458, 5.1457, 5.1458, 5.1457,\n",
      "        5.1458, 5.1458, 5.1459, 5.1458, 5.1459, 5.1458, 5.1456, 5.1454, 5.1456,\n",
      "        5.1456, 5.1452, 5.1453, 5.1452, 5.1457, 5.1458, 5.1457, 5.1452, 5.1457,\n",
      "        5.1456, 5.1456, 5.1455, 5.1456, 5.1457, 5.1457, 5.1455, 5.1457, 5.1452,\n",
      "        5.1452, 5.1455, 5.1455, 5.1456, 5.1458, 5.1453, 5.1452, 5.1454, 5.1453,\n",
      "        5.1453, 5.1458, 5.1458], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.112871  [2938924/5599865]\n",
      "average delta from current occupancy tensor([5.0097, 5.0097, 5.0094, 5.0094, 5.0093, 5.0093, 5.0092, 5.0093, 5.0093,\n",
      "        5.0091, 5.0091, 5.0091, 5.0092, 5.0093, 5.0092, 5.0094, 5.0095, 5.0095,\n",
      "        5.0094, 5.0095, 5.0094, 5.0094, 5.0094, 5.0095, 5.0095, 5.0095, 5.0094,\n",
      "        5.0092, 5.0092, 5.0092, 5.0093, 5.0093, 5.0094, 5.0094, 5.0092, 5.0093,\n",
      "        5.0093, 5.0093, 5.0093, 5.0091, 5.0092, 5.0089, 5.0089, 5.0090, 5.0090,\n",
      "        5.0091, 5.0092, 5.0092, 5.0091, 5.0090, 5.0089, 5.0089, 5.0089, 5.0087,\n",
      "        5.0087, 5.0085, 5.0084, 5.0083, 5.0082, 5.0082, 5.0082, 5.0084, 5.0082,\n",
      "        5.0086, 5.0085, 5.0086, 5.0086, 5.0087, 5.0086, 5.0087, 5.0086, 5.0086,\n",
      "        5.0087, 5.0087, 5.0088, 5.0088, 5.0086, 5.0086, 5.0086, 5.0087, 5.0085,\n",
      "        5.0086, 5.0086, 5.0086, 5.0087, 5.0088, 5.0090, 5.0091, 5.0089, 5.0088,\n",
      "        5.0087, 5.0088, 5.0087, 5.0087, 5.0086, 5.0085, 5.0086, 5.0088, 5.0085,\n",
      "        5.0085, 5.0087, 5.0089, 5.0089, 5.0088, 5.0088, 5.0090, 5.0090, 5.0091,\n",
      "        5.0089, 5.0086, 5.0087, 5.0087, 5.0088, 5.0089, 5.0091, 5.0089, 5.0090,\n",
      "        5.0091, 5.0089, 5.0089], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.750136  [2951324/5599865]\n",
      "average delta from current occupancy tensor([4.7882, 4.7881, 4.7878, 4.7877, 4.7872, 4.7872, 4.7874, 4.7874, 4.7875,\n",
      "        4.7877, 4.7878, 4.7877, 4.7875, 4.7877, 4.7879, 4.7876, 4.7878, 4.7878,\n",
      "        4.7878, 4.7884, 4.7882, 4.7881, 4.7879, 4.7882, 4.7881, 4.7879, 4.7877,\n",
      "        4.7878, 4.7876, 4.7876, 4.7875, 4.7877, 4.7877, 4.7875, 4.7878, 4.7881,\n",
      "        4.7878, 4.7877, 4.7876, 4.7875, 4.7878, 4.7880, 4.7881, 4.7880, 4.7881,\n",
      "        4.7874, 4.7875, 4.7874, 4.7874, 4.7875, 4.7874, 4.7875, 4.7881, 4.7876,\n",
      "        4.7875, 4.7873, 4.7876, 4.7873, 4.7874, 4.7873, 4.7872, 4.7869, 4.7868,\n",
      "        4.7871, 4.7872, 4.7874, 4.7870, 4.7870, 4.7871, 4.7870, 4.7872, 4.7872,\n",
      "        4.7871, 4.7871, 4.7874, 4.7875, 4.7870, 4.7874, 4.7875, 4.7877, 4.7875,\n",
      "        4.7877, 4.7877, 4.7879, 4.7876, 4.7873, 4.7877, 4.7874, 4.7873, 4.7874,\n",
      "        4.7874, 4.7875, 4.7876, 4.7873, 4.7872, 4.7874, 4.7873, 4.7874, 4.7870,\n",
      "        4.7872, 4.7872, 4.7877, 4.7878, 4.7875, 4.7872, 4.7879, 4.7872, 4.7874,\n",
      "        4.7872, 4.7871, 4.7869, 4.7869, 4.7868, 4.7867, 4.7872, 4.7870, 4.7873,\n",
      "        4.7872, 4.7874, 4.7874], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.696545  [2963724/5599865]\n",
      "average delta from current occupancy tensor([5.6617, 5.6617, 5.6618, 5.6620, 5.6618, 5.6618, 5.6618, 5.6619, 5.6620,\n",
      "        5.6617, 5.6616, 5.6615, 5.6616, 5.6616, 5.6615, 5.6617, 5.6617, 5.6616,\n",
      "        5.6616, 5.6616, 5.6617, 5.6618, 5.6616, 5.6617, 5.6617, 5.6617, 5.6618,\n",
      "        5.6618, 5.6618, 5.6618, 5.6618, 5.6618, 5.6617, 5.6618, 5.6618, 5.6616,\n",
      "        5.6616, 5.6618, 5.6619, 5.6619, 5.6619, 5.6620, 5.6619, 5.6619, 5.6619,\n",
      "        5.6619, 5.6620, 5.6619, 5.6619, 5.6619, 5.6620, 5.6619, 5.6619, 5.6619,\n",
      "        5.6620, 5.6620, 5.6621, 5.6619, 5.6619, 5.6620, 5.6619, 5.6618, 5.6618,\n",
      "        5.6618, 5.6618, 5.6618, 5.6617, 5.6617, 5.6616, 5.6616, 5.6617, 5.6614,\n",
      "        5.6613, 5.6614, 5.6615, 5.6615, 5.6614, 5.6616, 5.6617, 5.6618, 5.6617,\n",
      "        5.6617, 5.6618, 5.6619, 5.6619, 5.6617, 5.6619, 5.6618, 5.6618, 5.6618,\n",
      "        5.6619, 5.6619, 5.6619, 5.6618, 5.6619, 5.6619, 5.6620, 5.6620, 5.6618,\n",
      "        5.6618, 5.6618, 5.6619, 5.6619, 5.6616, 5.6617, 5.6618, 5.6616, 5.6617,\n",
      "        5.6617, 5.6616, 5.6614, 5.6615, 5.6615, 5.6615, 5.6616, 5.6615, 5.6616,\n",
      "        5.6616, 5.6618, 5.6617], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.810046  [2976124/5599865]\n",
      "average delta from current occupancy tensor([4.8473, 4.8473, 4.8474, 4.8474, 4.8475, 4.8473, 4.8473, 4.8475, 4.8473,\n",
      "        4.8471, 4.8468, 4.8468, 4.8471, 4.8473, 4.8472, 4.8475, 4.8476, 4.8476,\n",
      "        4.8474, 4.8478, 4.8478, 4.8476, 4.8477, 4.8476, 4.8477, 4.8476, 4.8477,\n",
      "        4.8476, 4.8476, 4.8476, 4.8477, 4.8475, 4.8476, 4.8478, 4.8475, 4.8476,\n",
      "        4.8476, 4.8476, 4.8475, 4.8475, 4.8475, 4.8475, 4.8475, 4.8469, 4.8475,\n",
      "        4.8473, 4.8468, 4.8472, 4.8470, 4.8469, 4.8475, 4.8475, 4.8473, 4.8471,\n",
      "        4.8473, 4.8476, 4.8474, 4.8475, 4.8478, 4.8477, 4.8479, 4.8479, 4.8479,\n",
      "        4.8478, 4.8478, 4.8479, 4.8476, 4.8478, 4.8477, 4.8474, 4.8476, 4.8469,\n",
      "        4.8476, 4.8474, 4.8474, 4.8477, 4.8476, 4.8474, 4.8474, 4.8468, 4.8469,\n",
      "        4.8469, 4.8470, 4.8469, 4.8469, 4.8468, 4.8468, 4.8468, 4.8472, 4.8469,\n",
      "        4.8468, 4.8471, 4.8468, 4.8468, 4.8468, 4.8468, 4.8469, 4.8474, 4.8473,\n",
      "        4.8471, 4.8473, 4.8472, 4.8473, 4.8473, 4.8473, 4.8473, 4.8471, 4.8470,\n",
      "        4.8470, 4.8468, 4.8468, 4.8469, 4.8470, 4.8468, 4.8468, 4.8468, 4.8468,\n",
      "        4.8468, 4.8469, 4.8470], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.403748  [2988524/5599865]\n",
      "average delta from current occupancy tensor([5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4437, 5.4437,\n",
      "        5.4436, 5.4437, 5.4437, 5.4436, 5.4437, 5.4436, 5.4436, 5.4436, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4437, 5.4437, 5.4436, 5.4437,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4437, 5.4436, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4436, 5.4436, 5.4437, 5.4436,\n",
      "        5.4436, 5.4437, 5.4437, 5.4437, 5.4437, 5.4437, 5.4437, 5.4436, 5.4437,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4437,\n",
      "        5.4437, 5.4437, 5.4436, 5.4436, 5.4436, 5.4436, 5.4437, 5.4437, 5.4437,\n",
      "        5.4437, 5.4437, 5.4437, 5.4437, 5.4437, 5.4436, 5.4437, 5.4437, 5.4437,\n",
      "        5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.512483  [3000924/5599865]\n",
      "average delta from current occupancy tensor([5.4356, 5.4357, 5.4357, 5.4356, 5.4356, 5.4356, 5.4356, 5.4356, 5.4356,\n",
      "        5.4355, 5.4356, 5.4356, 5.4356, 5.4356, 5.4356, 5.4356, 5.4356, 5.4357,\n",
      "        5.4356, 5.4357, 5.4357, 5.4357, 5.4357, 5.4356, 5.4357, 5.4357, 5.4357,\n",
      "        5.4357, 5.4357, 5.4357, 5.4356, 5.4357, 5.4357, 5.4357, 5.4357, 5.4357,\n",
      "        5.4357, 5.4357, 5.4357, 5.4356, 5.4356, 5.4356, 5.4356, 5.4355, 5.4356,\n",
      "        5.4356, 5.4356, 5.4356, 5.4356, 5.4356, 5.4357, 5.4356, 5.4356, 5.4356,\n",
      "        5.4356, 5.4357, 5.4357, 5.4356, 5.4356, 5.4357, 5.4357, 5.4356, 5.4356,\n",
      "        5.4356, 5.4356, 5.4356, 5.4356, 5.4357, 5.4357, 5.4357, 5.4358, 5.4358,\n",
      "        5.4358, 5.4358, 5.4358, 5.4357, 5.4357, 5.4358, 5.4357, 5.4357, 5.4357,\n",
      "        5.4358, 5.4357, 5.4356, 5.4358, 5.4358, 5.4358, 5.4358, 5.4358, 5.4358,\n",
      "        5.4357, 5.4358, 5.4358, 5.4357, 5.4357, 5.4356, 5.4357, 5.4358, 5.4358,\n",
      "        5.4358, 5.4358, 5.4358, 5.4357, 5.4357, 5.4357, 5.4357, 5.4358, 5.4359,\n",
      "        5.4358, 5.4358, 5.4357, 5.4357, 5.4358, 5.4357, 5.4358, 5.4357, 5.4358,\n",
      "        5.4357, 5.4358, 5.4357], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.413610  [3013324/5599865]\n",
      "average delta from current occupancy tensor([5.2434, 5.2433, 5.2433, 5.2433, 5.2433, 5.2432, 5.2433, 5.2434, 5.2434,\n",
      "        5.2432, 5.2432, 5.2432, 5.2433, 5.2432, 5.2432, 5.2431, 5.2429, 5.2428,\n",
      "        5.2430, 5.2429, 5.2430, 5.2430, 5.2430, 5.2431, 5.2431, 5.2431, 5.2432,\n",
      "        5.2431, 5.2432, 5.2432, 5.2432, 5.2430, 5.2431, 5.2429, 5.2428, 5.2429,\n",
      "        5.2429, 5.2430, 5.2428, 5.2430, 5.2429, 5.2432, 5.2432, 5.2431, 5.2431,\n",
      "        5.2430, 5.2429, 5.2430, 5.2429, 5.2428, 5.2427, 5.2426, 5.2427, 5.2426,\n",
      "        5.2426, 5.2428, 5.2428, 5.2429, 5.2430, 5.2430, 5.2428, 5.2430, 5.2431,\n",
      "        5.2432, 5.2431, 5.2430, 5.2430, 5.2430, 5.2429, 5.2427, 5.2428, 5.2427,\n",
      "        5.2424, 5.2425, 5.2426, 5.2428, 5.2427, 5.2424, 5.2425, 5.2425, 5.2426,\n",
      "        5.2424, 5.2428, 5.2427, 5.2422, 5.2423, 5.2425, 5.2425, 5.2425, 5.2426,\n",
      "        5.2427, 5.2428, 5.2427, 5.2429, 5.2430, 5.2429, 5.2428, 5.2426, 5.2425,\n",
      "        5.2425, 5.2425, 5.2427, 5.2428, 5.2427, 5.2429, 5.2428, 5.2424, 5.2425,\n",
      "        5.2425, 5.2426, 5.2429, 5.2428, 5.2427, 5.2429, 5.2427, 5.2428, 5.2427,\n",
      "        5.2429, 5.2427, 5.2428], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.810367  [3025724/5599865]\n",
      "average delta from current occupancy tensor([4.9769, 4.9766, 4.9766, 4.9767, 4.9765, 4.9763, 4.9764, 4.9766, 4.9766,\n",
      "        4.9763, 4.9760, 4.9759, 4.9760, 4.9760, 4.9759, 4.9759, 4.9760, 4.9762,\n",
      "        4.9763, 4.9761, 4.9762, 4.9761, 4.9763, 4.9760, 4.9762, 4.9760, 4.9759,\n",
      "        4.9760, 4.9761, 4.9759, 4.9760, 4.9759, 4.9760, 4.9760, 4.9761, 4.9759,\n",
      "        4.9763, 4.9760, 4.9760, 4.9762, 4.9761, 4.9760, 4.9762, 4.9762, 4.9760,\n",
      "        4.9759, 4.9761, 4.9760, 4.9761, 4.9763, 4.9759, 4.9761, 4.9761, 4.9760,\n",
      "        4.9760, 4.9760, 4.9760, 4.9760, 4.9761, 4.9761, 4.9761, 4.9760, 4.9760,\n",
      "        4.9760, 4.9760, 4.9759, 4.9759, 4.9761, 4.9761, 4.9760, 4.9759, 4.9760,\n",
      "        4.9759, 4.9760, 4.9761, 4.9760, 4.9761, 4.9761, 4.9761, 4.9761, 4.9760,\n",
      "        4.9761, 4.9760, 4.9764, 4.9763, 4.9765, 4.9760, 4.9763, 4.9760, 4.9760,\n",
      "        4.9760, 4.9761, 4.9760, 4.9760, 4.9762, 4.9760, 4.9759, 4.9761, 4.9762,\n",
      "        4.9765, 4.9764, 4.9767, 4.9765, 4.9763, 4.9766, 4.9764, 4.9764, 4.9761,\n",
      "        4.9766, 4.9764, 4.9763, 4.9764, 4.9761, 4.9764, 4.9762, 4.9763, 4.9766,\n",
      "        4.9766, 4.9767, 4.9766], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.640076  [3038124/5599865]\n",
      "average delta from current occupancy tensor([4.7505, 4.7511, 4.7509, 4.7509, 4.7509, 4.7513, 4.7514, 4.7513, 4.7510,\n",
      "        4.7510, 4.7504, 4.7508, 4.7506, 4.7504, 4.7508, 4.7504, 4.7504, 4.7506,\n",
      "        4.7506, 4.7505, 4.7503, 4.7501, 4.7509, 4.7507, 4.7511, 4.7504, 4.7501,\n",
      "        4.7501, 4.7506, 4.7503, 4.7502, 4.7503, 4.7506, 4.7506, 4.7506, 4.7508,\n",
      "        4.7512, 4.7511, 4.7508, 4.7511, 4.7509, 4.7502, 4.7502, 4.7500, 4.7500,\n",
      "        4.7503, 4.7500, 4.7504, 4.7502, 4.7500, 4.7504, 4.7501, 4.7500, 4.7502,\n",
      "        4.7502, 4.7501, 4.7500, 4.7500, 4.7500, 4.7500, 4.7503, 4.7505, 4.7505,\n",
      "        4.7503, 4.7502, 4.7502, 4.7510, 4.7503, 4.7501, 4.7500, 4.7502, 4.7501,\n",
      "        4.7500, 4.7500, 4.7502, 4.7502, 4.7502, 4.7500, 4.7501, 4.7502, 4.7500,\n",
      "        4.7502, 4.7503, 4.7500, 4.7500, 4.7500, 4.7503, 4.7501, 4.7502, 4.7503,\n",
      "        4.7504, 4.7500, 4.7500, 4.7500, 4.7500, 4.7505, 4.7512, 4.7506, 4.7503,\n",
      "        4.7500, 4.7500, 4.7507, 4.7503, 4.7508, 4.7505, 4.7506, 4.7509, 4.7510,\n",
      "        4.7512, 4.7512, 4.7509, 4.7512, 4.7511, 4.7513, 4.7514, 4.7513, 4.7513,\n",
      "        4.7513, 4.7512, 4.7511], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.159636  [3050524/5599865]\n",
      "average delta from current occupancy tensor([5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773,\n",
      "        5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773,\n",
      "        5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773,\n",
      "        5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1773, 5.1773, 5.1773,\n",
      "        5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1773, 5.1773,\n",
      "        5.1774, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1774, 5.1774,\n",
      "        5.1774, 5.1774, 5.1774, 5.1774, 5.1773, 5.1773, 5.1774, 5.1773, 5.1773,\n",
      "        5.1774, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1773, 5.1774, 5.1773,\n",
      "        5.1774, 5.1774, 5.1774, 5.1774, 5.1773, 5.1774, 5.1773, 5.1773, 5.1774,\n",
      "        5.1774, 5.1774, 5.1774, 5.1774, 5.1774, 5.1774, 5.1773, 5.1774, 5.1774,\n",
      "        5.1774, 5.1774, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1774, 5.1774,\n",
      "        5.1774, 5.1774, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1774,\n",
      "        5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1772, 5.1773, 5.1773, 5.1773,\n",
      "        5.1773, 5.1773, 5.1773], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.445403  [3062924/5599865]\n",
      "average delta from current occupancy tensor([5.5148, 5.5149, 5.5150, 5.5151, 5.5152, 5.5152, 5.5151, 5.5151, 5.5152,\n",
      "        5.5151, 5.5151, 5.5150, 5.5152, 5.5152, 5.5152, 5.5153, 5.5152, 5.5153,\n",
      "        5.5152, 5.5152, 5.5151, 5.5153, 5.5151, 5.5151, 5.5151, 5.5154, 5.5153,\n",
      "        5.5152, 5.5153, 5.5153, 5.5152, 5.5153, 5.5153, 5.5155, 5.5153, 5.5153,\n",
      "        5.5152, 5.5153, 5.5154, 5.5153, 5.5154, 5.5154, 5.5151, 5.5151, 5.5151,\n",
      "        5.5151, 5.5150, 5.5151, 5.5151, 5.5152, 5.5152, 5.5153, 5.5150, 5.5151,\n",
      "        5.5150, 5.5151, 5.5153, 5.5152, 5.5153, 5.5151, 5.5151, 5.5151, 5.5152,\n",
      "        5.5153, 5.5152, 5.5152, 5.5152, 5.5153, 5.5151, 5.5152, 5.5152, 5.5152,\n",
      "        5.5152, 5.5152, 5.5151, 5.5152, 5.5153, 5.5151, 5.5152, 5.5153, 5.5152,\n",
      "        5.5151, 5.5151, 5.5152, 5.5153, 5.5150, 5.5151, 5.5151, 5.5149, 5.5150,\n",
      "        5.5150, 5.5150, 5.5150, 5.5150, 5.5151, 5.5149, 5.5151, 5.5150, 5.5151,\n",
      "        5.5152, 5.5151, 5.5153, 5.5153, 5.5153, 5.5153, 5.5152, 5.5153, 5.5152,\n",
      "        5.5152, 5.5152, 5.5153, 5.5152, 5.5153, 5.5152, 5.5150, 5.5151, 5.5150,\n",
      "        5.5150, 5.5150, 5.5149], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.069241  [3075324/5599865]\n",
      "average delta from current occupancy tensor([5.0249, 5.0250, 5.0250, 5.0250, 5.0250, 5.0250, 5.0250, 5.0249, 5.0250,\n",
      "        5.0251, 5.0250, 5.0251, 5.0251, 5.0251, 5.0251, 5.0250, 5.0251, 5.0251,\n",
      "        5.0251, 5.0251, 5.0252, 5.0251, 5.0251, 5.0251, 5.0251, 5.0252, 5.0252,\n",
      "        5.0251, 5.0252, 5.0251, 5.0252, 5.0252, 5.0252, 5.0252, 5.0252, 5.0252,\n",
      "        5.0252, 5.0252, 5.0251, 5.0251, 5.0251, 5.0252, 5.0251, 5.0251, 5.0252,\n",
      "        5.0250, 5.0251, 5.0250, 5.0251, 5.0251, 5.0251, 5.0251, 5.0251, 5.0250,\n",
      "        5.0250, 5.0251, 5.0250, 5.0249, 5.0251, 5.0251, 5.0249, 5.0250, 5.0250,\n",
      "        5.0251, 5.0252, 5.0251, 5.0250, 5.0250, 5.0249, 5.0249, 5.0250, 5.0251,\n",
      "        5.0251, 5.0250, 5.0251, 5.0250, 5.0250, 5.0249, 5.0250, 5.0250, 5.0250,\n",
      "        5.0250, 5.0250, 5.0249, 5.0250, 5.0250, 5.0251, 5.0250, 5.0250, 5.0251,\n",
      "        5.0250, 5.0250, 5.0250, 5.0250, 5.0250, 5.0250, 5.0250, 5.0251, 5.0250,\n",
      "        5.0250, 5.0250, 5.0251, 5.0251, 5.0250, 5.0251, 5.0251, 5.0251, 5.0252,\n",
      "        5.0251, 5.0251, 5.0252, 5.0252, 5.0251, 5.0252, 5.0252, 5.0252, 5.0252,\n",
      "        5.0252, 5.0252, 5.0253], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.469315  [3087724/5599865]\n",
      "average delta from current occupancy tensor([5.8071, 5.8069, 5.8070, 5.8070, 5.8071, 5.8072, 5.8071, 5.8070, 5.8072,\n",
      "        5.8072, 5.8071, 5.8073, 5.8069, 5.8069, 5.8071, 5.8070, 5.8071, 5.8068,\n",
      "        5.8068, 5.8068, 5.8069, 5.8069, 5.8069, 5.8069, 5.8070, 5.8069, 5.8070,\n",
      "        5.8071, 5.8071, 5.8069, 5.8071, 5.8071, 5.8071, 5.8071, 5.8071, 5.8070,\n",
      "        5.8068, 5.8068, 5.8070, 5.8069, 5.8068, 5.8069, 5.8069, 5.8070, 5.8068,\n",
      "        5.8067, 5.8068, 5.8067, 5.8068, 5.8068, 5.8069, 5.8069, 5.8068, 5.8068,\n",
      "        5.8069, 5.8069, 5.8067, 5.8067, 5.8068, 5.8069, 5.8066, 5.8065, 5.8068,\n",
      "        5.8068, 5.8071, 5.8069, 5.8069, 5.8068, 5.8067, 5.8067, 5.8066, 5.8067,\n",
      "        5.8066, 5.8065, 5.8066, 5.8067, 5.8066, 5.8067, 5.8067, 5.8067, 5.8067,\n",
      "        5.8066, 5.8065, 5.8065, 5.8065, 5.8065, 5.8067, 5.8067, 5.8066, 5.8065,\n",
      "        5.8066, 5.8065, 5.8067, 5.8066, 5.8065, 5.8066, 5.8068, 5.8068, 5.8066,\n",
      "        5.8067, 5.8066, 5.8065, 5.8065, 5.8065, 5.8065, 5.8067, 5.8066, 5.8067,\n",
      "        5.8065, 5.8065, 5.8067, 5.8070, 5.8068, 5.8068, 5.8068, 5.8069, 5.8070,\n",
      "        5.8069, 5.8072, 5.8072], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.112469  [3100124/5599865]\n",
      "average delta from current occupancy tensor([5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1856, 5.1855, 5.1856, 5.1855, 5.1856, 5.1855,\n",
      "        5.1856, 5.1856, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1856, 5.1855,\n",
      "        5.1855, 5.1855, 5.1856, 5.1855, 5.1856, 5.1856, 5.1856, 5.1856, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1856, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1856, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1855, 5.1856, 5.1856, 5.1856, 5.1856, 5.1856, 5.1855,\n",
      "        5.1856, 5.1856, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1855, 5.1856, 5.1856, 5.1856, 5.1856, 5.1856, 5.1856, 5.1856,\n",
      "        5.1856, 5.1856, 5.1855], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.726637  [3112524/5599865]\n",
      "average delta from current occupancy tensor([5.4922, 5.4922, 5.4921, 5.4922, 5.4922, 5.4924, 5.4924, 5.4924, 5.4923,\n",
      "        5.4922, 5.4922, 5.4920, 5.4921, 5.4922, 5.4922, 5.4921, 5.4922, 5.4923,\n",
      "        5.4921, 5.4922, 5.4922, 5.4921, 5.4921, 5.4922, 5.4921, 5.4921, 5.4923,\n",
      "        5.4924, 5.4923, 5.4923, 5.4923, 5.4923, 5.4923, 5.4922, 5.4923, 5.4922,\n",
      "        5.4924, 5.4924, 5.4922, 5.4920, 5.4920, 5.4922, 5.4921, 5.4920, 5.4921,\n",
      "        5.4920, 5.4921, 5.4920, 5.4921, 5.4921, 5.4920, 5.4921, 5.4920, 5.4921,\n",
      "        5.4922, 5.4921, 5.4920, 5.4921, 5.4920, 5.4922, 5.4921, 5.4921, 5.4921,\n",
      "        5.4922, 5.4922, 5.4922, 5.4922, 5.4921, 5.4921, 5.4920, 5.4921, 5.4922,\n",
      "        5.4922, 5.4922, 5.4922, 5.4922, 5.4921, 5.4921, 5.4923, 5.4922, 5.4921,\n",
      "        5.4922, 5.4920, 5.4920, 5.4923, 5.4920, 5.4920, 5.4922, 5.4921, 5.4922,\n",
      "        5.4923, 5.4922, 5.4924, 5.4923, 5.4924, 5.4924, 5.4924, 5.4924, 5.4923,\n",
      "        5.4924, 5.4924, 5.4921, 5.4921, 5.4921, 5.4921, 5.4919, 5.4921, 5.4920,\n",
      "        5.4920, 5.4920, 5.4919, 5.4920, 5.4920, 5.4922, 5.4922, 5.4921, 5.4920,\n",
      "        5.4920, 5.4921, 5.4921], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.295130  [3124924/5599865]\n",
      "average delta from current occupancy tensor([6.7067, 6.7066, 6.7064, 6.7066, 6.7065, 6.7065, 6.7066, 6.7066, 6.7064,\n",
      "        6.7066, 6.7067, 6.7063, 6.7068, 6.7066, 6.7067, 6.7063, 6.7064, 6.7064,\n",
      "        6.7060, 6.7063, 6.7063, 6.7063, 6.7061, 6.7060, 6.7060, 6.7059, 6.7066,\n",
      "        6.7063, 6.7061, 6.7061, 6.7064, 6.7062, 6.7063, 6.7063, 6.7064, 6.7064,\n",
      "        6.7062, 6.7063, 6.7059, 6.7055, 6.7056, 6.7056, 6.7056, 6.7055, 6.7055,\n",
      "        6.7057, 6.7059, 6.7057, 6.7056, 6.7058, 6.7059, 6.7056, 6.7057, 6.7058,\n",
      "        6.7058, 6.7058, 6.7058, 6.7055, 6.7058, 6.7056, 6.7056, 6.7052, 6.7055,\n",
      "        6.7057, 6.7058, 6.7061, 6.7058, 6.7058, 6.7056, 6.7056, 6.7057, 6.7058,\n",
      "        6.7061, 6.7057, 6.7053, 6.7062, 6.7054, 6.7053, 6.7056, 6.7061, 6.7061,\n",
      "        6.7064, 6.7066, 6.7066, 6.7064, 6.7064, 6.7063, 6.7059, 6.7064, 6.7062,\n",
      "        6.7055, 6.7054, 6.7063, 6.7062, 6.7063, 6.7063, 6.7062, 6.7063, 6.7055,\n",
      "        6.7055, 6.7062, 6.7062, 6.7058, 6.7057, 6.7055, 6.7061, 6.7058, 6.7058,\n",
      "        6.7065, 6.7062, 6.7069, 6.7061, 6.7064, 6.7058, 6.7058, 6.7066, 6.7063,\n",
      "        6.7055, 6.7058, 6.7055], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.377452  [3137324/5599865]\n",
      "average delta from current occupancy tensor([5.4451, 5.4449, 5.4447, 5.4447, 5.4447, 5.4447, 5.4448, 5.4450, 5.4446,\n",
      "        5.4449, 5.4448, 5.4444, 5.4447, 5.4449, 5.4449, 5.4446, 5.4447, 5.4446,\n",
      "        5.4441, 5.4443, 5.4445, 5.4443, 5.4445, 5.4442, 5.4443, 5.4439, 5.4444,\n",
      "        5.4443, 5.4440, 5.4440, 5.4443, 5.4442, 5.4443, 5.4444, 5.4444, 5.4443,\n",
      "        5.4442, 5.4442, 5.4439, 5.4437, 5.4436, 5.4437, 5.4437, 5.4437, 5.4438,\n",
      "        5.4437, 5.4437, 5.4438, 5.4436, 5.4437, 5.4436, 5.4436, 5.4436, 5.4437,\n",
      "        5.4436, 5.4436, 5.4437, 5.4437, 5.4437, 5.4439, 5.4437, 5.4439, 5.4441,\n",
      "        5.4440, 5.4440, 5.4438, 5.4440, 5.4441, 5.4442, 5.4441, 5.4442, 5.4442,\n",
      "        5.4436, 5.4440, 5.4440, 5.4436, 5.4440, 5.4441, 5.4438, 5.4436, 5.4436,\n",
      "        5.4436, 5.4436, 5.4436, 5.4437, 5.4436, 5.4437, 5.4436, 5.4437, 5.4437,\n",
      "        5.4440, 5.4441, 5.4437, 5.4436, 5.4438, 5.4438, 5.4436, 5.4436, 5.4439,\n",
      "        5.4438, 5.4437, 5.4437, 5.4437, 5.4438, 5.4438, 5.4437, 5.4437, 5.4438,\n",
      "        5.4437, 5.4438, 5.4436, 5.4437, 5.4436, 5.4438, 5.4438, 5.4437, 5.4437,\n",
      "        5.4439, 5.4438, 5.4439], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.260823  [3149724/5599865]\n",
      "average delta from current occupancy tensor([5.0977, 5.0976, 5.0976, 5.0977, 5.0979, 5.0979, 5.0981, 5.0984, 5.0981,\n",
      "        5.0984, 5.0981, 5.0985, 5.0980, 5.0981, 5.0982, 5.0985, 5.0982, 5.0983,\n",
      "        5.0983, 5.0986, 5.0986, 5.0986, 5.0984, 5.0984, 5.0985, 5.0983, 5.0982,\n",
      "        5.0983, 5.0982, 5.0979, 5.0985, 5.0983, 5.0983, 5.0980, 5.0983, 5.0983,\n",
      "        5.0986, 5.0984, 5.0980, 5.0982, 5.0979, 5.0977, 5.0982, 5.0980, 5.0982,\n",
      "        5.0982, 5.0984, 5.0983, 5.0982, 5.0986, 5.0985, 5.0984, 5.0982, 5.0986,\n",
      "        5.0983, 5.0984, 5.0985, 5.0982, 5.0983, 5.0979, 5.0980, 5.0982, 5.0982,\n",
      "        5.0979, 5.0978, 5.0974, 5.0978, 5.0978, 5.0977, 5.0976, 5.0979, 5.0976,\n",
      "        5.0978, 5.0977, 5.0977, 5.0978, 5.0978, 5.0981, 5.0978, 5.0981, 5.0978,\n",
      "        5.0981, 5.0981, 5.0981, 5.0979, 5.0979, 5.0979, 5.0980, 5.0980, 5.0978,\n",
      "        5.0979, 5.0979, 5.0979, 5.0978, 5.0978, 5.0978, 5.0977, 5.0979, 5.0979,\n",
      "        5.0979, 5.0979, 5.0979, 5.0980, 5.0977, 5.0979, 5.0978, 5.0981, 5.0980,\n",
      "        5.0985, 5.0986, 5.0981, 5.0982, 5.0981, 5.0983, 5.0980, 5.0988, 5.0983,\n",
      "        5.0984, 5.0984, 5.0983], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.038302  [3162124/5599865]\n",
      "average delta from current occupancy tensor([4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9759, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9759, 4.9759, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9759, 4.9758, 4.9759, 4.9759, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9759, 4.9758, 4.9759, 4.9759, 4.9759, 4.9759, 4.9759, 4.9759,\n",
      "        4.9759, 4.9759, 4.9759, 4.9759, 4.9759, 4.9758, 4.9759, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758, 4.9758,\n",
      "        4.9758, 4.9758, 4.9758], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.038955  [3174524/5599865]\n",
      "average delta from current occupancy tensor([4.8147, 4.8147, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146,\n",
      "        4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146,\n",
      "        4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146,\n",
      "        4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146,\n",
      "        4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146, 4.8146,\n",
      "        4.8147, 4.8147, 4.8147, 4.8147, 4.8146, 4.8147, 4.8147, 4.8146, 4.8147,\n",
      "        4.8146, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147,\n",
      "        4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147,\n",
      "        4.8147, 4.8147, 4.8147, 4.8147, 4.8146, 4.8146, 4.8147, 4.8147, 4.8147,\n",
      "        4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147,\n",
      "        4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147, 4.8147,\n",
      "        4.8147, 4.8146, 4.8146, 4.8146, 4.8147, 4.8147, 4.8147, 4.8146, 4.8146,\n",
      "        4.8146, 4.8147, 4.8147, 4.8147, 4.8147, 4.8146, 4.8146, 4.8146, 4.8147,\n",
      "        4.8147, 4.8147, 4.8147], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.475586  [3186924/5599865]\n",
      "average delta from current occupancy tensor([4.5161, 4.5161, 4.5161, 4.5161, 4.5160, 4.5161, 4.5160, 4.5160, 4.5161,\n",
      "        4.5161, 4.5161, 4.5160, 4.5160, 4.5161, 4.5160, 4.5160, 4.5160, 4.5161,\n",
      "        4.5161, 4.5162, 4.5161, 4.5161, 4.5161, 4.5161, 4.5160, 4.5160, 4.5160,\n",
      "        4.5161, 4.5161, 4.5161, 4.5161, 4.5161, 4.5160, 4.5161, 4.5161, 4.5161,\n",
      "        4.5161, 4.5161, 4.5161, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5161, 4.5160, 4.5161, 4.5160, 4.5161,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5161, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5161, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160, 4.5161, 4.5161, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5160, 4.5160, 4.5160], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.784737  [3199324/5599865]\n",
      "average delta from current occupancy tensor([4.8943, 4.8943, 4.8945, 4.8944, 4.8945, 4.8946, 4.8946, 4.8946, 4.8946,\n",
      "        4.8945, 4.8945, 4.8945, 4.8943, 4.8943, 4.8943, 4.8944, 4.8943, 4.8943,\n",
      "        4.8943, 4.8943, 4.8946, 4.8942, 4.8945, 4.8943, 4.8943, 4.8944, 4.8943,\n",
      "        4.8942, 4.8942, 4.8942, 4.8942, 4.8942, 4.8941, 4.8943, 4.8945, 4.8942,\n",
      "        4.8941, 4.8943, 4.8943, 4.8941, 4.8940, 4.8939, 4.8940, 4.8938, 4.8938,\n",
      "        4.8938, 4.8938, 4.8940, 4.8938, 4.8939, 4.8940, 4.8940, 4.8942, 4.8942,\n",
      "        4.8943, 4.8941, 4.8941, 4.8941, 4.8942, 4.8942, 4.8943, 4.8941, 4.8945,\n",
      "        4.8943, 4.8944, 4.8942, 4.8946, 4.8947, 4.8944, 4.8943, 4.8946, 4.8945,\n",
      "        4.8948, 4.8943, 4.8948, 4.8946, 4.8943, 4.8946, 4.8944, 4.8941, 4.8943,\n",
      "        4.8943, 4.8944, 4.8945, 4.8944, 4.8947, 4.8948, 4.8949, 4.8952, 4.8950,\n",
      "        4.8954, 4.8951, 4.8949, 4.8945, 4.8945, 4.8944, 4.8945, 4.8944, 4.8945,\n",
      "        4.8944, 4.8944, 4.8944, 4.8948, 4.8945, 4.8944, 4.8943, 4.8949, 4.8945,\n",
      "        4.8947, 4.8944, 4.8945, 4.8947, 4.8947, 4.8943, 4.8942, 4.8944, 4.8944,\n",
      "        4.8942, 4.8945, 4.8944], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.441421  [3211724/5599865]\n",
      "average delta from current occupancy tensor([4.8705, 4.8704, 4.8705, 4.8705, 4.8706, 4.8706, 4.8706, 4.8706, 4.8705,\n",
      "        4.8705, 4.8705, 4.8704, 4.8704, 4.8704, 4.8704, 4.8704, 4.8705, 4.8704,\n",
      "        4.8705, 4.8705, 4.8704, 4.8705, 4.8705, 4.8705, 4.8705, 4.8705, 4.8705,\n",
      "        4.8704, 4.8705, 4.8704, 4.8705, 4.8703, 4.8703, 4.8704, 4.8703, 4.8703,\n",
      "        4.8703, 4.8703, 4.8704, 4.8703, 4.8704, 4.8703, 4.8704, 4.8704, 4.8704,\n",
      "        4.8703, 4.8704, 4.8703, 4.8703, 4.8703, 4.8704, 4.8704, 4.8703, 4.8704,\n",
      "        4.8704, 4.8705, 4.8705, 4.8704, 4.8704, 4.8705, 4.8705, 4.8705, 4.8704,\n",
      "        4.8705, 4.8705, 4.8705, 4.8705, 4.8704, 4.8705, 4.8705, 4.8705, 4.8705,\n",
      "        4.8704, 4.8705, 4.8705, 4.8705, 4.8704, 4.8704, 4.8705, 4.8704, 4.8705,\n",
      "        4.8705, 4.8704, 4.8704, 4.8704, 4.8705, 4.8704, 4.8705, 4.8705, 4.8705,\n",
      "        4.8703, 4.8704, 4.8704, 4.8705, 4.8704, 4.8704, 4.8704, 4.8705, 4.8705,\n",
      "        4.8704, 4.8704, 4.8704, 4.8705, 4.8703, 4.8703, 4.8703, 4.8704, 4.8703,\n",
      "        4.8703, 4.8704, 4.8704, 4.8704, 4.8704, 4.8705, 4.8705, 4.8704, 4.8704,\n",
      "        4.8704, 4.8705, 4.8705], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.325746  [3224124/5599865]\n",
      "average delta from current occupancy tensor([5.1374, 5.1374, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373, 5.1374,\n",
      "        5.1374, 5.1374, 5.1374, 5.1374, 5.1374, 5.1374, 5.1374, 5.1374, 5.1374,\n",
      "        5.1374, 5.1374, 5.1374, 5.1374, 5.1373, 5.1373, 5.1373, 5.1373, 5.1372,\n",
      "        5.1373, 5.1373, 5.1373, 5.1372, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373,\n",
      "        5.1373, 5.1373, 5.1373, 5.1373, 5.1372, 5.1373, 5.1372, 5.1373, 5.1373,\n",
      "        5.1373, 5.1372, 5.1373, 5.1373, 5.1372, 5.1372, 5.1372, 5.1372, 5.1372,\n",
      "        5.1372, 5.1371, 5.1371, 5.1371, 5.1372, 5.1371, 5.1372, 5.1373, 5.1372,\n",
      "        5.1373, 5.1374, 5.1374, 5.1373, 5.1371, 5.1373, 5.1372, 5.1373, 5.1373,\n",
      "        5.1371, 5.1371, 5.1372, 5.1371, 5.1371, 5.1372, 5.1371, 5.1372, 5.1371,\n",
      "        5.1371, 5.1372, 5.1372, 5.1372, 5.1371, 5.1371, 5.1372, 5.1371, 5.1371,\n",
      "        5.1372, 5.1372, 5.1372, 5.1372, 5.1372, 5.1373, 5.1373, 5.1373, 5.1373,\n",
      "        5.1373, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373, 5.1373,\n",
      "        5.1373, 5.1373, 5.1373, 5.1372, 5.1372, 5.1372, 5.1372, 5.1372, 5.1372,\n",
      "        5.1372, 5.1372, 5.1373], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.857117  [3236524/5599865]\n",
      "average delta from current occupancy tensor([4.8955, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8955,\n",
      "        4.8954, 4.8955, 4.8955, 4.8956, 4.8955, 4.8954, 4.8956, 4.8955, 4.8955,\n",
      "        4.8954, 4.8954, 4.8955, 4.8953, 4.8953, 4.8954, 4.8953, 4.8954, 4.8954,\n",
      "        4.8954, 4.8954, 4.8955, 4.8954, 4.8955, 4.8953, 4.8954, 4.8955, 4.8955,\n",
      "        4.8955, 4.8955, 4.8954, 4.8954, 4.8955, 4.8954, 4.8955, 4.8954, 4.8953,\n",
      "        4.8954, 4.8955, 4.8954, 4.8955, 4.8955, 4.8955, 4.8954, 4.8954, 4.8954,\n",
      "        4.8954, 4.8954, 4.8955, 4.8955, 4.8955, 4.8953, 4.8954, 4.8954, 4.8953,\n",
      "        4.8953, 4.8954, 4.8954, 4.8953, 4.8953, 4.8953, 4.8954, 4.8953, 4.8954,\n",
      "        4.8954, 4.8954, 4.8953, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954,\n",
      "        4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8954, 4.8953, 4.8953, 4.8954,\n",
      "        4.8954, 4.8954, 4.8953, 4.8953, 4.8953, 4.8953, 4.8953, 4.8952, 4.8953,\n",
      "        4.8954, 4.8952, 4.8954, 4.8953, 4.8953, 4.8953, 4.8953, 4.8953, 4.8953,\n",
      "        4.8953, 4.8953, 4.8953, 4.8953, 4.8953, 4.8953, 4.8953, 4.8953, 4.8954,\n",
      "        4.8953, 4.8954, 4.8954], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.983675  [3248924/5599865]\n",
      "average delta from current occupancy tensor([5.0073, 5.0073, 5.0072, 5.0072, 5.0072, 5.0073, 5.0074, 5.0074, 5.0075,\n",
      "        5.0074, 5.0074, 5.0075, 5.0077, 5.0075, 5.0073, 5.0075, 5.0074, 5.0074,\n",
      "        5.0073, 5.0074, 5.0073, 5.0073, 5.0074, 5.0074, 5.0074, 5.0073, 5.0074,\n",
      "        5.0074, 5.0074, 5.0073, 5.0073, 5.0074, 5.0073, 5.0074, 5.0074, 5.0075,\n",
      "        5.0075, 5.0074, 5.0074, 5.0073, 5.0075, 5.0073, 5.0076, 5.0074, 5.0073,\n",
      "        5.0073, 5.0075, 5.0074, 5.0074, 5.0075, 5.0075, 5.0074, 5.0074, 5.0074,\n",
      "        5.0073, 5.0073, 5.0074, 5.0074, 5.0073, 5.0072, 5.0073, 5.0073, 5.0072,\n",
      "        5.0072, 5.0072, 5.0072, 5.0072, 5.0072, 5.0072, 5.0071, 5.0071, 5.0072,\n",
      "        5.0072, 5.0073, 5.0072, 5.0072, 5.0072, 5.0072, 5.0073, 5.0073, 5.0073,\n",
      "        5.0073, 5.0073, 5.0073, 5.0073, 5.0073, 5.0073, 5.0072, 5.0072, 5.0073,\n",
      "        5.0073, 5.0073, 5.0072, 5.0073, 5.0072, 5.0073, 5.0072, 5.0072, 5.0072,\n",
      "        5.0073, 5.0073, 5.0073, 5.0073, 5.0073, 5.0073, 5.0073, 5.0073, 5.0073,\n",
      "        5.0073, 5.0074, 5.0074, 5.0073, 5.0073, 5.0072, 5.0073, 5.0073, 5.0073,\n",
      "        5.0073, 5.0072, 5.0072], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.949879  [3261324/5599865]\n",
      "average delta from current occupancy tensor([4.8310, 4.8310, 4.8312, 4.8307, 4.8307, 4.8307, 4.8307, 4.8307, 4.8307,\n",
      "        4.8307, 4.8307, 4.8307, 4.8311, 4.8307, 4.8307, 4.8307, 4.8308, 4.8308,\n",
      "        4.8307, 4.8307, 4.8307, 4.8307, 4.8308, 4.8308, 4.8308, 4.8308, 4.8308,\n",
      "        4.8308, 4.8308, 4.8307, 4.8308, 4.8307, 4.8308, 4.8306, 4.8306, 4.8309,\n",
      "        4.8309, 4.8307, 4.8307, 4.8306, 4.8311, 4.8307, 4.8309, 4.8308, 4.8307,\n",
      "        4.8308, 4.8314, 4.8309, 4.8307, 4.8312, 4.8311, 4.8307, 4.8308, 4.8307,\n",
      "        4.8307, 4.8307, 4.8309, 4.8307, 4.8309, 4.8307, 4.8309, 4.8307, 4.8308,\n",
      "        4.8308, 4.8307, 4.8307, 4.8307, 4.8307, 4.8308, 4.8308, 4.8310, 4.8307,\n",
      "        4.8307, 4.8308, 4.8307, 4.8307, 4.8307, 4.8307, 4.8306, 4.8307, 4.8308,\n",
      "        4.8310, 4.8310, 4.8309, 4.8309, 4.8310, 4.8310, 4.8309, 4.8307, 4.8309,\n",
      "        4.8310, 4.8310, 4.8307, 4.8308, 4.8309, 4.8309, 4.8310, 4.8307, 4.8308,\n",
      "        4.8308, 4.8308, 4.8309, 4.8309, 4.8308, 4.8308, 4.8307, 4.8308, 4.8309,\n",
      "        4.8309, 4.8308, 4.8309, 4.8309, 4.8309, 4.8309, 4.8309, 4.8310, 4.8311,\n",
      "        4.8311, 4.8311, 4.8310], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.223401  [3273724/5599865]\n",
      "average delta from current occupancy tensor([4.1274, 4.1275, 4.1278, 4.1273, 4.1273, 4.1273, 4.1273, 4.1275, 4.1275,\n",
      "        4.1274, 4.1274, 4.1272, 4.1272, 4.1272, 4.1275, 4.1272, 4.1276, 4.1273,\n",
      "        4.1273, 4.1273, 4.1273, 4.1274, 4.1274, 4.1274, 4.1274, 4.1273, 4.1271,\n",
      "        4.1271, 4.1270, 4.1271, 4.1272, 4.1271, 4.1272, 4.1271, 4.1272, 4.1271,\n",
      "        4.1271, 4.1270, 4.1270, 4.1270, 4.1271, 4.1269, 4.1270, 4.1270, 4.1269,\n",
      "        4.1269, 4.1270, 4.1270, 4.1269, 4.1270, 4.1269, 4.1271, 4.1270, 4.1270,\n",
      "        4.1269, 4.1270, 4.1269, 4.1269, 4.1270, 4.1269, 4.1270, 4.1269, 4.1270,\n",
      "        4.1270, 4.1270, 4.1270, 4.1271, 4.1271, 4.1270, 4.1270, 4.1269, 4.1271,\n",
      "        4.1272, 4.1274, 4.1272, 4.1272, 4.1271, 4.1270, 4.1270, 4.1270, 4.1272,\n",
      "        4.1275, 4.1274, 4.1276, 4.1277, 4.1274, 4.1277, 4.1274, 4.1274, 4.1276,\n",
      "        4.1277, 4.1276, 4.1272, 4.1275, 4.1275, 4.1275, 4.1274, 4.1272, 4.1273,\n",
      "        4.1275, 4.1276, 4.1274, 4.1273, 4.1274, 4.1275, 4.1276, 4.1275, 4.1276,\n",
      "        4.1276, 4.1275, 4.1275, 4.1274, 4.1274, 4.1274, 4.1274, 4.1273, 4.1273,\n",
      "        4.1273, 4.1274, 4.1274], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.450670  [3286124/5599865]\n",
      "average delta from current occupancy tensor([5.5239, 5.5238, 5.5238, 5.5238, 5.5238, 5.5238, 5.5240, 5.5239, 5.5240,\n",
      "        5.5238, 5.5239, 5.5240, 5.5239, 5.5240, 5.5239, 5.5238, 5.5240, 5.5239,\n",
      "        5.5238, 5.5238, 5.5239, 5.5240, 5.5238, 5.5237, 5.5237, 5.5236, 5.5237,\n",
      "        5.5238, 5.5238, 5.5236, 5.5238, 5.5238, 5.5237, 5.5237, 5.5237, 5.5238,\n",
      "        5.5239, 5.5237, 5.5237, 5.5236, 5.5238, 5.5237, 5.5239, 5.5236, 5.5238,\n",
      "        5.5236, 5.5238, 5.5238, 5.5238, 5.5240, 5.5237, 5.5237, 5.5238, 5.5240,\n",
      "        5.5239, 5.5239, 5.5240, 5.5240, 5.5239, 5.5239, 5.5238, 5.5240, 5.5239,\n",
      "        5.5238, 5.5239, 5.5239, 5.5238, 5.5238, 5.5237, 5.5236, 5.5237, 5.5240,\n",
      "        5.5240, 5.5238, 5.5239, 5.5240, 5.5239, 5.5239, 5.5240, 5.5239, 5.5240,\n",
      "        5.5240, 5.5240, 5.5240, 5.5240, 5.5240, 5.5240, 5.5239, 5.5239, 5.5239,\n",
      "        5.5240, 5.5240, 5.5240, 5.5240, 5.5240, 5.5239, 5.5240, 5.5240, 5.5241,\n",
      "        5.5240, 5.5240, 5.5241, 5.5238, 5.5240, 5.5241, 5.5240, 5.5239, 5.5240,\n",
      "        5.5239, 5.5238, 5.5237, 5.5239, 5.5237, 5.5238, 5.5238, 5.5240, 5.5240,\n",
      "        5.5239, 5.5239, 5.5238], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.231135  [3298524/5599865]\n",
      "average delta from current occupancy tensor([5.1237, 5.1239, 5.1239, 5.1240, 5.1239, 5.1238, 5.1241, 5.1240, 5.1240,\n",
      "        5.1238, 5.1243, 5.1244, 5.1240, 5.1244, 5.1241, 5.1242, 5.1243, 5.1242,\n",
      "        5.1240, 5.1241, 5.1243, 5.1246, 5.1238, 5.1238, 5.1237, 5.1239, 5.1240,\n",
      "        5.1240, 5.1240, 5.1237, 5.1239, 5.1236, 5.1236, 5.1236, 5.1237, 5.1237,\n",
      "        5.1240, 5.1239, 5.1239, 5.1243, 5.1239, 5.1241, 5.1240, 5.1243, 5.1239,\n",
      "        5.1242, 5.1237, 5.1238, 5.1238, 5.1235, 5.1235, 5.1239, 5.1234, 5.1240,\n",
      "        5.1236, 5.1234, 5.1243, 5.1241, 5.1243, 5.1242, 5.1243, 5.1246, 5.1247,\n",
      "        5.1247, 5.1242, 5.1241, 5.1246, 5.1246, 5.1248, 5.1248, 5.1248, 5.1249,\n",
      "        5.1247, 5.1245, 5.1247, 5.1250, 5.1249, 5.1248, 5.1248, 5.1249, 5.1248,\n",
      "        5.1247, 5.1251, 5.1248, 5.1247, 5.1248, 5.1249, 5.1247, 5.1249, 5.1247,\n",
      "        5.1250, 5.1248, 5.1249, 5.1249, 5.1249, 5.1248, 5.1250, 5.1251, 5.1249,\n",
      "        5.1250, 5.1251, 5.1251, 5.1251, 5.1252, 5.1252, 5.1251, 5.1247, 5.1248,\n",
      "        5.1247, 5.1246, 5.1250, 5.1246, 5.1249, 5.1245, 5.1247, 5.1247, 5.1246,\n",
      "        5.1245, 5.1245, 5.1245], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.970786  [3310924/5599865]\n",
      "average delta from current occupancy tensor([5.0561, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0561, 5.0562, 5.0561, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0561, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0561,\n",
      "        5.0562, 5.0562, 5.0561, 5.0561, 5.0561, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0561, 5.0562, 5.0563, 5.0562, 5.0562, 5.0562, 5.0563, 5.0563,\n",
      "        5.0562, 5.0562, 5.0563, 5.0562, 5.0562, 5.0563, 5.0563, 5.0563, 5.0563,\n",
      "        5.0563, 5.0563, 5.0563, 5.0562, 5.0563, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0563, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562, 5.0562,\n",
      "        5.0562, 5.0562, 5.0562], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.397453  [3323324/5599865]\n",
      "average delta from current occupancy tensor([5.5164, 5.5165, 5.5164, 5.5162, 5.5163, 5.5162, 5.5163, 5.5164, 5.5163,\n",
      "        5.5162, 5.5163, 5.5164, 5.5164, 5.5165, 5.5162, 5.5164, 5.5163, 5.5165,\n",
      "        5.5164, 5.5164, 5.5165, 5.5165, 5.5164, 5.5165, 5.5163, 5.5165, 5.5163,\n",
      "        5.5163, 5.5163, 5.5164, 5.5164, 5.5164, 5.5163, 5.5164, 5.5164, 5.5163,\n",
      "        5.5163, 5.5162, 5.5162, 5.5162, 5.5163, 5.5164, 5.5164, 5.5164, 5.5164,\n",
      "        5.5164, 5.5165, 5.5165, 5.5164, 5.5164, 5.5164, 5.5163, 5.5162, 5.5164,\n",
      "        5.5163, 5.5162, 5.5163, 5.5162, 5.5162, 5.5162, 5.5162, 5.5163, 5.5163,\n",
      "        5.5162, 5.5162, 5.5163, 5.5165, 5.5164, 5.5164, 5.5164, 5.5164, 5.5164,\n",
      "        5.5166, 5.5166, 5.5166, 5.5166, 5.5165, 5.5166, 5.5166, 5.5166, 5.5165,\n",
      "        5.5166, 5.5165, 5.5164, 5.5163, 5.5166, 5.5163, 5.5163, 5.5164, 5.5162,\n",
      "        5.5162, 5.5165, 5.5165, 5.5165, 5.5166, 5.5165, 5.5164, 5.5163, 5.5162,\n",
      "        5.5162, 5.5162, 5.5163, 5.5164, 5.5165, 5.5166, 5.5164, 5.5162, 5.5162,\n",
      "        5.5163, 5.5162, 5.5164, 5.5163, 5.5162, 5.5162, 5.5162, 5.5164, 5.5163,\n",
      "        5.5165, 5.5163, 5.5164], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.042271  [3335724/5599865]\n",
      "average delta from current occupancy tensor([4.9438, 4.9438, 4.9436, 4.9435, 4.9435, 4.9437, 4.9435, 4.9435, 4.9436,\n",
      "        4.9436, 4.9436, 4.9440, 4.9435, 4.9440, 4.9435, 4.9436, 4.9437, 4.9439,\n",
      "        4.9438, 4.9439, 4.9438, 4.9440, 4.9438, 4.9438, 4.9436, 4.9436, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9436,\n",
      "        4.9437, 4.9437, 4.9438, 4.9436, 4.9435, 4.9435, 4.9436, 4.9436, 4.9440,\n",
      "        4.9439, 4.9440, 4.9437, 4.9437, 4.9437, 4.9437, 4.9436, 4.9435, 4.9437,\n",
      "        4.9435, 4.9435, 4.9434, 4.9435, 4.9436, 4.9437, 4.9434, 4.9436, 4.9435,\n",
      "        4.9434, 4.9435, 4.9435, 4.9436, 4.9435, 4.9435, 4.9434, 4.9434, 4.9434,\n",
      "        4.9434, 4.9434, 4.9437, 4.9437, 4.9439, 4.9437, 4.9438, 4.9438, 4.9438,\n",
      "        4.9437, 4.9437, 4.9437, 4.9438, 4.9436, 4.9436, 4.9435, 4.9437, 4.9436,\n",
      "        4.9436, 4.9438, 4.9439, 4.9438, 4.9438, 4.9437, 4.9437, 4.9438, 4.9435,\n",
      "        4.9435, 4.9435, 4.9436, 4.9437, 4.9437, 4.9436, 4.9435, 4.9435, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9433, 4.9433, 4.9434, 4.9434,\n",
      "        4.9436, 4.9434, 4.9433], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.455996  [3348124/5599865]\n",
      "average delta from current occupancy tensor([5.2974, 5.2974, 5.2975, 5.2975, 5.2974, 5.2974, 5.2974, 5.2972, 5.2971,\n",
      "        5.2972, 5.2974, 5.2973, 5.2971, 5.2975, 5.2974, 5.2974, 5.2973, 5.2974,\n",
      "        5.2972, 5.2972, 5.2971, 5.2971, 5.2971, 5.2971, 5.2970, 5.2972, 5.2972,\n",
      "        5.2972, 5.2972, 5.2972, 5.2971, 5.2971, 5.2971, 5.2971, 5.2972, 5.2971,\n",
      "        5.2972, 5.2972, 5.2971, 5.2970, 5.2972, 5.2971, 5.2972, 5.2972, 5.2972,\n",
      "        5.2972, 5.2972, 5.2972, 5.2972, 5.2972, 5.2972, 5.2972, 5.2971, 5.2971,\n",
      "        5.2971, 5.2970, 5.2970, 5.2970, 5.2970, 5.2970, 5.2970, 5.2970, 5.2970,\n",
      "        5.2970, 5.2970, 5.2971, 5.2971, 5.2971, 5.2971, 5.2972, 5.2972, 5.2971,\n",
      "        5.2971, 5.2971, 5.2971, 5.2972, 5.2971, 5.2971, 5.2972, 5.2971, 5.2972,\n",
      "        5.2971, 5.2972, 5.2972, 5.2973, 5.2972, 5.2971, 5.2971, 5.2972, 5.2973,\n",
      "        5.2972, 5.2972, 5.2972, 5.2973, 5.2972, 5.2972, 5.2975, 5.2973, 5.2971,\n",
      "        5.2971, 5.2971, 5.2971, 5.2971, 5.2972, 5.2973, 5.2971, 5.2970, 5.2970,\n",
      "        5.2970, 5.2970, 5.2971, 5.2972, 5.2970, 5.2971, 5.2971, 5.2971, 5.2970,\n",
      "        5.2970, 5.2971, 5.2971], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.410524  [3360524/5599865]\n",
      "average delta from current occupancy tensor([5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.180565  [3372924/5599865]\n",
      "average delta from current occupancy tensor([5.1694, 5.1695, 5.1695, 5.1695, 5.1695, 5.1694, 5.1695, 5.1694, 5.1694,\n",
      "        5.1694, 5.1695, 5.1695, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1695, 5.1694,\n",
      "        5.1695, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694, 5.1694,\n",
      "        5.1694, 5.1694, 5.1694], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.884272  [3385324/5599865]\n",
      "average delta from current occupancy tensor([5.8498, 5.8498, 5.8496, 5.8498, 5.8497, 5.8497, 5.8498, 5.8499, 5.8500,\n",
      "        5.8497, 5.8499, 5.8499, 5.8499, 5.8498, 5.8498, 5.8498, 5.8499, 5.8500,\n",
      "        5.8499, 5.8500, 5.8501, 5.8501, 5.8500, 5.8501, 5.8499, 5.8500, 5.8501,\n",
      "        5.8499, 5.8500, 5.8501, 5.8501, 5.8502, 5.8500, 5.8503, 5.8500, 5.8504,\n",
      "        5.8501, 5.8502, 5.8502, 5.8502, 5.8500, 5.8500, 5.8500, 5.8502, 5.8503,\n",
      "        5.8500, 5.8499, 5.8502, 5.8500, 5.8501, 5.8501, 5.8499, 5.8501, 5.8500,\n",
      "        5.8501, 5.8501, 5.8500, 5.8501, 5.8504, 5.8502, 5.8498, 5.8500, 5.8501,\n",
      "        5.8503, 5.8500, 5.8502, 5.8501, 5.8504, 5.8502, 5.8503, 5.8505, 5.8503,\n",
      "        5.8502, 5.8504, 5.8504, 5.8501, 5.8503, 5.8502, 5.8501, 5.8502, 5.8501,\n",
      "        5.8498, 5.8503, 5.8501, 5.8501, 5.8499, 5.8499, 5.8501, 5.8501, 5.8501,\n",
      "        5.8502, 5.8499, 5.8501, 5.8497, 5.8503, 5.8501, 5.8502, 5.8503, 5.8503,\n",
      "        5.8504, 5.8503, 5.8504, 5.8505, 5.8504, 5.8504, 5.8506, 5.8504, 5.8506,\n",
      "        5.8503, 5.8503, 5.8503, 5.8502, 5.8504, 5.8503, 5.8502, 5.8502, 5.8502,\n",
      "        5.8503, 5.8504, 5.8503], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.843557  [3397724/5599865]\n",
      "average delta from current occupancy tensor([5.8389, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390, 5.8391,\n",
      "        5.8390, 5.8390, 5.8390, 5.8391, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390,\n",
      "        5.8391, 5.8392, 5.8390, 5.8390, 5.8391, 5.8391, 5.8391, 5.8391, 5.8390,\n",
      "        5.8391, 5.8390, 5.8390, 5.8390, 5.8390, 5.8391, 5.8388, 5.8390, 5.8389,\n",
      "        5.8390, 5.8388, 5.8388, 5.8388, 5.8388, 5.8389, 5.8388, 5.8389, 5.8389,\n",
      "        5.8389, 5.8389, 5.8389, 5.8389, 5.8388, 5.8389, 5.8390, 5.8390, 5.8389,\n",
      "        5.8390, 5.8390, 5.8390, 5.8389, 5.8390, 5.8389, 5.8388, 5.8388, 5.8387,\n",
      "        5.8389, 5.8387, 5.8389, 5.8388, 5.8388, 5.8388, 5.8389, 5.8389, 5.8390,\n",
      "        5.8390, 5.8389, 5.8389, 5.8388, 5.8389, 5.8389, 5.8390, 5.8389, 5.8389,\n",
      "        5.8390, 5.8389, 5.8389, 5.8389, 5.8389, 5.8389, 5.8389, 5.8389, 5.8389,\n",
      "        5.8388, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390, 5.8390,\n",
      "        5.8388, 5.8387, 5.8388, 5.8388, 5.8389, 5.8388, 5.8388, 5.8389, 5.8388,\n",
      "        5.8390, 5.8389, 5.8390, 5.8391, 5.8390, 5.8391, 5.8390, 5.8391, 5.8390,\n",
      "        5.8391, 5.8390, 5.8390], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.059301  [3410124/5599865]\n",
      "average delta from current occupancy tensor([5.3541, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542,\n",
      "        5.3542, 5.3542, 5.3542, 5.3541, 5.3541, 5.3542, 5.3542, 5.3542, 5.3542,\n",
      "        5.3541, 5.3542, 5.3542, 5.3542, 5.3541, 5.3541, 5.3541, 5.3541, 5.3542,\n",
      "        5.3542, 5.3541, 5.3542, 5.3542, 5.3542, 5.3542, 5.3541, 5.3542, 5.3542,\n",
      "        5.3542, 5.3541, 5.3542, 5.3542, 5.3542, 5.3541, 5.3542, 5.3542, 5.3542,\n",
      "        5.3542, 5.3542, 5.3542, 5.3541, 5.3542, 5.3541, 5.3542, 5.3542, 5.3542,\n",
      "        5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542,\n",
      "        5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3543, 5.3543, 5.3543,\n",
      "        5.3543, 5.3543, 5.3542, 5.3542, 5.3542, 5.3542, 5.3543, 5.3542, 5.3542,\n",
      "        5.3542, 5.3541, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542,\n",
      "        5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542,\n",
      "        5.3541, 5.3541, 5.3541, 5.3540, 5.3541, 5.3541, 5.3541, 5.3542, 5.3541,\n",
      "        5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542, 5.3542,\n",
      "        5.3542, 5.3543, 5.3542], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.565000  [3422524/5599865]\n",
      "average delta from current occupancy tensor([5.6048, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047,\n",
      "        5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047, 5.6047,\n",
      "        5.6047, 5.6048, 5.6047, 5.6047, 5.6047, 5.6047, 5.6048, 5.6048, 5.6048,\n",
      "        5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048,\n",
      "        5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048,\n",
      "        5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048,\n",
      "        5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048,\n",
      "        5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048, 5.6048,\n",
      "        5.6048, 5.6048, 5.6049, 5.6050, 5.6050, 5.6049, 5.6050, 5.6050, 5.6049,\n",
      "        5.6050, 5.6049, 5.6049, 5.6049, 5.6049, 5.6051, 5.6051, 5.6050, 5.6050,\n",
      "        5.6050, 5.6050, 5.6050, 5.6050, 5.6049, 5.6050, 5.6050, 5.6051, 5.6049,\n",
      "        5.6048, 5.6049, 5.6048, 5.6049, 5.6050, 5.6048, 5.6048, 5.6049, 5.6048,\n",
      "        5.6048, 5.6049, 5.6048, 5.6048, 5.6048, 5.6048, 5.6049, 5.6049, 5.6048,\n",
      "        5.6048, 5.6048, 5.6048], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.361622  [3434924/5599865]\n",
      "average delta from current occupancy tensor([5.5408, 5.5407, 5.5407, 5.5406, 5.5406, 5.5407, 5.5408, 5.5408, 5.5408,\n",
      "        5.5407, 5.5407, 5.5409, 5.5406, 5.5405, 5.5405, 5.5405, 5.5404, 5.5404,\n",
      "        5.5406, 5.5408, 5.5406, 5.5406, 5.5405, 5.5406, 5.5405, 5.5407, 5.5407,\n",
      "        5.5409, 5.5407, 5.5411, 5.5412, 5.5407, 5.5408, 5.5409, 5.5409, 5.5411,\n",
      "        5.5409, 5.5410, 5.5408, 5.5408, 5.5405, 5.5409, 5.5408, 5.5408, 5.5408,\n",
      "        5.5408, 5.5408, 5.5411, 5.5410, 5.5409, 5.5409, 5.5409, 5.5409, 5.5409,\n",
      "        5.5410, 5.5410, 5.5409, 5.5411, 5.5410, 5.5410, 5.5410, 5.5409, 5.5409,\n",
      "        5.5407, 5.5409, 5.5408, 5.5409, 5.5408, 5.5408, 5.5409, 5.5407, 5.5408,\n",
      "        5.5408, 5.5407, 5.5408, 5.5408, 5.5407, 5.5409, 5.5410, 5.5407, 5.5409,\n",
      "        5.5408, 5.5411, 5.5408, 5.5410, 5.5408, 5.5410, 5.5408, 5.5408, 5.5406,\n",
      "        5.5407, 5.5411, 5.5409, 5.5408, 5.5410, 5.5411, 5.5408, 5.5409, 5.5409,\n",
      "        5.5408, 5.5411, 5.5413, 5.5414, 5.5411, 5.5410, 5.5411, 5.5412, 5.5411,\n",
      "        5.5412, 5.5412, 5.5409, 5.5410, 5.5412, 5.5411, 5.5409, 5.5409, 5.5409,\n",
      "        5.5409, 5.5409, 5.5408], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.260648  [3447324/5599865]\n",
      "average delta from current occupancy tensor([5.2497, 5.2497, 5.2497, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498,\n",
      "        5.2499, 5.2499, 5.2498, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2498, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2498, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2498, 5.2498, 5.2499, 5.2499, 5.2498, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.114342  [3459724/5599865]\n",
      "average delta from current occupancy tensor([4.3467, 4.3467, 4.3466, 4.3466, 4.3467, 4.3467, 4.3467, 4.3467, 4.3467,\n",
      "        4.3467, 4.3467, 4.3466, 4.3466, 4.3466, 4.3466, 4.3467, 4.3467, 4.3467,\n",
      "        4.3466, 4.3467, 4.3466, 4.3467, 4.3467, 4.3467, 4.3467, 4.3467, 4.3466,\n",
      "        4.3467, 4.3467, 4.3467, 4.3467, 4.3467, 4.3467, 4.3468, 4.3467, 4.3467,\n",
      "        4.3467, 4.3466, 4.3466, 4.3466, 4.3467, 4.3467, 4.3466, 4.3466, 4.3466,\n",
      "        4.3466, 4.3466, 4.3466, 4.3466, 4.3466, 4.3466, 4.3466, 4.3466, 4.3466,\n",
      "        4.3467, 4.3466, 4.3466, 4.3465, 4.3466, 4.3466, 4.3466, 4.3466, 4.3465,\n",
      "        4.3465, 4.3465, 4.3465, 4.3465, 4.3465, 4.3466, 4.3465, 4.3465, 4.3465,\n",
      "        4.3466, 4.3466, 4.3466, 4.3466, 4.3466, 4.3465, 4.3465, 4.3466, 4.3465,\n",
      "        4.3465, 4.3465, 4.3465, 4.3465, 4.3465, 4.3465, 4.3464, 4.3464, 4.3464,\n",
      "        4.3465, 4.3464, 4.3464, 4.3465, 4.3465, 4.3466, 4.3465, 4.3465, 4.3465,\n",
      "        4.3465, 4.3466, 4.3465, 4.3466, 4.3466, 4.3466, 4.3466, 4.3465, 4.3466,\n",
      "        4.3465, 4.3464, 4.3464, 4.3465, 4.3465, 4.3466, 4.3465, 4.3465, 4.3465,\n",
      "        4.3465, 4.3465, 4.3465], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.589267  [3472124/5599865]\n",
      "average delta from current occupancy tensor([5.6534, 5.6536, 5.6534, 5.6535, 5.6534, 5.6535, 5.6533, 5.6535, 5.6535,\n",
      "        5.6535, 5.6534, 5.6532, 5.6533, 5.6533, 5.6532, 5.6534, 5.6535, 5.6535,\n",
      "        5.6532, 5.6535, 5.6534, 5.6535, 5.6534, 5.6533, 5.6533, 5.6532, 5.6533,\n",
      "        5.6533, 5.6533, 5.6534, 5.6534, 5.6533, 5.6534, 5.6534, 5.6533, 5.6534,\n",
      "        5.6533, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6533, 5.6533, 5.6533, 5.6533, 5.6532, 5.6533, 5.6532,\n",
      "        5.6533, 5.6532, 5.6532, 5.6532, 5.6533, 5.6532, 5.6532, 5.6532, 5.6533,\n",
      "        5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6531, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6532, 5.6532, 5.6531, 5.6532, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6531, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532, 5.6532,\n",
      "        5.6532, 5.6532, 5.6532], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.716152  [3484524/5599865]\n",
      "average delta from current occupancy tensor([4.8709, 4.8709, 4.8709, 4.8709, 4.8708, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8708, 4.8709, 4.8709,\n",
      "        4.8709, 4.8708, 4.8709, 4.8709, 4.8708, 4.8708, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8708, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8708, 4.8708, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8708, 4.8709, 4.8709, 4.8709, 4.8708, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709, 4.8709,\n",
      "        4.8709, 4.8709, 4.8709], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.026155  [3496924/5599865]\n",
      "average delta from current occupancy tensor([5.2255, 5.2255, 5.2256, 5.2255, 5.2254, 5.2253, 5.2253, 5.2253, 5.2253,\n",
      "        5.2254, 5.2254, 5.2251, 5.2251, 5.2251, 5.2251, 5.2251, 5.2250, 5.2250,\n",
      "        5.2250, 5.2250, 5.2250, 5.2251, 5.2250, 5.2251, 5.2251, 5.2251, 5.2251,\n",
      "        5.2250, 5.2251, 5.2249, 5.2250, 5.2250, 5.2250, 5.2249, 5.2249, 5.2250,\n",
      "        5.2250, 5.2250, 5.2250, 5.2250, 5.2250, 5.2249, 5.2250, 5.2250, 5.2249,\n",
      "        5.2251, 5.2252, 5.2250, 5.2250, 5.2250, 5.2250, 5.2250, 5.2250, 5.2250,\n",
      "        5.2250, 5.2249, 5.2249, 5.2250, 5.2249, 5.2249, 5.2248, 5.2249, 5.2249,\n",
      "        5.2249, 5.2248, 5.2249, 5.2250, 5.2249, 5.2250, 5.2251, 5.2251, 5.2252,\n",
      "        5.2251, 5.2251, 5.2251, 5.2251, 5.2251, 5.2251, 5.2250, 5.2251, 5.2252,\n",
      "        5.2251, 5.2251, 5.2251, 5.2250, 5.2250, 5.2251, 5.2250, 5.2250, 5.2250,\n",
      "        5.2251, 5.2250, 5.2250, 5.2251, 5.2250, 5.2250, 5.2250, 5.2250, 5.2250,\n",
      "        5.2251, 5.2251, 5.2251, 5.2252, 5.2252, 5.2252, 5.2251, 5.2251, 5.2252,\n",
      "        5.2251, 5.2252, 5.2252, 5.2250, 5.2251, 5.2250, 5.2251, 5.2250, 5.2251,\n",
      "        5.2251, 5.2250, 5.2250], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.914734  [3509324/5599865]\n",
      "average delta from current occupancy tensor([4.8148, 4.8149, 4.8149, 4.8148, 4.8148, 4.8149, 4.8149, 4.8149, 4.8149,\n",
      "        4.8148, 4.8149, 4.8149, 4.8149, 4.8149, 4.8148, 4.8148, 4.8149, 4.8149,\n",
      "        4.8149, 4.8148, 4.8149, 4.8148, 4.8149, 4.8148, 4.8149, 4.8149, 4.8148,\n",
      "        4.8149, 4.8148, 4.8149, 4.8149, 4.8149, 4.8149, 4.8148, 4.8148, 4.8148,\n",
      "        4.8149, 4.8148, 4.8148, 4.8148, 4.8149, 4.8148, 4.8149, 4.8148, 4.8149,\n",
      "        4.8149, 4.8148, 4.8149, 4.8149, 4.8149, 4.8148, 4.8149, 4.8148, 4.8148,\n",
      "        4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8148, 4.8149, 4.8148,\n",
      "        4.8148, 4.8148, 4.8148, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8148,\n",
      "        4.8148, 4.8148, 4.8148, 4.8149, 4.8149, 4.8149, 4.8148, 4.8149, 4.8149,\n",
      "        4.8149, 4.8149, 4.8149, 4.8148, 4.8148, 4.8148, 4.8148, 4.8148, 4.8149,\n",
      "        4.8148, 4.8149, 4.8149, 4.8149, 4.8149, 4.8148, 4.8149, 4.8149, 4.8149,\n",
      "        4.8149, 4.8149, 4.8149, 4.8148, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149,\n",
      "        4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149, 4.8149,\n",
      "        4.8149, 4.8149, 4.8149], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.306612  [3521724/5599865]\n",
      "average delta from current occupancy tensor([5.2597, 5.2597, 5.2597, 5.2596, 5.2597, 5.2596, 5.2596, 5.2596, 5.2596,\n",
      "        5.2595, 5.2596, 5.2596, 5.2595, 5.2596, 5.2594, 5.2595, 5.2596, 5.2595,\n",
      "        5.2596, 5.2596, 5.2597, 5.2596, 5.2597, 5.2596, 5.2596, 5.2596, 5.2595,\n",
      "        5.2596, 5.2596, 5.2597, 5.2597, 5.2596, 5.2594, 5.2595, 5.2594, 5.2595,\n",
      "        5.2594, 5.2595, 5.2594, 5.2595, 5.2594, 5.2595, 5.2595, 5.2595, 5.2594,\n",
      "        5.2595, 5.2594, 5.2595, 5.2594, 5.2594, 5.2594, 5.2594, 5.2594, 5.2595,\n",
      "        5.2594, 5.2594, 5.2595, 5.2595, 5.2595, 5.2594, 5.2595, 5.2595, 5.2594,\n",
      "        5.2595, 5.2594, 5.2594, 5.2594, 5.2595, 5.2595, 5.2596, 5.2596, 5.2595,\n",
      "        5.2595, 5.2596, 5.2596, 5.2596, 5.2596, 5.2596, 5.2596, 5.2596, 5.2596,\n",
      "        5.2596, 5.2596, 5.2596, 5.2596, 5.2595, 5.2595, 5.2595, 5.2596, 5.2595,\n",
      "        5.2595, 5.2597, 5.2595, 5.2596, 5.2594, 5.2594, 5.2596, 5.2595, 5.2594,\n",
      "        5.2596, 5.2596, 5.2597, 5.2596, 5.2596, 5.2596, 5.2596, 5.2596, 5.2595,\n",
      "        5.2596, 5.2595, 5.2595, 5.2594, 5.2595, 5.2596, 5.2595, 5.2595, 5.2595,\n",
      "        5.2596, 5.2596, 5.2595], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.981779  [3534124/5599865]\n",
      "average delta from current occupancy tensor([5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806, 5.0806,\n",
      "        5.0806, 5.0806, 5.0806], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.302737  [3546524/5599865]\n",
      "average delta from current occupancy tensor([5.4840, 5.4840, 5.4839, 5.4839, 5.4840, 5.4839, 5.4839, 5.4839, 5.4839,\n",
      "        5.4839, 5.4839, 5.4839, 5.4839, 5.4839, 5.4839, 5.4839, 5.4839, 5.4840,\n",
      "        5.4842, 5.4839, 5.4841, 5.4841, 5.4841, 5.4841, 5.4841, 5.4844, 5.4842,\n",
      "        5.4843, 5.4844, 5.4842, 5.4843, 5.4840, 5.4840, 5.4840, 5.4840, 5.4841,\n",
      "        5.4843, 5.4841, 5.4840, 5.4841, 5.4842, 5.4842, 5.4841, 5.4841, 5.4841,\n",
      "        5.4841, 5.4841, 5.4841, 5.4842, 5.4843, 5.4842, 5.4843, 5.4843, 5.4842,\n",
      "        5.4842, 5.4843, 5.4841, 5.4841, 5.4841, 5.4842, 5.4842, 5.4843, 5.4841,\n",
      "        5.4841, 5.4843, 5.4843, 5.4841, 5.4841, 5.4843, 5.4841, 5.4842, 5.4840,\n",
      "        5.4840, 5.4843, 5.4842, 5.4842, 5.4842, 5.4841, 5.4841, 5.4841, 5.4841,\n",
      "        5.4841, 5.4841, 5.4839, 5.4840, 5.4841, 5.4840, 5.4841, 5.4840, 5.4840,\n",
      "        5.4840, 5.4840, 5.4839, 5.4839, 5.4839, 5.4839, 5.4839, 5.4839, 5.4839,\n",
      "        5.4839, 5.4839, 5.4839, 5.4840, 5.4840, 5.4840, 5.4841, 5.4840, 5.4839,\n",
      "        5.4841, 5.4841, 5.4840, 5.4840, 5.4839, 5.4839, 5.4839, 5.4839, 5.4838,\n",
      "        5.4839, 5.4838, 5.4839], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.389409  [3558924/5599865]\n",
      "average delta from current occupancy tensor([5.4099, 5.4099, 5.4102, 5.4101, 5.4099, 5.4100, 5.4104, 5.4102, 5.4103,\n",
      "        5.4103, 5.4104, 5.4104, 5.4105, 5.4104, 5.4104, 5.4105, 5.4105, 5.4104,\n",
      "        5.4101, 5.4102, 5.4104, 5.4104, 5.4101, 5.4101, 5.4102, 5.4105, 5.4104,\n",
      "        5.4105, 5.4107, 5.4106, 5.4106, 5.4105, 5.4107, 5.4104, 5.4103, 5.4105,\n",
      "        5.4102, 5.4100, 5.4100, 5.4103, 5.4099, 5.4103, 5.4103, 5.4102, 5.4102,\n",
      "        5.4099, 5.4098, 5.4100, 5.4095, 5.4097, 5.4096, 5.4094, 5.4094, 5.4092,\n",
      "        5.4094, 5.4093, 5.4094, 5.4093, 5.4088, 5.4094, 5.4095, 5.4095, 5.4094,\n",
      "        5.4097, 5.4090, 5.4086, 5.4084, 5.4091, 5.4093, 5.4092, 5.4093, 5.4096,\n",
      "        5.4099, 5.4099, 5.4100, 5.4102, 5.4100, 5.4103, 5.4102, 5.4098, 5.4103,\n",
      "        5.4102, 5.4104, 5.4100, 5.4098, 5.4097, 5.4096, 5.4098, 5.4098, 5.4099,\n",
      "        5.4100, 5.4099, 5.4101, 5.4098, 5.4098, 5.4098, 5.4098, 5.4099, 5.4099,\n",
      "        5.4100, 5.4096, 5.4097, 5.4093, 5.4096, 5.4092, 5.4090, 5.4091, 5.4089,\n",
      "        5.4091, 5.4091, 5.4092, 5.4095, 5.4098, 5.4096, 5.4093, 5.4100, 5.4097,\n",
      "        5.4103, 5.4092, 5.4095], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.310631  [3571324/5599865]\n",
      "average delta from current occupancy tensor([5.2984, 5.2985, 5.2987, 5.2986, 5.2985, 5.2987, 5.2987, 5.2984, 5.2985,\n",
      "        5.2985, 5.2988, 5.2985, 5.2985, 5.2986, 5.2988, 5.2987, 5.2989, 5.2987,\n",
      "        5.2984, 5.2986, 5.2986, 5.2988, 5.2986, 5.2986, 5.2985, 5.2985, 5.2989,\n",
      "        5.2985, 5.2985, 5.2985, 5.2985, 5.2985, 5.2985, 5.2987, 5.2986, 5.2986,\n",
      "        5.2986, 5.2987, 5.2985, 5.2989, 5.2987, 5.2989, 5.2985, 5.2989, 5.2986,\n",
      "        5.2986, 5.2987, 5.2985, 5.2985, 5.2986, 5.2985, 5.2988, 5.2985, 5.2986,\n",
      "        5.2984, 5.2988, 5.2985, 5.2985, 5.2985, 5.2985, 5.2985, 5.2985, 5.2985,\n",
      "        5.2985, 5.2988, 5.2984, 5.2984, 5.2984, 5.2986, 5.2986, 5.2984, 5.2984,\n",
      "        5.2985, 5.2987, 5.2985, 5.2986, 5.2985, 5.2986, 5.2987, 5.2986, 5.2987,\n",
      "        5.2984, 5.2984, 5.2985, 5.2984, 5.2986, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2983, 5.2984, 5.2985, 5.2985, 5.2982, 5.2984, 5.2984, 5.2983,\n",
      "        5.2983, 5.2986, 5.2987, 5.2984, 5.2984, 5.2987, 5.2990, 5.2992, 5.2998,\n",
      "        5.2994, 5.2995, 5.2995, 5.2995, 5.2994, 5.2992, 5.2991, 5.2985, 5.2990,\n",
      "        5.2984, 5.2985, 5.2994], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.218347  [3583724/5599865]\n",
      "average delta from current occupancy tensor([5.2334, 5.2334, 5.2334, 5.2333, 5.2333, 5.2333, 5.2332, 5.2332, 5.2332,\n",
      "        5.2332, 5.2331, 5.2332, 5.2332, 5.2331, 5.2332, 5.2332, 5.2331, 5.2332,\n",
      "        5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2333, 5.2332,\n",
      "        5.2333, 5.2333, 5.2333, 5.2332, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333,\n",
      "        5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2333, 5.2334, 5.2332,\n",
      "        5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2332, 5.2333, 5.2333, 5.2333,\n",
      "        5.2334, 5.2334, 5.2333, 5.2333, 5.2333, 5.2333, 5.2334, 5.2333, 5.2333,\n",
      "        5.2332, 5.2332, 5.2332, 5.2333, 5.2332, 5.2331, 5.2333, 5.2332, 5.2332,\n",
      "        5.2332, 5.2332, 5.2332, 5.2331, 5.2332, 5.2332, 5.2332, 5.2331, 5.2330,\n",
      "        5.2331, 5.2331, 5.2332, 5.2332, 5.2331, 5.2332, 5.2331, 5.2332, 5.2332,\n",
      "        5.2332, 5.2332, 5.2333, 5.2332, 5.2332, 5.2332, 5.2333, 5.2333, 5.2334,\n",
      "        5.2333, 5.2334, 5.2334, 5.2334, 5.2334, 5.2335, 5.2334, 5.2334, 5.2334,\n",
      "        5.2334, 5.2334, 5.2334, 5.2334, 5.2335, 5.2335, 5.2335, 5.2334, 5.2335,\n",
      "        5.2334, 5.2335, 5.2334], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.478005  [3596124/5599865]\n",
      "average delta from current occupancy tensor([4.6124, 4.6124, 4.6124, 4.6123, 4.6126, 4.6128, 4.6127, 4.6127, 4.6125,\n",
      "        4.6125, 4.6125, 4.6126, 4.6125, 4.6126, 4.6127, 4.6126, 4.6127, 4.6125,\n",
      "        4.6127, 4.6125, 4.6125, 4.6124, 4.6123, 4.6122, 4.6123, 4.6123, 4.6123,\n",
      "        4.6124, 4.6125, 4.6124, 4.6125, 4.6124, 4.6125, 4.6124, 4.6125, 4.6125,\n",
      "        4.6125, 4.6125, 4.6125, 4.6125, 4.6125, 4.6125, 4.6125, 4.6126, 4.6127,\n",
      "        4.6127, 4.6126, 4.6128, 4.6126, 4.6125, 4.6124, 4.6125, 4.6125, 4.6125,\n",
      "        4.6125, 4.6126, 4.6126, 4.6124, 4.6123, 4.6124, 4.6125, 4.6124, 4.6123,\n",
      "        4.6124, 4.6124, 4.6123, 4.6124, 4.6123, 4.6123, 4.6123, 4.6122, 4.6123,\n",
      "        4.6125, 4.6125, 4.6125, 4.6129, 4.6126, 4.6124, 4.6124, 4.6126, 4.6129,\n",
      "        4.6125, 4.6125, 4.6124, 4.6125, 4.6125, 4.6126, 4.6126, 4.6126, 4.6126,\n",
      "        4.6126, 4.6127, 4.6128, 4.6127, 4.6127, 4.6126, 4.6126, 4.6125, 4.6125,\n",
      "        4.6126, 4.6126, 4.6125, 4.6125, 4.6126, 4.6126, 4.6125, 4.6126, 4.6124,\n",
      "        4.6126, 4.6125, 4.6124, 4.6126, 4.6126, 4.6125, 4.6126, 4.6123, 4.6123,\n",
      "        4.6122, 4.6123, 4.6123], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.164636  [3608524/5599865]\n",
      "average delta from current occupancy tensor([5.2181, 5.2181, 5.2180, 5.2180, 5.2180, 5.2182, 5.2182, 5.2182, 5.2182,\n",
      "        5.2182, 5.2182, 5.2182, 5.2182, 5.2182, 5.2182, 5.2182, 5.2182, 5.2182,\n",
      "        5.2182, 5.2181, 5.2182, 5.2181, 5.2181, 5.2181, 5.2181, 5.2181, 5.2182,\n",
      "        5.2182, 5.2181, 5.2181, 5.2182, 5.2182, 5.2181, 5.2182, 5.2182, 5.2182,\n",
      "        5.2182, 5.2182, 5.2182, 5.2182, 5.2181, 5.2182, 5.2182, 5.2182, 5.2181,\n",
      "        5.2181, 5.2182, 5.2181, 5.2182, 5.2181, 5.2182, 5.2182, 5.2182, 5.2182,\n",
      "        5.2182, 5.2182, 5.2182, 5.2182, 5.2182, 5.2182, 5.2183, 5.2183, 5.2183,\n",
      "        5.2183, 5.2182, 5.2183, 5.2184, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183,\n",
      "        5.2183, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183, 5.2184, 5.2183, 5.2183,\n",
      "        5.2184, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183,\n",
      "        5.2182, 5.2183, 5.2182, 5.2182, 5.2182, 5.2181, 5.2182, 5.2182, 5.2182,\n",
      "        5.2182, 5.2182, 5.2181, 5.2181, 5.2182, 5.2182, 5.2181, 5.2182, 5.2181,\n",
      "        5.2181, 5.2181, 5.2181, 5.2182, 5.2183, 5.2183, 5.2183, 5.2183, 5.2183,\n",
      "        5.2182, 5.2183, 5.2182], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.972497  [3620924/5599865]\n",
      "average delta from current occupancy tensor([5.0239, 5.0240, 5.0239, 5.0239, 5.0239, 5.0239, 5.0240, 5.0240, 5.0240,\n",
      "        5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240,\n",
      "        5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240,\n",
      "        5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240, 5.0240,\n",
      "        5.0240, 5.0240, 5.0240, 5.0240, 5.0241, 5.0240, 5.0240, 5.0240, 5.0241,\n",
      "        5.0240, 5.0240, 5.0241, 5.0241, 5.0241, 5.0240, 5.0241, 5.0241, 5.0241,\n",
      "        5.0241, 5.0242, 5.0241, 5.0241, 5.0241, 5.0241, 5.0241, 5.0242, 5.0242,\n",
      "        5.0242, 5.0241, 5.0242, 5.0243, 5.0242, 5.0242, 5.0242, 5.0242, 5.0243,\n",
      "        5.0244, 5.0242, 5.0244, 5.0243, 5.0243, 5.0243, 5.0243, 5.0243, 5.0242,\n",
      "        5.0242, 5.0243, 5.0243, 5.0242, 5.0242, 5.0241, 5.0242, 5.0242, 5.0241,\n",
      "        5.0243, 5.0242, 5.0242, 5.0241, 5.0241, 5.0242, 5.0242, 5.0241, 5.0241,\n",
      "        5.0241, 5.0242, 5.0241, 5.0241, 5.0241, 5.0241, 5.0240, 5.0241, 5.0240,\n",
      "        5.0240, 5.0240, 5.0240, 5.0241, 5.0241, 5.0241, 5.0241, 5.0241, 5.0241,\n",
      "        5.0240, 5.0240, 5.0240], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.091826  [3633324/5599865]\n",
      "average delta from current occupancy tensor([3.9032, 3.9032, 3.9033, 3.9033, 3.9032, 3.9033, 3.9032, 3.9032, 3.9032,\n",
      "        3.9032, 3.9034, 3.9032, 3.9032, 3.9032, 3.9032, 3.9032, 3.9033, 3.9032,\n",
      "        3.9032, 3.9033, 3.9032, 3.9032, 3.9032, 3.9033, 3.9032, 3.9032, 3.9032,\n",
      "        3.9032, 3.9032, 3.9033, 3.9032, 3.9033, 3.9032, 3.9032, 3.9033, 3.9033,\n",
      "        3.9032, 3.9032, 3.9032, 3.9033, 3.9033, 3.9032, 3.9032, 3.9033, 3.9033,\n",
      "        3.9033, 3.9033, 3.9032, 3.9033, 3.9033, 3.9033, 3.9033, 3.9034, 3.9033,\n",
      "        3.9033, 3.9032, 3.9032, 3.9032, 3.9033, 3.9032, 3.9033, 3.9032, 3.9032,\n",
      "        3.9032, 3.9033, 3.9032, 3.9032, 3.9032, 3.9032, 3.9033, 3.9032, 3.9033,\n",
      "        3.9032, 3.9033, 3.9033, 3.9033, 3.9032, 3.9033, 3.9032, 3.9032, 3.9033,\n",
      "        3.9033, 3.9032, 3.9032, 3.9032, 3.9033, 3.9033, 3.9033, 3.9032, 3.9033,\n",
      "        3.9033, 3.9033, 3.9033, 3.9033, 3.9033, 3.9033, 3.9033, 3.9033, 3.9033,\n",
      "        3.9033, 3.9033, 3.9033, 3.9033, 3.9032, 3.9033, 3.9033, 3.9033, 3.9032,\n",
      "        3.9033, 3.9032, 3.9032, 3.9032, 3.9032, 3.9032, 3.9032, 3.9032, 3.9033,\n",
      "        3.9032, 3.9032, 3.9032], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.158885  [3645724/5599865]\n",
      "average delta from current occupancy tensor([5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792,\n",
      "        5.8791, 5.8792, 5.8792, 5.8791, 5.8791, 5.8792, 5.8790, 5.8791, 5.8791,\n",
      "        5.8791, 5.8792, 5.8791, 5.8792, 5.8791, 5.8792, 5.8792, 5.8792, 5.8792,\n",
      "        5.8792, 5.8792, 5.8791, 5.8791, 5.8792, 5.8791, 5.8791, 5.8791, 5.8791,\n",
      "        5.8791, 5.8792, 5.8792, 5.8792, 5.8793, 5.8790, 5.8791, 5.8791, 5.8791,\n",
      "        5.8792, 5.8792, 5.8791, 5.8792, 5.8792, 5.8792, 5.8791, 5.8791, 5.8790,\n",
      "        5.8791, 5.8792, 5.8791, 5.8792, 5.8792, 5.8792, 5.8790, 5.8792, 5.8791,\n",
      "        5.8792, 5.8792, 5.8793, 5.8790, 5.8791, 5.8793, 5.8791, 5.8793, 5.8793,\n",
      "        5.8791, 5.8792, 5.8791, 5.8791, 5.8790, 5.8791, 5.8791, 5.8791, 5.8792,\n",
      "        5.8793, 5.8791, 5.8791, 5.8792, 5.8792, 5.8791, 5.8791, 5.8791, 5.8791,\n",
      "        5.8791, 5.8792, 5.8791, 5.8791, 5.8791, 5.8791, 5.8791, 5.8791, 5.8791,\n",
      "        5.8792, 5.8791, 5.8791, 5.8791, 5.8791, 5.8791, 5.8791, 5.8790, 5.8791,\n",
      "        5.8791, 5.8791, 5.8791, 5.8790, 5.8791, 5.8791, 5.8790, 5.8791, 5.8791,\n",
      "        5.8791, 5.8790, 5.8792], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.292517  [3658124/5599865]\n",
      "average delta from current occupancy tensor([5.5074, 5.5075, 5.5075, 5.5074, 5.5074, 5.5074, 5.5074, 5.5072, 5.5074,\n",
      "        5.5072, 5.5074, 5.5075, 5.5076, 5.5076, 5.5075, 5.5074, 5.5077, 5.5075,\n",
      "        5.5074, 5.5074, 5.5073, 5.5073, 5.5074, 5.5074, 5.5075, 5.5075, 5.5076,\n",
      "        5.5075, 5.5076, 5.5076, 5.5075, 5.5076, 5.5075, 5.5075, 5.5075, 5.5074,\n",
      "        5.5073, 5.5074, 5.5076, 5.5077, 5.5075, 5.5074, 5.5076, 5.5076, 5.5076,\n",
      "        5.5077, 5.5075, 5.5077, 5.5075, 5.5076, 5.5078, 5.5077, 5.5078, 5.5076,\n",
      "        5.5077, 5.5078, 5.5076, 5.5078, 5.5076, 5.5077, 5.5077, 5.5076, 5.5076,\n",
      "        5.5076, 5.5076, 5.5074, 5.5075, 5.5074, 5.5075, 5.5075, 5.5075, 5.5076,\n",
      "        5.5076, 5.5076, 5.5076, 5.5076, 5.5076, 5.5077, 5.5077, 5.5076, 5.5077,\n",
      "        5.5077, 5.5076, 5.5076, 5.5076, 5.5076, 5.5076, 5.5076, 5.5076, 5.5077,\n",
      "        5.5077, 5.5076, 5.5077, 5.5076, 5.5075, 5.5074, 5.5074, 5.5074, 5.5075,\n",
      "        5.5072, 5.5073, 5.5074, 5.5072, 5.5074, 5.5074, 5.5075, 5.5073, 5.5074,\n",
      "        5.5075, 5.5074, 5.5073, 5.5073, 5.5072, 5.5073, 5.5073, 5.5072, 5.5071,\n",
      "        5.5071, 5.5071, 5.5070], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.073029  [3670524/5599865]\n",
      "average delta from current occupancy tensor([4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7824, 4.7823,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7824, 4.7824,\n",
      "        4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823,\n",
      "        4.7823, 4.7824, 4.7824, 4.7823, 4.7823, 4.7823, 4.7823, 4.7823, 4.7824,\n",
      "        4.7823, 4.7823, 4.7823, 4.7824, 4.7824, 4.7823, 4.7824, 4.7823, 4.7824,\n",
      "        4.7824, 4.7823, 4.7824, 4.7823, 4.7824, 4.7824, 4.7825, 4.7824, 4.7824,\n",
      "        4.7824, 4.7823, 4.7823, 4.7823, 4.7823, 4.7824, 4.7824, 4.7823, 4.7824,\n",
      "        4.7823, 4.7824, 4.7824, 4.7824, 4.7824, 4.7824, 4.7825, 4.7823, 4.7823,\n",
      "        4.7824, 4.7824, 4.7824, 4.7824, 4.7825, 4.7825, 4.7824, 4.7825, 4.7824,\n",
      "        4.7824, 4.7824, 4.7823, 4.7824, 4.7825, 4.7825, 4.7825, 4.7824, 4.7824,\n",
      "        4.7826, 4.7825, 4.7825, 4.7825, 4.7825, 4.7825, 4.7825, 4.7825, 4.7825,\n",
      "        4.7825, 4.7825, 4.7825, 4.7825, 4.7824, 4.7824, 4.7824, 4.7825, 4.7825,\n",
      "        4.7824, 4.7823, 4.7823, 4.7823, 4.7824, 4.7825, 4.7825, 4.7823, 4.7823,\n",
      "        4.7824, 4.7823, 4.7824], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.970449  [3682924/5599865]\n",
      "average delta from current occupancy tensor([5.9354, 5.9355, 5.9354, 5.9353, 5.9354, 5.9353, 5.9354, 5.9354, 5.9354,\n",
      "        5.9354, 5.9355, 5.9354, 5.9353, 5.9354, 5.9356, 5.9355, 5.9355, 5.9356,\n",
      "        5.9356, 5.9356, 5.9357, 5.9357, 5.9356, 5.9357, 5.9355, 5.9356, 5.9356,\n",
      "        5.9356, 5.9357, 5.9354, 5.9356, 5.9355, 5.9357, 5.9356, 5.9355, 5.9357,\n",
      "        5.9358, 5.9355, 5.9356, 5.9357, 5.9357, 5.9354, 5.9356, 5.9358, 5.9358,\n",
      "        5.9357, 5.9359, 5.9357, 5.9358, 5.9357, 5.9356, 5.9358, 5.9355, 5.9355,\n",
      "        5.9356, 5.9357, 5.9358, 5.9358, 5.9356, 5.9356, 5.9358, 5.9356, 5.9358,\n",
      "        5.9358, 5.9357, 5.9358, 5.9357, 5.9358, 5.9360, 5.9359, 5.9358, 5.9360,\n",
      "        5.9361, 5.9362, 5.9362, 5.9360, 5.9359, 5.9360, 5.9356, 5.9360, 5.9356,\n",
      "        5.9358, 5.9357, 5.9360, 5.9360, 5.9360, 5.9361, 5.9361, 5.9361, 5.9360,\n",
      "        5.9359, 5.9360, 5.9363, 5.9361, 5.9361, 5.9360, 5.9361, 5.9363, 5.9362,\n",
      "        5.9362, 5.9364, 5.9362, 5.9362, 5.9358, 5.9357, 5.9357, 5.9361, 5.9359,\n",
      "        5.9361, 5.9358, 5.9357, 5.9361, 5.9360, 5.9361, 5.9362, 5.9357, 5.9361,\n",
      "        5.9357, 5.9357, 5.9360], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.700889  [3695324/5599865]\n",
      "average delta from current occupancy tensor([5.6501, 5.6504, 5.6501, 5.6507, 5.6500, 5.6505, 5.6505, 5.6492, 5.6505,\n",
      "        5.6495, 5.6506, 5.6498, 5.6501, 5.6502, 5.6500, 5.6490, 5.6491, 5.6495,\n",
      "        5.6497, 5.6500, 5.6494, 5.6492, 5.6498, 5.6495, 5.6494, 5.6497, 5.6497,\n",
      "        5.6498, 5.6499, 5.6498, 5.6502, 5.6500, 5.6501, 5.6504, 5.6497, 5.6496,\n",
      "        5.6496, 5.6497, 5.6495, 5.6494, 5.6494, 5.6507, 5.6497, 5.6499, 5.6500,\n",
      "        5.6498, 5.6502, 5.6498, 5.6496, 5.6497, 5.6497, 5.6496, 5.6500, 5.6493,\n",
      "        5.6495, 5.6497, 5.6495, 5.6497, 5.6504, 5.6501, 5.6491, 5.6494, 5.6490,\n",
      "        5.6496, 5.6492, 5.6489, 5.6489, 5.6489, 5.6495, 5.6492, 5.6499, 5.6495,\n",
      "        5.6493, 5.6491, 5.6495, 5.6502, 5.6498, 5.6497, 5.6486, 5.6494, 5.6499,\n",
      "        5.6497, 5.6499, 5.6494, 5.6488, 5.6498, 5.6492, 5.6487, 5.6495, 5.6497,\n",
      "        5.6497, 5.6494, 5.6499, 5.6497, 5.6493, 5.6488, 5.6488, 5.6488, 5.6493,\n",
      "        5.6489, 5.6487, 5.6491, 5.6493, 5.6484, 5.6492, 5.6488, 5.6488, 5.6487,\n",
      "        5.6488, 5.6486, 5.6489, 5.6487, 5.6488, 5.6489, 5.6490, 5.6494, 5.6487,\n",
      "        5.6494, 5.6482, 5.6483], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.601820  [3707724/5599865]\n",
      "average delta from current occupancy tensor([4.7020, 4.7020, 4.7020, 4.7020, 4.7019, 4.7020, 4.7020, 4.7017, 4.7020,\n",
      "        4.7018, 4.7020, 4.7019, 4.7019, 4.7020, 4.7019, 4.7018, 4.7018, 4.7019,\n",
      "        4.7019, 4.7020, 4.7019, 4.7019, 4.7020, 4.7020, 4.7018, 4.7019, 4.7019,\n",
      "        4.7020, 4.7020, 4.7020, 4.7020, 4.7020, 4.7020, 4.7020, 4.7019, 4.7019,\n",
      "        4.7019, 4.7019, 4.7018, 4.7018, 4.7018, 4.7020, 4.7019, 4.7019, 4.7020,\n",
      "        4.7020, 4.7020, 4.7020, 4.7019, 4.7020, 4.7020, 4.7020, 4.7020, 4.7019,\n",
      "        4.7019, 4.7019, 4.7019, 4.7019, 4.7020, 4.7019, 4.7018, 4.7018, 4.7017,\n",
      "        4.7019, 4.7019, 4.7018, 4.7018, 4.7019, 4.7019, 4.7018, 4.7019, 4.7019,\n",
      "        4.7019, 4.7018, 4.7018, 4.7020, 4.7019, 4.7019, 4.7017, 4.7018, 4.7018,\n",
      "        4.7018, 4.7017, 4.7016, 4.7017, 4.7018, 4.7016, 4.7016, 4.7017, 4.7017,\n",
      "        4.7018, 4.7018, 4.7019, 4.7019, 4.7018, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7017, 4.7017, 4.7018, 4.7018, 4.7018, 4.7019, 4.7018, 4.7017, 4.7018,\n",
      "        4.7018, 4.7017, 4.7018, 4.7018, 4.7018, 4.7018, 4.7018, 4.7019, 4.7017,\n",
      "        4.7018, 4.7017, 4.7017], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.602369  [3720124/5599865]\n",
      "average delta from current occupancy tensor([5.5089, 5.5085, 5.5089, 5.5088, 5.5087, 5.5086, 5.5083, 5.5097, 5.5084,\n",
      "        5.5092, 5.5085, 5.5090, 5.5087, 5.5083, 5.5083, 5.5089, 5.5091, 5.5086,\n",
      "        5.5085, 5.5089, 5.5083, 5.5088, 5.5085, 5.5089, 5.5087, 5.5089, 5.5085,\n",
      "        5.5089, 5.5090, 5.5089, 5.5089, 5.5090, 5.5090, 5.5088, 5.5087, 5.5091,\n",
      "        5.5086, 5.5086, 5.5089, 5.5090, 5.5091, 5.5083, 5.5089, 5.5083, 5.5088,\n",
      "        5.5088, 5.5086, 5.5087, 5.5087, 5.5086, 5.5085, 5.5087, 5.5087, 5.5081,\n",
      "        5.5085, 5.5087, 5.5083, 5.5082, 5.5086, 5.5083, 5.5089, 5.5090, 5.5091,\n",
      "        5.5085, 5.5090, 5.5090, 5.5091, 5.5091, 5.5090, 5.5091, 5.5087, 5.5086,\n",
      "        5.5089, 5.5088, 5.5086, 5.5085, 5.5085, 5.5086, 5.5091, 5.5088, 5.5090,\n",
      "        5.5094, 5.5095, 5.5098, 5.5098, 5.5092, 5.5095, 5.5091, 5.5091, 5.5091,\n",
      "        5.5088, 5.5089, 5.5084, 5.5081, 5.5084, 5.5083, 5.5085, 5.5083, 5.5086,\n",
      "        5.5090, 5.5087, 5.5085, 5.5086, 5.5085, 5.5083, 5.5083, 5.5087, 5.5087,\n",
      "        5.5086, 5.5086, 5.5084, 5.5082, 5.5081, 5.5081, 5.5081, 5.5087, 5.5081,\n",
      "        5.5081, 5.5082, 5.5081], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.790446  [3732524/5599865]\n",
      "average delta from current occupancy tensor([4.7174, 4.7174, 4.7174, 4.7175, 4.7174, 4.7175, 4.7174, 4.7175, 4.7175,\n",
      "        4.7175, 4.7175, 4.7175, 4.7174, 4.7174, 4.7175, 4.7174, 4.7175, 4.7175,\n",
      "        4.7174, 4.7175, 4.7175, 4.7175, 4.7175, 4.7175, 4.7174, 4.7174, 4.7174,\n",
      "        4.7174, 4.7175, 4.7174, 4.7175, 4.7174, 4.7175, 4.7175, 4.7175, 4.7175,\n",
      "        4.7175, 4.7175, 4.7174, 4.7173, 4.7174, 4.7173, 4.7173, 4.7173, 4.7174,\n",
      "        4.7173, 4.7174, 4.7173, 4.7173, 4.7174, 4.7173, 4.7173, 4.7173, 4.7173,\n",
      "        4.7173, 4.7174, 4.7173, 4.7174, 4.7174, 4.7174, 4.7174, 4.7175, 4.7174,\n",
      "        4.7173, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7173,\n",
      "        4.7173, 4.7174, 4.7174, 4.7173, 4.7173, 4.7174, 4.7174, 4.7174, 4.7174,\n",
      "        4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7175, 4.7175, 4.7174,\n",
      "        4.7174, 4.7174, 4.7174, 4.7173, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174,\n",
      "        4.7175, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7174, 4.7175, 4.7175,\n",
      "        4.7175, 4.7175, 4.7175, 4.7174, 4.7174, 4.7174, 4.7175, 4.7174, 4.7174,\n",
      "        4.7174, 4.7174, 4.7174], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.532433  [3744924/5599865]\n",
      "average delta from current occupancy tensor([5.3790, 5.3791, 5.3790, 5.3790, 5.3790, 5.3791, 5.3790, 5.3790, 5.3790,\n",
      "        5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3791, 5.3791,\n",
      "        5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3791, 5.3790, 5.3790, 5.3791,\n",
      "        5.3791, 5.3790, 5.3791, 5.3791, 5.3790, 5.3791, 5.3790, 5.3790, 5.3790,\n",
      "        5.3791, 5.3791, 5.3791, 5.3790, 5.3790, 5.3790, 5.3791, 5.3790, 5.3790,\n",
      "        5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3790, 5.3790,\n",
      "        5.3791, 5.3791, 5.3790, 5.3791, 5.3791, 5.3790, 5.3791, 5.3791, 5.3791,\n",
      "        5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3792, 5.3791,\n",
      "        5.3791, 5.3791, 5.3792, 5.3791, 5.3791, 5.3791, 5.3791, 5.3792, 5.3791,\n",
      "        5.3791, 5.3791, 5.3791, 5.3792, 5.3791, 5.3791, 5.3791, 5.3791, 5.3791,\n",
      "        5.3791, 5.3792, 5.3792, 5.3791, 5.3791, 5.3792, 5.3792, 5.3791, 5.3791,\n",
      "        5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3791, 5.3792,\n",
      "        5.3791, 5.3791, 5.3791, 5.3791, 5.3792, 5.3791, 5.3791, 5.3791, 5.3791,\n",
      "        5.3791, 5.3791, 5.3791], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.589731  [3757324/5599865]\n",
      "average delta from current occupancy tensor([5.4678, 5.4678, 5.4677, 5.4677, 5.4677, 5.4677, 5.4678, 5.4677, 5.4678,\n",
      "        5.4677, 5.4677, 5.4677, 5.4678, 5.4677, 5.4680, 5.4680, 5.4678, 5.4679,\n",
      "        5.4677, 5.4677, 5.4677, 5.4678, 5.4678, 5.4677, 5.4678, 5.4677, 5.4678,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4678, 5.4678,\n",
      "        5.4677, 5.4678, 5.4678, 5.4678, 5.4677, 5.4677, 5.4677, 5.4678, 5.4678,\n",
      "        5.4677, 5.4678, 5.4682, 5.4679, 5.4679, 5.4678, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4676, 5.4677, 5.4677, 5.4677, 5.4678, 5.4679, 5.4678, 5.4678,\n",
      "        5.4678, 5.4678, 5.4678, 5.4679, 5.4679, 5.4678, 5.4677, 5.4677, 5.4678,\n",
      "        5.4678, 5.4679, 5.4680, 5.4679, 5.4680, 5.4678, 5.4678, 5.4680, 5.4680,\n",
      "        5.4679, 5.4678, 5.4680, 5.4680, 5.4678, 5.4679, 5.4678, 5.4678, 5.4680,\n",
      "        5.4681, 5.4680, 5.4681, 5.4680, 5.4680, 5.4681, 5.4681, 5.4681, 5.4681,\n",
      "        5.4679, 5.4682, 5.4679, 5.4680, 5.4681, 5.4680, 5.4682, 5.4677, 5.4679,\n",
      "        5.4678, 5.4678, 5.4679, 5.4681, 5.4681, 5.4679, 5.4678, 5.4680, 5.4681,\n",
      "        5.4682, 5.4680, 5.4682], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.727284  [3769724/5599865]\n",
      "average delta from current occupancy tensor([4.7987, 4.7987, 4.7986, 4.7985, 4.7985, 4.7985, 4.7987, 4.7986, 4.7987,\n",
      "        4.7986, 4.7986, 4.7986, 4.7985, 4.7986, 4.7987, 4.7987, 4.7986, 4.7986,\n",
      "        4.7986, 4.7987, 4.7986, 4.7986, 4.7987, 4.7987, 4.7987, 4.7985, 4.7986,\n",
      "        4.7984, 4.7985, 4.7986, 4.7985, 4.7984, 4.7985, 4.7985, 4.7984, 4.7985,\n",
      "        4.7985, 4.7986, 4.7985, 4.7987, 4.7985, 4.7985, 4.7986, 4.7984, 4.7984,\n",
      "        4.7984, 4.7984, 4.7984, 4.7985, 4.7984, 4.7984, 4.7984, 4.7984, 4.7984,\n",
      "        4.7984, 4.7985, 4.7985, 4.7985, 4.7984, 4.7987, 4.7985, 4.7986, 4.7985,\n",
      "        4.7987, 4.7986, 4.7985, 4.7985, 4.7984, 4.7984, 4.7984, 4.7985, 4.7984,\n",
      "        4.7984, 4.7985, 4.7985, 4.7984, 4.7984, 4.7985, 4.7984, 4.7985, 4.7984,\n",
      "        4.7984, 4.7985, 4.7985, 4.7985, 4.7984, 4.7986, 4.7985, 4.7985, 4.7985,\n",
      "        4.7986, 4.7984, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7984, 4.7985,\n",
      "        4.7985, 4.7985, 4.7985, 4.7984, 4.7984, 4.7984, 4.7984, 4.7985, 4.7984,\n",
      "        4.7985, 4.7984, 4.7984, 4.7985, 4.7984, 4.7984, 4.7984, 4.7985, 4.7984,\n",
      "        4.7984, 4.7985, 4.7984], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.603049  [3782124/5599865]\n",
      "average delta from current occupancy tensor([5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968, 5.5968,\n",
      "        5.5968, 5.5968, 5.5968], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.753202  [3794524/5599865]\n",
      "average delta from current occupancy tensor([4.7500, 4.7500, 4.7500, 4.7498, 4.7500, 4.7499, 4.7498, 4.7499, 4.7499,\n",
      "        4.7499, 4.7499, 4.7499, 4.7498, 4.7496, 4.7497, 4.7500, 4.7499, 4.7500,\n",
      "        4.7497, 4.7498, 4.7496, 4.7497, 4.7495, 4.7499, 4.7498, 4.7495, 4.7498,\n",
      "        4.7496, 4.7497, 4.7496, 4.7495, 4.7495, 4.7496, 4.7495, 4.7498, 4.7495,\n",
      "        4.7499, 4.7500, 4.7500, 4.7500, 4.7498, 4.7500, 4.7499, 4.7499, 4.7499,\n",
      "        4.7499, 4.7498, 4.7500, 4.7498, 4.7500, 4.7499, 4.7500, 4.7500, 4.7500,\n",
      "        4.7500, 4.7500, 4.7500, 4.7500, 4.7497, 4.7498, 4.7498, 4.7498, 4.7500,\n",
      "        4.7500, 4.7500, 4.7500, 4.7500, 4.7498, 4.7500, 4.7498, 4.7500, 4.7499,\n",
      "        4.7499, 4.7500, 4.7498, 4.7500, 4.7500, 4.7500, 4.7499, 4.7499, 4.7499,\n",
      "        4.7499, 4.7499, 4.7500, 4.7500, 4.7499, 4.7499, 4.7500, 4.7499, 4.7500,\n",
      "        4.7500, 4.7500, 4.7499, 4.7500, 4.7499, 4.7499, 4.7499, 4.7500, 4.7498,\n",
      "        4.7499, 4.7499, 4.7498, 4.7499, 4.7500, 4.7497, 4.7499, 4.7499, 4.7500,\n",
      "        4.7499, 4.7498, 4.7498, 4.7500, 4.7499, 4.7499, 4.7500, 4.7499, 4.7499,\n",
      "        4.7499, 4.7499, 4.7498], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.743314  [3806924/5599865]\n",
      "average delta from current occupancy tensor([4.6306, 4.6302, 4.6302, 4.6302, 4.6302, 4.6304, 4.6303, 4.6301, 4.6304,\n",
      "        4.6305, 4.6302, 4.6304, 4.6304, 4.6303, 4.6305, 4.6303, 4.6306, 4.6304,\n",
      "        4.6303, 4.6302, 4.6305, 4.6301, 4.6299, 4.6300, 4.6302, 4.6304, 4.6306,\n",
      "        4.6304, 4.6308, 4.6306, 4.6305, 4.6304, 4.6308, 4.6308, 4.6310, 4.6307,\n",
      "        4.6308, 4.6307, 4.6308, 4.6310, 4.6309, 4.6310, 4.6309, 4.6309, 4.6309,\n",
      "        4.6306, 4.6305, 4.6306, 4.6306, 4.6307, 4.6307, 4.6306, 4.6307, 4.6305,\n",
      "        4.6309, 4.6306, 4.6311, 4.6307, 4.6307, 4.6305, 4.6305, 4.6306, 4.6307,\n",
      "        4.6301, 4.6298, 4.6300, 4.6301, 4.6306, 4.6300, 4.6296, 4.6306, 4.6301,\n",
      "        4.6308, 4.6300, 4.6303, 4.6303, 4.6301, 4.6301, 4.6300, 4.6298, 4.6301,\n",
      "        4.6299, 4.6302, 4.6302, 4.6302, 4.6303, 4.6303, 4.6303, 4.6304, 4.6300,\n",
      "        4.6301, 4.6302, 4.6302, 4.6296, 4.6297, 4.6301, 4.6303, 4.6300, 4.6298,\n",
      "        4.6299, 4.6298, 4.6297, 4.6302, 4.6298, 4.6297, 4.6298, 4.6295, 4.6296,\n",
      "        4.6295, 4.6295, 4.6297, 4.6295, 4.6293, 4.6296, 4.6291, 4.6292, 4.6294,\n",
      "        4.6293, 4.6293, 4.6292], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.768271  [3819324/5599865]\n",
      "average delta from current occupancy tensor([4.9194, 4.9194, 4.9194, 4.9194, 4.9195, 4.9196, 4.9194, 4.9194, 4.9195,\n",
      "        4.9194, 4.9194, 4.9195, 4.9195, 4.9195, 4.9195, 4.9194, 4.9194, 4.9194,\n",
      "        4.9195, 4.9195, 4.9195, 4.9194, 4.9195, 4.9195, 4.9196, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9195, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9195, 4.9196, 4.9195, 4.9195, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9195, 4.9194, 4.9195, 4.9196, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194, 4.9194,\n",
      "        4.9194, 4.9194, 4.9195, 4.9196, 4.9195, 4.9195, 4.9195, 4.9194, 4.9194,\n",
      "        4.9196, 4.9195, 4.9196, 4.9195, 4.9195, 4.9195, 4.9194, 4.9195, 4.9194,\n",
      "        4.9194, 4.9194, 4.9194], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.843599  [3831724/5599865]\n",
      "average delta from current occupancy tensor([5.0080, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079,\n",
      "        5.0080, 5.0080, 5.0080, 5.0079, 5.0080, 5.0080, 5.0080, 5.0080, 5.0079,\n",
      "        5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0081, 5.0080, 5.0080, 5.0080, 5.0081, 5.0081, 5.0080,\n",
      "        5.0081, 5.0081, 5.0081, 5.0081, 5.0080, 5.0081, 5.0082, 5.0082, 5.0082,\n",
      "        5.0081, 5.0081, 5.0080, 5.0081, 5.0081, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0079, 5.0080, 5.0080, 5.0079, 5.0079, 5.0079, 5.0079,\n",
      "        5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079,\n",
      "        5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079, 5.0079,\n",
      "        5.0079, 5.0080, 5.0080, 5.0080, 5.0079, 5.0080, 5.0080, 5.0079, 5.0079,\n",
      "        5.0079, 5.0080, 5.0079, 5.0080, 5.0080, 5.0080, 5.0079, 5.0079, 5.0080,\n",
      "        5.0080, 5.0079, 5.0079, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0080, 5.0080, 5.0081, 5.0080, 5.0080, 5.0080, 5.0080,\n",
      "        5.0080, 5.0080, 5.0080], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.711069  [3844124/5599865]\n",
      "average delta from current occupancy tensor([4.8549, 4.8550, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8550, 4.8550, 4.8549,\n",
      "        4.8549, 4.8550, 4.8549, 4.8549, 4.8550, 4.8550, 4.8550, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8548, 4.8549, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8548, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8548, 4.8549, 4.8548,\n",
      "        4.8548, 4.8549, 4.8549, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548, 4.8548,\n",
      "        4.8549, 4.8549, 4.8548, 4.8548, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549,\n",
      "        4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8550, 4.8549, 4.8550, 4.8549,\n",
      "        4.8550, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8549, 4.8550,\n",
      "        4.8550, 4.8549, 4.8549], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.843235  [3856524/5599865]\n",
      "average delta from current occupancy tensor([4.7101, 4.7102, 4.7101, 4.7101, 4.7102, 4.7103, 4.7100, 4.7101, 4.7101,\n",
      "        4.7104, 4.7103, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7102, 4.7102,\n",
      "        4.7101, 4.7102, 4.7104, 4.7101, 4.7102, 4.7104, 4.7101, 4.7101, 4.7101,\n",
      "        4.7101, 4.7102, 4.7103, 4.7102, 4.7102, 4.7102, 4.7102, 4.7102, 4.7102,\n",
      "        4.7102, 4.7102, 4.7102, 4.7102, 4.7102, 4.7102, 4.7101, 4.7102, 4.7102,\n",
      "        4.7102, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7102, 4.7101,\n",
      "        4.7101, 4.7101, 4.7101, 4.7102, 4.7102, 4.7102, 4.7101, 4.7102, 4.7101,\n",
      "        4.7101, 4.7100, 4.7101, 4.7100, 4.7100, 4.7101, 4.7100, 4.7101, 4.7101,\n",
      "        4.7101, 4.7101, 4.7100, 4.7101, 4.7101, 4.7100, 4.7101, 4.7101, 4.7101,\n",
      "        4.7101, 4.7101, 4.7102, 4.7100, 4.7100, 4.7100, 4.7100, 4.7100, 4.7100,\n",
      "        4.7100, 4.7100, 4.7101, 4.7101, 4.7101, 4.7100, 4.7101, 4.7101, 4.7101,\n",
      "        4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7102, 4.7101,\n",
      "        4.7101, 4.7101, 4.7100, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101, 4.7101,\n",
      "        4.7101, 4.7100, 4.7101], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.347401  [3868924/5599865]\n",
      "average delta from current occupancy tensor([5.5251, 5.5252, 5.5252, 5.5252, 5.5251, 5.5250, 5.5251, 5.5250, 5.5252,\n",
      "        5.5250, 5.5250, 5.5250, 5.5250, 5.5249, 5.5249, 5.5249, 5.5249, 5.5250,\n",
      "        5.5250, 5.5250, 5.5250, 5.5250, 5.5250, 5.5249, 5.5249, 5.5248, 5.5249,\n",
      "        5.5248, 5.5248, 5.5248, 5.5249, 5.5247, 5.5247, 5.5249, 5.5247, 5.5247,\n",
      "        5.5249, 5.5248, 5.5248, 5.5248, 5.5249, 5.5249, 5.5249, 5.5247, 5.5248,\n",
      "        5.5249, 5.5248, 5.5249, 5.5247, 5.5247, 5.5247, 5.5246, 5.5247, 5.5247,\n",
      "        5.5246, 5.5247, 5.5246, 5.5246, 5.5245, 5.5245, 5.5245, 5.5245, 5.5245,\n",
      "        5.5245, 5.5245, 5.5246, 5.5245, 5.5245, 5.5245, 5.5245, 5.5246, 5.5244,\n",
      "        5.5246, 5.5246, 5.5245, 5.5246, 5.5245, 5.5245, 5.5245, 5.5247, 5.5246,\n",
      "        5.5246, 5.5247, 5.5248, 5.5248, 5.5248, 5.5248, 5.5248, 5.5248, 5.5248,\n",
      "        5.5248, 5.5247, 5.5248, 5.5248, 5.5247, 5.5248, 5.5247, 5.5248, 5.5248,\n",
      "        5.5246, 5.5247, 5.5246, 5.5247, 5.5246, 5.5247, 5.5247, 5.5247, 5.5247,\n",
      "        5.5247, 5.5248, 5.5248, 5.5247, 5.5248, 5.5248, 5.5247, 5.5248, 5.5248,\n",
      "        5.5248, 5.5248, 5.5246], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.045130  [3881324/5599865]\n",
      "average delta from current occupancy tensor([5.8629, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630,\n",
      "        5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630,\n",
      "        5.8630, 5.8630, 5.8629, 5.8630, 5.8630, 5.8630, 5.8629, 5.8630, 5.8630,\n",
      "        5.8630, 5.8630, 5.8629, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630,\n",
      "        5.8630, 5.8630, 5.8630, 5.8629, 5.8629, 5.8630, 5.8629, 5.8629, 5.8630,\n",
      "        5.8630, 5.8630, 5.8630, 5.8629, 5.8629, 5.8629, 5.8629, 5.8630, 5.8629,\n",
      "        5.8629, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8629, 5.8629, 5.8629,\n",
      "        5.8630, 5.8629, 5.8629, 5.8630, 5.8629, 5.8630, 5.8630, 5.8630, 5.8630,\n",
      "        5.8630, 5.8630, 5.8629, 5.8629, 5.8629, 5.8629, 5.8630, 5.8630, 5.8629,\n",
      "        5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630, 5.8630,\n",
      "        5.8630, 5.8630, 5.8629, 5.8629, 5.8630, 5.8629, 5.8630, 5.8630, 5.8630,\n",
      "        5.8629, 5.8630, 5.8630, 5.8630, 5.8630, 5.8629, 5.8630, 5.8630, 5.8630,\n",
      "        5.8630, 5.8629, 5.8629, 5.8630, 5.8629, 5.8630, 5.8629, 5.8629, 5.8629,\n",
      "        5.8630, 5.8630, 5.8629], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.986458  [3893724/5599865]\n",
      "average delta from current occupancy tensor([4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.183671  [3906124/5599865]\n",
      "average delta from current occupancy tensor([4.0559, 4.0560, 4.0559, 4.0559, 4.0558, 4.0560, 4.0558, 4.0559, 4.0557,\n",
      "        4.0557, 4.0559, 4.0558, 4.0557, 4.0557, 4.0557, 4.0558, 4.0557, 4.0557,\n",
      "        4.0556, 4.0558, 4.0558, 4.0556, 4.0557, 4.0557, 4.0556, 4.0556, 4.0556,\n",
      "        4.0555, 4.0556, 4.0556, 4.0557, 4.0557, 4.0556, 4.0558, 4.0558, 4.0558,\n",
      "        4.0557, 4.0557, 4.0558, 4.0557, 4.0559, 4.0556, 4.0557, 4.0558, 4.0557,\n",
      "        4.0557, 4.0557, 4.0556, 4.0556, 4.0557, 4.0556, 4.0557, 4.0557, 4.0558,\n",
      "        4.0558, 4.0557, 4.0556, 4.0557, 4.0558, 4.0557, 4.0557, 4.0557, 4.0557,\n",
      "        4.0555, 4.0556, 4.0556, 4.0556, 4.0556, 4.0556, 4.0555, 4.0556, 4.0556,\n",
      "        4.0555, 4.0554, 4.0554, 4.0554, 4.0554, 4.0555, 4.0553, 4.0554, 4.0554,\n",
      "        4.0554, 4.0555, 4.0555, 4.0555, 4.0556, 4.0555, 4.0555, 4.0554, 4.0554,\n",
      "        4.0555, 4.0553, 4.0555, 4.0554, 4.0555, 4.0554, 4.0552, 4.0554, 4.0554,\n",
      "        4.0555, 4.0553, 4.0554, 4.0556, 4.0555, 4.0555, 4.0554, 4.0555, 4.0555,\n",
      "        4.0555, 4.0555, 4.0556, 4.0555, 4.0555, 4.0555, 4.0555, 4.0557, 4.0556,\n",
      "        4.0555, 4.0558, 4.0557], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.075004  [3918524/5599865]\n",
      "average delta from current occupancy tensor([4.8311, 4.8310, 4.8310, 4.8310, 4.8311, 4.8310, 4.8311, 4.8311, 4.8311,\n",
      "        4.8311, 4.8311, 4.8311, 4.8310, 4.8311, 4.8310, 4.8310, 4.8311, 4.8311,\n",
      "        4.8310, 4.8311, 4.8311, 4.8311, 4.8311, 4.8310, 4.8311, 4.8311, 4.8311,\n",
      "        4.8311, 4.8311, 4.8311, 4.8311, 4.8310, 4.8310, 4.8311, 4.8311, 4.8311,\n",
      "        4.8311, 4.8311, 4.8311, 4.8312, 4.8311, 4.8311, 4.8311, 4.8312, 4.8311,\n",
      "        4.8311, 4.8311, 4.8312, 4.8311, 4.8312, 4.8311, 4.8311, 4.8311, 4.8312,\n",
      "        4.8312, 4.8311, 4.8312, 4.8311, 4.8311, 4.8312, 4.8312, 4.8312, 4.8312,\n",
      "        4.8311, 4.8311, 4.8312, 4.8312, 4.8311, 4.8312, 4.8311, 4.8312, 4.8311,\n",
      "        4.8312, 4.8311, 4.8310, 4.8311, 4.8311, 4.8311, 4.8310, 4.8310, 4.8311,\n",
      "        4.8309, 4.8310, 4.8310, 4.8308, 4.8310, 4.8310, 4.8311, 4.8309, 4.8309,\n",
      "        4.8310, 4.8311, 4.8310, 4.8309, 4.8310, 4.8309, 4.8310, 4.8309, 4.8309,\n",
      "        4.8309, 4.8309, 4.8310, 4.8310, 4.8310, 4.8310, 4.8308, 4.8310, 4.8310,\n",
      "        4.8310, 4.8310, 4.8310, 4.8311, 4.8310, 4.8311, 4.8311, 4.8311, 4.8311,\n",
      "        4.8310, 4.8310, 4.8310], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.235573  [3930924/5599865]\n",
      "average delta from current occupancy tensor([5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887,\n",
      "        5.0887, 5.0887, 5.0888, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887,\n",
      "        5.0888, 5.0887, 5.0887, 5.0888, 5.0888, 5.0887, 5.0887, 5.0888, 5.0887,\n",
      "        5.0887, 5.0888, 5.0888, 5.0887, 5.0888, 5.0887, 5.0887, 5.0887, 5.0888,\n",
      "        5.0888, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887,\n",
      "        5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887,\n",
      "        5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0888,\n",
      "        5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887,\n",
      "        5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887, 5.0887,\n",
      "        5.0887, 5.0887, 5.0888, 5.0887, 5.0887, 5.0887, 5.0888, 5.0888, 5.0887,\n",
      "        5.0887, 5.0888, 5.0888, 5.0888, 5.0888, 5.0887, 5.0887, 5.0888, 5.0888,\n",
      "        5.0888, 5.0887, 5.0888, 5.0888, 5.0888, 5.0888, 5.0888, 5.0887, 5.0888,\n",
      "        5.0888, 5.0887, 5.0887, 5.0888, 5.0888, 5.0888, 5.0888, 5.0888, 5.0888,\n",
      "        5.0888, 5.0888, 5.0888], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.107942  [3943324/5599865]\n",
      "average delta from current occupancy tensor([5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2500, 5.2500, 5.2499, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2499, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500,\n",
      "        5.2500, 5.2499, 5.2499, 5.2499, 5.2499, 5.2500, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2500, 5.2500, 5.2500, 5.2499,\n",
      "        5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.415370  [3955724/5599865]\n",
      "average delta from current occupancy tensor([5.3469, 5.3469, 5.3469, 5.3469, 5.3471, 5.3470, 5.3470, 5.3469, 5.3469,\n",
      "        5.3468, 5.3468, 5.3469, 5.3468, 5.3469, 5.3470, 5.3469, 5.3471, 5.3470,\n",
      "        5.3471, 5.3472, 5.3471, 5.3470, 5.3470, 5.3470, 5.3471, 5.3470, 5.3471,\n",
      "        5.3470, 5.3472, 5.3471, 5.3473, 5.3472, 5.3475, 5.3472, 5.3472, 5.3472,\n",
      "        5.3472, 5.3471, 5.3469, 5.3469, 5.3469, 5.3468, 5.3470, 5.3469, 5.3469,\n",
      "        5.3468, 5.3468, 5.3469, 5.3470, 5.3471, 5.3470, 5.3468, 5.3469, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468, 5.3468,\n",
      "        5.3469, 5.3469, 5.3470, 5.3469, 5.3470, 5.3470, 5.3470, 5.3470, 5.3472,\n",
      "        5.3471, 5.3471, 5.3472, 5.3472, 5.3471, 5.3472, 5.3472, 5.3472, 5.3471,\n",
      "        5.3471, 5.3472, 5.3472, 5.3473, 5.3471, 5.3471, 5.3471, 5.3471, 5.3470,\n",
      "        5.3470, 5.3471, 5.3470, 5.3469, 5.3470, 5.3471, 5.3470, 5.3469, 5.3470,\n",
      "        5.3472, 5.3470, 5.3470, 5.3471, 5.3472, 5.3472, 5.3472, 5.3472, 5.3471,\n",
      "        5.3470, 5.3470, 5.3470], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.226008  [3968124/5599865]\n",
      "average delta from current occupancy tensor([6.3657, 6.3653, 6.3654, 6.3656, 6.3658, 6.3656, 6.3657, 6.3658, 6.3659,\n",
      "        6.3657, 6.3655, 6.3657, 6.3658, 6.3660, 6.3661, 6.3658, 6.3662, 6.3663,\n",
      "        6.3666, 6.3668, 6.3666, 6.3665, 6.3663, 6.3660, 6.3663, 6.3659, 6.3661,\n",
      "        6.3660, 6.3665, 6.3660, 6.3666, 6.3667, 6.3662, 6.3668, 6.3665, 6.3666,\n",
      "        6.3666, 6.3666, 6.3656, 6.3653, 6.3652, 6.3654, 6.3652, 6.3650, 6.3650,\n",
      "        6.3653, 6.3651, 6.3652, 6.3654, 6.3655, 6.3655, 6.3652, 6.3652, 6.3652,\n",
      "        6.3654, 6.3655, 6.3656, 6.3653, 6.3657, 6.3654, 6.3650, 6.3655, 6.3652,\n",
      "        6.3654, 6.3661, 6.3657, 6.3656, 6.3659, 6.3663, 6.3657, 6.3656, 6.3655,\n",
      "        6.3660, 6.3658, 6.3663, 6.3658, 6.3662, 6.3661, 6.3659, 6.3662, 6.3665,\n",
      "        6.3661, 6.3661, 6.3662, 6.3661, 6.3659, 6.3663, 6.3658, 6.3660, 6.3659,\n",
      "        6.3659, 6.3664, 6.3664, 6.3666, 6.3663, 6.3662, 6.3661, 6.3661, 6.3655,\n",
      "        6.3654, 6.3659, 6.3655, 6.3658, 6.3658, 6.3657, 6.3655, 6.3654, 6.3656,\n",
      "        6.3654, 6.3652, 6.3653, 6.3651, 6.3653, 6.3654, 6.3654, 6.3657, 6.3653,\n",
      "        6.3653, 6.3651, 6.3651], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.996176  [3980524/5599865]\n",
      "average delta from current occupancy tensor([5.0734, 5.0734, 5.0734, 5.0735, 5.0735, 5.0734, 5.0734, 5.0734, 5.0734,\n",
      "        5.0734, 5.0734, 5.0734, 5.0734, 5.0733, 5.0733, 5.0734, 5.0733, 5.0733,\n",
      "        5.0734, 5.0734, 5.0734, 5.0734, 5.0733, 5.0733, 5.0734, 5.0734, 5.0734,\n",
      "        5.0733, 5.0734, 5.0734, 5.0734, 5.0735, 5.0734, 5.0735, 5.0735, 5.0735,\n",
      "        5.0735, 5.0735, 5.0734, 5.0735, 5.0735, 5.0735, 5.0734, 5.0735, 5.0735,\n",
      "        5.0735, 5.0735, 5.0735, 5.0735, 5.0734, 5.0735, 5.0735, 5.0735, 5.0735,\n",
      "        5.0735, 5.0735, 5.0734, 5.0735, 5.0735, 5.0735, 5.0734, 5.0735, 5.0734,\n",
      "        5.0734, 5.0734, 5.0734, 5.0734, 5.0733, 5.0734, 5.0733, 5.0734, 5.0734,\n",
      "        5.0734, 5.0733, 5.0734, 5.0733, 5.0733, 5.0733, 5.0733, 5.0734, 5.0734,\n",
      "        5.0734, 5.0734, 5.0734, 5.0734, 5.0734, 5.0734, 5.0733, 5.0733, 5.0733,\n",
      "        5.0733, 5.0733, 5.0734, 5.0734, 5.0734, 5.0733, 5.0733, 5.0733, 5.0733,\n",
      "        5.0733, 5.0733, 5.0733, 5.0734, 5.0733, 5.0733, 5.0733, 5.0733, 5.0733,\n",
      "        5.0733, 5.0733, 5.0733, 5.0733, 5.0734, 5.0733, 5.0732, 5.0733, 5.0733,\n",
      "        5.0733, 5.0733, 5.0733], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.303073  [3992924/5599865]\n",
      "average delta from current occupancy tensor([4.2015, 4.2015, 4.2017, 4.2016, 4.2015, 4.2017, 4.2020, 4.2019, 4.2017,\n",
      "        4.2016, 4.2018, 4.2017, 4.2017, 4.2025, 4.2027, 4.2017, 4.2023, 4.2024,\n",
      "        4.2018, 4.2016, 4.2017, 4.2021, 4.2020, 4.2024, 4.2019, 4.2016, 4.2018,\n",
      "        4.2024, 4.2017, 4.2022, 4.2014, 4.2016, 4.2018, 4.2012, 4.2015, 4.2014,\n",
      "        4.2012, 4.2011, 4.2017, 4.2015, 4.2015, 4.2016, 4.2015, 4.2011, 4.2008,\n",
      "        4.2012, 4.2012, 4.2011, 4.2011, 4.2010, 4.2010, 4.2009, 4.2009, 4.2009,\n",
      "        4.2011, 4.2012, 4.2012, 4.2009, 4.2010, 4.2010, 4.2013, 4.2012, 4.2012,\n",
      "        4.2014, 4.2015, 4.2013, 4.2014, 4.2020, 4.2019, 4.2019, 4.2017, 4.2021,\n",
      "        4.2022, 4.2023, 4.2020, 4.2027, 4.2026, 4.2025, 4.2023, 4.2021, 4.2021,\n",
      "        4.2027, 4.2028, 4.2020, 4.2020, 4.2022, 4.2019, 4.2027, 4.2029, 4.2027,\n",
      "        4.2027, 4.2026, 4.2025, 4.2022, 4.2027, 4.2030, 4.2031, 4.2028, 4.2029,\n",
      "        4.2030, 4.2027, 4.2032, 4.2030, 4.2031, 4.2033, 4.2028, 4.2029, 4.2034,\n",
      "        4.2031, 4.2027, 4.2028, 4.2032, 4.2031, 4.2034, 4.2034, 4.2032, 4.2031,\n",
      "        4.2032, 4.2028, 4.2029], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.019600  [4005324/5599865]\n",
      "average delta from current occupancy tensor([4.9849, 4.9848, 4.9846, 4.9847, 4.9848, 4.9848, 4.9847, 4.9848, 4.9849,\n",
      "        4.9847, 4.9846, 4.9846, 4.9847, 4.9845, 4.9844, 4.9848, 4.9846, 4.9846,\n",
      "        4.9847, 4.9848, 4.9848, 4.9848, 4.9849, 4.9848, 4.9849, 4.9848, 4.9847,\n",
      "        4.9846, 4.9847, 4.9849, 4.9850, 4.9849, 4.9849, 4.9848, 4.9852, 4.9851,\n",
      "        4.9848, 4.9849, 4.9850, 4.9850, 4.9850, 4.9850, 4.9850, 4.9846, 4.9846,\n",
      "        4.9848, 4.9848, 4.9847, 4.9845, 4.9846, 4.9848, 4.9848, 4.9848, 4.9846,\n",
      "        4.9849, 4.9850, 4.9849, 4.9848, 4.9849, 4.9849, 4.9849, 4.9849, 4.9849,\n",
      "        4.9849, 4.9850, 4.9847, 4.9848, 4.9848, 4.9848, 4.9847, 4.9850, 4.9847,\n",
      "        4.9848, 4.9848, 4.9852, 4.9849, 4.9849, 4.9849, 4.9849, 4.9849, 4.9850,\n",
      "        4.9851, 4.9851, 4.9851, 4.9851, 4.9851, 4.9852, 4.9851, 4.9849, 4.9850,\n",
      "        4.9850, 4.9849, 4.9849, 4.9849, 4.9847, 4.9848, 4.9848, 4.9848, 4.9847,\n",
      "        4.9847, 4.9847, 4.9848, 4.9848, 4.9849, 4.9849, 4.9848, 4.9849, 4.9850,\n",
      "        4.9850, 4.9850, 4.9849, 4.9848, 4.9848, 4.9848, 4.9848, 4.9848, 4.9847,\n",
      "        4.9848, 4.9848, 4.9847], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.521434  [4017724/5599865]\n",
      "average delta from current occupancy tensor([4.3627, 4.3628, 4.3628, 4.3628, 4.3628, 4.3628, 4.3629, 4.3629, 4.3632,\n",
      "        4.3628, 4.3628, 4.3627, 4.3627, 4.3629, 4.3629, 4.3627, 4.3628, 4.3627,\n",
      "        4.3627, 4.3627, 4.3626, 4.3627, 4.3626, 4.3628, 4.3627, 4.3627, 4.3627,\n",
      "        4.3627, 4.3628, 4.3628, 4.3631, 4.3630, 4.3627, 4.3627, 4.3628, 4.3627,\n",
      "        4.3628, 4.3627, 4.3627, 4.3627, 4.3626, 4.3626, 4.3627, 4.3627, 4.3626,\n",
      "        4.3626, 4.3626, 4.3626, 4.3627, 4.3627, 4.3625, 4.3625, 4.3625, 4.3626,\n",
      "        4.3626, 4.3625, 4.3626, 4.3628, 4.3628, 4.3627, 4.3625, 4.3627, 4.3626,\n",
      "        4.3625, 4.3625, 4.3627, 4.3628, 4.3626, 4.3628, 4.3627, 4.3625, 4.3626,\n",
      "        4.3626, 4.3627, 4.3623, 4.3627, 4.3625, 4.3625, 4.3625, 4.3625, 4.3626,\n",
      "        4.3622, 4.3622, 4.3622, 4.3624, 4.3627, 4.3624, 4.3624, 4.3622, 4.3621,\n",
      "        4.3623, 4.3622, 4.3623, 4.3623, 4.3620, 4.3624, 4.3623, 4.3624, 4.3623,\n",
      "        4.3622, 4.3623, 4.3623, 4.3623, 4.3623, 4.3619, 4.3617, 4.3619, 4.3623,\n",
      "        4.3624, 4.3622, 4.3618, 4.3619, 4.3618, 4.3619, 4.3620, 4.3617, 4.3616,\n",
      "        4.3616, 4.3618, 4.3617], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.743940  [4030124/5599865]\n",
      "average delta from current occupancy tensor([4.7905, 4.7906, 4.7904, 4.7903, 4.7903, 4.7903, 4.7903, 4.7903, 4.7902,\n",
      "        4.7903, 4.7904, 4.7903, 4.7903, 4.7904, 4.7905, 4.7904, 4.7904, 4.7903,\n",
      "        4.7901, 4.7900, 4.7903, 4.7903, 4.7902, 4.7901, 4.7902, 4.7903, 4.7903,\n",
      "        4.7903, 4.7903, 4.7902, 4.7904, 4.7902, 4.7903, 4.7903, 4.7903, 4.7904,\n",
      "        4.7903, 4.7903, 4.7904, 4.7903, 4.7903, 4.7903, 4.7904, 4.7903, 4.7903,\n",
      "        4.7903, 4.7908, 4.7909, 4.7903, 4.7905, 4.7907, 4.7905, 4.7903, 4.7908,\n",
      "        4.7903, 4.7907, 4.7903, 4.7907, 4.7904, 4.7905, 4.7905, 4.7907, 4.7903,\n",
      "        4.7903, 4.7903, 4.7905, 4.7907, 4.7906, 4.7909, 4.7903, 4.7903, 4.7903,\n",
      "        4.7903, 4.7903, 4.7902, 4.7903, 4.7905, 4.7904, 4.7906, 4.7903, 4.7912,\n",
      "        4.7906, 4.7905, 4.7905, 4.7910, 4.7911, 4.7904, 4.7903, 4.7910, 4.7909,\n",
      "        4.7905, 4.7906, 4.7909, 4.7910, 4.7906, 4.7909, 4.7905, 4.7904, 4.7904,\n",
      "        4.7907, 4.7907, 4.7905, 4.7904, 4.7904, 4.7904, 4.7903, 4.7904, 4.7904,\n",
      "        4.7903, 4.7904, 4.7903, 4.7903, 4.7903, 4.7907, 4.7909, 4.7903, 4.7905,\n",
      "        4.7903, 4.7904, 4.7903], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.164791  [4042524/5599865]\n",
      "average delta from current occupancy tensor([6.0395, 6.0404, 6.0405, 6.0399, 6.0396, 6.0399, 6.0402, 6.0399, 6.0396,\n",
      "        6.0400, 6.0400, 6.0398, 6.0403, 6.0410, 6.0399, 6.0398, 6.0398, 6.0381,\n",
      "        6.0385, 6.0383, 6.0375, 6.0379, 6.0371, 6.0374, 6.0382, 6.0382, 6.0376,\n",
      "        6.0387, 6.0388, 6.0388, 6.0394, 6.0383, 6.0390, 6.0389, 6.0378, 6.0401,\n",
      "        6.0392, 6.0400, 6.0398, 6.0387, 6.0383, 6.0390, 6.0389, 6.0384, 6.0383,\n",
      "        6.0381, 6.0390, 6.0385, 6.0376, 6.0376, 6.0371, 6.0373, 6.0363, 6.0367,\n",
      "        6.0363, 6.0367, 6.0355, 6.0356, 6.0359, 6.0359, 6.0355, 6.0357, 6.0357,\n",
      "        6.0363, 6.0358, 6.0368, 6.0363, 6.0368, 6.0370, 6.0369, 6.0365, 6.0361,\n",
      "        6.0363, 6.0360, 6.0361, 6.0356, 6.0363, 6.0365, 6.0369, 6.0365, 6.0377,\n",
      "        6.0368, 6.0369, 6.0365, 6.0366, 6.0372, 6.0376, 6.0380, 6.0382, 6.0389,\n",
      "        6.0385, 6.0382, 6.0384, 6.0382, 6.0381, 6.0377, 6.0381, 6.0385, 6.0382,\n",
      "        6.0377, 6.0379, 6.0378, 6.0376, 6.0377, 6.0379, 6.0371, 6.0383, 6.0389,\n",
      "        6.0382, 6.0386, 6.0368, 6.0384, 6.0380, 6.0389, 6.0386, 6.0384, 6.0383,\n",
      "        6.0380, 6.0385, 6.0384], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.046450  [4054924/5599865]\n",
      "average delta from current occupancy tensor([5.1782, 5.1786, 5.1787, 5.1784, 5.1783, 5.1785, 5.1786, 5.1785, 5.1784,\n",
      "        5.1785, 5.1784, 5.1781, 5.1785, 5.1785, 5.1782, 5.1782, 5.1783, 5.1786,\n",
      "        5.1787, 5.1787, 5.1786, 5.1788, 5.1788, 5.1789, 5.1789, 5.1789, 5.1791,\n",
      "        5.1788, 5.1788, 5.1789, 5.1789, 5.1792, 5.1792, 5.1789, 5.1793, 5.1788,\n",
      "        5.1790, 5.1789, 5.1789, 5.1792, 5.1791, 5.1792, 5.1791, 5.1792, 5.1791,\n",
      "        5.1792, 5.1791, 5.1791, 5.1791, 5.1791, 5.1790, 5.1789, 5.1790, 5.1788,\n",
      "        5.1790, 5.1790, 5.1790, 5.1790, 5.1790, 5.1790, 5.1792, 5.1791, 5.1791,\n",
      "        5.1790, 5.1792, 5.1789, 5.1790, 5.1791, 5.1791, 5.1792, 5.1793, 5.1791,\n",
      "        5.1789, 5.1790, 5.1789, 5.1789, 5.1789, 5.1788, 5.1788, 5.1789, 5.1789,\n",
      "        5.1789, 5.1789, 5.1789, 5.1790, 5.1787, 5.1791, 5.1790, 5.1790, 5.1790,\n",
      "        5.1791, 5.1789, 5.1789, 5.1788, 5.1790, 5.1788, 5.1788, 5.1788, 5.1789,\n",
      "        5.1788, 5.1788, 5.1788, 5.1789, 5.1790, 5.1789, 5.1790, 5.1788, 5.1788,\n",
      "        5.1788, 5.1788, 5.1789, 5.1788, 5.1789, 5.1788, 5.1787, 5.1789, 5.1789,\n",
      "        5.1789, 5.1786, 5.1788], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.554424  [4067324/5599865]\n",
      "average delta from current occupancy tensor([4.5643, 4.5640, 4.5641, 4.5644, 4.5643, 4.5641, 4.5639, 4.5640, 4.5641,\n",
      "        4.5642, 4.5643, 4.5646, 4.5645, 4.5645, 4.5646, 4.5646, 4.5645, 4.5639,\n",
      "        4.5639, 4.5639, 4.5642, 4.5641, 4.5642, 4.5639, 4.5639, 4.5639, 4.5637,\n",
      "        4.5640, 4.5640, 4.5637, 4.5637, 4.5635, 4.5637, 4.5640, 4.5637, 4.5641,\n",
      "        4.5639, 4.5641, 4.5641, 4.5637, 4.5638, 4.5637, 4.5636, 4.5634, 4.5635,\n",
      "        4.5634, 4.5636, 4.5636, 4.5638, 4.5637, 4.5638, 4.5639, 4.5638, 4.5640,\n",
      "        4.5635, 4.5636, 4.5636, 4.5636, 4.5636, 4.5635, 4.5633, 4.5635, 4.5637,\n",
      "        4.5637, 4.5635, 4.5639, 4.5640, 4.5639, 4.5639, 4.5637, 4.5637, 4.5639,\n",
      "        4.5642, 4.5643, 4.5643, 4.5644, 4.5643, 4.5644, 4.5644, 4.5642, 4.5641,\n",
      "        4.5641, 4.5640, 4.5640, 4.5640, 4.5642, 4.5638, 4.5640, 4.5641, 4.5640,\n",
      "        4.5641, 4.5640, 4.5639, 4.5638, 4.5639, 4.5641, 4.5641, 4.5640, 4.5637,\n",
      "        4.5637, 4.5638, 4.5637, 4.5637, 4.5636, 4.5637, 4.5637, 4.5639, 4.5640,\n",
      "        4.5639, 4.5640, 4.5636, 4.5637, 4.5638, 4.5637, 4.5638, 4.5637, 4.5638,\n",
      "        4.5638, 4.5640, 4.5638], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.905160  [4079724/5599865]\n",
      "average delta from current occupancy tensor([4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7901, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7901, 4.7902, 4.7902, 4.7902, 4.7902, 4.7901,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902,\n",
      "        4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7902, 4.7901,\n",
      "        4.7902, 4.7902, 4.7901, 4.7902, 4.7901, 4.7902, 4.7901, 4.7902, 4.7902,\n",
      "        4.7901, 4.7902, 4.7902], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.854973  [4092124/5599865]\n",
      "average delta from current occupancy tensor([5.8807, 5.8806, 5.8808, 5.8807, 5.8808, 5.8807, 5.8809, 5.8808, 5.8809,\n",
      "        5.8808, 5.8806, 5.8808, 5.8808, 5.8807, 5.8807, 5.8807, 5.8807, 5.8807,\n",
      "        5.8807, 5.8807, 5.8809, 5.8808, 5.8810, 5.8810, 5.8809, 5.8808, 5.8807,\n",
      "        5.8807, 5.8807, 5.8807, 5.8808, 5.8804, 5.8805, 5.8809, 5.8809, 5.8809,\n",
      "        5.8807, 5.8805, 5.8805, 5.8806, 5.8805, 5.8806, 5.8805, 5.8804, 5.8806,\n",
      "        5.8804, 5.8802, 5.8803, 5.8805, 5.8802, 5.8805, 5.8804, 5.8805, 5.8804,\n",
      "        5.8804, 5.8805, 5.8803, 5.8805, 5.8803, 5.8802, 5.8802, 5.8802, 5.8802,\n",
      "        5.8803, 5.8803, 5.8806, 5.8805, 5.8803, 5.8803, 5.8801, 5.8801, 5.8803,\n",
      "        5.8805, 5.8805, 5.8806, 5.8805, 5.8806, 5.8804, 5.8807, 5.8806, 5.8804,\n",
      "        5.8805, 5.8807, 5.8805, 5.8807, 5.8807, 5.8806, 5.8808, 5.8806, 5.8808,\n",
      "        5.8805, 5.8807, 5.8806, 5.8806, 5.8802, 5.8803, 5.8805, 5.8806, 5.8803,\n",
      "        5.8804, 5.8803, 5.8805, 5.8801, 5.8802, 5.8801, 5.8803, 5.8804, 5.8804,\n",
      "        5.8807, 5.8805, 5.8805, 5.8806, 5.8805, 5.8805, 5.8807, 5.8805, 5.8809,\n",
      "        5.8811, 5.8809, 5.8809], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.835356  [4104524/5599865]\n",
      "average delta from current occupancy tensor([5.1207, 5.1206, 5.1207, 5.1207, 5.1206, 5.1207, 5.1207, 5.1207, 5.1207,\n",
      "        5.1208, 5.1208, 5.1208, 5.1208, 5.1209, 5.1207, 5.1208, 5.1208, 5.1208,\n",
      "        5.1208, 5.1207, 5.1207, 5.1208, 5.1208, 5.1207, 5.1207, 5.1208, 5.1207,\n",
      "        5.1207, 5.1208, 5.1208, 5.1208, 5.1208, 5.1209, 5.1209, 5.1208, 5.1207,\n",
      "        5.1209, 5.1208, 5.1208, 5.1208, 5.1207, 5.1207, 5.1207, 5.1206, 5.1206,\n",
      "        5.1205, 5.1208, 5.1206, 5.1205, 5.1206, 5.1206, 5.1205, 5.1206, 5.1206,\n",
      "        5.1205, 5.1205, 5.1207, 5.1206, 5.1205, 5.1205, 5.1207, 5.1205, 5.1206,\n",
      "        5.1206, 5.1206, 5.1206, 5.1206, 5.1207, 5.1206, 5.1212, 5.1206, 5.1207,\n",
      "        5.1207, 5.1207, 5.1207, 5.1208, 5.1208, 5.1208, 5.1207, 5.1207, 5.1208,\n",
      "        5.1208, 5.1208, 5.1208, 5.1209, 5.1210, 5.1210, 5.1209, 5.1211, 5.1209,\n",
      "        5.1212, 5.1211, 5.1209, 5.1207, 5.1208, 5.1207, 5.1207, 5.1208, 5.1209,\n",
      "        5.1209, 5.1208, 5.1208, 5.1208, 5.1210, 5.1209, 5.1209, 5.1208, 5.1207,\n",
      "        5.1209, 5.1209, 5.1210, 5.1208, 5.1209, 5.1208, 5.1207, 5.1208, 5.1208,\n",
      "        5.1208, 5.1209, 5.1209], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.677413  [4116924/5599865]\n",
      "average delta from current occupancy tensor([5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5809, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5809, 5.5810, 5.5810, 5.5809, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5809, 5.5809, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5809, 5.5809, 5.5809, 5.5809, 5.5809, 5.5810, 5.5810,\n",
      "        5.5809, 5.5809, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810, 5.5810,\n",
      "        5.5810, 5.5810, 5.5810], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.662130  [4129324/5599865]\n",
      "average delta from current occupancy tensor([4.7663, 4.7662, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7664, 4.7664,\n",
      "        4.7664, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7662, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7662, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664,\n",
      "        4.7663, 4.7664, 4.7664, 4.7664, 4.7664, 4.7663, 4.7663, 4.7663, 4.7663,\n",
      "        4.7663, 4.7663, 4.7663, 4.7663, 4.7663, 4.7664, 4.7664, 4.7664, 4.7664,\n",
      "        4.7664, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664, 4.7664, 4.7663, 4.7663,\n",
      "        4.7664, 4.7663, 4.7663], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.851469  [4141724/5599865]\n",
      "average delta from current occupancy tensor([4.8466, 4.8466, 4.8466, 4.8467, 4.8467, 4.8467, 4.8467, 4.8466, 4.8466,\n",
      "        4.8465, 4.8466, 4.8466, 4.8466, 4.8466, 4.8467, 4.8466, 4.8466, 4.8466,\n",
      "        4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8467, 4.8466, 4.8466, 4.8466,\n",
      "        4.8467, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8467, 4.8466,\n",
      "        4.8466, 4.8466, 4.8467, 4.8467, 4.8466, 4.8467, 4.8467, 4.8467, 4.8466,\n",
      "        4.8467, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466,\n",
      "        4.8467, 4.8467, 4.8466, 4.8467, 4.8466, 4.8467, 4.8467, 4.8467, 4.8467,\n",
      "        4.8467, 4.8469, 4.8467, 4.8467, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466,\n",
      "        4.8466, 4.8466, 4.8466, 4.8465, 4.8466, 4.8466, 4.8467, 4.8467, 4.8467,\n",
      "        4.8467, 4.8467, 4.8467, 4.8467, 4.8467, 4.8466, 4.8467, 4.8466, 4.8467,\n",
      "        4.8468, 4.8466, 4.8467, 4.8468, 4.8467, 4.8468, 4.8469, 4.8468, 4.8471,\n",
      "        4.8468, 4.8468, 4.8469, 4.8467, 4.8467, 4.8467, 4.8467, 4.8467, 4.8466,\n",
      "        4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8467, 4.8466, 4.8466, 4.8467,\n",
      "        4.8467, 4.8470, 4.8468], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.253054  [4154124/5599865]\n",
      "average delta from current occupancy tensor([5.4032, 5.4032, 5.4033, 5.4033, 5.4032, 5.4032, 5.4032, 5.4033, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4033, 5.4033, 5.4032, 5.4033, 5.4032, 5.4032, 5.4032, 5.4033,\n",
      "        5.4033, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032, 5.4033, 5.4032, 5.4033,\n",
      "        5.4033, 5.4033, 5.4032, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4032, 5.4032, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4032, 5.4032, 5.4032, 5.4033, 5.4033, 5.4033, 5.4032,\n",
      "        5.4032, 5.4033, 5.4033, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4033, 5.4032, 5.4033, 5.4033, 5.4032, 5.4032, 5.4033, 5.4033,\n",
      "        5.4032, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032, 5.4033, 5.4032, 5.4032,\n",
      "        5.4033, 5.4032, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4032, 5.4033, 5.4033], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.449963  [4166524/5599865]\n",
      "average delta from current occupancy tensor([4.5318, 4.5318, 4.5319, 4.5319, 4.5319, 4.5318, 4.5318, 4.5319, 4.5318,\n",
      "        4.5318, 4.5318, 4.5317, 4.5318, 4.5318, 4.5318, 4.5318, 4.5319, 4.5318,\n",
      "        4.5320, 4.5319, 4.5319, 4.5320, 4.5319, 4.5317, 4.5317, 4.5318, 4.5317,\n",
      "        4.5317, 4.5320, 4.5320, 4.5319, 4.5319, 4.5318, 4.5318, 4.5318, 4.5317,\n",
      "        4.5318, 4.5318, 4.5318, 4.5318, 4.5317, 4.5317, 4.5317, 4.5317, 4.5318,\n",
      "        4.5317, 4.5317, 4.5318, 4.5318, 4.5318, 4.5317, 4.5317, 4.5318, 4.5317,\n",
      "        4.5318, 4.5317, 4.5317, 4.5317, 4.5317, 4.5317, 4.5318, 4.5317, 4.5317,\n",
      "        4.5317, 4.5317, 4.5317, 4.5318, 4.5317, 4.5317, 4.5318, 4.5318, 4.5318,\n",
      "        4.5318, 4.5318, 4.5318, 4.5317, 4.5317, 4.5317, 4.5317, 4.5317, 4.5317,\n",
      "        4.5317, 4.5317, 4.5317, 4.5317, 4.5317, 4.5316, 4.5316, 4.5316, 4.5316,\n",
      "        4.5316, 4.5316, 4.5317, 4.5316, 4.5317, 4.5315, 4.5316, 4.5316, 4.5315,\n",
      "        4.5315, 4.5315, 4.5315, 4.5316, 4.5316, 4.5316, 4.5316, 4.5316, 4.5316,\n",
      "        4.5316, 4.5316, 4.5316, 4.5316, 4.5316, 4.5316, 4.5316, 4.5316, 4.5316,\n",
      "        4.5315, 4.5316, 4.5315], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.306573  [4178924/5599865]\n",
      "average delta from current occupancy tensor([5.2413, 5.2414, 5.2413, 5.2413, 5.2412, 5.2412, 5.2412, 5.2412, 5.2412,\n",
      "        5.2412, 5.2413, 5.2411, 5.2412, 5.2412, 5.2411, 5.2411, 5.2413, 5.2413,\n",
      "        5.2414, 5.2414, 5.2414, 5.2414, 5.2414, 5.2412, 5.2411, 5.2412, 5.2412,\n",
      "        5.2413, 5.2415, 5.2414, 5.2414, 5.2415, 5.2413, 5.2413, 5.2413, 5.2412,\n",
      "        5.2412, 5.2413, 5.2412, 5.2413, 5.2413, 5.2413, 5.2413, 5.2412, 5.2413,\n",
      "        5.2413, 5.2412, 5.2412, 5.2413, 5.2413, 5.2411, 5.2411, 5.2412, 5.2411,\n",
      "        5.2412, 5.2410, 5.2410, 5.2410, 5.2410, 5.2411, 5.2411, 5.2410, 5.2411,\n",
      "        5.2411, 5.2411, 5.2411, 5.2412, 5.2410, 5.2413, 5.2413, 5.2414, 5.2412,\n",
      "        5.2413, 5.2413, 5.2413, 5.2412, 5.2412, 5.2412, 5.2413, 5.2412, 5.2411,\n",
      "        5.2411, 5.2411, 5.2412, 5.2412, 5.2412, 5.2412, 5.2411, 5.2411, 5.2410,\n",
      "        5.2411, 5.2411, 5.2411, 5.2410, 5.2410, 5.2409, 5.2409, 5.2410, 5.2410,\n",
      "        5.2410, 5.2409, 5.2410, 5.2410, 5.2410, 5.2410, 5.2409, 5.2408, 5.2409,\n",
      "        5.2409, 5.2407, 5.2408, 5.2408, 5.2408, 5.2407, 5.2408, 5.2408, 5.2409,\n",
      "        5.2409, 5.2410, 5.2409], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.002042  [4191324/5599865]\n",
      "average delta from current occupancy tensor([4.9041, 4.9042, 4.9041, 4.9041, 4.9040, 4.9041, 4.9040, 4.9040, 4.9040,\n",
      "        4.9040, 4.9041, 4.9040, 4.9042, 4.9041, 4.9040, 4.9041, 4.9041, 4.9039,\n",
      "        4.9039, 4.9042, 4.9041, 4.9040, 4.9040, 4.9040, 4.9038, 4.9036, 4.9040,\n",
      "        4.9037, 4.9038, 4.9038, 4.9039, 4.9039, 4.9039, 4.9038, 4.9036, 4.9036,\n",
      "        4.9039, 4.9037, 4.9036, 4.9037, 4.9036, 4.9036, 4.9036, 4.9037, 4.9038,\n",
      "        4.9038, 4.9035, 4.9036, 4.9037, 4.9037, 4.9035, 4.9036, 4.9038, 4.9035,\n",
      "        4.9038, 4.9037, 4.9038, 4.9038, 4.9036, 4.9034, 4.9035, 4.9034, 4.9034,\n",
      "        4.9034, 4.9035, 4.9035, 4.9034, 4.9036, 4.9035, 4.9034, 4.9033, 4.9035,\n",
      "        4.9034, 4.9034, 4.9033, 4.9032, 4.9032, 4.9032, 4.9032, 4.9033, 4.9034,\n",
      "        4.9033, 4.9033, 4.9034, 4.9034, 4.9036, 4.9035, 4.9033, 4.9033, 4.9034,\n",
      "        4.9033, 4.9034, 4.9033, 4.9034, 4.9035, 4.9038, 4.9035, 4.9036, 4.9036,\n",
      "        4.9036, 4.9035, 4.9037, 4.9038, 4.9037, 4.9037, 4.9038, 4.9038, 4.9034,\n",
      "        4.9034, 4.9034, 4.9034, 4.9033, 4.9034, 4.9035, 4.9035, 4.9037, 4.9034,\n",
      "        4.9037, 4.9038, 4.9038], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.072523  [4203724/5599865]\n",
      "average delta from current occupancy tensor([4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9842, 4.9842,\n",
      "        4.9841, 4.9841, 4.9841, 4.9842, 4.9843, 4.9843, 4.9843, 4.9842, 4.9841,\n",
      "        4.9840, 4.9841, 4.9841, 4.9842, 4.9842, 4.9843, 4.9841, 4.9840, 4.9842,\n",
      "        4.9839, 4.9840, 4.9841, 4.9840, 4.9839, 4.9839, 4.9842, 4.9839, 4.9839,\n",
      "        4.9840, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9840, 4.9840, 4.9840,\n",
      "        4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839,\n",
      "        4.9839, 4.9839, 4.9839, 4.9840, 4.9839, 4.9839, 4.9839, 4.9839, 4.9841,\n",
      "        4.9840, 4.9840, 4.9839, 4.9839, 4.9840, 4.9840, 4.9840, 4.9839, 4.9839,\n",
      "        4.9839, 4.9839, 4.9839, 4.9840, 4.9839, 4.9839, 4.9840, 4.9839, 4.9840,\n",
      "        4.9839, 4.9839, 4.9839, 4.9840, 4.9839, 4.9839, 4.9840, 4.9840, 4.9840,\n",
      "        4.9840, 4.9841, 4.9840, 4.9839, 4.9839, 4.9840, 4.9839, 4.9839, 4.9839,\n",
      "        4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9840, 4.9840, 4.9840,\n",
      "        4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839, 4.9839,\n",
      "        4.9839, 4.9839, 4.9839], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.004222  [4216124/5599865]\n",
      "average delta from current occupancy tensor([4.8066, 4.8065, 4.8065, 4.8065, 4.8065, 4.8066, 4.8065, 4.8066, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8066, 4.8065, 4.8065, 4.8065, 4.8067, 4.8066, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8066, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8067, 4.8066, 4.8067, 4.8065, 4.8067,\n",
      "        4.8068, 4.8066, 4.8068, 4.8068, 4.8069, 4.8070, 4.8066, 4.8069, 4.8068,\n",
      "        4.8067, 4.8067, 4.8066, 4.8067, 4.8065, 4.8066, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065, 4.8065,\n",
      "        4.8066, 4.8065, 4.8066], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.897674  [4228524/5599865]\n",
      "average delta from current occupancy tensor([5.1056, 5.1055, 5.1056, 5.1055, 5.1056, 5.1056, 5.1056, 5.1055, 5.1056,\n",
      "        5.1057, 5.1055, 5.1055, 5.1055, 5.1055, 5.1055, 5.1056, 5.1056, 5.1055,\n",
      "        5.1055, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1055, 5.1055,\n",
      "        5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1055, 5.1055, 5.1056,\n",
      "        5.1055, 5.1055, 5.1056, 5.1055, 5.1055, 5.1054, 5.1053, 5.1053, 5.1053,\n",
      "        5.1053, 5.1053, 5.1054, 5.1054, 5.1054, 5.1054, 5.1053, 5.1053, 5.1054,\n",
      "        5.1054, 5.1054, 5.1054, 5.1054, 5.1053, 5.1053, 5.1053, 5.1053, 5.1052,\n",
      "        5.1053, 5.1053, 5.1054, 5.1054, 5.1054, 5.1053, 5.1053, 5.1053, 5.1053,\n",
      "        5.1054, 5.1054, 5.1054, 5.1053, 5.1053, 5.1054, 5.1053, 5.1054, 5.1054,\n",
      "        5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1054, 5.1053, 5.1053, 5.1054,\n",
      "        5.1053, 5.1053, 5.1053, 5.1053, 5.1054, 5.1053, 5.1054, 5.1054, 5.1053,\n",
      "        5.1054, 5.1053, 5.1054, 5.1053, 5.1053, 5.1052, 5.1053, 5.1054, 5.1054,\n",
      "        5.1053, 5.1053, 5.1054, 5.1054, 5.1054, 5.1053, 5.1053, 5.1053, 5.1053,\n",
      "        5.1053, 5.1054, 5.1055], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.378885  [4240924/5599865]\n",
      "average delta from current occupancy tensor([5.3314, 5.3312, 5.3316, 5.3313, 5.3315, 5.3313, 5.3315, 5.3314, 5.3317,\n",
      "        5.3318, 5.3316, 5.3317, 5.3317, 5.3317, 5.3317, 5.3319, 5.3320, 5.3317,\n",
      "        5.3315, 5.3315, 5.3317, 5.3317, 5.3315, 5.3314, 5.3313, 5.3312, 5.3311,\n",
      "        5.3307, 5.3310, 5.3309, 5.3310, 5.3310, 5.3309, 5.3309, 5.3309, 5.3312,\n",
      "        5.3311, 5.3310, 5.3311, 5.3309, 5.3309, 5.3309, 5.3307, 5.3308, 5.3310,\n",
      "        5.3309, 5.3307, 5.3310, 5.3310, 5.3309, 5.3307, 5.3307, 5.3309, 5.3307,\n",
      "        5.3307, 5.3309, 5.3308, 5.3309, 5.3307, 5.3307, 5.3306, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3306,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3309, 5.3310, 5.3311, 5.3312,\n",
      "        5.3312, 5.3311, 5.3310, 5.3309, 5.3311, 5.3312, 5.3311, 5.3310, 5.3309,\n",
      "        5.3308, 5.3307, 5.3306, 5.3306, 5.3307, 5.3307, 5.3306, 5.3307, 5.3308,\n",
      "        5.3307, 5.3306, 5.3307, 5.3307, 5.3310, 5.3311, 5.3306, 5.3306, 5.3307,\n",
      "        5.3309, 5.3311, 5.3307, 5.3306, 5.3310, 5.3308, 5.3310, 5.3308, 5.3311,\n",
      "        5.3310, 5.3306, 5.3306], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.853556  [4253324/5599865]\n",
      "average delta from current occupancy tensor([4.7658, 4.7658, 4.7659, 4.7659, 4.7659, 4.7659, 4.7658, 4.7658, 4.7659,\n",
      "        4.7659, 4.7658, 4.7659, 4.7660, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7660, 4.7660, 4.7659, 4.7659, 4.7659, 4.7660, 4.7660,\n",
      "        4.7659, 4.7659, 4.7659, 4.7660, 4.7659, 4.7659, 4.7659, 4.7660, 4.7659,\n",
      "        4.7659, 4.7659, 4.7658, 4.7660, 4.7659, 4.7658, 4.7660, 4.7659, 4.7658,\n",
      "        4.7659, 4.7658, 4.7659, 4.7659, 4.7659, 4.7659, 4.7660, 4.7659, 4.7659,\n",
      "        4.7660, 4.7660, 4.7660, 4.7659, 4.7659, 4.7658, 4.7659, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7660, 4.7660, 4.7660, 4.7660, 4.7660, 4.7660, 4.7660,\n",
      "        4.7660, 4.7660, 4.7660, 4.7660, 4.7659, 4.7660, 4.7659, 4.7659, 4.7659,\n",
      "        4.7660, 4.7659, 4.7660, 4.7659, 4.7659, 4.7659, 4.7660, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7660, 4.7658, 4.7658, 4.7659, 4.7658, 4.7659, 4.7660,\n",
      "        4.7659, 4.7659, 4.7658, 4.7660, 4.7659, 4.7659, 4.7659, 4.7658, 4.7659,\n",
      "        4.7660, 4.7659, 4.7659, 4.7660, 4.7660, 4.7661, 4.7660, 4.7660, 4.7661,\n",
      "        4.7661, 4.7660, 4.7661], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.009898  [4265724/5599865]\n",
      "average delta from current occupancy tensor([4.9552, 4.9550, 4.9550, 4.9553, 4.9551, 4.9551, 4.9551, 4.9553, 4.9556,\n",
      "        4.9557, 4.9552, 4.9555, 4.9556, 4.9557, 4.9559, 4.9558, 4.9560, 4.9563,\n",
      "        4.9561, 4.9561, 4.9561, 4.9558, 4.9559, 4.9560, 4.9560, 4.9561, 4.9558,\n",
      "        4.9560, 4.9561, 4.9561, 4.9553, 4.9559, 4.9563, 4.9561, 4.9554, 4.9561,\n",
      "        4.9559, 4.9557, 4.9552, 4.9557, 4.9556, 4.9559, 4.9558, 4.9561, 4.9555,\n",
      "        4.9560, 4.9559, 4.9561, 4.9560, 4.9559, 4.9561, 4.9560, 4.9561, 4.9560,\n",
      "        4.9562, 4.9552, 4.9554, 4.9558, 4.9561, 4.9561, 4.9561, 4.9565, 4.9562,\n",
      "        4.9562, 4.9561, 4.9564, 4.9557, 4.9562, 4.9566, 4.9558, 4.9559, 4.9566,\n",
      "        4.9566, 4.9565, 4.9565, 4.9562, 4.9565, 4.9568, 4.9566, 4.9567, 4.9569,\n",
      "        4.9566, 4.9569, 4.9565, 4.9566, 4.9564, 4.9566, 4.9563, 4.9565, 4.9568,\n",
      "        4.9566, 4.9568, 4.9565, 4.9568, 4.9567, 4.9568, 4.9569, 4.9570, 4.9569,\n",
      "        4.9571, 4.9568, 4.9568, 4.9569, 4.9572, 4.9574, 4.9569, 4.9573, 4.9574,\n",
      "        4.9573, 4.9571, 4.9570, 4.9568, 4.9569, 4.9561, 4.9568, 4.9568, 4.9564,\n",
      "        4.9566, 4.9566, 4.9561], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.330426  [4278124/5599865]\n",
      "average delta from current occupancy tensor([5.4356, 5.4356, 5.4355, 5.4355, 5.4355, 5.4356, 5.4356, 5.4356, 5.4358,\n",
      "        5.4358, 5.4357, 5.4357, 5.4356, 5.4356, 5.4357, 5.4358, 5.4357, 5.4357,\n",
      "        5.4356, 5.4356, 5.4356, 5.4357, 5.4356, 5.4355, 5.4356, 5.4357, 5.4357,\n",
      "        5.4357, 5.4357, 5.4357, 5.4355, 5.4356, 5.4358, 5.4357, 5.4355, 5.4357,\n",
      "        5.4357, 5.4356, 5.4356, 5.4355, 5.4356, 5.4356, 5.4356, 5.4357, 5.4356,\n",
      "        5.4356, 5.4357, 5.4357, 5.4356, 5.4357, 5.4357, 5.4358, 5.4357, 5.4358,\n",
      "        5.4357, 5.4356, 5.4356, 5.4357, 5.4358, 5.4358, 5.4357, 5.4356, 5.4357,\n",
      "        5.4357, 5.4358, 5.4357, 5.4358, 5.4357, 5.4355, 5.4358, 5.4358, 5.4355,\n",
      "        5.4356, 5.4357, 5.4356, 5.4358, 5.4358, 5.4356, 5.4356, 5.4356, 5.4355,\n",
      "        5.4355, 5.4354, 5.4355, 5.4354, 5.4355, 5.4353, 5.4354, 5.4354, 5.4353,\n",
      "        5.4354, 5.4353, 5.4355, 5.4354, 5.4355, 5.4354, 5.4354, 5.4354, 5.4354,\n",
      "        5.4354, 5.4355, 5.4355, 5.4354, 5.4353, 5.4352, 5.4354, 5.4352, 5.4352,\n",
      "        5.4353, 5.4353, 5.4352, 5.4353, 5.4353, 5.4356, 5.4353, 5.4354, 5.4355,\n",
      "        5.4354, 5.4355, 5.4357], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.887052  [4290524/5599865]\n",
      "average delta from current occupancy tensor([5.8634, 5.8633, 5.8632, 5.8632, 5.8632, 5.8633, 5.8633, 5.8632, 5.8632,\n",
      "        5.8631, 5.8630, 5.8631, 5.8631, 5.8632, 5.8632, 5.8632, 5.8633, 5.8635,\n",
      "        5.8633, 5.8633, 5.8633, 5.8633, 5.8632, 5.8632, 5.8632, 5.8633, 5.8633,\n",
      "        5.8633, 5.8632, 5.8633, 5.8633, 5.8633, 5.8634, 5.8634, 5.8632, 5.8632,\n",
      "        5.8632, 5.8631, 5.8631, 5.8633, 5.8632, 5.8632, 5.8633, 5.8634, 5.8633,\n",
      "        5.8632, 5.8634, 5.8633, 5.8632, 5.8633, 5.8633, 5.8634, 5.8634, 5.8633,\n",
      "        5.8634, 5.8633, 5.8634, 5.8637, 5.8635, 5.8635, 5.8634, 5.8635, 5.8634,\n",
      "        5.8634, 5.8634, 5.8633, 5.8633, 5.8632, 5.8632, 5.8633, 5.8632, 5.8632,\n",
      "        5.8632, 5.8633, 5.8633, 5.8633, 5.8632, 5.8632, 5.8631, 5.8632, 5.8631,\n",
      "        5.8633, 5.8632, 5.8633, 5.8632, 5.8633, 5.8633, 5.8632, 5.8632, 5.8632,\n",
      "        5.8633, 5.8631, 5.8633, 5.8634, 5.8633, 5.8630, 5.8631, 5.8631, 5.8631,\n",
      "        5.8631, 5.8631, 5.8630, 5.8631, 5.8632, 5.8631, 5.8633, 5.8631, 5.8633,\n",
      "        5.8631, 5.8631, 5.8631, 5.8631, 5.8631, 5.8631, 5.8630, 5.8633, 5.8631,\n",
      "        5.8633, 5.8632, 5.8631], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.003196  [4302924/5599865]\n",
      "average delta from current occupancy tensor([5.0742, 5.0744, 5.0744, 5.0743, 5.0743, 5.0743, 5.0743, 5.0743, 5.0742,\n",
      "        5.0742, 5.0743, 5.0742, 5.0743, 5.0743, 5.0743, 5.0742, 5.0742, 5.0745,\n",
      "        5.0744, 5.0744, 5.0744, 5.0744, 5.0744, 5.0743, 5.0743, 5.0743, 5.0743,\n",
      "        5.0743, 5.0743, 5.0742, 5.0742, 5.0742, 5.0742, 5.0742, 5.0742, 5.0741,\n",
      "        5.0742, 5.0741, 5.0743, 5.0743, 5.0741, 5.0744, 5.0743, 5.0745, 5.0743,\n",
      "        5.0742, 5.0745, 5.0744, 5.0744, 5.0745, 5.0744, 5.0745, 5.0746, 5.0745,\n",
      "        5.0744, 5.0744, 5.0744, 5.0743, 5.0747, 5.0745, 5.0743, 5.0742, 5.0744,\n",
      "        5.0744, 5.0743, 5.0742, 5.0742, 5.0742, 5.0744, 5.0744, 5.0743, 5.0743,\n",
      "        5.0743, 5.0742, 5.0743, 5.0743, 5.0742, 5.0745, 5.0745, 5.0746, 5.0744,\n",
      "        5.0744, 5.0743, 5.0743, 5.0744, 5.0745, 5.0744, 5.0744, 5.0745, 5.0745,\n",
      "        5.0744, 5.0746, 5.0744, 5.0745, 5.0744, 5.0745, 5.0744, 5.0743, 5.0742,\n",
      "        5.0743, 5.0745, 5.0744, 5.0744, 5.0743, 5.0745, 5.0744, 5.0743, 5.0745,\n",
      "        5.0746, 5.0746, 5.0746, 5.0746, 5.0746, 5.0746, 5.0745, 5.0746, 5.0744,\n",
      "        5.0745, 5.0746, 5.0746], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.168454  [4315324/5599865]\n",
      "average delta from current occupancy tensor([5.0732, 5.0733, 5.0734, 5.0735, 5.0735, 5.0734, 5.0737, 5.0736, 5.0735,\n",
      "        5.0734, 5.0735, 5.0734, 5.0734, 5.0734, 5.0733, 5.0733, 5.0734, 5.0732,\n",
      "        5.0733, 5.0732, 5.0731, 5.0732, 5.0732, 5.0732, 5.0732, 5.0731, 5.0730,\n",
      "        5.0730, 5.0732, 5.0733, 5.0733, 5.0733, 5.0733, 5.0732, 5.0731, 5.0731,\n",
      "        5.0731, 5.0733, 5.0730, 5.0731, 5.0730, 5.0729, 5.0728, 5.0727, 5.0731,\n",
      "        5.0729, 5.0730, 5.0728, 5.0730, 5.0728, 5.0728, 5.0728, 5.0726, 5.0727,\n",
      "        5.0730, 5.0728, 5.0729, 5.0729, 5.0729, 5.0727, 5.0731, 5.0733, 5.0728,\n",
      "        5.0727, 5.0729, 5.0732, 5.0732, 5.0734, 5.0732, 5.0732, 5.0734, 5.0734,\n",
      "        5.0735, 5.0733, 5.0732, 5.0732, 5.0732, 5.0729, 5.0728, 5.0728, 5.0732,\n",
      "        5.0732, 5.0732, 5.0732, 5.0733, 5.0727, 5.0731, 5.0731, 5.0730, 5.0732,\n",
      "        5.0732, 5.0735, 5.0732, 5.0733, 5.0729, 5.0731, 5.0732, 5.0734, 5.0734,\n",
      "        5.0735, 5.0728, 5.0729, 5.0733, 5.0733, 5.0727, 5.0733, 5.0733, 5.0727,\n",
      "        5.0730, 5.0728, 5.0727, 5.0730, 5.0733, 5.0729, 5.0731, 5.0733, 5.0734,\n",
      "        5.0735, 5.0729, 5.0729], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.834967  [4327724/5599865]\n",
      "average delta from current occupancy tensor([4.7098, 4.7098, 4.7097, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098,\n",
      "        4.7099, 4.7099, 4.7098, 4.7099, 4.7099, 4.7099, 4.7098, 4.7099, 4.7098,\n",
      "        4.7099, 4.7098, 4.7098, 4.7098, 4.7099, 4.7098, 4.7098, 4.7098, 4.7097,\n",
      "        4.7098, 4.7098, 4.7099, 4.7098, 4.7098, 4.7098, 4.7098, 4.7097, 4.7098,\n",
      "        4.7098, 4.7098, 4.7097, 4.7098, 4.7097, 4.7097, 4.7098, 4.7098, 4.7098,\n",
      "        4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7097, 4.7097, 4.7098,\n",
      "        4.7098, 4.7097, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098,\n",
      "        4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098,\n",
      "        4.7097, 4.7098, 4.7098, 4.7099, 4.7097, 4.7098, 4.7098, 4.7098, 4.7099,\n",
      "        4.7099, 4.7097, 4.7098, 4.7098, 4.7100, 4.7100, 4.7100, 4.7099, 4.7098,\n",
      "        4.7098, 4.7098, 4.7098, 4.7099, 4.7097, 4.7098, 4.7098, 4.7099, 4.7098,\n",
      "        4.7098, 4.7101, 4.7100, 4.7099, 4.7099, 4.7099, 4.7099, 4.7098, 4.7099,\n",
      "        4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7098, 4.7099,\n",
      "        4.7099, 4.7100, 4.7099], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.251080  [4340124/5599865]\n",
      "average delta from current occupancy tensor([5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2984, 5.2985, 5.2984,\n",
      "        5.2984, 5.2984, 5.2984], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.657616  [4352524/5599865]\n",
      "average delta from current occupancy tensor([4.5636, 4.5637, 4.5637, 4.5636, 4.5637, 4.5636, 4.5635, 4.5637, 4.5637,\n",
      "        4.5636, 4.5636, 4.5637, 4.5637, 4.5636, 4.5637, 4.5637, 4.5636, 4.5637,\n",
      "        4.5636, 4.5636, 4.5637, 4.5637, 4.5637, 4.5637, 4.5637, 4.5636, 4.5637,\n",
      "        4.5637, 4.5636, 4.5637, 4.5636, 4.5636, 4.5636, 4.5635, 4.5636, 4.5635,\n",
      "        4.5635, 4.5636, 4.5637, 4.5636, 4.5636, 4.5636, 4.5636, 4.5636, 4.5636,\n",
      "        4.5636, 4.5636, 4.5636, 4.5636, 4.5636, 4.5636, 4.5636, 4.5636, 4.5635,\n",
      "        4.5635, 4.5635, 4.5636, 4.5636, 4.5635, 4.5635, 4.5635, 4.5635, 4.5635,\n",
      "        4.5636, 4.5636, 4.5635, 4.5636, 4.5636, 4.5636, 4.5637, 4.5637, 4.5637,\n",
      "        4.5636, 4.5636, 4.5637, 4.5636, 4.5636, 4.5637, 4.5638, 4.5638, 4.5637,\n",
      "        4.5637, 4.5637, 4.5638, 4.5636, 4.5635, 4.5636, 4.5635, 4.5637, 4.5637,\n",
      "        4.5636, 4.5636, 4.5634, 4.5636, 4.5635, 4.5637, 4.5638, 4.5638, 4.5639,\n",
      "        4.5639, 4.5636, 4.5636, 4.5636, 4.5637, 4.5636, 4.5636, 4.5638, 4.5635,\n",
      "        4.5636, 4.5636, 4.5639, 4.5636, 4.5638, 4.5638, 4.5639, 4.5636, 4.5636,\n",
      "        4.5637, 4.5637, 4.5636], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.410258  [4364924/5599865]\n",
      "average delta from current occupancy tensor([4.7426, 4.7424, 4.7425, 4.7427, 4.7424, 4.7424, 4.7424, 4.7425, 4.7424,\n",
      "        4.7424, 4.7424, 4.7424, 4.7426, 4.7424, 4.7424, 4.7425, 4.7425, 4.7426,\n",
      "        4.7426, 4.7426, 4.7426, 4.7426, 4.7426, 4.7424, 4.7426, 4.7426, 4.7427,\n",
      "        4.7426, 4.7428, 4.7427, 4.7426, 4.7425, 4.7426, 4.7428, 4.7428, 4.7428,\n",
      "        4.7431, 4.7430, 4.7430, 4.7429, 4.7429, 4.7431, 4.7429, 4.7431, 4.7430,\n",
      "        4.7428, 4.7428, 4.7428, 4.7427, 4.7429, 4.7429, 4.7427, 4.7427, 4.7426,\n",
      "        4.7429, 4.7429, 4.7431, 4.7429, 4.7427, 4.7427, 4.7426, 4.7426, 4.7425,\n",
      "        4.7427, 4.7426, 4.7427, 4.7426, 4.7428, 4.7427, 4.7429, 4.7429, 4.7426,\n",
      "        4.7430, 4.7432, 4.7430, 4.7429, 4.7431, 4.7429, 4.7429, 4.7428, 4.7429,\n",
      "        4.7428, 4.7428, 4.7429, 4.7428, 4.7429, 4.7427, 4.7427, 4.7426, 4.7426,\n",
      "        4.7427, 4.7428, 4.7427, 4.7425, 4.7426, 4.7426, 4.7426, 4.7428, 4.7425,\n",
      "        4.7426, 4.7428, 4.7428, 4.7429, 4.7429, 4.7428, 4.7429, 4.7429, 4.7432,\n",
      "        4.7430, 4.7435, 4.7432, 4.7434, 4.7433, 4.7433, 4.7432, 4.7432, 4.7433,\n",
      "        4.7434, 4.7434, 4.7434], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.409072  [4377324/5599865]\n",
      "average delta from current occupancy tensor([5.3873, 5.3874, 5.3874, 5.3873, 5.3873, 5.3876, 5.3875, 5.3874, 5.3874,\n",
      "        5.3874, 5.3873, 5.3873, 5.3873, 5.3873, 5.3874, 5.3873, 5.3873, 5.3873,\n",
      "        5.3873, 5.3873, 5.3874, 5.3875, 5.3874, 5.3874, 5.3874, 5.3874, 5.3875,\n",
      "        5.3875, 5.3876, 5.3874, 5.3874, 5.3875, 5.3874, 5.3875, 5.3875, 5.3874,\n",
      "        5.3874, 5.3874, 5.3874, 5.3874, 5.3875, 5.3875, 5.3874, 5.3873, 5.3874,\n",
      "        5.3874, 5.3874, 5.3875, 5.3875, 5.3875, 5.3874, 5.3875, 5.3874, 5.3875,\n",
      "        5.3875, 5.3875, 5.3876, 5.3876, 5.3877, 5.3876, 5.3875, 5.3875, 5.3875,\n",
      "        5.3876, 5.3874, 5.3875, 5.3873, 5.3873, 5.3874, 5.3873, 5.3874, 5.3874,\n",
      "        5.3874, 5.3873, 5.3874, 5.3873, 5.3874, 5.3874, 5.3874, 5.3874, 5.3875,\n",
      "        5.3875, 5.3875, 5.3876, 5.3877, 5.3877, 5.3876, 5.3876, 5.3875, 5.3875,\n",
      "        5.3874, 5.3875, 5.3874, 5.3872, 5.3873, 5.3873, 5.3873, 5.3873, 5.3872,\n",
      "        5.3874, 5.3873, 5.3874, 5.3875, 5.3873, 5.3875, 5.3873, 5.3875, 5.3875,\n",
      "        5.3875, 5.3876, 5.3876, 5.3873, 5.3873, 5.3875, 5.3875, 5.3875, 5.3875,\n",
      "        5.3875, 5.3876, 5.3876], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.398946  [4389724/5599865]\n",
      "average delta from current occupancy tensor([4.3861, 4.3861, 4.3860, 4.3861, 4.3860, 4.3860, 4.3861, 4.3861, 4.3861,\n",
      "        4.3860, 4.3861, 4.3861, 4.3859, 4.3859, 4.3860, 4.3860, 4.3860, 4.3861,\n",
      "        4.3863, 4.3863, 4.3861, 4.3860, 4.3859, 4.3859, 4.3860, 4.3860, 4.3858,\n",
      "        4.3859, 4.3859, 4.3861, 4.3863, 4.3861, 4.3862, 4.3862, 4.3861, 4.3863,\n",
      "        4.3862, 4.3861, 4.3862, 4.3862, 4.3859, 4.3862, 4.3862, 4.3865, 4.3863,\n",
      "        4.3862, 4.3867, 4.3861, 4.3861, 4.3862, 4.3862, 4.3862, 4.3861, 4.3862,\n",
      "        4.3862, 4.3861, 4.3862, 4.3863, 4.3861, 4.3863, 4.3864, 4.3863, 4.3866,\n",
      "        4.3863, 4.3864, 4.3861, 4.3863, 4.3863, 4.3865, 4.3866, 4.3862, 4.3864,\n",
      "        4.3862, 4.3865, 4.3865, 4.3864, 4.3865, 4.3862, 4.3866, 4.3864, 4.3861,\n",
      "        4.3862, 4.3862, 4.3865, 4.3865, 4.3865, 4.3865, 4.3864, 4.3868, 4.3866,\n",
      "        4.3866, 4.3866, 4.3866, 4.3860, 4.3864, 4.3864, 4.3866, 4.3865, 4.3864,\n",
      "        4.3863, 4.3867, 4.3862, 4.3862, 4.3867, 4.3863, 4.3865, 4.3861, 4.3863,\n",
      "        4.3864, 4.3867, 4.3864, 4.3863, 4.3865, 4.3862, 4.3864, 4.3860, 4.3861,\n",
      "        4.3862, 4.3864, 4.3863], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.077428  [4402124/5599865]\n",
      "average delta from current occupancy tensor([5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4116, 5.4116, 5.4116, 5.4116, 5.4116,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115, 5.4115,\n",
      "        5.4115, 5.4115, 5.4115], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.284722  [4414524/5599865]\n",
      "average delta from current occupancy tensor([4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1049, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1049, 4.1048, 4.1049, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1050, 4.1048, 4.1049, 4.1050, 4.1049, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1051, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048, 4.1048,\n",
      "        4.1048, 4.1048, 4.1048], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.162260  [4426924/5599865]\n",
      "average delta from current occupancy tensor([5.1708, 5.1712, 5.1712, 5.1712, 5.1711, 5.1710, 5.1709, 5.1709, 5.1708,\n",
      "        5.1709, 5.1709, 5.1710, 5.1710, 5.1710, 5.1711, 5.1711, 5.1711, 5.1711,\n",
      "        5.1711, 5.1710, 5.1710, 5.1710, 5.1709, 5.1710, 5.1710, 5.1711, 5.1710,\n",
      "        5.1711, 5.1712, 5.1710, 5.1710, 5.1710, 5.1710, 5.1709, 5.1709, 5.1710,\n",
      "        5.1709, 5.1711, 5.1711, 5.1713, 5.1713, 5.1714, 5.1712, 5.1713, 5.1713,\n",
      "        5.1712, 5.1714, 5.1714, 5.1714, 5.1714, 5.1715, 5.1714, 5.1713, 5.1712,\n",
      "        5.1713, 5.1714, 5.1713, 5.1713, 5.1713, 5.1714, 5.1713, 5.1715, 5.1713,\n",
      "        5.1715, 5.1714, 5.1714, 5.1714, 5.1715, 5.1712, 5.1713, 5.1714, 5.1713,\n",
      "        5.1713, 5.1715, 5.1714, 5.1715, 5.1716, 5.1716, 5.1714, 5.1715, 5.1715,\n",
      "        5.1715, 5.1714, 5.1716, 5.1714, 5.1715, 5.1715, 5.1714, 5.1713, 5.1716,\n",
      "        5.1716, 5.1715, 5.1715, 5.1713, 5.1713, 5.1713, 5.1714, 5.1717, 5.1717,\n",
      "        5.1717, 5.1716, 5.1716, 5.1717, 5.1715, 5.1715, 5.1716, 5.1716, 5.1717,\n",
      "        5.1717, 5.1716, 5.1717, 5.1717, 5.1717, 5.1717, 5.1717, 5.1717, 5.1715,\n",
      "        5.1717, 5.1714, 5.1715], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.648486  [4439324/5599865]\n",
      "average delta from current occupancy tensor([4.5162, 4.5161, 4.5161, 4.5162, 4.5162, 4.5162, 4.5162, 4.5162, 4.5162,\n",
      "        4.5161, 4.5161, 4.5161, 4.5161, 4.5161, 4.5162, 4.5161, 4.5161, 4.5162,\n",
      "        4.5162, 4.5162, 4.5162, 4.5161, 4.5162, 4.5162, 4.5162, 4.5162, 4.5162,\n",
      "        4.5161, 4.5162, 4.5162, 4.5162, 4.5161, 4.5161, 4.5162, 4.5161, 4.5161,\n",
      "        4.5161, 4.5161, 4.5161, 4.5161, 4.5163, 4.5163, 4.5162, 4.5162, 4.5161,\n",
      "        4.5161, 4.5161, 4.5161, 4.5161, 4.5161, 4.5162, 4.5162, 4.5162, 4.5162,\n",
      "        4.5161, 4.5163, 4.5163, 4.5162, 4.5163, 4.5164, 4.5163, 4.5164, 4.5162,\n",
      "        4.5164, 4.5164, 4.5165, 4.5165, 4.5165, 4.5161, 4.5162, 4.5162, 4.5162,\n",
      "        4.5162, 4.5164, 4.5164, 4.5166, 4.5165, 4.5165, 4.5165, 4.5166, 4.5167,\n",
      "        4.5167, 4.5167, 4.5168, 4.5166, 4.5169, 4.5170, 4.5168, 4.5168, 4.5169,\n",
      "        4.5168, 4.5167, 4.5167, 4.5165, 4.5165, 4.5165, 4.5166, 4.5169, 4.5168,\n",
      "        4.5168, 4.5167, 4.5167, 4.5169, 4.5168, 4.5168, 4.5168, 4.5166, 4.5168,\n",
      "        4.5168, 4.5166, 4.5168, 4.5168, 4.5169, 4.5170, 4.5170, 4.5168, 4.5166,\n",
      "        4.5169, 4.5166, 4.5168], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.551222  [4451724/5599865]\n",
      "average delta from current occupancy tensor([5.4758, 5.4757, 5.4757, 5.4757, 5.4757, 5.4757, 5.4758, 5.4757, 5.4757,\n",
      "        5.4757, 5.4757, 5.4757, 5.4758, 5.4758, 5.4758, 5.4757, 5.4757, 5.4758,\n",
      "        5.4757, 5.4757, 5.4758, 5.4760, 5.4758, 5.4763, 5.4760, 5.4762, 5.4761,\n",
      "        5.4761, 5.4761, 5.4759, 5.4758, 5.4758, 5.4760, 5.4758, 5.4758, 5.4758,\n",
      "        5.4757, 5.4757, 5.4757, 5.4756, 5.4756, 5.4756, 5.4756, 5.4756, 5.4756,\n",
      "        5.4757, 5.4756, 5.4758, 5.4756, 5.4757, 5.4756, 5.4757, 5.4756, 5.4756,\n",
      "        5.4757, 5.4756, 5.4756, 5.4757, 5.4757, 5.4757, 5.4757, 5.4757, 5.4757,\n",
      "        5.4757, 5.4757, 5.4757, 5.4757, 5.4758, 5.4757, 5.4757, 5.4757, 5.4757,\n",
      "        5.4757, 5.4757, 5.4757, 5.4757, 5.4756, 5.4757, 5.4757, 5.4757, 5.4757,\n",
      "        5.4758, 5.4757, 5.4760, 5.4758, 5.4757, 5.4759, 5.4758, 5.4758, 5.4759,\n",
      "        5.4759, 5.4757, 5.4759, 5.4757, 5.4757, 5.4758, 5.4758, 5.4759, 5.4760,\n",
      "        5.4758, 5.4761, 5.4760, 5.4759, 5.4760, 5.4760, 5.4758, 5.4757, 5.4757,\n",
      "        5.4758, 5.4758, 5.4760, 5.4759, 5.4759, 5.4759, 5.4760, 5.4759, 5.4757,\n",
      "        5.4757, 5.4757, 5.4757], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.809892  [4464124/5599865]\n",
      "average delta from current occupancy tensor([4.6288, 4.6287, 4.6289, 4.6287, 4.6288, 4.6286, 4.6288, 4.6289, 4.6289,\n",
      "        4.6287, 4.6288, 4.6288, 4.6288, 4.6288, 4.6289, 4.6288, 4.6288, 4.6287,\n",
      "        4.6287, 4.6287, 4.6286, 4.6287, 4.6288, 4.6287, 4.6287, 4.6288, 4.6288,\n",
      "        4.6289, 4.6288, 4.6288, 4.6288, 4.6285, 4.6286, 4.6288, 4.6289, 4.6289,\n",
      "        4.6288, 4.6290, 4.6289, 4.6289, 4.6288, 4.6289, 4.6286, 4.6288, 4.6287,\n",
      "        4.6288, 4.6286, 4.6285, 4.6286, 4.6288, 4.6287, 4.6288, 4.6287, 4.6287,\n",
      "        4.6289, 4.6288, 4.6289, 4.6288, 4.6288, 4.6287, 4.6288, 4.6289, 4.6288,\n",
      "        4.6289, 4.6289, 4.6289, 4.6289, 4.6291, 4.6291, 4.6288, 4.6290, 4.6290,\n",
      "        4.6289, 4.6290, 4.6291, 4.6289, 4.6290, 4.6291, 4.6287, 4.6289, 4.6291,\n",
      "        4.6290, 4.6290, 4.6289, 4.6289, 4.6291, 4.6289, 4.6292, 4.6291, 4.6288,\n",
      "        4.6289, 4.6288, 4.6290, 4.6290, 4.6289, 4.6289, 4.6288, 4.6288, 4.6288,\n",
      "        4.6288, 4.6289, 4.6289, 4.6289, 4.6290, 4.6288, 4.6288, 4.6288, 4.6289,\n",
      "        4.6289, 4.6290, 4.6289, 4.6290, 4.6292, 4.6288, 4.6288, 4.6288, 4.6289,\n",
      "        4.6289, 4.6287, 4.6287], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.523359  [4476524/5599865]\n",
      "average delta from current occupancy tensor([5.5148, 5.5149, 5.5147, 5.5149, 5.5150, 5.5150, 5.5148, 5.5149, 5.5149,\n",
      "        5.5147, 5.5147, 5.5147, 5.5150, 5.5149, 5.5146, 5.5146, 5.5148, 5.5146,\n",
      "        5.5147, 5.5146, 5.5146, 5.5146, 5.5145, 5.5146, 5.5146, 5.5147, 5.5143,\n",
      "        5.5143, 5.5147, 5.5147, 5.5143, 5.5145, 5.5144, 5.5147, 5.5145, 5.5143,\n",
      "        5.5143, 5.5146, 5.5146, 5.5145, 5.5140, 5.5143, 5.5142, 5.5141, 5.5146,\n",
      "        5.5142, 5.5140, 5.5143, 5.5142, 5.5141, 5.5143, 5.5140, 5.5146, 5.5142,\n",
      "        5.5142, 5.5140, 5.5139, 5.5141, 5.5138, 5.5142, 5.5142, 5.5140, 5.5139,\n",
      "        5.5141, 5.5142, 5.5143, 5.5139, 5.5144, 5.5142, 5.5143, 5.5142, 5.5141,\n",
      "        5.5141, 5.5142, 5.5145, 5.5142, 5.5142, 5.5146, 5.5146, 5.5143, 5.5141,\n",
      "        5.5141, 5.5142, 5.5144, 5.5145, 5.5142, 5.5144, 5.5145, 5.5143, 5.5144,\n",
      "        5.5140, 5.5142, 5.5142, 5.5144, 5.5143, 5.5148, 5.5142, 5.5147, 5.5146,\n",
      "        5.5151, 5.5148, 5.5148, 5.5146, 5.5147, 5.5148, 5.5147, 5.5147, 5.5145,\n",
      "        5.5147, 5.5145, 5.5148, 5.5146, 5.5145, 5.5150, 5.5148, 5.5148, 5.5145,\n",
      "        5.5146, 5.5149, 5.5150], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.572376  [4488924/5599865]\n",
      "average delta from current occupancy tensor([4.5405, 4.5403, 4.5406, 4.5404, 4.5404, 4.5405, 4.5404, 4.5405, 4.5405,\n",
      "        4.5403, 4.5406, 4.5406, 4.5404, 4.5403, 4.5406, 4.5404, 4.5405, 4.5405,\n",
      "        4.5403, 4.5403, 4.5403, 4.5403, 4.5406, 4.5403, 4.5403, 4.5403, 4.5403,\n",
      "        4.5403, 4.5403, 4.5403, 4.5403, 4.5404, 4.5403, 4.5403, 4.5403, 4.5405,\n",
      "        4.5403, 4.5403, 4.5402, 4.5403, 4.5402, 4.5402, 4.5403, 4.5402, 4.5402,\n",
      "        4.5403, 4.5404, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403, 4.5403,\n",
      "        4.5402, 4.5403, 4.5402, 4.5402, 4.5403, 4.5403, 4.5402, 4.5403, 4.5403,\n",
      "        4.5402, 4.5402, 4.5402, 4.5403, 4.5403, 4.5403, 4.5402, 4.5402, 4.5403,\n",
      "        4.5403, 4.5402, 4.5402, 4.5402, 4.5402, 4.5402, 4.5402, 4.5402, 4.5402,\n",
      "        4.5402, 4.5402, 4.5402, 4.5403, 4.5402, 4.5403, 4.5403, 4.5402, 4.5404,\n",
      "        4.5402, 4.5405, 4.5404, 4.5405, 4.5404, 4.5405, 4.5402, 4.5403, 4.5404,\n",
      "        4.5403, 4.5406, 4.5405, 4.5404, 4.5404, 4.5404, 4.5403, 4.5404, 4.5403,\n",
      "        4.5403, 4.5403, 4.5403, 4.5402, 4.5402, 4.5402, 4.5401, 4.5401, 4.5402,\n",
      "        4.5402, 4.5401, 4.5401], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.742885  [4501324/5599865]\n",
      "average delta from current occupancy tensor([4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5241,\n",
      "        4.5241, 4.5240, 4.5241, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5239,\n",
      "        4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240, 4.5240,\n",
      "        4.5240, 4.5240, 4.5239, 4.5239, 4.5240, 4.5240, 4.5240, 4.5240, 4.5241,\n",
      "        4.5240, 4.5241, 4.5240, 4.5240, 4.5241, 4.5240, 4.5240, 4.5240, 4.5240,\n",
      "        4.5240, 4.5240, 4.5240, 4.5241, 4.5240, 4.5240, 4.5240, 4.5240, 4.5241,\n",
      "        4.5241, 4.5241, 4.5240, 4.5240, 4.5241, 4.5241, 4.5241, 4.5240, 4.5240,\n",
      "        4.5241, 4.5241, 4.5240, 4.5242, 4.5241, 4.5241, 4.5240, 4.5241, 4.5240,\n",
      "        4.5241, 4.5241, 4.5242, 4.5241, 4.5242, 4.5242, 4.5241, 4.5240, 4.5241,\n",
      "        4.5240, 4.5240, 4.5241, 4.5241, 4.5241, 4.5241, 4.5241, 4.5241, 4.5241,\n",
      "        4.5241, 4.5241, 4.5241, 4.5241, 4.5241, 4.5241, 4.5241, 4.5241, 4.5242,\n",
      "        4.5241, 4.5241, 4.5241, 4.5242, 4.5241, 4.5241, 4.5241, 4.5242, 4.5241,\n",
      "        4.5241, 4.5241, 4.5241, 4.5241, 4.5240, 4.5241, 4.5240, 4.5240, 4.5241,\n",
      "        4.5241, 4.5240, 4.5240], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.417916  [4513724/5599865]\n",
      "average delta from current occupancy tensor([4.4482, 4.4484, 4.4481, 4.4478, 4.4478, 4.4479, 4.4479, 4.4480, 4.4480,\n",
      "        4.4479, 4.4479, 4.4479, 4.4479, 4.4481, 4.4481, 4.4480, 4.4480, 4.4481,\n",
      "        4.4481, 4.4483, 4.4481, 4.4483, 4.4481, 4.4482, 4.4484, 4.4482, 4.4479,\n",
      "        4.4483, 4.4485, 4.4482, 4.4481, 4.4480, 4.4480, 4.4480, 4.4479, 4.4480,\n",
      "        4.4480, 4.4481, 4.4481, 4.4480, 4.4479, 4.4480, 4.4482, 4.4481, 4.4481,\n",
      "        4.4482, 4.4479, 4.4479, 4.4480, 4.4480, 4.4479, 4.4479, 4.4479, 4.4478,\n",
      "        4.4477, 4.4477, 4.4478, 4.4478, 4.4476, 4.4477, 4.4478, 4.4478, 4.4479,\n",
      "        4.4478, 4.4479, 4.4479, 4.4480, 4.4478, 4.4480, 4.4481, 4.4480, 4.4481,\n",
      "        4.4480, 4.4480, 4.4481, 4.4479, 4.4479, 4.4479, 4.4481, 4.4481, 4.4482,\n",
      "        4.4480, 4.4480, 4.4482, 4.4483, 4.4484, 4.4484, 4.4483, 4.4482, 4.4481,\n",
      "        4.4482, 4.4484, 4.4484, 4.4483, 4.4483, 4.4483, 4.4482, 4.4483, 4.4483,\n",
      "        4.4484, 4.4484, 4.4484, 4.4483, 4.4485, 4.4484, 4.4484, 4.4483, 4.4486,\n",
      "        4.4485, 4.4485, 4.4489, 4.4486, 4.4487, 4.4487, 4.4486, 4.4484, 4.4487,\n",
      "        4.4487, 4.4485, 4.4486], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.685107  [4526124/5599865]\n",
      "average delta from current occupancy tensor([4.8700, 4.8698, 4.8700, 4.8696, 4.8696, 4.8697, 4.8697, 4.8697, 4.8696,\n",
      "        4.8695, 4.8696, 4.8698, 4.8697, 4.8699, 4.8700, 4.8699, 4.8699, 4.8701,\n",
      "        4.8700, 4.8700, 4.8701, 4.8699, 4.8701, 4.8702, 4.8701, 4.8701, 4.8700,\n",
      "        4.8702, 4.8700, 4.8702, 4.8703, 4.8700, 4.8700, 4.8699, 4.8696, 4.8699,\n",
      "        4.8699, 4.8700, 4.8701, 4.8699, 4.8697, 4.8697, 4.8700, 4.8698, 4.8699,\n",
      "        4.8701, 4.8696, 4.8697, 4.8700, 4.8700, 4.8700, 4.8698, 4.8698, 4.8698,\n",
      "        4.8698, 4.8698, 4.8696, 4.8696, 4.8696, 4.8698, 4.8699, 4.8701, 4.8700,\n",
      "        4.8701, 4.8701, 4.8700, 4.8701, 4.8700, 4.8702, 4.8699, 4.8699, 4.8701,\n",
      "        4.8700, 4.8701, 4.8699, 4.8701, 4.8702, 4.8701, 4.8699, 4.8700, 4.8698,\n",
      "        4.8700, 4.8700, 4.8699, 4.8698, 4.8698, 4.8699, 4.8700, 4.8701, 4.8701,\n",
      "        4.8701, 4.8700, 4.8700, 4.8701, 4.8701, 4.8700, 4.8699, 4.8698, 4.8698,\n",
      "        4.8700, 4.8698, 4.8698, 4.8697, 4.8697, 4.8700, 4.8698, 4.8698, 4.8697,\n",
      "        4.8697, 4.8698, 4.8698, 4.8697, 4.8698, 4.8698, 4.8697, 4.8697, 4.8697,\n",
      "        4.8698, 4.8697, 4.8697], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.054921  [4538524/5599865]\n",
      "average delta from current occupancy tensor([5.2019, 5.2018, 5.2019, 5.2019, 5.2019, 5.2018, 5.2019, 5.2019, 5.2018,\n",
      "        5.2018, 5.2019, 5.2019, 5.2019, 5.2019, 5.2018, 5.2018, 5.2019, 5.2018,\n",
      "        5.2019, 5.2018, 5.2019, 5.2019, 5.2019, 5.2019, 5.2018, 5.2018, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2018, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2018, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2018, 5.2018, 5.2018, 5.2018, 5.2019, 5.2019, 5.2019,\n",
      "        5.2019, 5.2019, 5.2019, 5.2019, 5.2019, 5.2018, 5.2019, 5.2018, 5.2018,\n",
      "        5.2019, 5.2018, 5.2018, 5.2019, 5.2018, 5.2019, 5.2018, 5.2018, 5.2018,\n",
      "        5.2018, 5.2018, 5.2018, 5.2019, 5.2018, 5.2019, 5.2019, 5.2019, 5.2019,\n",
      "        5.2018, 5.2019, 5.2018], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.502199  [4550924/5599865]\n",
      "average delta from current occupancy tensor([5.3071, 5.3071, 5.3070, 5.3070, 5.3070, 5.3070, 5.3071, 5.3071, 5.3071,\n",
      "        5.3072, 5.3072, 5.3071, 5.3071, 5.3072, 5.3072, 5.3071, 5.3072, 5.3072,\n",
      "        5.3071, 5.3071, 5.3071, 5.3071, 5.3071, 5.3071, 5.3071, 5.3071, 5.3072,\n",
      "        5.3071, 5.3071, 5.3071, 5.3072, 5.3072, 5.3072, 5.3073, 5.3072, 5.3072,\n",
      "        5.3072, 5.3072, 5.3072, 5.3072, 5.3072, 5.3072, 5.3071, 5.3071, 5.3071,\n",
      "        5.3071, 5.3071, 5.3071, 5.3072, 5.3071, 5.3072, 5.3072, 5.3072, 5.3072,\n",
      "        5.3073, 5.3073, 5.3073, 5.3072, 5.3073, 5.3073, 5.3072, 5.3073, 5.3072,\n",
      "        5.3072, 5.3072, 5.3072, 5.3072, 5.3073, 5.3073, 5.3073, 5.3074, 5.3073,\n",
      "        5.3074, 5.3073, 5.3073, 5.3073, 5.3073, 5.3073, 5.3073, 5.3073, 5.3071,\n",
      "        5.3073, 5.3072, 5.3073, 5.3073, 5.3073, 5.3073, 5.3072, 5.3071, 5.3072,\n",
      "        5.3072, 5.3073, 5.3073, 5.3073, 5.3072, 5.3073, 5.3074, 5.3073, 5.3073,\n",
      "        5.3073, 5.3072, 5.3074, 5.3073, 5.3073, 5.3073, 5.3073, 5.3073, 5.3073,\n",
      "        5.3072, 5.3072, 5.3073, 5.3072, 5.3073, 5.3072, 5.3071, 5.3072, 5.3072,\n",
      "        5.3072, 5.3072, 5.3072], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.436484  [4563324/5599865]\n",
      "average delta from current occupancy tensor([5.3855, 5.3857, 5.3854, 5.3855, 5.3852, 5.3852, 5.3855, 5.3852, 5.3855,\n",
      "        5.3856, 5.3855, 5.3851, 5.3852, 5.3856, 5.3857, 5.3857, 5.3858, 5.3858,\n",
      "        5.3857, 5.3858, 5.3859, 5.3852, 5.3851, 5.3851, 5.3848, 5.3852, 5.3855,\n",
      "        5.3855, 5.3853, 5.3855, 5.3853, 5.3851, 5.3849, 5.3851, 5.3853, 5.3849,\n",
      "        5.3852, 5.3850, 5.3853, 5.3851, 5.3850, 5.3850, 5.3851, 5.3850, 5.3852,\n",
      "        5.3854, 5.3857, 5.3854, 5.3854, 5.3853, 5.3853, 5.3848, 5.3847, 5.3846,\n",
      "        5.3847, 5.3847, 5.3849, 5.3846, 5.3844, 5.3845, 5.3849, 5.3847, 5.3848,\n",
      "        5.3845, 5.3848, 5.3847, 5.3849, 5.3847, 5.3849, 5.3849, 5.3850, 5.3852,\n",
      "        5.3848, 5.3851, 5.3853, 5.3853, 5.3855, 5.3857, 5.3857, 5.3856, 5.3856,\n",
      "        5.3857, 5.3858, 5.3856, 5.3854, 5.3853, 5.3852, 5.3853, 5.3859, 5.3854,\n",
      "        5.3855, 5.3854, 5.3856, 5.3858, 5.3857, 5.3852, 5.3848, 5.3854, 5.3854,\n",
      "        5.3853, 5.3857, 5.3850, 5.3847, 5.3848, 5.3843, 5.3844, 5.3848, 5.3847,\n",
      "        5.3850, 5.3849, 5.3848, 5.3855, 5.3851, 5.3855, 5.3857, 5.3853, 5.3856,\n",
      "        5.3852, 5.3856, 5.3857], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.868023  [4575724/5599865]\n",
      "average delta from current occupancy tensor([5.9457, 5.9458, 5.9456, 5.9458, 5.9453, 5.9452, 5.9457, 5.9457, 5.9457,\n",
      "        5.9457, 5.9457, 5.9456, 5.9457, 5.9458, 5.9458, 5.9459, 5.9460, 5.9460,\n",
      "        5.9459, 5.9459, 5.9458, 5.9457, 5.9456, 5.9456, 5.9456, 5.9457, 5.9458,\n",
      "        5.9457, 5.9457, 5.9457, 5.9458, 5.9458, 5.9458, 5.9458, 5.9458, 5.9458,\n",
      "        5.9457, 5.9456, 5.9456, 5.9456, 5.9454, 5.9456, 5.9456, 5.9456, 5.9456,\n",
      "        5.9457, 5.9457, 5.9458, 5.9457, 5.9457, 5.9457, 5.9455, 5.9454, 5.9451,\n",
      "        5.9454, 5.9455, 5.9454, 5.9451, 5.9452, 5.9453, 5.9455, 5.9453, 5.9456,\n",
      "        5.9454, 5.9456, 5.9454, 5.9456, 5.9456, 5.9457, 5.9456, 5.9458, 5.9457,\n",
      "        5.9455, 5.9456, 5.9457, 5.9457, 5.9457, 5.9458, 5.9459, 5.9458, 5.9458,\n",
      "        5.9457, 5.9457, 5.9456, 5.9456, 5.9455, 5.9455, 5.9456, 5.9456, 5.9455,\n",
      "        5.9454, 5.9455, 5.9456, 5.9456, 5.9455, 5.9454, 5.9454, 5.9455, 5.9455,\n",
      "        5.9454, 5.9456, 5.9455, 5.9455, 5.9456, 5.9456, 5.9455, 5.9456, 5.9456,\n",
      "        5.9456, 5.9456, 5.9455, 5.9457, 5.9457, 5.9458, 5.9457, 5.9457, 5.9457,\n",
      "        5.9456, 5.9456, 5.9456], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.483766  [4588124/5599865]\n",
      "average delta from current occupancy tensor([5.3171, 5.3171, 5.3168, 5.3173, 5.3164, 5.3161, 5.3170, 5.3170, 5.3170,\n",
      "        5.3171, 5.3173, 5.3171, 5.3176, 5.3177, 5.3175, 5.3178, 5.3177, 5.3178,\n",
      "        5.3179, 5.3177, 5.3173, 5.3171, 5.3171, 5.3172, 5.3171, 5.3172, 5.3175,\n",
      "        5.3172, 5.3172, 5.3172, 5.3174, 5.3175, 5.3176, 5.3175, 5.3175, 5.3176,\n",
      "        5.3176, 5.3174, 5.3171, 5.3174, 5.3170, 5.3172, 5.3172, 5.3171, 5.3172,\n",
      "        5.3174, 5.3172, 5.3173, 5.3172, 5.3170, 5.3171, 5.3167, 5.3166, 5.3163,\n",
      "        5.3167, 5.3168, 5.3167, 5.3161, 5.3163, 5.3164, 5.3168, 5.3167, 5.3171,\n",
      "        5.3168, 5.3172, 5.3169, 5.3172, 5.3171, 5.3173, 5.3171, 5.3173, 5.3171,\n",
      "        5.3169, 5.3169, 5.3171, 5.3170, 5.3170, 5.3174, 5.3174, 5.3176, 5.3176,\n",
      "        5.3175, 5.3174, 5.3173, 5.3174, 5.3173, 5.3174, 5.3174, 5.3174, 5.3172,\n",
      "        5.3170, 5.3174, 5.3176, 5.3177, 5.3179, 5.3176, 5.3176, 5.3178, 5.3180,\n",
      "        5.3179, 5.3180, 5.3182, 5.3181, 5.3182, 5.3184, 5.3180, 5.3182, 5.3179,\n",
      "        5.3179, 5.3180, 5.3178, 5.3181, 5.3181, 5.3181, 5.3179, 5.3181, 5.3179,\n",
      "        5.3181, 5.3179, 5.3178], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.299304  [4600524/5599865]\n",
      "average delta from current occupancy tensor([5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387, 5.3387,\n",
      "        5.3387, 5.3387, 5.3387], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.559565  [4612924/5599865]\n",
      "average delta from current occupancy tensor([4.3381, 4.3380, 4.3380, 4.3382, 4.3380, 4.3380, 4.3380, 4.3381, 4.3381,\n",
      "        4.3382, 4.3382, 4.3381, 4.3383, 4.3382, 4.3383, 4.3382, 4.3382, 4.3380,\n",
      "        4.3380, 4.3381, 4.3382, 4.3380, 4.3380, 4.3382, 4.3381, 4.3381, 4.3381,\n",
      "        4.3381, 4.3382, 4.3381, 4.3381, 4.3381, 4.3380, 4.3379, 4.3380, 4.3380,\n",
      "        4.3380, 4.3382, 4.3382, 4.3382, 4.3384, 4.3382, 4.3383, 4.3384, 4.3383,\n",
      "        4.3382, 4.3382, 4.3383, 4.3384, 4.3384, 4.3384, 4.3384, 4.3384, 4.3384,\n",
      "        4.3384, 4.3384, 4.3383, 4.3385, 4.3384, 4.3384, 4.3383, 4.3383, 4.3383,\n",
      "        4.3385, 4.3383, 4.3383, 4.3382, 4.3382, 4.3382, 4.3383, 4.3383, 4.3384,\n",
      "        4.3384, 4.3383, 4.3382, 4.3383, 4.3382, 4.3381, 4.3381, 4.3379, 4.3378,\n",
      "        4.3379, 4.3379, 4.3379, 4.3379, 4.3380, 4.3381, 4.3380, 4.3380, 4.3380,\n",
      "        4.3380, 4.3379, 4.3379, 4.3379, 4.3378, 4.3379, 4.3379, 4.3378, 4.3377,\n",
      "        4.3377, 4.3377, 4.3376, 4.3377, 4.3376, 4.3375, 4.3376, 4.3375, 4.3376,\n",
      "        4.3377, 4.3377, 4.3377, 4.3376, 4.3377, 4.3377, 4.3377, 4.3377, 4.3378,\n",
      "        4.3377, 4.3377, 4.3377], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.804510  [4625324/5599865]\n",
      "average delta from current occupancy tensor([4.9116, 4.9116, 4.9116, 4.9116, 4.9117, 4.9116, 4.9116, 4.9116, 4.9116,\n",
      "        4.9117, 4.9117, 4.9116, 4.9117, 4.9117, 4.9117, 4.9117, 4.9116, 4.9117,\n",
      "        4.9117, 4.9116, 4.9117, 4.9117, 4.9117, 4.9117, 4.9117, 4.9117, 4.9117,\n",
      "        4.9117, 4.9118, 4.9117, 4.9117, 4.9116, 4.9117, 4.9117, 4.9117, 4.9117,\n",
      "        4.9117, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118,\n",
      "        4.9117, 4.9117, 4.9117, 4.9118, 4.9118, 4.9118, 4.9117, 4.9117, 4.9117,\n",
      "        4.9118, 4.9118, 4.9118, 4.9117, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118,\n",
      "        4.9118, 4.9117, 4.9117, 4.9116, 4.9116, 4.9116, 4.9117, 4.9117, 4.9117,\n",
      "        4.9117, 4.9117, 4.9116, 4.9116, 4.9117, 4.9117, 4.9117, 4.9118, 4.9118,\n",
      "        4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118, 4.9118,\n",
      "        4.9118, 4.9118, 4.9118, 4.9118, 4.9119, 4.9119, 4.9119, 4.9119, 4.9119,\n",
      "        4.9119, 4.9119, 4.9120, 4.9120, 4.9120, 4.9120, 4.9119, 4.9120, 4.9120,\n",
      "        4.9120, 4.9119, 4.9119, 4.9119, 4.9119, 4.9119, 4.9118, 4.9119, 4.9118,\n",
      "        4.9119, 4.9119, 4.9119], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.044884  [4637724/5599865]\n",
      "average delta from current occupancy tensor([5.1853, 5.1853, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854,\n",
      "        5.1854, 5.1854, 5.1853, 5.1854, 5.1854, 5.1854, 5.1854, 5.1853, 5.1853,\n",
      "        5.1854, 5.1853, 5.1853, 5.1853, 5.1853, 5.1854, 5.1854, 5.1854, 5.1853,\n",
      "        5.1854, 5.1854, 5.1854, 5.1854, 5.1853, 5.1853, 5.1853, 5.1854, 5.1853,\n",
      "        5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854, 5.1854,\n",
      "        5.1854, 5.1854, 5.1854, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855, 5.1855,\n",
      "        5.1855, 5.1854, 5.1854, 5.1854, 5.1855, 5.1854, 5.1854, 5.1855, 5.1854,\n",
      "        5.1854, 5.1854, 5.1854, 5.1854, 5.1853, 5.1853, 5.1854, 5.1854, 5.1854,\n",
      "        5.1854, 5.1854, 5.1853, 5.1853, 5.1853, 5.1854, 5.1854, 5.1854, 5.1854,\n",
      "        5.1853, 5.1854, 5.1854, 5.1853, 5.1854, 5.1854, 5.1853, 5.1853, 5.1854,\n",
      "        5.1854, 5.1853, 5.1852, 5.1851, 5.1850, 5.1850, 5.1851, 5.1850, 5.1849,\n",
      "        5.1850, 5.1850, 5.1848, 5.1849, 5.1849, 5.1848, 5.1849, 5.1848, 5.1849,\n",
      "        5.1850, 5.1851, 5.1851, 5.1851, 5.1852, 5.1850, 5.1852, 5.1851, 5.1853,\n",
      "        5.1852, 5.1852, 5.1852], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.771054  [4650124/5599865]\n",
      "average delta from current occupancy tensor([4.8870, 4.8870, 4.8871, 4.8871, 4.8870, 4.8870, 4.8870, 4.8870, 4.8870,\n",
      "        4.8870, 4.8870, 4.8870, 4.8871, 4.8871, 4.8871, 4.8871, 4.8873, 4.8871,\n",
      "        4.8871, 4.8872, 4.8873, 4.8871, 4.8871, 4.8871, 4.8872, 4.8872, 4.8872,\n",
      "        4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871, 4.8870,\n",
      "        4.8871, 4.8871, 4.8871, 4.8870, 4.8871, 4.8870, 4.8870, 4.8870, 4.8870,\n",
      "        4.8870, 4.8870, 4.8870, 4.8871, 4.8872, 4.8871, 4.8870, 4.8871, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8872, 4.8871, 4.8871, 4.8873, 4.8872, 4.8871,\n",
      "        4.8871, 4.8871, 4.8872, 4.8871, 4.8871, 4.8871, 4.8871, 4.8870, 4.8871,\n",
      "        4.8871, 4.8871, 4.8871, 4.8872, 4.8871, 4.8871, 4.8871, 4.8871, 4.8871,\n",
      "        4.8871, 4.8870, 4.8870, 4.8870, 4.8870, 4.8870, 4.8870, 4.8871, 4.8870,\n",
      "        4.8870, 4.8870, 4.8870, 4.8870, 4.8871, 4.8870, 4.8870, 4.8870, 4.8871,\n",
      "        4.8871, 4.8870, 4.8871, 4.8873, 4.8872, 4.8871, 4.8874, 4.8871, 4.8874,\n",
      "        4.8871, 4.8870, 4.8870, 4.8871, 4.8871, 4.8872, 4.8871, 4.8871, 4.8870,\n",
      "        4.8871, 4.8871, 4.8871], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.603107  [4662524/5599865]\n",
      "average delta from current occupancy tensor([5.2421, 5.2420, 5.2420, 5.2420, 5.2419, 5.2421, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2421, 5.2421, 5.2421, 5.2421, 5.2421, 5.2421, 5.2421, 5.2422,\n",
      "        5.2422, 5.2423, 5.2422, 5.2422, 5.2421, 5.2420, 5.2420, 5.2421, 5.2420,\n",
      "        5.2421, 5.2421, 5.2420, 5.2420, 5.2421, 5.2421, 5.2421, 5.2420, 5.2422,\n",
      "        5.2421, 5.2421, 5.2420, 5.2420, 5.2421, 5.2421, 5.2420, 5.2420, 5.2420,\n",
      "        5.2420, 5.2421, 5.2422, 5.2423, 5.2423, 5.2422, 5.2422, 5.2423, 5.2422,\n",
      "        5.2420, 5.2421, 5.2421, 5.2422, 5.2422, 5.2422, 5.2423, 5.2423, 5.2423,\n",
      "        5.2423, 5.2424, 5.2423, 5.2424, 5.2424, 5.2424, 5.2424, 5.2424, 5.2424,\n",
      "        5.2424, 5.2424, 5.2423, 5.2422, 5.2423, 5.2423, 5.2423, 5.2422, 5.2423,\n",
      "        5.2423, 5.2422, 5.2423, 5.2423, 5.2423, 5.2422, 5.2422, 5.2423, 5.2423,\n",
      "        5.2423, 5.2424, 5.2424, 5.2424, 5.2423, 5.2422, 5.2421, 5.2421, 5.2422,\n",
      "        5.2422, 5.2421, 5.2422, 5.2421, 5.2420, 5.2422, 5.2422, 5.2423, 5.2422,\n",
      "        5.2422, 5.2423, 5.2422, 5.2422, 5.2423, 5.2421, 5.2422, 5.2422, 5.2421,\n",
      "        5.2421, 5.2423, 5.2422], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.171566  [4674924/5599865]\n",
      "average delta from current occupancy tensor([4.8385, 4.8385, 4.8384, 4.8384, 4.8384, 4.8384, 4.8384, 4.8384, 4.8384,\n",
      "        4.8384, 4.8385, 4.8385, 4.8386, 4.8385, 4.8385, 4.8386, 4.8388, 4.8384,\n",
      "        4.8386, 4.8387, 4.8384, 4.8386, 4.8386, 4.8385, 4.8386, 4.8385, 4.8385,\n",
      "        4.8386, 4.8386, 4.8386, 4.8385, 4.8386, 4.8386, 4.8387, 4.8387, 4.8387,\n",
      "        4.8387, 4.8387, 4.8386, 4.8387, 4.8386, 4.8386, 4.8387, 4.8386, 4.8386,\n",
      "        4.8386, 4.8386, 4.8386, 4.8386, 4.8387, 4.8386, 4.8388, 4.8387, 4.8387,\n",
      "        4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8387, 4.8388, 4.8388, 4.8387,\n",
      "        4.8386, 4.8389, 4.8387, 4.8387, 4.8389, 4.8388, 4.8387, 4.8388, 4.8388,\n",
      "        4.8388, 4.8387, 4.8387, 4.8387, 4.8386, 4.8385, 4.8386, 4.8386, 4.8385,\n",
      "        4.8385, 4.8384, 4.8385, 4.8385, 4.8387, 4.8384, 4.8384, 4.8386, 4.8386,\n",
      "        4.8386, 4.8385, 4.8385, 4.8386, 4.8386, 4.8387, 4.8388, 4.8387, 4.8388,\n",
      "        4.8387, 4.8387, 4.8387, 4.8386, 4.8387, 4.8386, 4.8387, 4.8386, 4.8385,\n",
      "        4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8386, 4.8385, 4.8385, 4.8386,\n",
      "        4.8386, 4.8385, 4.8385], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.527504  [4687324/5599865]\n",
      "average delta from current occupancy tensor([5.2104, 5.2105, 5.2102, 5.2103, 5.2102, 5.2102, 5.2101, 5.2103, 5.2097,\n",
      "        5.2100, 5.2099, 5.2097, 5.2099, 5.2099, 5.2101, 5.2096, 5.2098, 5.2097,\n",
      "        5.2097, 5.2097, 5.2097, 5.2099, 5.2102, 5.2102, 5.2102, 5.2103, 5.2104,\n",
      "        5.2102, 5.2103, 5.2102, 5.2105, 5.2102, 5.2102, 5.2100, 5.2100, 5.2104,\n",
      "        5.2103, 5.2102, 5.2102, 5.2104, 5.2103, 5.2105, 5.2105, 5.2104, 5.2104,\n",
      "        5.2103, 5.2102, 5.2102, 5.2104, 5.2107, 5.2103, 5.2107, 5.2102, 5.2103,\n",
      "        5.2103, 5.2103, 5.2103, 5.2104, 5.2104, 5.2106, 5.2107, 5.2106, 5.2107,\n",
      "        5.2106, 5.2104, 5.2102, 5.2101, 5.2103, 5.2102, 5.2102, 5.2101, 5.2100,\n",
      "        5.2100, 5.2101, 5.2100, 5.2102, 5.2100, 5.2102, 5.2100, 5.2101, 5.2100,\n",
      "        5.2100, 5.2100, 5.2100, 5.2100, 5.2101, 5.2100, 5.2097, 5.2098, 5.2098,\n",
      "        5.2096, 5.2096, 5.2098, 5.2096, 5.2096, 5.2097, 5.2097, 5.2096, 5.2098,\n",
      "        5.2097, 5.2097, 5.2098, 5.2096, 5.2099, 5.2096, 5.2097, 5.2096, 5.2097,\n",
      "        5.2096, 5.2096, 5.2096, 5.2095, 5.2095, 5.2095, 5.2096, 5.2096, 5.2096,\n",
      "        5.2096, 5.2096, 5.2096], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.410101  [4699724/5599865]\n",
      "average delta from current occupancy tensor([5.4729, 5.4729, 5.4731, 5.4731, 5.4734, 5.4735, 5.4733, 5.4732, 5.4733,\n",
      "        5.4732, 5.4732, 5.4730, 5.4729, 5.4729, 5.4729, 5.4727, 5.4728, 5.4728,\n",
      "        5.4730, 5.4729, 5.4731, 5.4730, 5.4731, 5.4729, 5.4729, 5.4730, 5.4728,\n",
      "        5.4731, 5.4727, 5.4728, 5.4725, 5.4726, 5.4726, 5.4728, 5.4731, 5.4728,\n",
      "        5.4729, 5.4731, 5.4733, 5.4730, 5.4730, 5.4728, 5.4729, 5.4730, 5.4729,\n",
      "        5.4731, 5.4734, 5.4733, 5.4732, 5.4731, 5.4732, 5.4732, 5.4734, 5.4733,\n",
      "        5.4731, 5.4732, 5.4733, 5.4734, 5.4734, 5.4733, 5.4731, 5.4734, 5.4732,\n",
      "        5.4735, 5.4734, 5.4737, 5.4735, 5.4736, 5.4735, 5.4736, 5.4736, 5.4736,\n",
      "        5.4733, 5.4734, 5.4734, 5.4732, 5.4737, 5.4734, 5.4733, 5.4734, 5.4734,\n",
      "        5.4733, 5.4733, 5.4733, 5.4731, 5.4731, 5.4731, 5.4734, 5.4733, 5.4732,\n",
      "        5.4733, 5.4732, 5.4733, 5.4733, 5.4733, 5.4734, 5.4733, 5.4733, 5.4730,\n",
      "        5.4733, 5.4733, 5.4732, 5.4731, 5.4732, 5.4731, 5.4728, 5.4729, 5.4730,\n",
      "        5.4730, 5.4732, 5.4730, 5.4729, 5.4729, 5.4727, 5.4731, 5.4732, 5.4733,\n",
      "        5.4733, 5.4733, 5.4734], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.118101  [4712124/5599865]\n",
      "average delta from current occupancy tensor([5.0577, 5.0577, 5.0577, 5.0580, 5.0579, 5.0580, 5.0580, 5.0580, 5.0579,\n",
      "        5.0579, 5.0579, 5.0579, 5.0579, 5.0578, 5.0579, 5.0580, 5.0580, 5.0581,\n",
      "        5.0579, 5.0579, 5.0580, 5.0580, 5.0580, 5.0578, 5.0579, 5.0580, 5.0579,\n",
      "        5.0579, 5.0578, 5.0579, 5.0580, 5.0579, 5.0580, 5.0580, 5.0581, 5.0579,\n",
      "        5.0581, 5.0580, 5.0580, 5.0581, 5.0579, 5.0579, 5.0579, 5.0579, 5.0579,\n",
      "        5.0580, 5.0580, 5.0581, 5.0581, 5.0581, 5.0582, 5.0581, 5.0580, 5.0580,\n",
      "        5.0581, 5.0580, 5.0580, 5.0580, 5.0579, 5.0579, 5.0579, 5.0580, 5.0580,\n",
      "        5.0580, 5.0580, 5.0580, 5.0580, 5.0580, 5.0580, 5.0579, 5.0579, 5.0578,\n",
      "        5.0579, 5.0579, 5.0579, 5.0580, 5.0579, 5.0579, 5.0580, 5.0580, 5.0579,\n",
      "        5.0579, 5.0580, 5.0579, 5.0580, 5.0578, 5.0579, 5.0579, 5.0579, 5.0580,\n",
      "        5.0580, 5.0579, 5.0579, 5.0580, 5.0580, 5.0581, 5.0580, 5.0581, 5.0581,\n",
      "        5.0581, 5.0582, 5.0581, 5.0582, 5.0581, 5.0581, 5.0580, 5.0581, 5.0582,\n",
      "        5.0580, 5.0580, 5.0580, 5.0580, 5.0580, 5.0579, 5.0580, 5.0579, 5.0580,\n",
      "        5.0581, 5.0580, 5.0580], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.678255  [4724524/5599865]\n",
      "average delta from current occupancy tensor([5.6142, 5.6144, 5.6143, 5.6141, 5.6142, 5.6144, 5.6141, 5.6143, 5.6140,\n",
      "        5.6138, 5.6138, 5.6141, 5.6141, 5.6150, 5.6143, 5.6145, 5.6146, 5.6145,\n",
      "        5.6146, 5.6144, 5.6149, 5.6149, 5.6147, 5.6144, 5.6147, 5.6148, 5.6147,\n",
      "        5.6148, 5.6150, 5.6151, 5.6142, 5.6147, 5.6143, 5.6147, 5.6144, 5.6149,\n",
      "        5.6147, 5.6152, 5.6148, 5.6148, 5.6150, 5.6151, 5.6151, 5.6155, 5.6148,\n",
      "        5.6149, 5.6148, 5.6154, 5.6151, 5.6145, 5.6144, 5.6145, 5.6148, 5.6146,\n",
      "        5.6146, 5.6147, 5.6145, 5.6143, 5.6145, 5.6144, 5.6141, 5.6145, 5.6144,\n",
      "        5.6145, 5.6139, 5.6141, 5.6138, 5.6141, 5.6141, 5.6142, 5.6147, 5.6148,\n",
      "        5.6149, 5.6148, 5.6146, 5.6142, 5.6145, 5.6146, 5.6147, 5.6140, 5.6143,\n",
      "        5.6143, 5.6142, 5.6141, 5.6135, 5.6141, 5.6138, 5.6141, 5.6141, 5.6138,\n",
      "        5.6140, 5.6146, 5.6143, 5.6140, 5.6140, 5.6137, 5.6133, 5.6136, 5.6135,\n",
      "        5.6135, 5.6135, 5.6132, 5.6133, 5.6134, 5.6132, 5.6136, 5.6131, 5.6132,\n",
      "        5.6135, 5.6135, 5.6135, 5.6137, 5.6140, 5.6138, 5.6139, 5.6137, 5.6138,\n",
      "        5.6136, 5.6140, 5.6137], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.741841  [4736924/5599865]\n",
      "average delta from current occupancy tensor([4.6270, 4.6271, 4.6271, 4.6273, 4.6271, 4.6270, 4.6269, 4.6269, 4.6270,\n",
      "        4.6267, 4.6270, 4.6270, 4.6273, 4.6274, 4.6272, 4.6271, 4.6272, 4.6273,\n",
      "        4.6275, 4.6274, 4.6271, 4.6270, 4.6274, 4.6275, 4.6271, 4.6273, 4.6271,\n",
      "        4.6272, 4.6272, 4.6276, 4.6273, 4.6273, 4.6275, 4.6273, 4.6270, 4.6272,\n",
      "        4.6273, 4.6277, 4.6273, 4.6275, 4.6275, 4.6278, 4.6279, 4.6274, 4.6276,\n",
      "        4.6275, 4.6272, 4.6277, 4.6277, 4.6274, 4.6272, 4.6276, 4.6274, 4.6278,\n",
      "        4.6277, 4.6273, 4.6278, 4.6279, 4.6278, 4.6278, 4.6278, 4.6277, 4.6276,\n",
      "        4.6277, 4.6276, 4.6275, 4.6275, 4.6275, 4.6277, 4.6275, 4.6275, 4.6275,\n",
      "        4.6273, 4.6277, 4.6277, 4.6277, 4.6277, 4.6276, 4.6276, 4.6279, 4.6275,\n",
      "        4.6276, 4.6273, 4.6275, 4.6279, 4.6278, 4.6276, 4.6278, 4.6275, 4.6276,\n",
      "        4.6275, 4.6275, 4.6275, 4.6275, 4.6272, 4.6278, 4.6274, 4.6275, 4.6276,\n",
      "        4.6274, 4.6276, 4.6274, 4.6274, 4.6274, 4.6274, 4.6273, 4.6273, 4.6272,\n",
      "        4.6275, 4.6273, 4.6273, 4.6271, 4.6272, 4.6271, 4.6276, 4.6274, 4.6274,\n",
      "        4.6272, 4.6271, 4.6275], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.643978  [4749324/5599865]\n",
      "average delta from current occupancy tensor([4.6210, 4.6210, 4.6210, 4.6211, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6211, 4.6211, 4.6210, 4.6210, 4.6211, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6211, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6211, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6211, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6211, 4.6211, 4.6210, 4.6211, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6211, 4.6210, 4.6211,\n",
      "        4.6211, 4.6210, 4.6211, 4.6210, 4.6211, 4.6211, 4.6211, 4.6211, 4.6211,\n",
      "        4.6211, 4.6211, 4.6211, 4.6211, 4.6210, 4.6210, 4.6210, 4.6211, 4.6211,\n",
      "        4.6210, 4.6211, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210,\n",
      "        4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6210, 4.6211, 4.6210, 4.6211,\n",
      "        4.6211, 4.6211, 4.6211], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.170746  [4761724/5599865]\n",
      "average delta from current occupancy tensor([5.2820, 5.2820, 5.2820, 5.2820, 5.2820, 5.2820, 5.2820, 5.2819, 5.2821,\n",
      "        5.2819, 5.2819, 5.2820, 5.2821, 5.2821, 5.2821, 5.2820, 5.2821, 5.2820,\n",
      "        5.2821, 5.2821, 5.2820, 5.2820, 5.2821, 5.2821, 5.2820, 5.2820, 5.2821,\n",
      "        5.2821, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821,\n",
      "        5.2821, 5.2822, 5.2821, 5.2821, 5.2823, 5.2822, 5.2822, 5.2822, 5.2821,\n",
      "        5.2821, 5.2819, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821, 5.2821,\n",
      "        5.2821, 5.2820, 5.2821, 5.2821, 5.2821, 5.2821, 5.2822, 5.2821, 5.2821,\n",
      "        5.2821, 5.2821, 5.2821, 5.2821, 5.2820, 5.2820, 5.2820, 5.2820, 5.2820,\n",
      "        5.2820, 5.2821, 5.2820, 5.2818, 5.2819, 5.2820, 5.2815, 5.2817, 5.2816,\n",
      "        5.2817, 5.2817, 5.2816, 5.2818, 5.2818, 5.2820, 5.2818, 5.2818, 5.2820,\n",
      "        5.2817, 5.2817, 5.2818, 5.2819, 5.2820, 5.2821, 5.2820, 5.2820, 5.2819,\n",
      "        5.2819, 5.2820, 5.2821, 5.2820, 5.2821, 5.2820, 5.2820, 5.2820, 5.2820,\n",
      "        5.2819, 5.2817, 5.2820, 5.2816, 5.2820, 5.2819, 5.2820, 5.2820, 5.2820,\n",
      "        5.2820, 5.2821, 5.2821], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.405347  [4774124/5599865]\n",
      "average delta from current occupancy tensor([5.4033, 5.4032, 5.4033, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032, 5.4033,\n",
      "        5.4032, 5.4033, 5.4032, 5.4032, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4032,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4032,\n",
      "        5.4032, 5.4033, 5.4032, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4032, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4032, 5.4033, 5.4033,\n",
      "        5.4033, 5.4034, 5.4033, 5.4033, 5.4033, 5.4033, 5.4032, 5.4033, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4033, 5.4033, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033, 5.4033,\n",
      "        5.4033, 5.4033, 5.4033, 5.4032, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4033, 5.4032, 5.4033, 5.4034, 5.4033, 5.4033, 5.4033, 5.4032, 5.4033,\n",
      "        5.4032, 5.4033, 5.4033, 5.4033, 5.4032, 5.4032, 5.4032, 5.4033, 5.4032,\n",
      "        5.4032, 5.4032, 5.4033], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.960640  [4786524/5599865]\n",
      "average delta from current occupancy tensor([4.8628, 4.8627, 4.8629, 4.8628, 4.8628, 4.8628, 4.8628, 4.8629, 4.8628,\n",
      "        4.8628, 4.8628, 4.8628, 4.8627, 4.8627, 4.8628, 4.8626, 4.8626, 4.8625,\n",
      "        4.8624, 4.8627, 4.8626, 4.8627, 4.8627, 4.8626, 4.8625, 4.8627, 4.8625,\n",
      "        4.8624, 4.8628, 4.8628, 4.8628, 4.8628, 4.8628, 4.8628, 4.8629, 4.8627,\n",
      "        4.8627, 4.8627, 4.8627, 4.8628, 4.8629, 4.8629, 4.8629, 4.8628, 4.8628,\n",
      "        4.8627, 4.8627, 4.8628, 4.8628, 4.8628, 4.8628, 4.8627, 4.8627, 4.8627,\n",
      "        4.8627, 4.8627, 4.8627, 4.8628, 4.8629, 4.8628, 4.8627, 4.8628, 4.8629,\n",
      "        4.8629, 4.8628, 4.8629, 4.8629, 4.8629, 4.8628, 4.8630, 4.8629, 4.8629,\n",
      "        4.8629, 4.8628, 4.8630, 4.8629, 4.8628, 4.8628, 4.8627, 4.8629, 4.8628,\n",
      "        4.8629, 4.8628, 4.8629, 4.8629, 4.8630, 4.8629, 4.8628, 4.8629, 4.8627,\n",
      "        4.8627, 4.8629, 4.8627, 4.8628, 4.8626, 4.8628, 4.8624, 4.8625, 4.8624,\n",
      "        4.8626, 4.8627, 4.8625, 4.8623, 4.8623, 4.8624, 4.8625, 4.8624, 4.8624,\n",
      "        4.8625, 4.8625, 4.8624, 4.8628, 4.8628, 4.8626, 4.8629, 4.8625, 4.8629,\n",
      "        4.8628, 4.8626, 4.8625], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.961064  [4798924/5599865]\n",
      "average delta from current occupancy tensor([4.8221, 4.8221, 4.8221, 4.8221, 4.8222, 4.8221, 4.8221, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8222, 4.8222, 4.8222, 4.8222, 4.8222, 4.8221,\n",
      "        4.8222, 4.8222, 4.8222, 4.8221, 4.8221, 4.8222, 4.8222, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8222, 4.8222, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8222, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8222, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221, 4.8221,\n",
      "        4.8222, 4.8221, 4.8222, 4.8222, 4.8222, 4.8222, 4.8222, 4.8222, 4.8222,\n",
      "        4.8221, 4.8221, 4.8221, 4.8222, 4.8222, 4.8222, 4.8221, 4.8222, 4.8222,\n",
      "        4.8221, 4.8222, 4.8221, 4.8221, 4.8221, 4.8221, 4.8222, 4.8221, 4.8221,\n",
      "        4.8221, 4.8221, 4.8221], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.499439  [4811324/5599865]\n",
      "average delta from current occupancy tensor([5.7846, 5.7848, 5.7844, 5.7849, 5.7844, 5.7842, 5.7844, 5.7840, 5.7841,\n",
      "        5.7841, 5.7841, 5.7840, 5.7838, 5.7841, 5.7840, 5.7842, 5.7838, 5.7845,\n",
      "        5.7841, 5.7843, 5.7843, 5.7848, 5.7844, 5.7844, 5.7844, 5.7852, 5.7849,\n",
      "        5.7849, 5.7850, 5.7851, 5.7849, 5.7853, 5.7851, 5.7849, 5.7849, 5.7856,\n",
      "        5.7854, 5.7852, 5.7849, 5.7848, 5.7848, 5.7851, 5.7851, 5.7849, 5.7849,\n",
      "        5.7853, 5.7853, 5.7854, 5.7854, 5.7852, 5.7857, 5.7852, 5.7854, 5.7854,\n",
      "        5.7853, 5.7854, 5.7855, 5.7858, 5.7862, 5.7865, 5.7868, 5.7868, 5.7869,\n",
      "        5.7870, 5.7869, 5.7869, 5.7865, 5.7863, 5.7866, 5.7866, 5.7867, 5.7867,\n",
      "        5.7868, 5.7868, 5.7867, 5.7872, 5.7873, 5.7867, 5.7867, 5.7869, 5.7871,\n",
      "        5.7869, 5.7868, 5.7866, 5.7866, 5.7866, 5.7869, 5.7867, 5.7867, 5.7871,\n",
      "        5.7870, 5.7871, 5.7869, 5.7870, 5.7870, 5.7863, 5.7869, 5.7867, 5.7867,\n",
      "        5.7866, 5.7868, 5.7864, 5.7866, 5.7865, 5.7863, 5.7864, 5.7863, 5.7863,\n",
      "        5.7866, 5.7866, 5.7865, 5.7866, 5.7867, 5.7865, 5.7863, 5.7866, 5.7866,\n",
      "        5.7862, 5.7861, 5.7864], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.458417  [4823724/5599865]\n",
      "average delta from current occupancy tensor([4.6852, 4.6852, 4.6852, 4.6852, 4.6852, 4.6852, 4.6852, 4.6852, 4.6852,\n",
      "        4.6852, 4.6852, 4.6852, 4.6852, 4.6852, 4.6853, 4.6853, 4.6853, 4.6853,\n",
      "        4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6852, 4.6853,\n",
      "        4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853,\n",
      "        4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6852, 4.6853,\n",
      "        4.6852, 4.6853, 4.6853, 4.6853, 4.6852, 4.6853, 4.6853, 4.6853, 4.6853,\n",
      "        4.6852, 4.6852, 4.6853, 4.6852, 4.6852, 4.6852, 4.6853, 4.6852, 4.6853,\n",
      "        4.6852, 4.6853, 4.6852, 4.6853, 4.6852, 4.6852, 4.6852, 4.6853, 4.6853,\n",
      "        4.6852, 4.6853, 4.6852, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853,\n",
      "        4.6853, 4.6853, 4.6852, 4.6852, 4.6853, 4.6853, 4.6852, 4.6852, 4.6853,\n",
      "        4.6853, 4.6853, 4.6853, 4.6853, 4.6852, 4.6853, 4.6853, 4.6853, 4.6852,\n",
      "        4.6852, 4.6852, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853,\n",
      "        4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6853, 4.6854, 4.6853, 4.6853,\n",
      "        4.6853, 4.6853, 4.6853], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.582135  [4836124/5599865]\n",
      "average delta from current occupancy tensor([5.5748, 5.5744, 5.5744, 5.5742, 5.5741, 5.5739, 5.5744, 5.5747, 5.5747,\n",
      "        5.5745, 5.5750, 5.5748, 5.5747, 5.5747, 5.5749, 5.5748, 5.5750, 5.5740,\n",
      "        5.5752, 5.5751, 5.5749, 5.5746, 5.5747, 5.5751, 5.5754, 5.5753, 5.5753,\n",
      "        5.5753, 5.5753, 5.5754, 5.5751, 5.5756, 5.5748, 5.5742, 5.5740, 5.5748,\n",
      "        5.5755, 5.5751, 5.5753, 5.5744, 5.5752, 5.5746, 5.5752, 5.5760, 5.5751,\n",
      "        5.5744, 5.5750, 5.5746, 5.5750, 5.5751, 5.5750, 5.5746, 5.5746, 5.5740,\n",
      "        5.5741, 5.5738, 5.5744, 5.5747, 5.5744, 5.5743, 5.5745, 5.5750, 5.5739,\n",
      "        5.5749, 5.5751, 5.5751, 5.5751, 5.5753, 5.5748, 5.5751, 5.5746, 5.5751,\n",
      "        5.5758, 5.5751, 5.5757, 5.5754, 5.5759, 5.5761, 5.5761, 5.5762, 5.5763,\n",
      "        5.5765, 5.5764, 5.5764, 5.5760, 5.5763, 5.5767, 5.5762, 5.5759, 5.5764,\n",
      "        5.5763, 5.5761, 5.5761, 5.5762, 5.5760, 5.5763, 5.5763, 5.5764, 5.5768,\n",
      "        5.5763, 5.5762, 5.5760, 5.5762, 5.5760, 5.5762, 5.5762, 5.5764, 5.5763,\n",
      "        5.5765, 5.5764, 5.5766, 5.5765, 5.5765, 5.5763, 5.5765, 5.5766, 5.5764,\n",
      "        5.5767, 5.5765, 5.5762], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.445608  [4848524/5599865]\n",
      "average delta from current occupancy tensor([5.8794, 5.8794, 5.8792, 5.8793, 5.8792, 5.8792, 5.8793, 5.8793, 5.8793,\n",
      "        5.8793, 5.8793, 5.8794, 5.8794, 5.8794, 5.8793, 5.8792, 5.8793, 5.8792,\n",
      "        5.8793, 5.8793, 5.8792, 5.8795, 5.8793, 5.8794, 5.8793, 5.8791, 5.8792,\n",
      "        5.8793, 5.8793, 5.8793, 5.8792, 5.8794, 5.8794, 5.8794, 5.8795, 5.8793,\n",
      "        5.8793, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8793, 5.8792,\n",
      "        5.8791, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8792, 5.8793, 5.8792,\n",
      "        5.8791, 5.8793, 5.8794, 5.8792, 5.8793, 5.8794, 5.8792, 5.8793, 5.8793,\n",
      "        5.8792, 5.8793, 5.8791, 5.8792, 5.8791, 5.8791, 5.8792, 5.8792, 5.8792,\n",
      "        5.8793, 5.8793, 5.8792, 5.8792, 5.8792, 5.8792, 5.8793, 5.8792, 5.8793,\n",
      "        5.8792, 5.8793, 5.8792, 5.8793, 5.8792, 5.8793, 5.8791, 5.8793, 5.8793,\n",
      "        5.8793, 5.8794, 5.8792, 5.8792, 5.8793, 5.8794, 5.8793, 5.8794, 5.8793,\n",
      "        5.8793, 5.8793, 5.8794, 5.8793, 5.8792, 5.8793, 5.8793, 5.8793, 5.8794,\n",
      "        5.8793, 5.8793, 5.8793, 5.8792, 5.8791, 5.8792, 5.8792, 5.8793, 5.8792,\n",
      "        5.8793, 5.8791, 5.8791], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.905963  [4860924/5599865]\n",
      "average delta from current occupancy tensor([5.9199, 5.9204, 5.9203, 5.9201, 5.9202, 5.9202, 5.9200, 5.9199, 5.9201,\n",
      "        5.9201, 5.9198, 5.9201, 5.9201, 5.9198, 5.9198, 5.9201, 5.9198, 5.9202,\n",
      "        5.9202, 5.9200, 5.9199, 5.9198, 5.9198, 5.9200, 5.9198, 5.9200, 5.9199,\n",
      "        5.9201, 5.9200, 5.9198, 5.9198, 5.9197, 5.9200, 5.9199, 5.9197, 5.9199,\n",
      "        5.9199, 5.9201, 5.9197, 5.9198, 5.9199, 5.9197, 5.9199, 5.9198, 5.9198,\n",
      "        5.9200, 5.9198, 5.9198, 5.9197, 5.9199, 5.9198, 5.9198, 5.9197, 5.9199,\n",
      "        5.9197, 5.9197, 5.9197, 5.9196, 5.9196, 5.9197, 5.9200, 5.9200, 5.9199,\n",
      "        5.9197, 5.9199, 5.9197, 5.9200, 5.9198, 5.9197, 5.9199, 5.9197, 5.9198,\n",
      "        5.9199, 5.9198, 5.9198, 5.9199, 5.9199, 5.9199, 5.9202, 5.9199, 5.9202,\n",
      "        5.9202, 5.9203, 5.9202, 5.9201, 5.9200, 5.9201, 5.9200, 5.9200, 5.9202,\n",
      "        5.9201, 5.9202, 5.9200, 5.9199, 5.9200, 5.9201, 5.9205, 5.9202, 5.9200,\n",
      "        5.9199, 5.9198, 5.9200, 5.9200, 5.9202, 5.9199, 5.9199, 5.9200, 5.9201,\n",
      "        5.9200, 5.9200, 5.9199, 5.9199, 5.9200, 5.9200, 5.9200, 5.9200, 5.9200,\n",
      "        5.9200, 5.9196, 5.9198], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.945326  [4873324/5599865]\n",
      "average delta from current occupancy tensor([5.1849, 5.1850, 5.1848, 5.1849, 5.1849, 5.1850, 5.1849, 5.1849, 5.1849,\n",
      "        5.1849, 5.1849, 5.1849, 5.1849, 5.1850, 5.1849, 5.1848, 5.1849, 5.1850,\n",
      "        5.1850, 5.1850, 5.1850, 5.1849, 5.1849, 5.1850, 5.1850, 5.1850, 5.1849,\n",
      "        5.1849, 5.1848, 5.1848, 5.1849, 5.1849, 5.1849, 5.1849, 5.1848, 5.1849,\n",
      "        5.1848, 5.1849, 5.1848, 5.1849, 5.1848, 5.1848, 5.1848, 5.1848, 5.1849,\n",
      "        5.1848, 5.1849, 5.1849, 5.1848, 5.1848, 5.1849, 5.1849, 5.1849, 5.1848,\n",
      "        5.1849, 5.1849, 5.1849, 5.1849, 5.1848, 5.1848, 5.1849, 5.1847, 5.1849,\n",
      "        5.1849, 5.1847, 5.1848, 5.1849, 5.1849, 5.1849, 5.1847, 5.1848, 5.1847,\n",
      "        5.1848, 5.1849, 5.1849, 5.1849, 5.1849, 5.1849, 5.1849, 5.1849, 5.1849,\n",
      "        5.1848, 5.1848, 5.1847, 5.1850, 5.1847, 5.1849, 5.1850, 5.1849, 5.1847,\n",
      "        5.1850, 5.1850, 5.1850, 5.1849, 5.1847, 5.1848, 5.1849, 5.1847, 5.1847,\n",
      "        5.1848, 5.1849, 5.1848, 5.1847, 5.1847, 5.1848, 5.1847, 5.1848, 5.1848,\n",
      "        5.1847, 5.1846, 5.1847, 5.1847, 5.1847, 5.1846, 5.1847, 5.1845, 5.1846,\n",
      "        5.1846, 5.1845, 5.1846], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.493999  [4885724/5599865]\n",
      "average delta from current occupancy tensor([5.3707, 5.3707, 5.3708, 5.3708, 5.3708, 5.3707, 5.3708, 5.3707, 5.3707,\n",
      "        5.3708, 5.3707, 5.3708, 5.3709, 5.3707, 5.3707, 5.3708, 5.3708, 5.3708,\n",
      "        5.3708, 5.3708, 5.3708, 5.3707, 5.3708, 5.3708, 5.3707, 5.3708, 5.3707,\n",
      "        5.3710, 5.3710, 5.3710, 5.3709, 5.3710, 5.3709, 5.3710, 5.3710, 5.3710,\n",
      "        5.3709, 5.3709, 5.3709, 5.3709, 5.3710, 5.3710, 5.3710, 5.3709, 5.3710,\n",
      "        5.3709, 5.3710, 5.3710, 5.3709, 5.3709, 5.3710, 5.3709, 5.3710, 5.3709,\n",
      "        5.3710, 5.3709, 5.3710, 5.3709, 5.3710, 5.3710, 5.3711, 5.3710, 5.3710,\n",
      "        5.3709, 5.3710, 5.3709, 5.3709, 5.3708, 5.3708, 5.3708, 5.3708, 5.3709,\n",
      "        5.3709, 5.3709, 5.3709, 5.3710, 5.3708, 5.3709, 5.3709, 5.3709, 5.3708,\n",
      "        5.3709, 5.3709, 5.3711, 5.3710, 5.3709, 5.3709, 5.3709, 5.3709, 5.3709,\n",
      "        5.3709, 5.3709, 5.3709, 5.3709, 5.3711, 5.3710, 5.3709, 5.3709, 5.3709,\n",
      "        5.3709, 5.3710, 5.3711, 5.3711, 5.3711, 5.3710, 5.3711, 5.3711, 5.3712,\n",
      "        5.3712, 5.3712, 5.3712, 5.3711, 5.3711, 5.3712, 5.3713, 5.3711, 5.3711,\n",
      "        5.3712, 5.3711, 5.3712], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.989007  [4898124/5599865]\n",
      "average delta from current occupancy tensor([4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9356, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9356, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.146278  [4910524/5599865]\n",
      "average delta from current occupancy tensor([5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226, 5.3226,\n",
      "        5.3226, 5.3226, 5.3226], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.952550  [4922924/5599865]\n",
      "average delta from current occupancy tensor([4.7750, 4.7751, 4.7751, 4.7747, 4.7749, 4.7748, 4.7750, 4.7747, 4.7748,\n",
      "        4.7747, 4.7750, 4.7753, 4.7753, 4.7749, 4.7748, 4.7747, 4.7749, 4.7752,\n",
      "        4.7752, 4.7752, 4.7753, 4.7751, 4.7748, 4.7747, 4.7750, 4.7746, 4.7746,\n",
      "        4.7748, 4.7751, 4.7747, 4.7747, 4.7749, 4.7747, 4.7748, 4.7747, 4.7748,\n",
      "        4.7747, 4.7750, 4.7749, 4.7748, 4.7748, 4.7750, 4.7750, 4.7749, 4.7750,\n",
      "        4.7750, 4.7749, 4.7750, 4.7749, 4.7749, 4.7749, 4.7751, 4.7750, 4.7750,\n",
      "        4.7752, 4.7751, 4.7748, 4.7750, 4.7751, 4.7751, 4.7751, 4.7750, 4.7750,\n",
      "        4.7752, 4.7751, 4.7751, 4.7751, 4.7749, 4.7747, 4.7748, 4.7748, 4.7749,\n",
      "        4.7749, 4.7749, 4.7749, 4.7750, 4.7750, 4.7749, 4.7749, 4.7748, 4.7751,\n",
      "        4.7749, 4.7749, 4.7748, 4.7751, 4.7750, 4.7749, 4.7751, 4.7750, 4.7753,\n",
      "        4.7751, 4.7753, 4.7751, 4.7752, 4.7751, 4.7751, 4.7750, 4.7752, 4.7751,\n",
      "        4.7751, 4.7751, 4.7752, 4.7751, 4.7752, 4.7752, 4.7751, 4.7751, 4.7753,\n",
      "        4.7751, 4.7751, 4.7750, 4.7751, 4.7751, 4.7751, 4.7752, 4.7751, 4.7751,\n",
      "        4.7752, 4.7753, 4.7749], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.679255  [4935324/5599865]\n",
      "average delta from current occupancy tensor([4.6207, 4.6206, 4.6207, 4.6205, 4.6205, 4.6205, 4.6206, 4.6205, 4.6205,\n",
      "        4.6206, 4.6207, 4.6208, 4.6208, 4.6206, 4.6206, 4.6205, 4.6206, 4.6208,\n",
      "        4.6207, 4.6207, 4.6208, 4.6207, 4.6207, 4.6206, 4.6208, 4.6207, 4.6207,\n",
      "        4.6207, 4.6206, 4.6205, 4.6205, 4.6207, 4.6206, 4.6205, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6209, 4.6207, 4.6208, 4.6207, 4.6207, 4.6207, 4.6208,\n",
      "        4.6209, 4.6209, 4.6209, 4.6208, 4.6209, 4.6209, 4.6205, 4.6206, 4.6206,\n",
      "        4.6207, 4.6206, 4.6208, 4.6206, 4.6206, 4.6206, 4.6206, 4.6205, 4.6205,\n",
      "        4.6207, 4.6205, 4.6206, 4.6207, 4.6210, 4.6209, 4.6210, 4.6209, 4.6209,\n",
      "        4.6207, 4.6208, 4.6208, 4.6207, 4.6207, 4.6207, 4.6206, 4.6207, 4.6207,\n",
      "        4.6207, 4.6206, 4.6208, 4.6206, 4.6207, 4.6208, 4.6208, 4.6207, 4.6207,\n",
      "        4.6207, 4.6208, 4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6208, 4.6210,\n",
      "        4.6209, 4.6208, 4.6208, 4.6208, 4.6208, 4.6207, 4.6207, 4.6207, 4.6207,\n",
      "        4.6206, 4.6205, 4.6206, 4.6206, 4.6206, 4.6205, 4.6206, 4.6205, 4.6206,\n",
      "        4.6206, 4.6207, 4.6205], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.728513  [4947724/5599865]\n",
      "average delta from current occupancy tensor([5.8306, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8306, 5.8307,\n",
      "        5.8307, 5.8306, 5.8306, 5.8307, 5.8307, 5.8307, 5.8306, 5.8307, 5.8307,\n",
      "        5.8307, 5.8307, 5.8307, 5.8309, 5.8309, 5.8307, 5.8308, 5.8308, 5.8308,\n",
      "        5.8308, 5.8307, 5.8307, 5.8307, 5.8308, 5.8307, 5.8307, 5.8308, 5.8308,\n",
      "        5.8308, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8306, 5.8307,\n",
      "        5.8307, 5.8307, 5.8306, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8306,\n",
      "        5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8306, 5.8307,\n",
      "        5.8307, 5.8307, 5.8307, 5.8307, 5.8306, 5.8307, 5.8307, 5.8307, 5.8306,\n",
      "        5.8307, 5.8306, 5.8306, 5.8307, 5.8307, 5.8306, 5.8307, 5.8306, 5.8307,\n",
      "        5.8307, 5.8309, 5.8306, 5.8307, 5.8307, 5.8306, 5.8306, 5.8307, 5.8307,\n",
      "        5.8307, 5.8307, 5.8307, 5.8306, 5.8306, 5.8307, 5.8307, 5.8306, 5.8307,\n",
      "        5.8306, 5.8306, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307, 5.8307,\n",
      "        5.8306, 5.8306, 5.8307, 5.8306, 5.8307, 5.8307, 5.8306, 5.8307, 5.8307,\n",
      "        5.8306, 5.8307, 5.8307], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.009498  [4960124/5599865]\n",
      "average delta from current occupancy tensor([4.9435, 4.9434, 4.9434, 4.9435, 4.9435, 4.9434, 4.9435, 4.9433, 4.9435,\n",
      "        4.9434, 4.9434, 4.9435, 4.9433, 4.9433, 4.9434, 4.9433, 4.9433, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9435, 4.9434,\n",
      "        4.9434, 4.9433, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9434, 4.9435, 4.9435, 4.9434, 4.9434, 4.9435,\n",
      "        4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9435, 4.9435, 4.9434, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9434, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9434,\n",
      "        4.9435, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9435,\n",
      "        4.9434, 4.9435, 4.9435, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434,\n",
      "        4.9434, 4.9434, 4.9434, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435, 4.9435,\n",
      "        4.9435, 4.9434, 4.9435, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434, 4.9434,\n",
      "        4.9434, 4.9434, 4.9435], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.918355  [4972524/5599865]\n",
      "average delta from current occupancy tensor([4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097, 4.7097,\n",
      "        4.7097, 4.7097, 4.7097], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.689231  [4984924/5599865]\n",
      "average delta from current occupancy tensor([4.7430, 4.7429, 4.7429, 4.7430, 4.7430, 4.7429, 4.7429, 4.7429, 4.7430,\n",
      "        4.7429, 4.7429, 4.7429, 4.7429, 4.7429, 4.7429, 4.7429, 4.7430, 4.7430,\n",
      "        4.7429, 4.7428, 4.7428, 4.7429, 4.7429, 4.7428, 4.7429, 4.7429, 4.7428,\n",
      "        4.7428, 4.7428, 4.7428, 4.7428, 4.7428, 4.7427, 4.7428, 4.7427, 4.7427,\n",
      "        4.7428, 4.7428, 4.7428, 4.7427, 4.7428, 4.7428, 4.7428, 4.7428, 4.7428,\n",
      "        4.7428, 4.7429, 4.7428, 4.7428, 4.7429, 4.7429, 4.7430, 4.7429, 4.7429,\n",
      "        4.7430, 4.7429, 4.7428, 4.7429, 4.7429, 4.7430, 4.7429, 4.7429, 4.7429,\n",
      "        4.7429, 4.7429, 4.7429, 4.7428, 4.7428, 4.7428, 4.7429, 4.7428, 4.7427,\n",
      "        4.7427, 4.7428, 4.7427, 4.7427, 4.7427, 4.7428, 4.7428, 4.7427, 4.7427,\n",
      "        4.7427, 4.7428, 4.7428, 4.7428, 4.7428, 4.7428, 4.7427, 4.7427, 4.7427,\n",
      "        4.7427, 4.7427, 4.7427, 4.7428, 4.7429, 4.7429, 4.7429, 4.7430, 4.7430,\n",
      "        4.7430, 4.7428, 4.7429, 4.7429, 4.7430, 4.7429, 4.7429, 4.7429, 4.7430,\n",
      "        4.7431, 4.7430, 4.7429, 4.7429, 4.7430, 4.7431, 4.7430, 4.7430, 4.7430,\n",
      "        4.7430, 4.7429, 4.7429], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.108869  [4997324/5599865]\n",
      "average delta from current occupancy tensor([5.2826, 5.2825, 5.2825, 5.2825, 5.2825, 5.2823, 5.2823, 5.2824, 5.2826,\n",
      "        5.2825, 5.2825, 5.2824, 5.2825, 5.2824, 5.2824, 5.2824, 5.2825, 5.2825,\n",
      "        5.2824, 5.2823, 5.2823, 5.2824, 5.2826, 5.2824, 5.2827, 5.2826, 5.2824,\n",
      "        5.2823, 5.2824, 5.2824, 5.2824, 5.2823, 5.2825, 5.2824, 5.2826, 5.2826,\n",
      "        5.2823, 5.2824, 5.2825, 5.2824, 5.2825, 5.2825, 5.2824, 5.2824, 5.2825,\n",
      "        5.2826, 5.2824, 5.2826, 5.2825, 5.2825, 5.2826, 5.2824, 5.2825, 5.2826,\n",
      "        5.2826, 5.2827, 5.2827, 5.2826, 5.2826, 5.2826, 5.2826, 5.2826, 5.2826,\n",
      "        5.2826, 5.2828, 5.2828, 5.2829, 5.2827, 5.2827, 5.2828, 5.2826, 5.2827,\n",
      "        5.2827, 5.2827, 5.2827, 5.2827, 5.2826, 5.2827, 5.2827, 5.2828, 5.2826,\n",
      "        5.2826, 5.2826, 5.2827, 5.2827, 5.2826, 5.2826, 5.2827, 5.2826, 5.2825,\n",
      "        5.2826, 5.2826, 5.2827, 5.2827, 5.2825, 5.2823, 5.2825, 5.2824, 5.2823,\n",
      "        5.2824, 5.2825, 5.2825, 5.2823, 5.2824, 5.2825, 5.2823, 5.2824, 5.2825,\n",
      "        5.2825, 5.2824, 5.2823, 5.2823, 5.2824, 5.2826, 5.2825, 5.2823, 5.2824,\n",
      "        5.2824, 5.2823, 5.2823], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.076530  [5009724/5599865]\n",
      "average delta from current occupancy tensor([5.2984, 5.2981, 5.2983, 5.2978, 5.2980, 5.2982, 5.2980, 5.2981, 5.2983,\n",
      "        5.2984, 5.2980, 5.2984, 5.2981, 5.2985, 5.2981, 5.2980, 5.2981, 5.2979,\n",
      "        5.2984, 5.2983, 5.2982, 5.2983, 5.2983, 5.2981, 5.2981, 5.2980, 5.2983,\n",
      "        5.2984, 5.2984, 5.2982, 5.2982, 5.2984, 5.2980, 5.2979, 5.2981, 5.2980,\n",
      "        5.2981, 5.2982, 5.2981, 5.2980, 5.2982, 5.2980, 5.2981, 5.2980, 5.2980,\n",
      "        5.2979, 5.2982, 5.2982, 5.2978, 5.2977, 5.2979, 5.2983, 5.2981, 5.2978,\n",
      "        5.2979, 5.2980, 5.2979, 5.2978, 5.2978, 5.2979, 5.2978, 5.2977, 5.2981,\n",
      "        5.2978, 5.2978, 5.2979, 5.2979, 5.2981, 5.2981, 5.2981, 5.2980, 5.2983,\n",
      "        5.2983, 5.2983, 5.2982, 5.2984, 5.2983, 5.2982, 5.2984, 5.2981, 5.2983,\n",
      "        5.2983, 5.2981, 5.2982, 5.2982, 5.2981, 5.2981, 5.2979, 5.2981, 5.2981,\n",
      "        5.2980, 5.2982, 5.2979, 5.2982, 5.2979, 5.2978, 5.2979, 5.2980, 5.2978,\n",
      "        5.2980, 5.2980, 5.2978, 5.2978, 5.2977, 5.2978, 5.2977, 5.2977, 5.2978,\n",
      "        5.2981, 5.2980, 5.2981, 5.2982, 5.2977, 5.2976, 5.2976, 5.2977, 5.2978,\n",
      "        5.2979, 5.2979, 5.2978], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.715747  [5022124/5599865]\n",
      "average delta from current occupancy tensor([4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532, 4.6532,\n",
      "        4.6532, 4.6532, 4.6532], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.423395  [5034524/5599865]\n",
      "average delta from current occupancy tensor([5.0970, 5.0970, 5.0970, 5.0970, 5.0971, 5.0970, 5.0971, 5.0971, 5.0970,\n",
      "        5.0970, 5.0971, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0969, 5.0970,\n",
      "        5.0970, 5.0969, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0971,\n",
      "        5.0970, 5.0971, 5.0970, 5.0970, 5.0970, 5.0970, 5.0969, 5.0970, 5.0969,\n",
      "        5.0970, 5.0969, 5.0970, 5.0970, 5.0969, 5.0969, 5.0969, 5.0970, 5.0969,\n",
      "        5.0969, 5.0970, 5.0970, 5.0969, 5.0969, 5.0969, 5.0970, 5.0970, 5.0969,\n",
      "        5.0969, 5.0969, 5.0969, 5.0969, 5.0969, 5.0969, 5.0970, 5.0970, 5.0970,\n",
      "        5.0969, 5.0969, 5.0970, 5.0969, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970,\n",
      "        5.0970, 5.0970, 5.0970, 5.0971, 5.0971, 5.0970, 5.0970, 5.0970, 5.0970,\n",
      "        5.0971, 5.0970, 5.0971, 5.0971, 5.0971, 5.0971, 5.0970, 5.0971, 5.0970,\n",
      "        5.0971, 5.0971, 5.0970, 5.0970, 5.0970, 5.0971, 5.0970, 5.0970, 5.0970,\n",
      "        5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0970, 5.0971,\n",
      "        5.0971, 5.0972, 5.0972, 5.0972, 5.0971, 5.0971, 5.0971, 5.0971, 5.0971,\n",
      "        5.0971, 5.0971, 5.0971], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.779891  [5046924/5599865]\n",
      "average delta from current occupancy tensor([4.7017, 4.7018, 4.7018, 4.7017, 4.7018, 4.7017, 4.7018, 4.7018, 4.7018,\n",
      "        4.7018, 4.7018, 4.7018, 4.7017, 4.7018, 4.7017, 4.7018, 4.7017, 4.7017,\n",
      "        4.7017, 4.7016, 4.7017, 4.7017, 4.7017, 4.7016, 4.7017, 4.7016, 4.7017,\n",
      "        4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7017, 4.7017,\n",
      "        4.7016, 4.7017, 4.7016, 4.7017, 4.7016, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7017, 4.7017, 4.7017, 4.7018, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7016, 4.7017, 4.7016, 4.7016, 4.7017, 4.7016, 4.7017, 4.7017, 4.7017,\n",
      "        4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7016, 4.7016,\n",
      "        4.7016, 4.7016, 4.7017, 4.7016, 4.7016, 4.7017, 4.7017, 4.7017, 4.7016,\n",
      "        4.7017, 4.7017, 4.7016, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017, 4.7017,\n",
      "        4.7016, 4.7016, 4.7016], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.579145  [5059324/5599865]\n",
      "average delta from current occupancy tensor([4.5810, 4.5810, 4.5810, 4.5809, 4.5809, 4.5810, 4.5810, 4.5809, 4.5811,\n",
      "        4.5808, 4.5809, 4.5809, 4.5809, 4.5812, 4.5814, 4.5809, 4.5813, 4.5812,\n",
      "        4.5814, 4.5812, 4.5814, 4.5814, 4.5813, 4.5809, 4.5815, 4.5810, 4.5812,\n",
      "        4.5809, 4.5812, 4.5811, 4.5810, 4.5813, 4.5815, 4.5814, 4.5810, 4.5809,\n",
      "        4.5813, 4.5811, 4.5812, 4.5812, 4.5812, 4.5810, 4.5808, 4.5807, 4.5810,\n",
      "        4.5810, 4.5809, 4.5809, 4.5809, 4.5806, 4.5808, 4.5808, 4.5808, 4.5807,\n",
      "        4.5807, 4.5808, 4.5807, 4.5807, 4.5808, 4.5806, 4.5806, 4.5806, 4.5805,\n",
      "        4.5806, 4.5806, 4.5806, 4.5807, 4.5807, 4.5807, 4.5808, 4.5807, 4.5809,\n",
      "        4.5810, 4.5807, 4.5806, 4.5807, 4.5808, 4.5811, 4.5808, 4.5807, 4.5808,\n",
      "        4.5812, 4.5813, 4.5812, 4.5813, 4.5813, 4.5813, 4.5812, 4.5810, 4.5813,\n",
      "        4.5813, 4.5812, 4.5813, 4.5813, 4.5812, 4.5812, 4.5812, 4.5810, 4.5811,\n",
      "        4.5813, 4.5814, 4.5811, 4.5814, 4.5812, 4.5815, 4.5813, 4.5815, 4.5814,\n",
      "        4.5812, 4.5811, 4.5814, 4.5809, 4.5810, 4.5809, 4.5812, 4.5810, 4.5810,\n",
      "        4.5810, 4.5812, 4.5812], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.185225  [5071724/5599865]\n",
      "average delta from current occupancy tensor([4.9101, 4.9100, 4.9099, 4.9102, 4.9100, 4.9101, 4.9100, 4.9098, 4.9100,\n",
      "        4.9101, 4.9102, 4.9103, 4.9102, 4.9099, 4.9100, 4.9099, 4.9101, 4.9100,\n",
      "        4.9102, 4.9103, 4.9102, 4.9103, 4.9103, 4.9104, 4.9104, 4.9104, 4.9105,\n",
      "        4.9105, 4.9105, 4.9106, 4.9104, 4.9105, 4.9105, 4.9105, 4.9105, 4.9106,\n",
      "        4.9106, 4.9106, 4.9106, 4.9104, 4.9105, 4.9104, 4.9103, 4.9104, 4.9106,\n",
      "        4.9104, 4.9103, 4.9104, 4.9106, 4.9105, 4.9105, 4.9105, 4.9103, 4.9105,\n",
      "        4.9105, 4.9105, 4.9104, 4.9105, 4.9101, 4.9105, 4.9105, 4.9104, 4.9105,\n",
      "        4.9101, 4.9102, 4.9104, 4.9104, 4.9104, 4.9103, 4.9103, 4.9103, 4.9103,\n",
      "        4.9103, 4.9103, 4.9106, 4.9105, 4.9105, 4.9105, 4.9107, 4.9107, 4.9107,\n",
      "        4.9107, 4.9106, 4.9106, 4.9106, 4.9107, 4.9105, 4.9105, 4.9105, 4.9104,\n",
      "        4.9105, 4.9105, 4.9105, 4.9106, 4.9104, 4.9105, 4.9105, 4.9104, 4.9105,\n",
      "        4.9104, 4.9104, 4.9104, 4.9105, 4.9106, 4.9105, 4.9105, 4.9105, 4.9105,\n",
      "        4.9105, 4.9104, 4.9106, 4.9104, 4.9105, 4.9105, 4.9105, 4.9105, 4.9104,\n",
      "        4.9104, 4.9105, 4.9105], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.766250  [5084124/5599865]\n",
      "average delta from current occupancy tensor([4.8553, 4.8553, 4.8553, 4.8554, 4.8553, 4.8553, 4.8552, 4.8552, 4.8552,\n",
      "        4.8552, 4.8553, 4.8552, 4.8552, 4.8553, 4.8553, 4.8553, 4.8553, 4.8553,\n",
      "        4.8551, 4.8551, 4.8553, 4.8551, 4.8551, 4.8552, 4.8552, 4.8553, 4.8553,\n",
      "        4.8552, 4.8553, 4.8553, 4.8551, 4.8551, 4.8552, 4.8551, 4.8551, 4.8552,\n",
      "        4.8551, 4.8553, 4.8552, 4.8552, 4.8552, 4.8551, 4.8552, 4.8551, 4.8552,\n",
      "        4.8551, 4.8552, 4.8551, 4.8552, 4.8551, 4.8551, 4.8552, 4.8552, 4.8551,\n",
      "        4.8551, 4.8551, 4.8552, 4.8552, 4.8551, 4.8552, 4.8551, 4.8551, 4.8551,\n",
      "        4.8552, 4.8552, 4.8552, 4.8551, 4.8552, 4.8552, 4.8551, 4.8551, 4.8552,\n",
      "        4.8551, 4.8551, 4.8553, 4.8553, 4.8553, 4.8551, 4.8552, 4.8552, 4.8552,\n",
      "        4.8552, 4.8553, 4.8552, 4.8551, 4.8552, 4.8552, 4.8552, 4.8552, 4.8552,\n",
      "        4.8553, 4.8551, 4.8551, 4.8552, 4.8551, 4.8552, 4.8552, 4.8552, 4.8553,\n",
      "        4.8552, 4.8553, 4.8552, 4.8552, 4.8553, 4.8552, 4.8553, 4.8551, 4.8553,\n",
      "        4.8552, 4.8553, 4.8553, 4.8553, 4.8553, 4.8553, 4.8552, 4.8553, 4.8552,\n",
      "        4.8553, 4.8551, 4.8551], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.009013  [5096524/5599865]\n",
      "average delta from current occupancy tensor([5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0646, 5.0646, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0646, 5.0646, 5.0646, 5.0645, 5.0646, 5.0647, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646, 5.0645, 5.0645, 5.0645,\n",
      "        5.0647, 5.0647, 5.0647, 5.0647, 5.0647, 5.0646, 5.0646, 5.0645, 5.0645,\n",
      "        5.0646, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0644, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0646,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0644, 5.0644, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0644, 5.0645, 5.0645, 5.0644,\n",
      "        5.0644, 5.0644, 5.0645, 5.0644, 5.0644, 5.0644, 5.0644, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645, 5.0645,\n",
      "        5.0645, 5.0645, 5.0645], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.642892  [5108924/5599865]\n",
      "average delta from current occupancy tensor([5.4677, 5.4676, 5.4677, 5.4676, 5.4678, 5.4677, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4678, 5.4676, 5.4676, 5.4677, 5.4677,\n",
      "        5.4677, 5.4676, 5.4677, 5.4678, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4676, 5.4677, 5.4676, 5.4676, 5.4678, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4676, 5.4677, 5.4676, 5.4678, 5.4678, 5.4678, 5.4678, 5.4679,\n",
      "        5.4678, 5.4678, 5.4678, 5.4679, 5.4678, 5.4677, 5.4677, 5.4676, 5.4676,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4676, 5.4677,\n",
      "        5.4677, 5.4677, 5.4677, 5.4676, 5.4678, 5.4676, 5.4676, 5.4676, 5.4677,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4678, 5.4678, 5.4677, 5.4677,\n",
      "        5.4677, 5.4676, 5.4677, 5.4677, 5.4677, 5.4677, 5.4676, 5.4677, 5.4678,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4678, 5.4677, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4677, 5.4677, 5.4677, 5.4678, 5.4678, 5.4677, 5.4677, 5.4677,\n",
      "        5.4677, 5.4677, 5.4676], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.742570  [5121324/5599865]\n",
      "average delta from current occupancy tensor([4.7629, 4.7627, 4.7625, 4.7629, 4.7628, 4.7627, 4.7627, 4.7629, 4.7630,\n",
      "        4.7629, 4.7626, 4.7623, 4.7627, 4.7627, 4.7627, 4.7627, 4.7626, 4.7624,\n",
      "        4.7627, 4.7625, 4.7626, 4.7624, 4.7625, 4.7624, 4.7623, 4.7621, 4.7623,\n",
      "        4.7622, 4.7621, 4.7619, 4.7618, 4.7618, 4.7618, 4.7620, 4.7623, 4.7621,\n",
      "        4.7620, 4.7622, 4.7621, 4.7622, 4.7620, 4.7621, 4.7623, 4.7625, 4.7624,\n",
      "        4.7623, 4.7622, 4.7623, 4.7621, 4.7622, 4.7620, 4.7621, 4.7622, 4.7622,\n",
      "        4.7622, 4.7621, 4.7622, 4.7622, 4.7623, 4.7623, 4.7625, 4.7621, 4.7621,\n",
      "        4.7621, 4.7620, 4.7622, 4.7622, 4.7619, 4.7620, 4.7620, 4.7616, 4.7619,\n",
      "        4.7619, 4.7620, 4.7619, 4.7620, 4.7622, 4.7620, 4.7618, 4.7620, 4.7620,\n",
      "        4.7622, 4.7621, 4.7620, 4.7619, 4.7623, 4.7620, 4.7620, 4.7621, 4.7616,\n",
      "        4.7620, 4.7622, 4.7619, 4.7622, 4.7619, 4.7620, 4.7618, 4.7617, 4.7617,\n",
      "        4.7615, 4.7618, 4.7616, 4.7620, 4.7620, 4.7620, 4.7620, 4.7621, 4.7623,\n",
      "        4.7620, 4.7622, 4.7622, 4.7622, 4.7621, 4.7620, 4.7621, 4.7619, 4.7620,\n",
      "        4.7621, 4.7620, 4.7621], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.000417  [5133724/5599865]\n",
      "average delta from current occupancy tensor([4.9927, 4.9926, 4.9926, 4.9926, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9928, 4.9927, 4.9927, 4.9928, 4.9927, 4.9927, 4.9927, 4.9927, 4.9928,\n",
      "        4.9928, 4.9927, 4.9927, 4.9928, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9926, 4.9927, 4.9927,\n",
      "        4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9926, 4.9927, 4.9927, 4.9927, 4.9926, 4.9927, 4.9926, 4.9926,\n",
      "        4.9926, 4.9927, 4.9927, 4.9927, 4.9927, 4.9928, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9927, 4.9927, 4.9927, 4.9928, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9928, 4.9928, 4.9928, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9926,\n",
      "        4.9928, 4.9927, 4.9928, 4.9927, 4.9927, 4.9927, 4.9926, 4.9927, 4.9927,\n",
      "        4.9927, 4.9926, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9927, 4.9927, 4.9928, 4.9928, 4.9927, 4.9927, 4.9927, 4.9927,\n",
      "        4.9927, 4.9927, 4.9926], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.737142  [5146124/5599865]\n",
      "average delta from current occupancy tensor([5.1528, 5.1529, 5.1529, 5.1528, 5.1529, 5.1528, 5.1527, 5.1528, 5.1528,\n",
      "        5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1529, 5.1529, 5.1529, 5.1529,\n",
      "        5.1529, 5.1529, 5.1528, 5.1528, 5.1527, 5.1528, 5.1528, 5.1527, 5.1528,\n",
      "        5.1528, 5.1527, 5.1528, 5.1529, 5.1528, 5.1528, 5.1529, 5.1529, 5.1528,\n",
      "        5.1528, 5.1529, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1529,\n",
      "        5.1529, 5.1528, 5.1529, 5.1528, 5.1528, 5.1528, 5.1529, 5.1528, 5.1528,\n",
      "        5.1528, 5.1528, 5.1528, 5.1529, 5.1529, 5.1528, 5.1529, 5.1529, 5.1528,\n",
      "        5.1529, 5.1528, 5.1529, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528,\n",
      "        5.1527, 5.1527, 5.1528, 5.1527, 5.1528, 5.1527, 5.1528, 5.1528, 5.1528,\n",
      "        5.1528, 5.1527, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1529, 5.1528,\n",
      "        5.1528, 5.1528, 5.1529, 5.1528, 5.1529, 5.1528, 5.1528, 5.1528, 5.1528,\n",
      "        5.1528, 5.1529, 5.1529, 5.1529, 5.1528, 5.1528, 5.1529, 5.1529, 5.1529,\n",
      "        5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528, 5.1528,\n",
      "        5.1528, 5.1528, 5.1528], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.828975  [5158524/5599865]\n",
      "average delta from current occupancy tensor([5.9861, 5.9858, 5.9856, 5.9858, 5.9854, 5.9854, 5.9855, 5.9854, 5.9854,\n",
      "        5.9855, 5.9853, 5.9853, 5.9854, 5.9855, 5.9853, 5.9852, 5.9854, 5.9855,\n",
      "        5.9854, 5.9853, 5.9854, 5.9855, 5.9859, 5.9856, 5.9856, 5.9858, 5.9857,\n",
      "        5.9857, 5.9856, 5.9854, 5.9854, 5.9856, 5.9857, 5.9852, 5.9850, 5.9850,\n",
      "        5.9846, 5.9844, 5.9845, 5.9846, 5.9847, 5.9848, 5.9846, 5.9844, 5.9844,\n",
      "        5.9844, 5.9845, 5.9844, 5.9845, 5.9845, 5.9847, 5.9846, 5.9848, 5.9847,\n",
      "        5.9846, 5.9846, 5.9842, 5.9843, 5.9842, 5.9843, 5.9843, 5.9841, 5.9841,\n",
      "        5.9843, 5.9841, 5.9842, 5.9841, 5.9842, 5.9839, 5.9839, 5.9840, 5.9838,\n",
      "        5.9841, 5.9841, 5.9838, 5.9840, 5.9840, 5.9843, 5.9840, 5.9841, 5.9842,\n",
      "        5.9844, 5.9846, 5.9844, 5.9844, 5.9845, 5.9846, 5.9847, 5.9849, 5.9848,\n",
      "        5.9848, 5.9846, 5.9845, 5.9844, 5.9845, 5.9844, 5.9844, 5.9845, 5.9839,\n",
      "        5.9838, 5.9839, 5.9840, 5.9842, 5.9842, 5.9840, 5.9838, 5.9838, 5.9840,\n",
      "        5.9840, 5.9843, 5.9841, 5.9840, 5.9842, 5.9843, 5.9844, 5.9844, 5.9845,\n",
      "        5.9844, 5.9844, 5.9845], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.158389  [5170924/5599865]\n",
      "average delta from current occupancy tensor([4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9111, 4.9111, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9111, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9111, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110, 4.9111, 4.9111, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9111, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9111,\n",
      "        4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9111, 4.9110, 4.9111, 4.9111, 4.9111, 4.9111, 4.9110,\n",
      "        4.9110, 4.9111, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110, 4.9110, 4.9111, 4.9111, 4.9111, 4.9111, 4.9110,\n",
      "        4.9110, 4.9110, 4.9110], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.817455  [5183324/5599865]\n",
      "average delta from current occupancy tensor([4.6774, 4.6774, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6774,\n",
      "        4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6774, 4.6774, 4.6774,\n",
      "        4.6774, 4.6773, 4.6774, 4.6773, 4.6774, 4.6774, 4.6774, 4.6774, 4.6773,\n",
      "        4.6774, 4.6774, 4.6774, 4.6773, 4.6773, 4.6773, 4.6774, 4.6774, 4.6774,\n",
      "        4.6773, 4.6774, 4.6774, 4.6773, 4.6774, 4.6774, 4.6774, 4.6774, 4.6773,\n",
      "        4.6774, 4.6774, 4.6774, 4.6773, 4.6774, 4.6773, 4.6774, 4.6773, 4.6773,\n",
      "        4.6774, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6774,\n",
      "        4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773,\n",
      "        4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773,\n",
      "        4.6773, 4.6773, 4.6773, 4.6773, 4.6774, 4.6773, 4.6773, 4.6773, 4.6773,\n",
      "        4.6774, 4.6773, 4.6774, 4.6774, 4.6774, 4.6773, 4.6774, 4.6774, 4.6774,\n",
      "        4.6773, 4.6774, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773,\n",
      "        4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773, 4.6773,\n",
      "        4.6773, 4.6773, 4.6773], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.556429  [5195724/5599865]\n",
      "average delta from current occupancy tensor([5.6059, 5.6058, 5.6058, 5.6059, 5.6059, 5.6059, 5.6058, 5.6058, 5.6059,\n",
      "        5.6058, 5.6058, 5.6059, 5.6058, 5.6057, 5.6059, 5.6057, 5.6058, 5.6059,\n",
      "        5.6058, 5.6059, 5.6059, 5.6057, 5.6057, 5.6059, 5.6060, 5.6060, 5.6059,\n",
      "        5.6058, 5.6059, 5.6058, 5.6058, 5.6058, 5.6058, 5.6059, 5.6059, 5.6061,\n",
      "        5.6058, 5.6061, 5.6058, 5.6058, 5.6059, 5.6058, 5.6059, 5.6061, 5.6058,\n",
      "        5.6060, 5.6059, 5.6058, 5.6058, 5.6059, 5.6058, 5.6061, 5.6058, 5.6057,\n",
      "        5.6061, 5.6058, 5.6059, 5.6058, 5.6057, 5.6058, 5.6056, 5.6058, 5.6058,\n",
      "        5.6058, 5.6058, 5.6058, 5.6058, 5.6058, 5.6058, 5.6058, 5.6058, 5.6058,\n",
      "        5.6059, 5.6058, 5.6058, 5.6058, 5.6058, 5.6060, 5.6058, 5.6061, 5.6059,\n",
      "        5.6061, 5.6061, 5.6062, 5.6059, 5.6061, 5.6060, 5.6060, 5.6060, 5.6061,\n",
      "        5.6060, 5.6059, 5.6059, 5.6061, 5.6061, 5.6062, 5.6062, 5.6062, 5.6060,\n",
      "        5.6060, 5.6060, 5.6059, 5.6060, 5.6059, 5.6058, 5.6059, 5.6059, 5.6059,\n",
      "        5.6059, 5.6059, 5.6058, 5.6058, 5.6059, 5.6059, 5.6059, 5.6058, 5.6059,\n",
      "        5.6059, 5.6059, 5.6060], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.667422  [5208124/5599865]\n",
      "average delta from current occupancy tensor([4.6442, 4.6440, 4.6441, 4.6441, 4.6440, 4.6442, 4.6439, 4.6441, 4.6442,\n",
      "        4.6442, 4.6443, 4.6442, 4.6439, 4.6442, 4.6442, 4.6442, 4.6440, 4.6442,\n",
      "        4.6442, 4.6442, 4.6441, 4.6442, 4.6441, 4.6443, 4.6442, 4.6442, 4.6441,\n",
      "        4.6443, 4.6442, 4.6442, 4.6441, 4.6441, 4.6441, 4.6442, 4.6442, 4.6441,\n",
      "        4.6442, 4.6443, 4.6442, 4.6441, 4.6441, 4.6441, 4.6441, 4.6443, 4.6441,\n",
      "        4.6441, 4.6442, 4.6441, 4.6441, 4.6442, 4.6441, 4.6443, 4.6441, 4.6442,\n",
      "        4.6441, 4.6441, 4.6442, 4.6442, 4.6442, 4.6441, 4.6442, 4.6441, 4.6441,\n",
      "        4.6441, 4.6442, 4.6442, 4.6442, 4.6441, 4.6441, 4.6442, 4.6441, 4.6441,\n",
      "        4.6441, 4.6440, 4.6441, 4.6440, 4.6441, 4.6441, 4.6440, 4.6440, 4.6440,\n",
      "        4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6441,\n",
      "        4.6441, 4.6440, 4.6441, 4.6440, 4.6441, 4.6441, 4.6440, 4.6440, 4.6441,\n",
      "        4.6440, 4.6441, 4.6440, 4.6441, 4.6441, 4.6440, 4.6440, 4.6440, 4.6439,\n",
      "        4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6440, 4.6441, 4.6441,\n",
      "        4.6440, 4.6440, 4.6440], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.768395  [5220524/5599865]\n",
      "average delta from current occupancy tensor([4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8788, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8790, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8790, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8790,\n",
      "        4.8790, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8789, 4.8788, 4.8789,\n",
      "        4.8789, 4.8789, 4.8789], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.459787  [5232924/5599865]\n",
      "average delta from current occupancy tensor([5.4122, 5.4124, 5.4127, 5.4126, 5.4124, 5.4121, 5.4126, 5.4123, 5.4123,\n",
      "        5.4122, 5.4125, 5.4125, 5.4121, 5.4121, 5.4122, 5.4124, 5.4119, 5.4122,\n",
      "        5.4124, 5.4124, 5.4128, 5.4127, 5.4128, 5.4126, 5.4126, 5.4126, 5.4127,\n",
      "        5.4128, 5.4125, 5.4126, 5.4128, 5.4126, 5.4128, 5.4126, 5.4124, 5.4127,\n",
      "        5.4125, 5.4122, 5.4124, 5.4125, 5.4128, 5.4129, 5.4128, 5.4129, 5.4129,\n",
      "        5.4128, 5.4126, 5.4129, 5.4125, 5.4126, 5.4130, 5.4126, 5.4126, 5.4125,\n",
      "        5.4127, 5.4122, 5.4122, 5.4120, 5.4125, 5.4119, 5.4121, 5.4119, 5.4121,\n",
      "        5.4123, 5.4124, 5.4125, 5.4124, 5.4124, 5.4124, 5.4126, 5.4123, 5.4123,\n",
      "        5.4123, 5.4126, 5.4126, 5.4127, 5.4127, 5.4123, 5.4125, 5.4122, 5.4123,\n",
      "        5.4122, 5.4119, 5.4118, 5.4119, 5.4121, 5.4117, 5.4115, 5.4117, 5.4119,\n",
      "        5.4119, 5.4121, 5.4123, 5.4124, 5.4121, 5.4122, 5.4125, 5.4120, 5.4123,\n",
      "        5.4126, 5.4125, 5.4126, 5.4128, 5.4126, 5.4129, 5.4127, 5.4128, 5.4128,\n",
      "        5.4130, 5.4132, 5.4133, 5.4133, 5.4132, 5.4131, 5.4132, 5.4130, 5.4132,\n",
      "        5.4132, 5.4132, 5.4128], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.838897  [5245324/5599865]\n",
      "average delta from current occupancy tensor([5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9033, 5.9034, 5.9034, 5.9034, 5.9033, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9033, 5.9033, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9033, 5.9033, 5.9033, 5.9033, 5.9033, 5.9033, 5.9033, 5.9033,\n",
      "        5.9033, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034,\n",
      "        5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9034, 5.9033,\n",
      "        5.9033, 5.9033, 5.9034, 5.9034, 5.9034, 5.9034, 5.9033, 5.9034, 5.9034,\n",
      "        5.9033, 5.9034, 5.9034], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.576602  [5257724/5599865]\n",
      "average delta from current occupancy tensor([4.6048, 4.6047, 4.6048, 4.6048, 4.6048, 4.6047, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6047, 4.6047,\n",
      "        4.6047, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6049, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6049, 4.6049, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6049, 4.6048, 4.6049, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6049, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6049, 4.6048, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6049, 4.6048, 4.6048, 4.6048, 4.6051, 4.6048, 4.6048, 4.6048,\n",
      "        4.6051, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048, 4.6048,\n",
      "        4.6048, 4.6048, 4.6048], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.871475  [5270124/5599865]\n",
      "average delta from current occupancy tensor([4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6450, 4.6451,\n",
      "        4.6451, 4.6450, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6450, 4.6451,\n",
      "        4.6451, 4.6451, 4.6451, 4.6450, 4.6450, 4.6450, 4.6450, 4.6451, 4.6451,\n",
      "        4.6451, 4.6451, 4.6450, 4.6450, 4.6450, 4.6450, 4.6450, 4.6450, 4.6450,\n",
      "        4.6450, 4.6451, 4.6450, 4.6451, 4.6450, 4.6450, 4.6451, 4.6450, 4.6451,\n",
      "        4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451,\n",
      "        4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6450,\n",
      "        4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451,\n",
      "        4.6451, 4.6451, 4.6451, 4.6451, 4.6450, 4.6451, 4.6451, 4.6450, 4.6450,\n",
      "        4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451,\n",
      "        4.6450, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6450, 4.6451,\n",
      "        4.6451, 4.6451, 4.6450, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451,\n",
      "        4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6451, 4.6450, 4.6451, 4.6451,\n",
      "        4.6451, 4.6451, 4.6451], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.503129  [5282524/5599865]\n",
      "average delta from current occupancy tensor([4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419, 4.7419,\n",
      "        4.7419, 4.7419, 4.7419], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.077931  [5294924/5599865]\n",
      "average delta from current occupancy tensor([4.8548, 4.8548, 4.8548, 4.8549, 4.8549, 4.8549, 4.8547, 4.8548, 4.8548,\n",
      "        4.8548, 4.8547, 4.8548, 4.8548, 4.8547, 4.8547, 4.8547, 4.8546, 4.8547,\n",
      "        4.8548, 4.8548, 4.8546, 4.8547, 4.8547, 4.8547, 4.8548, 4.8547, 4.8546,\n",
      "        4.8547, 4.8546, 4.8547, 4.8546, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8547, 4.8548, 4.8547, 4.8546, 4.8548, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8547, 4.8547, 4.8546, 4.8546, 4.8546, 4.8547, 4.8547, 4.8546,\n",
      "        4.8546, 4.8545, 4.8546, 4.8546, 4.8547, 4.8547, 4.8546, 4.8546, 4.8546,\n",
      "        4.8546, 4.8545, 4.8546, 4.8546, 4.8547, 4.8546, 4.8547, 4.8547, 4.8547,\n",
      "        4.8546, 4.8547, 4.8547, 4.8547, 4.8546, 4.8547, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8547, 4.8546, 4.8547,\n",
      "        4.8547, 4.8547, 4.8545, 4.8547, 4.8546, 4.8546, 4.8547, 4.8547, 4.8546,\n",
      "        4.8547, 4.8545, 4.8546, 4.8547, 4.8546, 4.8546, 4.8546, 4.8546, 4.8546,\n",
      "        4.8546, 4.8546, 4.8546, 4.8547, 4.8547, 4.8545, 4.8546, 4.8546, 4.8547,\n",
      "        4.8547, 4.8547, 4.8547], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.732512  [5307324/5599865]\n",
      "average delta from current occupancy tensor([4.5729, 4.5730, 4.5731, 4.5731, 4.5730, 4.5731, 4.5733, 4.5731, 4.5731,\n",
      "        4.5732, 4.5733, 4.5732, 4.5732, 4.5733, 4.5731, 4.5730, 4.5729, 4.5730,\n",
      "        4.5728, 4.5730, 4.5732, 4.5732, 4.5733, 4.5733, 4.5733, 4.5733, 4.5734,\n",
      "        4.5733, 4.5734, 4.5734, 4.5734, 4.5733, 4.5733, 4.5730, 4.5731, 4.5730,\n",
      "        4.5731, 4.5731, 4.5730, 4.5729, 4.5728, 4.5730, 4.5732, 4.5730, 4.5729,\n",
      "        4.5728, 4.5727, 4.5726, 4.5726, 4.5726, 4.5728, 4.5729, 4.5726, 4.5726,\n",
      "        4.5728, 4.5729, 4.5728, 4.5730, 4.5730, 4.5731, 4.5729, 4.5729, 4.5729,\n",
      "        4.5730, 4.5732, 4.5729, 4.5732, 4.5730, 4.5730, 4.5729, 4.5730, 4.5730,\n",
      "        4.5729, 4.5730, 4.5730, 4.5729, 4.5728, 4.5731, 4.5731, 4.5730, 4.5732,\n",
      "        4.5731, 4.5731, 4.5730, 4.5731, 4.5729, 4.5733, 4.5734, 4.5731, 4.5731,\n",
      "        4.5731, 4.5732, 4.5735, 4.5734, 4.5731, 4.5732, 4.5728, 4.5730, 4.5729,\n",
      "        4.5728, 4.5728, 4.5729, 4.5734, 4.5733, 4.5729, 4.5730, 4.5733, 4.5732,\n",
      "        4.5733, 4.5732, 4.5733, 4.5731, 4.5732, 4.5732, 4.5729, 4.5730, 4.5732,\n",
      "        4.5731, 4.5732, 4.5731], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.747371  [5319724/5599865]\n",
      "average delta from current occupancy tensor([5.8078, 5.8077, 5.8076, 5.8075, 5.8078, 5.8077, 5.8079, 5.8077, 5.8080,\n",
      "        5.8076, 5.8076, 5.8077, 5.8076, 5.8074, 5.8071, 5.8075, 5.8074, 5.8076,\n",
      "        5.8074, 5.8074, 5.8069, 5.8069, 5.8071, 5.8068, 5.8072, 5.8068, 5.8070,\n",
      "        5.8068, 5.8070, 5.8070, 5.8071, 5.8070, 5.8073, 5.8074, 5.8073, 5.8075,\n",
      "        5.8070, 5.8071, 5.8073, 5.8065, 5.8071, 5.8071, 5.8067, 5.8067, 5.8073,\n",
      "        5.8073, 5.8072, 5.8073, 5.8071, 5.8070, 5.8067, 5.8069, 5.8070, 5.8067,\n",
      "        5.8068, 5.8065, 5.8065, 5.8068, 5.8068, 5.8071, 5.8071, 5.8072, 5.8073,\n",
      "        5.8073, 5.8072, 5.8075, 5.8073, 5.8075, 5.8075, 5.8071, 5.8073, 5.8069,\n",
      "        5.8071, 5.8071, 5.8069, 5.8068, 5.8066, 5.8068, 5.8065, 5.8067, 5.8069,\n",
      "        5.8069, 5.8068, 5.8066, 5.8067, 5.8065, 5.8067, 5.8065, 5.8065, 5.8068,\n",
      "        5.8068, 5.8069, 5.8071, 5.8071, 5.8068, 5.8065, 5.8065, 5.8065, 5.8066,\n",
      "        5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065,\n",
      "        5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065, 5.8065,\n",
      "        5.8065, 5.8065, 5.8065], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.499689  [5332124/5599865]\n",
      "average delta from current occupancy tensor([5.3789, 5.3789, 5.3790, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789,\n",
      "        5.3789, 5.3789, 5.3788, 5.3789, 5.3789, 5.3788, 5.3789, 5.3790, 5.3789,\n",
      "        5.3790, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789,\n",
      "        5.3789, 5.3790, 5.3790, 5.3791, 5.3792, 5.3791, 5.3792, 5.3792, 5.3793,\n",
      "        5.3791, 5.3790, 5.3793, 5.3792, 5.3790, 5.3789, 5.3790, 5.3790, 5.3791,\n",
      "        5.3791, 5.3790, 5.3792, 5.3790, 5.3791, 5.3791, 5.3789, 5.3790, 5.3790,\n",
      "        5.3793, 5.3794, 5.3793, 5.3791, 5.3790, 5.3791, 5.3790, 5.3790, 5.3790,\n",
      "        5.3789, 5.3789, 5.3790, 5.3789, 5.3789, 5.3789, 5.3790, 5.3790, 5.3789,\n",
      "        5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789,\n",
      "        5.3790, 5.3789, 5.3789, 5.3790, 5.3789, 5.3789, 5.3789, 5.3788, 5.3789,\n",
      "        5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3788, 5.3789,\n",
      "        5.3789, 5.3788, 5.3788, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789,\n",
      "        5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3789, 5.3788, 5.3789,\n",
      "        5.3789, 5.3789, 5.3789], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.323498  [5344524/5599865]\n",
      "average delta from current occupancy tensor([5.4149, 5.4151, 5.4148, 5.4148, 5.4146, 5.4147, 5.4148, 5.4146, 5.4146,\n",
      "        5.4145, 5.4146, 5.4147, 5.4145, 5.4144, 5.4143, 5.4146, 5.4145, 5.4144,\n",
      "        5.4141, 5.4140, 5.4139, 5.4138, 5.4139, 5.4137, 5.4139, 5.4139, 5.4141,\n",
      "        5.4141, 5.4139, 5.4139, 5.4142, 5.4142, 5.4143, 5.4141, 5.4139, 5.4140,\n",
      "        5.4141, 5.4140, 5.4138, 5.4138, 5.4137, 5.4138, 5.4139, 5.4142, 5.4141,\n",
      "        5.4141, 5.4143, 5.4142, 5.4143, 5.4141, 5.4139, 5.4141, 5.4142, 5.4140,\n",
      "        5.4141, 5.4140, 5.4140, 5.4141, 5.4139, 5.4139, 5.4135, 5.4135, 5.4136,\n",
      "        5.4137, 5.4137, 5.4138, 5.4136, 5.4138, 5.4137, 5.4138, 5.4139, 5.4138,\n",
      "        5.4139, 5.4138, 5.4139, 5.4137, 5.4138, 5.4140, 5.4138, 5.4138, 5.4138,\n",
      "        5.4137, 5.4139, 5.4138, 5.4136, 5.4137, 5.4134, 5.4139, 5.4138, 5.4140,\n",
      "        5.4135, 5.4137, 5.4138, 5.4138, 5.4139, 5.4140, 5.4141, 5.4141, 5.4139,\n",
      "        5.4140, 5.4139, 5.4138, 5.4139, 5.4139, 5.4140, 5.4141, 5.4140, 5.4141,\n",
      "        5.4142, 5.4141, 5.4141, 5.4140, 5.4140, 5.4141, 5.4140, 5.4138, 5.4138,\n",
      "        5.4138, 5.4138, 5.4138], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.037269  [5356924/5599865]\n",
      "average delta from current occupancy tensor([4.8465, 4.8465, 4.8465, 4.8465, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466,\n",
      "        4.8466, 4.8466, 4.8466, 4.8466, 4.8467, 4.8467, 4.8467, 4.8467, 4.8466,\n",
      "        4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466, 4.8466,\n",
      "        4.8466, 4.8465, 4.8465, 4.8466, 4.8466, 4.8466, 4.8466, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465, 4.8466, 4.8465, 4.8465, 4.8465, 4.8465, 4.8465,\n",
      "        4.8465, 4.8465, 4.8465], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.345509  [5369324/5599865]\n",
      "average delta from current occupancy tensor([5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194, 5.4194,\n",
      "        5.4194, 5.4194, 5.4194], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.525752  [5381724/5599865]\n",
      "average delta from current occupancy tensor([5.6618, 5.6616, 5.6616, 5.6618, 5.6617, 5.6618, 5.6617, 5.6613, 5.6613,\n",
      "        5.6613, 5.6614, 5.6614, 5.6613, 5.6613, 5.6613, 5.6613, 5.6615, 5.6615,\n",
      "        5.6617, 5.6618, 5.6617, 5.6615, 5.6616, 5.6613, 5.6614, 5.6615, 5.6615,\n",
      "        5.6616, 5.6616, 5.6616, 5.6617, 5.6618, 5.6621, 5.6619, 5.6617, 5.6619,\n",
      "        5.6619, 5.6619, 5.6619, 5.6618, 5.6620, 5.6620, 5.6620, 5.6620, 5.6620,\n",
      "        5.6620, 5.6620, 5.6619, 5.6618, 5.6618, 5.6617, 5.6617, 5.6617, 5.6613,\n",
      "        5.6614, 5.6614, 5.6614, 5.6615, 5.6616, 5.6615, 5.6615, 5.6615, 5.6614,\n",
      "        5.6614, 5.6613, 5.6613, 5.6614, 5.6614, 5.6614, 5.6615, 5.6613, 5.6613,\n",
      "        5.6614, 5.6613, 5.6614, 5.6616, 5.6613, 5.6615, 5.6616, 5.6615, 5.6615,\n",
      "        5.6615, 5.6615, 5.6617, 5.6618, 5.6618, 5.6620, 5.6620, 5.6618, 5.6618,\n",
      "        5.6621, 5.6621, 5.6621, 5.6621, 5.6618, 5.6617, 5.6617, 5.6615, 5.6614,\n",
      "        5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6614, 5.6615, 5.6614, 5.6614,\n",
      "        5.6613, 5.6614, 5.6613, 5.6613, 5.6613, 5.6615, 5.6614, 5.6614, 5.6614,\n",
      "        5.6615, 5.6613, 5.6613], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 3.987983  [5394124/5599865]\n",
      "average delta from current occupancy tensor([4.0789, 4.0785, 4.0784, 4.0782, 4.0782, 4.0784, 4.0783, 4.0782, 4.0782,\n",
      "        4.0783, 4.0785, 4.0785, 4.0785, 4.0784, 4.0785, 4.0785, 4.0785, 4.0783,\n",
      "        4.0783, 4.0782, 4.0781, 4.0782, 4.0784, 4.0781, 4.0783, 4.0781, 4.0782,\n",
      "        4.0783, 4.0783, 4.0784, 4.0782, 4.0784, 4.0782, 4.0784, 4.0782, 4.0780,\n",
      "        4.0784, 4.0782, 4.0785, 4.0783, 4.0784, 4.0783, 4.0783, 4.0783, 4.0782,\n",
      "        4.0783, 4.0785, 4.0783, 4.0783, 4.0784, 4.0785, 4.0786, 4.0785, 4.0784,\n",
      "        4.0785, 4.0782, 4.0784, 4.0786, 4.0782, 4.0786, 4.0787, 4.0787, 4.0783,\n",
      "        4.0785, 4.0783, 4.0785, 4.0785, 4.0783, 4.0782, 4.0785, 4.0781, 4.0783,\n",
      "        4.0781, 4.0783, 4.0783, 4.0784, 4.0784, 4.0783, 4.0783, 4.0783, 4.0782,\n",
      "        4.0782, 4.0782, 4.0782, 4.0783, 4.0782, 4.0782, 4.0783, 4.0782, 4.0782,\n",
      "        4.0784, 4.0784, 4.0783, 4.0782, 4.0781, 4.0782, 4.0782, 4.0781, 4.0781,\n",
      "        4.0782, 4.0781, 4.0782, 4.0781, 4.0782, 4.0783, 4.0784, 4.0783, 4.0784,\n",
      "        4.0783, 4.0783, 4.0783, 4.0783, 4.0783, 4.0782, 4.0784, 4.0784, 4.0784,\n",
      "        4.0785, 4.0787, 4.0787], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.519488  [5406524/5599865]\n",
      "average delta from current occupancy tensor([5.3364, 5.3364, 5.3370, 5.3372, 5.3376, 5.3373, 5.3377, 5.3372, 5.3370,\n",
      "        5.3373, 5.3372, 5.3370, 5.3374, 5.3371, 5.3367, 5.3368, 5.3371, 5.3376,\n",
      "        5.3378, 5.3379, 5.3376, 5.3378, 5.3373, 5.3382, 5.3375, 5.3381, 5.3384,\n",
      "        5.3378, 5.3372, 5.3376, 5.3374, 5.3376, 5.3378, 5.3377, 5.3380, 5.3382,\n",
      "        5.3374, 5.3376, 5.3377, 5.3373, 5.3369, 5.3373, 5.3370, 5.3372, 5.3371,\n",
      "        5.3372, 5.3372, 5.3375, 5.3377, 5.3374, 5.3372, 5.3368, 5.3375, 5.3379,\n",
      "        5.3369, 5.3382, 5.3377, 5.3374, 5.3383, 5.3374, 5.3371, 5.3370, 5.3377,\n",
      "        5.3379, 5.3384, 5.3382, 5.3383, 5.3383, 5.3388, 5.3378, 5.3384, 5.3381,\n",
      "        5.3382, 5.3377, 5.3384, 5.3382, 5.3379, 5.3378, 5.3380, 5.3383, 5.3381,\n",
      "        5.3379, 5.3383, 5.3376, 5.3377, 5.3378, 5.3374, 5.3371, 5.3376, 5.3373,\n",
      "        5.3367, 5.3361, 5.3358, 5.3370, 5.3369, 5.3371, 5.3375, 5.3377, 5.3373,\n",
      "        5.3373, 5.3371, 5.3379, 5.3377, 5.3378, 5.3378, 5.3365, 5.3374, 5.3367,\n",
      "        5.3363, 5.3364, 5.3370, 5.3363, 5.3367, 5.3361, 5.3372, 5.3366, 5.3360,\n",
      "        5.3364, 5.3360, 5.3363], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.855199  [5418924/5599865]\n",
      "average delta from current occupancy tensor([4.6811, 4.6811, 4.6813, 4.6817, 4.6821, 4.6817, 4.6814, 4.6812, 4.6814,\n",
      "        4.6814, 4.6815, 4.6813, 4.6819, 4.6817, 4.6818, 4.6820, 4.6823, 4.6818,\n",
      "        4.6822, 4.6824, 4.6819, 4.6824, 4.6822, 4.6830, 4.6824, 4.6820, 4.6829,\n",
      "        4.6823, 4.6816, 4.6816, 4.6817, 4.6814, 4.6811, 4.6815, 4.6818, 4.6817,\n",
      "        4.6813, 4.6811, 4.6818, 4.6813, 4.6810, 4.6807, 4.6805, 4.6805, 4.6803,\n",
      "        4.6809, 4.6807, 4.6813, 4.6809, 4.6807, 4.6803, 4.6805, 4.6810, 4.6814,\n",
      "        4.6801, 4.6814, 4.6809, 4.6809, 4.6820, 4.6811, 4.6807, 4.6803, 4.6820,\n",
      "        4.6817, 4.6817, 4.6817, 4.6817, 4.6821, 4.6815, 4.6818, 4.6808, 4.6812,\n",
      "        4.6820, 4.6811, 4.6820, 4.6817, 4.6810, 4.6810, 4.6811, 4.6818, 4.6809,\n",
      "        4.6816, 4.6824, 4.6813, 4.6809, 4.6808, 4.6810, 4.6813, 4.6816, 4.6805,\n",
      "        4.6806, 4.6806, 4.6803, 4.6805, 4.6805, 4.6802, 4.6801, 4.6799, 4.6799,\n",
      "        4.6800, 4.6800, 4.6802, 4.6800, 4.6804, 4.6807, 4.6795, 4.6804, 4.6798,\n",
      "        4.6798, 4.6800, 4.6801, 4.6796, 4.6796, 4.6795, 4.6795, 4.6792, 4.6791,\n",
      "        4.6796, 4.6796, 4.6797], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.592453  [5431324/5599865]\n",
      "average delta from current occupancy tensor([4.6260, 4.6258, 4.6259, 4.6261, 4.6266, 4.6267, 4.6267, 4.6263, 4.6264,\n",
      "        4.6262, 4.6267, 4.6267, 4.6263, 4.6263, 4.6263, 4.6264, 4.6264, 4.6263,\n",
      "        4.6263, 4.6264, 4.6264, 4.6266, 4.6265, 4.6265, 4.6267, 4.6265, 4.6265,\n",
      "        4.6267, 4.6266, 4.6265, 4.6266, 4.6264, 4.6264, 4.6265, 4.6265, 4.6264,\n",
      "        4.6267, 4.6267, 4.6268, 4.6267, 4.6264, 4.6265, 4.6262, 4.6260, 4.6259,\n",
      "        4.6262, 4.6262, 4.6266, 4.6261, 4.6258, 4.6259, 4.6260, 4.6263, 4.6266,\n",
      "        4.6258, 4.6267, 4.6265, 4.6267, 4.6265, 4.6267, 4.6268, 4.6263, 4.6266,\n",
      "        4.6266, 4.6268, 4.6269, 4.6266, 4.6264, 4.6266, 4.6266, 4.6263, 4.6265,\n",
      "        4.6265, 4.6266, 4.6266, 4.6265, 4.6267, 4.6268, 4.6267, 4.6266, 4.6267,\n",
      "        4.6265, 4.6264, 4.6265, 4.6264, 4.6264, 4.6264, 4.6263, 4.6265, 4.6263,\n",
      "        4.6264, 4.6266, 4.6262, 4.6264, 4.6263, 4.6260, 4.6260, 4.6258, 4.6260,\n",
      "        4.6259, 4.6260, 4.6260, 4.6261, 4.6261, 4.6264, 4.6256, 4.6261, 4.6256,\n",
      "        4.6258, 4.6260, 4.6260, 4.6256, 4.6256, 4.6253, 4.6253, 4.6252, 4.6252,\n",
      "        4.6255, 4.6254, 4.6255], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.821325  [5443724/5599865]\n",
      "average delta from current occupancy tensor([4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355, 4.9355,\n",
      "        4.9355, 4.9355, 4.9355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.734075  [5456124/5599865]\n",
      "average delta from current occupancy tensor([5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9680,\n",
      "        5.9680, 5.9679, 5.9679, 5.9680, 5.9679, 5.9680, 5.9679, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679,\n",
      "        5.9678, 5.9678, 5.9678, 5.9678, 5.9678, 5.9678, 5.9678, 5.9678, 5.9678,\n",
      "        5.9679, 5.9678, 5.9678, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9680, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9678, 5.9678, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679, 5.9679,\n",
      "        5.9679, 5.9679, 5.9679, 5.9679, 5.9678, 5.9678, 5.9678, 5.9679, 5.9678,\n",
      "        5.9678, 5.9679, 5.9679, 5.9678, 5.9679, 5.9679, 5.9679, 5.9679, 5.9678,\n",
      "        5.9678, 5.9679, 5.9679, 5.9678, 5.9678, 5.9678, 5.9678, 5.9678, 5.9678,\n",
      "        5.9679, 5.9678, 5.9679], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.189074  [5468524/5599865]\n",
      "average delta from current occupancy tensor([5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371,\n",
      "        5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1372,\n",
      "        5.1371, 5.1372, 5.1372, 5.1371, 5.1371, 5.1371, 5.1371, 5.1372, 5.1372,\n",
      "        5.1372, 5.1372, 5.1372, 5.1372, 5.1372, 5.1372, 5.1372, 5.1373, 5.1372,\n",
      "        5.1372, 5.1373, 5.1373, 5.1373, 5.1372, 5.1373, 5.1373, 5.1373, 5.1373,\n",
      "        5.1373, 5.1372, 5.1372, 5.1372, 5.1371, 5.1372, 5.1371, 5.1372, 5.1372,\n",
      "        5.1372, 5.1372, 5.1371, 5.1372, 5.1373, 5.1372, 5.1372, 5.1371, 5.1371,\n",
      "        5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1372, 5.1372, 5.1371, 5.1371,\n",
      "        5.1372, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371,\n",
      "        5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371,\n",
      "        5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371,\n",
      "        5.1371, 5.1372, 5.1371, 5.1371, 5.1371, 5.1372, 5.1371, 5.1371, 5.1371,\n",
      "        5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371, 5.1371,\n",
      "        5.1371, 5.1371, 5.1371], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.832791  [5480924/5599865]\n",
      "average delta from current occupancy tensor([4.7996, 4.7996, 4.7996, 4.7996, 4.7994, 4.7994, 4.7996, 4.7995, 4.7995,\n",
      "        4.7996, 4.7996, 4.7997, 4.7999, 4.7998, 4.7996, 4.7995, 4.7995, 4.7996,\n",
      "        4.7997, 4.7997, 4.7997, 4.7997, 4.7995, 4.7997, 4.7999, 4.7998, 4.7998,\n",
      "        4.7997, 4.7999, 4.7998, 4.7998, 4.7996, 4.7997, 4.7995, 4.7996, 4.7997,\n",
      "        4.7995, 4.7996, 4.7996, 4.7997, 4.7996, 4.7994, 4.7995, 4.7995, 4.7995,\n",
      "        4.7996, 4.7994, 4.7995, 4.7997, 4.7998, 4.7999, 4.7998, 4.7997, 4.7998,\n",
      "        4.7999, 4.7999, 4.7999, 4.7997, 4.7999, 4.7999, 4.7999, 4.7999, 4.7999,\n",
      "        4.7999, 4.8000, 4.8000, 4.8000, 4.8000, 4.7999, 4.7999, 4.8001, 4.8001,\n",
      "        4.8001, 4.8001, 4.8000, 4.8002, 4.8000, 4.8001, 4.8001, 4.8001, 4.8001,\n",
      "        4.8001, 4.8003, 4.8002, 4.8002, 4.8001, 4.8002, 4.8002, 4.8002, 4.8001,\n",
      "        4.8001, 4.8000, 4.8000, 4.7999, 4.7999, 4.8000, 4.8000, 4.8000, 4.8000,\n",
      "        4.8000, 4.8000, 4.8001, 4.8000, 4.8000, 4.7999, 4.7999, 4.7997, 4.8000,\n",
      "        4.8001, 4.8000, 4.8001, 4.8001, 4.8002, 4.8001, 4.8001, 4.8000, 4.8001,\n",
      "        4.8002, 4.8001, 4.8001], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.069497  [5493324/5599865]\n",
      "average delta from current occupancy tensor([5.0416, 5.0415, 5.0416, 5.0414, 5.0419, 5.0416, 5.0414, 5.0409, 5.0413,\n",
      "        5.0413, 5.0411, 5.0414, 5.0417, 5.0412, 5.0410, 5.0408, 5.0409, 5.0414,\n",
      "        5.0407, 5.0410, 5.0413, 5.0411, 5.0415, 5.0417, 5.0410, 5.0415, 5.0412,\n",
      "        5.0419, 5.0416, 5.0416, 5.0416, 5.0420, 5.0416, 5.0421, 5.0417, 5.0421,\n",
      "        5.0422, 5.0418, 5.0419, 5.0418, 5.0419, 5.0424, 5.0419, 5.0420, 5.0421,\n",
      "        5.0413, 5.0422, 5.0416, 5.0411, 5.0412, 5.0417, 5.0415, 5.0417, 5.0417,\n",
      "        5.0421, 5.0423, 5.0423, 5.0419, 5.0424, 5.0425, 5.0422, 5.0423, 5.0417,\n",
      "        5.0418, 5.0421, 5.0420, 5.0418, 5.0420, 5.0415, 5.0417, 5.0424, 5.0422,\n",
      "        5.0420, 5.0418, 5.0419, 5.0420, 5.0422, 5.0421, 5.0423, 5.0421, 5.0421,\n",
      "        5.0425, 5.0428, 5.0430, 5.0430, 5.0426, 5.0429, 5.0429, 5.0434, 5.0430,\n",
      "        5.0432, 5.0432, 5.0429, 5.0428, 5.0422, 5.0423, 5.0421, 5.0419, 5.0417,\n",
      "        5.0415, 5.0418, 5.0423, 5.0420, 5.0423, 5.0427, 5.0427, 5.0435, 5.0430,\n",
      "        5.0426, 5.0428, 5.0427, 5.0426, 5.0428, 5.0429, 5.0426, 5.0427, 5.0427,\n",
      "        5.0421, 5.0421, 5.0420], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.722904  [5505724/5599865]\n",
      "average delta from current occupancy tensor([5.9102, 5.9102, 5.9102, 5.9101, 5.9103, 5.9103, 5.9102, 5.9102, 5.9103,\n",
      "        5.9103, 5.9103, 5.9102, 5.9102, 5.9102, 5.9103, 5.9102, 5.9102, 5.9101,\n",
      "        5.9102, 5.9102, 5.9103, 5.9103, 5.9102, 5.9102, 5.9103, 5.9103, 5.9103,\n",
      "        5.9103, 5.9103, 5.9103, 5.9103, 5.9104, 5.9103, 5.9102, 5.9103, 5.9103,\n",
      "        5.9105, 5.9103, 5.9104, 5.9104, 5.9105, 5.9105, 5.9105, 5.9105, 5.9104,\n",
      "        5.9103, 5.9104, 5.9104, 5.9105, 5.9105, 5.9105, 5.9105, 5.9105, 5.9105,\n",
      "        5.9106, 5.9105, 5.9104, 5.9106, 5.9104, 5.9104, 5.9106, 5.9106, 5.9103,\n",
      "        5.9103, 5.9104, 5.9104, 5.9105, 5.9104, 5.9105, 5.9105, 5.9106, 5.9104,\n",
      "        5.9104, 5.9104, 5.9105, 5.9104, 5.9104, 5.9102, 5.9103, 5.9103, 5.9104,\n",
      "        5.9104, 5.9105, 5.9105, 5.9104, 5.9105, 5.9105, 5.9107, 5.9104, 5.9106,\n",
      "        5.9105, 5.9104, 5.9105, 5.9104, 5.9105, 5.9104, 5.9104, 5.9103, 5.9103,\n",
      "        5.9104, 5.9104, 5.9104, 5.9103, 5.9106, 5.9104, 5.9103, 5.9099, 5.9104,\n",
      "        5.9104, 5.9104, 5.9104, 5.9102, 5.9104, 5.9103, 5.9106, 5.9103, 5.9105,\n",
      "        5.9103, 5.9103, 5.9103], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.701879  [5518124/5599865]\n",
      "average delta from current occupancy tensor([5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871,\n",
      "        5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8872, 5.8871,\n",
      "        5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871,\n",
      "        5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871, 5.8871,\n",
      "        5.8871, 5.8871, 5.8871, 5.8872, 5.8872, 5.8871, 5.8872, 5.8871, 5.8872,\n",
      "        5.8872, 5.8872, 5.8871, 5.8871, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8871, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8871,\n",
      "        5.8872, 5.8872, 5.8872, 5.8871, 5.8871, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8872, 5.8872, 5.8872, 5.8871, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872, 5.8872,\n",
      "        5.8872, 5.8872, 5.8872], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.904736  [5530524/5599865]\n",
      "average delta from current occupancy tensor([6.0011, 6.0011, 6.0010, 6.0011, 6.0009, 6.0010, 6.0010, 6.0010, 6.0010,\n",
      "        6.0010, 6.0010, 6.0010, 6.0010, 6.0010, 6.0010, 6.0008, 6.0008, 6.0009,\n",
      "        6.0008, 6.0009, 6.0009, 6.0009, 6.0008, 6.0009, 6.0008, 6.0008, 6.0008,\n",
      "        6.0008, 6.0008, 6.0008, 6.0008, 6.0009, 6.0008, 6.0008, 6.0008, 6.0009,\n",
      "        6.0007, 6.0008, 6.0005, 6.0006, 6.0007, 6.0008, 6.0006, 6.0007, 6.0009,\n",
      "        6.0008, 6.0008, 6.0006, 6.0008, 6.0008, 6.0007, 6.0007, 6.0007, 6.0007,\n",
      "        6.0007, 6.0007, 6.0006, 6.0007, 6.0007, 6.0008, 6.0006, 6.0008, 6.0007,\n",
      "        6.0006, 6.0007, 6.0006, 6.0006, 6.0007, 6.0006, 6.0007, 6.0007, 6.0008,\n",
      "        6.0007, 6.0008, 6.0007, 6.0007, 6.0007, 6.0007, 6.0008, 6.0007, 6.0007,\n",
      "        6.0007, 6.0007, 6.0008, 6.0008, 6.0005, 6.0007, 6.0007, 6.0006, 6.0006,\n",
      "        6.0005, 6.0004, 6.0006, 6.0005, 6.0005, 6.0005, 6.0006, 6.0006, 6.0005,\n",
      "        6.0007, 6.0007, 6.0006, 6.0006, 6.0005, 6.0006, 6.0007, 6.0006, 6.0007,\n",
      "        6.0006, 6.0006, 6.0006, 6.0006, 6.0006, 6.0005, 6.0005, 6.0005, 6.0005,\n",
      "        6.0005, 6.0005, 6.0005], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.706034  [5542924/5599865]\n",
      "average delta from current occupancy tensor([4.7740, 4.7740, 4.7740, 4.7740, 4.7741, 4.7737, 4.7738, 4.7739, 4.7738,\n",
      "        4.7740, 4.7740, 4.7738, 4.7741, 4.7741, 4.7741, 4.7741, 4.7739, 4.7741,\n",
      "        4.7738, 4.7741, 4.7741, 4.7739, 4.7740, 4.7742, 4.7744, 4.7743, 4.7742,\n",
      "        4.7742, 4.7743, 4.7743, 4.7743, 4.7742, 4.7744, 4.7741, 4.7743, 4.7743,\n",
      "        4.7744, 4.7744, 4.7744, 4.7743, 4.7745, 4.7741, 4.7743, 4.7744, 4.7742,\n",
      "        4.7740, 4.7740, 4.7740, 4.7739, 4.7739, 4.7739, 4.7739, 4.7738, 4.7739,\n",
      "        4.7738, 4.7739, 4.7740, 4.7740, 4.7739, 4.7738, 4.7739, 4.7740, 4.7740,\n",
      "        4.7740, 4.7741, 4.7739, 4.7740, 4.7740, 4.7740, 4.7740, 4.7741, 4.7741,\n",
      "        4.7741, 4.7742, 4.7742, 4.7741, 4.7741, 4.7740, 4.7741, 4.7743, 4.7746,\n",
      "        4.7743, 4.7746, 4.7744, 4.7743, 4.7745, 4.7742, 4.7744, 4.7743, 4.7746,\n",
      "        4.7746, 4.7746, 4.7745, 4.7745, 4.7745, 4.7744, 4.7745, 4.7746, 4.7744,\n",
      "        4.7745, 4.7743, 4.7744, 4.7744, 4.7743, 4.7740, 4.7740, 4.7741, 4.7742,\n",
      "        4.7742, 4.7740, 4.7740, 4.7741, 4.7742, 4.7740, 4.7740, 4.7742, 4.7743,\n",
      "        4.7741, 4.7743, 4.7743], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.763627  [5555324/5599865]\n",
      "average delta from current occupancy tensor([5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290,\n",
      "        5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290,\n",
      "        5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290,\n",
      "        5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290,\n",
      "        5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290,\n",
      "        5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6290, 5.6292, 5.6291,\n",
      "        5.6291, 5.6290, 5.6290, 5.6290, 5.6290, 5.6293, 5.6291, 5.6290, 5.6290,\n",
      "        5.6290, 5.6297, 5.6292, 5.6290, 5.6293, 5.6292, 5.6293, 5.6296, 5.6296,\n",
      "        5.6296, 5.6297, 5.6296, 5.6294, 5.6296, 5.6295, 5.6295, 5.6296, 5.6297,\n",
      "        5.6298, 5.6299, 5.6297, 5.6298, 5.6298, 5.6299, 5.6299, 5.6300, 5.6299,\n",
      "        5.6300, 5.6299, 5.6296, 5.6296, 5.6293, 5.6294, 5.6294, 5.6295, 5.6297,\n",
      "        5.6296, 5.6297, 5.6298, 5.6297, 5.6297, 5.6296, 5.6293, 5.6296, 5.6295,\n",
      "        5.6295, 5.6292, 5.6292, 5.6295, 5.6295, 5.6292, 5.6294, 5.6299, 5.6300,\n",
      "        5.6297, 5.6299, 5.6297], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.927892  [5567724/5599865]\n",
      "average delta from current occupancy tensor([5.8240, 5.8240, 5.8240, 5.8241, 5.8242, 5.8239, 5.8240, 5.8237, 5.8229,\n",
      "        5.8234, 5.8234, 5.8230, 5.8225, 5.8227, 5.8226, 5.8229, 5.8236, 5.8225,\n",
      "        5.8227, 5.8225, 5.8225, 5.8231, 5.8226, 5.8225, 5.8225, 5.8226, 5.8227,\n",
      "        5.8226, 5.8227, 5.8230, 5.8225, 5.8225, 5.8225, 5.8229, 5.8225, 5.8225,\n",
      "        5.8225, 5.8225, 5.8225, 5.8225, 5.8225, 5.8225, 5.8232, 5.8233, 5.8231,\n",
      "        5.8225, 5.8231, 5.8228, 5.8229, 5.8229, 5.8232, 5.8234, 5.8230, 5.8234,\n",
      "        5.8232, 5.8230, 5.8230, 5.8225, 5.8230, 5.8229, 5.8228, 5.8231, 5.8233,\n",
      "        5.8232, 5.8234, 5.8232, 5.8230, 5.8230, 5.8227, 5.8229, 5.8225, 5.8226,\n",
      "        5.8228, 5.8226, 5.8228, 5.8227, 5.8229, 5.8228, 5.8228, 5.8227, 5.8227,\n",
      "        5.8228, 5.8229, 5.8229, 5.8230, 5.8228, 5.8225, 5.8226, 5.8225, 5.8225,\n",
      "        5.8227, 5.8226, 5.8229, 5.8228, 5.8226, 5.8229, 5.8226, 5.8226, 5.8226,\n",
      "        5.8227, 5.8226, 5.8225, 5.8225, 5.8226, 5.8225, 5.8228, 5.8227, 5.8228,\n",
      "        5.8228, 5.8226, 5.8226, 5.8228, 5.8228, 5.8226, 5.8226, 5.8225, 5.8225,\n",
      "        5.8226, 5.8226, 5.8226], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.357094  [5580124/5599865]\n",
      "average delta from current occupancy tensor([5.5951, 5.5950, 5.5949, 5.5949, 5.5951, 5.5950, 5.5952, 5.5952, 5.5953,\n",
      "        5.5952, 5.5953, 5.5952, 5.5950, 5.5952, 5.5954, 5.5955, 5.5951, 5.5952,\n",
      "        5.5951, 5.5950, 5.5950, 5.5948, 5.5949, 5.5950, 5.5951, 5.5953, 5.5951,\n",
      "        5.5952, 5.5952, 5.5954, 5.5956, 5.5950, 5.5951, 5.5953, 5.5954, 5.5954,\n",
      "        5.5955, 5.5953, 5.5952, 5.5949, 5.5946, 5.5948, 5.5947, 5.5948, 5.5950,\n",
      "        5.5949, 5.5952, 5.5953, 5.5956, 5.5959, 5.5958, 5.5956, 5.5957, 5.5957,\n",
      "        5.5956, 5.5954, 5.5959, 5.5957, 5.5958, 5.5956, 5.5956, 5.5957, 5.5958,\n",
      "        5.5956, 5.5955, 5.5956, 5.5956, 5.5955, 5.5954, 5.5953, 5.5951, 5.5953,\n",
      "        5.5953, 5.5951, 5.5950, 5.5949, 5.5952, 5.5953, 5.5953, 5.5955, 5.5957,\n",
      "        5.5958, 5.5955, 5.5956, 5.5955, 5.5955, 5.5955, 5.5957, 5.5956, 5.5957,\n",
      "        5.5959, 5.5957, 5.5959, 5.5960, 5.5958, 5.5961, 5.5959, 5.5958, 5.5958,\n",
      "        5.5959, 5.5957, 5.5956, 5.5956, 5.5958, 5.5957, 5.5956, 5.5954, 5.5952,\n",
      "        5.5954, 5.5954, 5.5952, 5.5954, 5.5953, 5.5954, 5.5955, 5.5956, 5.5956,\n",
      "        5.5955, 5.5956, 5.5956], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.004412  [5592524/5599865]\n",
      "average delta from current occupancy tensor([4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9678, 4.9678, 4.9678, 4.9677, 4.9678,\n",
      "        4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9679, 4.9678,\n",
      "        4.9679, 4.9679, 4.9678, 4.9679, 4.9678, 4.9679, 4.9679, 4.9679, 4.9678,\n",
      "        4.9679, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678,\n",
      "        4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9678, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9678, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9678, 4.9678, 4.9678, 4.9678,\n",
      "        4.9678, 4.9677, 4.9677, 4.9678, 4.9677, 4.9677, 4.9677, 4.9678, 4.9678,\n",
      "        4.9679, 4.9678, 4.9678, 4.9677, 4.9678, 4.9678, 4.9678, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Avg loss: 5.270412 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5.388652  [  124/5599865]\n",
      "average delta from current occupancy tensor([5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5081, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5081, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5081, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082, 5.5082,\n",
      "        5.5082, 5.5082, 5.5082], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.850617  [12524/5599865]\n",
      "average delta from current occupancy tensor([4.7720, 4.7720, 4.7719, 4.7719, 4.7720, 4.7720, 4.7720, 4.7720, 4.7721,\n",
      "        4.7720, 4.7719, 4.7719, 4.7719, 4.7719, 4.7720, 4.7719, 4.7720, 4.7718,\n",
      "        4.7720, 4.7720, 4.7719, 4.7719, 4.7720, 4.7720, 4.7719, 4.7720, 4.7719,\n",
      "        4.7720, 4.7719, 4.7719, 4.7718, 4.7716, 4.7718, 4.7717, 4.7719, 4.7721,\n",
      "        4.7721, 4.7719, 4.7719, 4.7720, 4.7720, 4.7719, 4.7719, 4.7720, 4.7721,\n",
      "        4.7720, 4.7719, 4.7719, 4.7720, 4.7720, 4.7720, 4.7721, 4.7721, 4.7720,\n",
      "        4.7721, 4.7720, 4.7721, 4.7721, 4.7719, 4.7718, 4.7720, 4.7718, 4.7720,\n",
      "        4.7719, 4.7718, 4.7718, 4.7718, 4.7718, 4.7718, 4.7717, 4.7718, 4.7717,\n",
      "        4.7716, 4.7717, 4.7717, 4.7717, 4.7718, 4.7718, 4.7716, 4.7717, 4.7716,\n",
      "        4.7717, 4.7715, 4.7718, 4.7717, 4.7718, 4.7718, 4.7718, 4.7717, 4.7716,\n",
      "        4.7717, 4.7716, 4.7715, 4.7717, 4.7716, 4.7717, 4.7716, 4.7716, 4.7717,\n",
      "        4.7716, 4.7717, 4.7715, 4.7714, 4.7716, 4.7717, 4.7715, 4.7715, 4.7715,\n",
      "        4.7716, 4.7714, 4.7715, 4.7716, 4.7715, 4.7715, 4.7716, 4.7716, 4.7717,\n",
      "        4.7718, 4.7718, 4.7719], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.218594  [24924/5599865]\n",
      "average delta from current occupancy tensor([5.1127, 5.1128, 5.1127, 5.1127, 5.1128, 5.1127, 5.1126, 5.1127, 5.1127,\n",
      "        5.1127, 5.1127, 5.1127, 5.1128, 5.1128, 5.1127, 5.1128, 5.1127, 5.1128,\n",
      "        5.1127, 5.1128, 5.1127, 5.1127, 5.1128, 5.1128, 5.1128, 5.1127, 5.1128,\n",
      "        5.1128, 5.1128, 5.1128, 5.1125, 5.1122, 5.1126, 5.1127, 5.1128, 5.1126,\n",
      "        5.1126, 5.1127, 5.1128, 5.1127, 5.1127, 5.1127, 5.1128, 5.1127, 5.1127,\n",
      "        5.1127, 5.1128, 5.1127, 5.1128, 5.1128, 5.1128, 5.1127, 5.1128, 5.1127,\n",
      "        5.1128, 5.1128, 5.1128, 5.1128, 5.1128, 5.1129, 5.1128, 5.1127, 5.1128,\n",
      "        5.1127, 5.1127, 5.1127, 5.1127, 5.1127, 5.1126, 5.1126, 5.1127, 5.1125,\n",
      "        5.1122, 5.1124, 5.1122, 5.1123, 5.1124, 5.1126, 5.1122, 5.1124, 5.1122,\n",
      "        5.1122, 5.1120, 5.1122, 5.1120, 5.1122, 5.1122, 5.1119, 5.1118, 5.1118,\n",
      "        5.1118, 5.1115, 5.1114, 5.1116, 5.1118, 5.1119, 5.1117, 5.1117, 5.1119,\n",
      "        5.1116, 5.1118, 5.1115, 5.1114, 5.1113, 5.1114, 5.1113, 5.1114, 5.1114,\n",
      "        5.1118, 5.1117, 5.1118, 5.1120, 5.1119, 5.1118, 5.1115, 5.1116, 5.1117,\n",
      "        5.1118, 5.1118, 5.1119], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.953286  [37324/5599865]\n",
      "average delta from current occupancy tensor([4.8546, 4.8545, 4.8546, 4.8546, 4.8546, 4.8545, 4.8544, 4.8546, 4.8543,\n",
      "        4.8545, 4.8544, 4.8545, 4.8544, 4.8545, 4.8545, 4.8545, 4.8544, 4.8544,\n",
      "        4.8545, 4.8548, 4.8545, 4.8546, 4.8545, 4.8544, 4.8545, 4.8545, 4.8545,\n",
      "        4.8546, 4.8545, 4.8545, 4.8545, 4.8545, 4.8545, 4.8546, 4.8547, 4.8546,\n",
      "        4.8546, 4.8546, 4.8546, 4.8547, 4.8546, 4.8546, 4.8547, 4.8546, 4.8546,\n",
      "        4.8546, 4.8546, 4.8547, 4.8546, 4.8545, 4.8545, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8546, 4.8548, 4.8548, 4.8547, 4.8546, 4.8547, 4.8547, 4.8547,\n",
      "        4.8547, 4.8549, 4.8548, 4.8548, 4.8548, 4.8549, 4.8548, 4.8547, 4.8546,\n",
      "        4.8547, 4.8546, 4.8547, 4.8546, 4.8546, 4.8545, 4.8547, 4.8546, 4.8546,\n",
      "        4.8547, 4.8548, 4.8548, 4.8546, 4.8547, 4.8548, 4.8546, 4.8545, 4.8544,\n",
      "        4.8544, 4.8541, 4.8539, 4.8542, 4.8543, 4.8543, 4.8543, 4.8544, 4.8545,\n",
      "        4.8543, 4.8545, 4.8543, 4.8542, 4.8542, 4.8543, 4.8542, 4.8542, 4.8543,\n",
      "        4.8546, 4.8546, 4.8547, 4.8546, 4.8545, 4.8546, 4.8547, 4.8547, 4.8546,\n",
      "        4.8546, 4.8547, 4.8546], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.561206  [49724/5599865]\n",
      "average delta from current occupancy tensor([4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323, 4.5323,\n",
      "        4.5323, 4.5323, 4.5323], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.914634  [62124/5599865]\n",
      "average delta from current occupancy tensor([4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918,\n",
      "        4.9918, 4.9918, 4.9918, 4.9918, 4.9919, 4.9919, 4.9918, 4.9918, 4.9918,\n",
      "        4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9917, 4.9918,\n",
      "        4.9917, 4.9918, 4.9917, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918,\n",
      "        4.9918, 4.9918, 4.9918, 4.9919, 4.9919, 4.9920, 4.9919, 4.9919, 4.9919,\n",
      "        4.9919, 4.9920, 4.9919, 4.9919, 4.9919, 4.9919, 4.9919, 4.9918, 4.9919,\n",
      "        4.9919, 4.9919, 4.9918, 4.9919, 4.9919, 4.9918, 4.9919, 4.9919, 4.9919,\n",
      "        4.9919, 4.9919, 4.9919, 4.9919, 4.9919, 4.9919, 4.9918, 4.9919, 4.9918,\n",
      "        4.9919, 4.9919, 4.9918, 4.9918, 4.9919, 4.9919, 4.9918, 4.9919, 4.9919,\n",
      "        4.9919, 4.9919, 4.9918, 4.9919, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918,\n",
      "        4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918, 4.9918,\n",
      "        4.9918, 4.9917, 4.9918, 4.9918, 4.9918, 4.9917, 4.9917, 4.9917, 4.9917,\n",
      "        4.9917, 4.9918, 4.9917, 4.9917, 4.9918, 4.9917, 4.9917, 4.9917, 4.9917,\n",
      "        4.9917, 4.9917, 4.9917], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.764441  [74524/5599865]\n",
      "average delta from current occupancy tensor([4.7660, 4.7661, 4.7660, 4.7660, 4.7661, 4.7661, 4.7661, 4.7660, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7660, 4.7661, 4.7660, 4.7660, 4.7660,\n",
      "        4.7660, 4.7661, 4.7660, 4.7661, 4.7660, 4.7661, 4.7661, 4.7661, 4.7660,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7660, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7660, 4.7661, 4.7660, 4.7660, 4.7660, 4.7660, 4.7660,\n",
      "        4.7660, 4.7660, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7660, 4.7659,\n",
      "        4.7660, 4.7659, 4.7659, 4.7659, 4.7660, 4.7659, 4.7659, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7661, 4.7660, 4.7659,\n",
      "        4.7660, 4.7659, 4.7660, 4.7660, 4.7659, 4.7660, 4.7660, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7660, 4.7661, 4.7661, 4.7660, 4.7660, 4.7659, 4.7660,\n",
      "        4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7660, 4.7659, 4.7659,\n",
      "        4.7660, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659, 4.7659,\n",
      "        4.7659, 4.7659, 4.7659], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.251184  [86924/5599865]\n",
      "average delta from current occupancy tensor([5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5242, 5.5242, 5.5243, 5.5242,\n",
      "        5.5242, 5.5243, 5.5242, 5.5242, 5.5242, 5.5242, 5.5243, 5.5242, 5.5242,\n",
      "        5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243,\n",
      "        5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243,\n",
      "        5.5243, 5.5243, 5.5243, 5.5243, 5.5242, 5.5242, 5.5242, 5.5243, 5.5242,\n",
      "        5.5242, 5.5242, 5.5242, 5.5243, 5.5242, 5.5242, 5.5243, 5.5243, 5.5242,\n",
      "        5.5243, 5.5243, 5.5242, 5.5243, 5.5243, 5.5242, 5.5242, 5.5243, 5.5243,\n",
      "        5.5243, 5.5243, 5.5242, 5.5243, 5.5242, 5.5242, 5.5243, 5.5243, 5.5242,\n",
      "        5.5242, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243, 5.5243,\n",
      "        5.5243, 5.5243, 5.5242, 5.5243, 5.5243, 5.5242, 5.5242, 5.5243, 5.5243,\n",
      "        5.5243, 5.5243, 5.5243, 5.5242, 5.5243, 5.5243, 5.5243, 5.5242, 5.5242,\n",
      "        5.5243, 5.5242, 5.5243, 5.5243, 5.5243, 5.5242, 5.5243, 5.5243, 5.5242,\n",
      "        5.5243, 5.5243, 5.5243, 5.5242, 5.5243, 5.5242, 5.5243, 5.5243, 5.5243,\n",
      "        5.5243, 5.5243, 5.5243], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.267721  [99324/5599865]\n",
      "average delta from current occupancy tensor([5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1614, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1614, 5.1613, 5.1613, 5.1613, 5.1613, 5.1614, 5.1613, 5.1614,\n",
      "        5.1613, 5.1613, 5.1614, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1614, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1614, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613, 5.1613,\n",
      "        5.1613, 5.1613, 5.1613], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.050954  [111724/5599865]\n",
      "average delta from current occupancy tensor([5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597, 5.9597,\n",
      "        5.9597, 5.9597, 5.9597], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.184499  [124124/5599865]\n",
      "average delta from current occupancy tensor([5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0809, 5.0808, 5.0808, 5.0808,\n",
      "        5.0808, 5.0809, 5.0808, 5.0808, 5.0809, 5.0809, 5.0809, 5.0808, 5.0809,\n",
      "        5.0810, 5.0810, 5.0809, 5.0809, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0809, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0809, 5.0810, 5.0810, 5.0811,\n",
      "        5.0810, 5.0809, 5.0810, 5.0808, 5.0810, 5.0808, 5.0808, 5.0809, 5.0808,\n",
      "        5.0808, 5.0808, 5.0808, 5.0809, 5.0808, 5.0809, 5.0809, 5.0809, 5.0809,\n",
      "        5.0810, 5.0810, 5.0811, 5.0811, 5.0811, 5.0811, 5.0811, 5.0810, 5.0810,\n",
      "        5.0811, 5.0811, 5.0810, 5.0810, 5.0810, 5.0811, 5.0811, 5.0810, 5.0810,\n",
      "        5.0809, 5.0809, 5.0808, 5.0808, 5.0808, 5.0808, 5.0808, 5.0809, 5.0808,\n",
      "        5.0809, 5.0809, 5.0810, 5.0809, 5.0810, 5.0810, 5.0811, 5.0810, 5.0811,\n",
      "        5.0810, 5.0810, 5.0810, 5.0811, 5.0811, 5.0810, 5.0810, 5.0810, 5.0810,\n",
      "        5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0810, 5.0809, 5.0809, 5.0809,\n",
      "        5.0809, 5.0809, 5.0809], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.270325  [136524/5599865]\n",
      "average delta from current occupancy tensor([5.3308, 5.3308, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3306, 5.3307, 5.3308, 5.3308, 5.3307, 5.3307,\n",
      "        5.3308, 5.3308, 5.3308, 5.3307, 5.3307, 5.3308, 5.3307, 5.3307, 5.3307,\n",
      "        5.3306, 5.3307, 5.3307, 5.3307, 5.3307, 5.3306, 5.3306, 5.3306, 5.3307,\n",
      "        5.3307, 5.3306, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3306, 5.3306, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3309, 5.3308, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3306, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307,\n",
      "        5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3307, 5.3308, 5.3307,\n",
      "        5.3308, 5.3308, 5.3308], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.559423  [148924/5599865]\n",
      "average delta from current occupancy tensor([5.6461, 5.6461, 5.6461, 5.6460, 5.6459, 5.6460, 5.6460, 5.6460, 5.6459,\n",
      "        5.6459, 5.6459, 5.6458, 5.6459, 5.6458, 5.6458, 5.6459, 5.6459, 5.6459,\n",
      "        5.6460, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459,\n",
      "        5.6459, 5.6460, 5.6460, 5.6460, 5.6460, 5.6460, 5.6459, 5.6459, 5.6459,\n",
      "        5.6460, 5.6460, 5.6460, 5.6458, 5.6458, 5.6460, 5.6458, 5.6460, 5.6460,\n",
      "        5.6459, 5.6459, 5.6458, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459, 5.6458,\n",
      "        5.6457, 5.6459, 5.6458, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459, 5.6459,\n",
      "        5.6459, 5.6459, 5.6460, 5.6459, 5.6460, 5.6459, 5.6459, 5.6459, 5.6458,\n",
      "        5.6458, 5.6459, 5.6458, 5.6458, 5.6458, 5.6458, 5.6457, 5.6457, 5.6458,\n",
      "        5.6458, 5.6459, 5.6458, 5.6458, 5.6458, 5.6457, 5.6456, 5.6456, 5.6457,\n",
      "        5.6456, 5.6456, 5.6456, 5.6456, 5.6456, 5.6456, 5.6456, 5.6456, 5.6457,\n",
      "        5.6456, 5.6456, 5.6457, 5.6457, 5.6456, 5.6457, 5.6458, 5.6458, 5.6458,\n",
      "        5.6459, 5.6459, 5.6460, 5.6457, 5.6457, 5.6456, 5.6457, 5.6458, 5.6457,\n",
      "        5.6456, 5.6457, 5.6458], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.615233  [161324/5599865]\n",
      "average delta from current occupancy tensor([4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6206, 4.6207, 4.6207,\n",
      "        4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6207, 4.6206,\n",
      "        4.6207, 4.6207, 4.6207, 4.6206, 4.6207, 4.6207, 4.6207, 4.6207, 4.6206,\n",
      "        4.6206, 4.6207, 4.6207, 4.6207, 4.6206, 4.6206, 4.6207, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6207,\n",
      "        4.6206, 4.6206, 4.6207, 4.6207, 4.6206, 4.6207, 4.6207, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6207, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6206, 4.6206, 4.6206, 4.6206, 4.6207, 4.6206, 4.6206, 4.6206, 4.6207,\n",
      "        4.6206, 4.6206, 4.6207, 4.6206, 4.6207, 4.6206, 4.6206, 4.6206, 4.6206,\n",
      "        4.6206, 4.6207, 4.6207], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.887359  [173724/5599865]\n",
      "average delta from current occupancy tensor([4.9657, 4.9656, 4.9658, 4.9656, 4.9656, 4.9656, 4.9655, 4.9656, 4.9656,\n",
      "        4.9657, 4.9656, 4.9655, 4.9655, 4.9655, 4.9657, 4.9656, 4.9655, 4.9654,\n",
      "        4.9657, 4.9656, 4.9655, 4.9654, 4.9655, 4.9656, 4.9658, 4.9658, 4.9656,\n",
      "        4.9656, 4.9656, 4.9656, 4.9656, 4.9655, 4.9655, 4.9656, 4.9657, 4.9655,\n",
      "        4.9654, 4.9655, 4.9656, 4.9656, 4.9656, 4.9655, 4.9657, 4.9656, 4.9656,\n",
      "        4.9656, 4.9657, 4.9656, 4.9657, 4.9657, 4.9658, 4.9659, 4.9657, 4.9657,\n",
      "        4.9656, 4.9656, 4.9656, 4.9655, 4.9654, 4.9654, 4.9655, 4.9654, 4.9654,\n",
      "        4.9654, 4.9654, 4.9655, 4.9654, 4.9654, 4.9654, 4.9654, 4.9655, 4.9657,\n",
      "        4.9656, 4.9656, 4.9656, 4.9658, 4.9656, 4.9656, 4.9656, 4.9657, 4.9656,\n",
      "        4.9657, 4.9656, 4.9656, 4.9654, 4.9654, 4.9655, 4.9654, 4.9655, 4.9653,\n",
      "        4.9654, 4.9654, 4.9653, 4.9653, 4.9653, 4.9654, 4.9654, 4.9654, 4.9653,\n",
      "        4.9653, 4.9653, 4.9654, 4.9653, 4.9656, 4.9655, 4.9654, 4.9654, 4.9654,\n",
      "        4.9654, 4.9653, 4.9656, 4.9655, 4.9656, 4.9656, 4.9657, 4.9656, 4.9656,\n",
      "        4.9656, 4.9657, 4.9657], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.418814  [186124/5599865]\n",
      "average delta from current occupancy tensor([5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3711, 5.3710, 5.3710, 5.3711, 5.3710, 5.3711, 5.3711, 5.3711,\n",
      "        5.3710, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711,\n",
      "        5.3710, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711, 5.3711,\n",
      "        5.3711, 5.3711, 5.3711, 5.3711, 5.3710, 5.3710, 5.3711, 5.3711, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3711,\n",
      "        5.3711, 5.3710, 5.3711, 5.3711, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710, 5.3710,\n",
      "        5.3710, 5.3710, 5.3710], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.510590  [198524/5599865]\n",
      "average delta from current occupancy tensor([4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2984, 4.2983, 4.2984,\n",
      "        4.2984, 4.2984, 4.2984, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2984,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2984, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983, 4.2983,\n",
      "        4.2983, 4.2983, 4.2983, 4.2984, 4.2984, 4.2984, 4.2984, 4.2984, 4.2985,\n",
      "        4.2988, 4.2989, 4.2984, 4.2984, 4.2984, 4.2984, 4.2983, 4.2984, 4.2983,\n",
      "        4.2984, 4.2983, 4.2983, 4.2984, 4.2987, 4.2984, 4.2983, 4.2983, 4.2984,\n",
      "        4.2983, 4.2983, 4.2983, 4.2983, 4.2984, 4.2984, 4.2984, 4.2983, 4.2983,\n",
      "        4.2983, 4.2984, 4.2983], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.515452  [210924/5599865]\n",
      "average delta from current occupancy tensor([4.5492, 4.5492, 4.5493, 4.5494, 4.5494, 4.5494, 4.5492, 4.5492, 4.5494,\n",
      "        4.5493, 4.5494, 4.5494, 4.5494, 4.5495, 4.5494, 4.5494, 4.5494, 4.5494,\n",
      "        4.5494, 4.5493, 4.5493, 4.5494, 4.5494, 4.5494, 4.5494, 4.5494, 4.5493,\n",
      "        4.5493, 4.5493, 4.5493, 4.5493, 4.5493, 4.5493, 4.5493, 4.5493, 4.5495,\n",
      "        4.5493, 4.5493, 4.5493, 4.5494, 4.5494, 4.5495, 4.5495, 4.5495, 4.5494,\n",
      "        4.5494, 4.5493, 4.5494, 4.5494, 4.5494, 4.5494, 4.5493, 4.5493, 4.5493,\n",
      "        4.5494, 4.5494, 4.5494, 4.5493, 4.5493, 4.5493, 4.5494, 4.5494, 4.5494,\n",
      "        4.5494, 4.5494, 4.5494, 4.5493, 4.5493, 4.5493, 4.5493, 4.5494, 4.5493,\n",
      "        4.5493, 4.5493, 4.5494, 4.5494, 4.5493, 4.5493, 4.5495, 4.5494, 4.5494,\n",
      "        4.5494, 4.5493, 4.5493, 4.5494, 4.5493, 4.5493, 4.5494, 4.5493, 4.5495,\n",
      "        4.5494, 4.5495, 4.5495, 4.5494, 4.5495, 4.5495, 4.5495, 4.5495, 4.5493,\n",
      "        4.5493, 4.5494, 4.5493, 4.5493, 4.5493, 4.5493, 4.5494, 4.5493, 4.5495,\n",
      "        4.5493, 4.5493, 4.5495, 4.5495, 4.5495, 4.5495, 4.5494, 4.5494, 4.5494,\n",
      "        4.5494, 4.5494, 4.5494], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.139898  [223324/5599865]\n",
      "average delta from current occupancy tensor([4.2091, 4.2090, 4.2093, 4.2091, 4.2094, 4.2095, 4.2091, 4.2094, 4.2095,\n",
      "        4.2095, 4.2096, 4.2092, 4.2094, 4.2091, 4.2092, 4.2092, 4.2092, 4.2091,\n",
      "        4.2092, 4.2089, 4.2088, 4.2089, 4.2087, 4.2089, 4.2088, 4.2089, 4.2087,\n",
      "        4.2085, 4.2083, 4.2084, 4.2087, 4.2088, 4.2088, 4.2087, 4.2088, 4.2086,\n",
      "        4.2088, 4.2087, 4.2089, 4.2091, 4.2092, 4.2090, 4.2093, 4.2092, 4.2094,\n",
      "        4.2092, 4.2092, 4.2091, 4.2092, 4.2091, 4.2092, 4.2092, 4.2093, 4.2094,\n",
      "        4.2094, 4.2096, 4.2097, 4.2095, 4.2093, 4.2094, 4.2091, 4.2090, 4.2091,\n",
      "        4.2094, 4.2092, 4.2091, 4.2090, 4.2091, 4.2090, 4.2089, 4.2090, 4.2090,\n",
      "        4.2090, 4.2091, 4.2089, 4.2088, 4.2088, 4.2089, 4.2087, 4.2088, 4.2084,\n",
      "        4.2087, 4.2088, 4.2089, 4.2088, 4.2089, 4.2089, 4.2089, 4.2090, 4.2088,\n",
      "        4.2087, 4.2087, 4.2085, 4.2084, 4.2083, 4.2085, 4.2087, 4.2088, 4.2091,\n",
      "        4.2090, 4.2091, 4.2090, 4.2090, 4.2089, 4.2091, 4.2090, 4.2090, 4.2090,\n",
      "        4.2091, 4.2089, 4.2090, 4.2092, 4.2093, 4.2092, 4.2092, 4.2089, 4.2088,\n",
      "        4.2089, 4.2090, 4.2088], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.915067  [235724/5599865]\n",
      "average delta from current occupancy tensor([5.0165, 5.0163, 5.0165, 5.0164, 5.0166, 5.0168, 5.0167, 5.0167, 5.0168,\n",
      "        5.0168, 5.0167, 5.0167, 5.0166, 5.0168, 5.0168, 5.0166, 5.0166, 5.0168,\n",
      "        5.0168, 5.0165, 5.0164, 5.0165, 5.0165, 5.0164, 5.0164, 5.0163, 5.0163,\n",
      "        5.0165, 5.0167, 5.0164, 5.0163, 5.0164, 5.0164, 5.0164, 5.0165, 5.0165,\n",
      "        5.0164, 5.0165, 5.0165, 5.0167, 5.0166, 5.0165, 5.0165, 5.0164, 5.0168,\n",
      "        5.0168, 5.0165, 5.0164, 5.0167, 5.0167, 5.0167, 5.0166, 5.0166, 5.0167,\n",
      "        5.0167, 5.0167, 5.0167, 5.0167, 5.0165, 5.0165, 5.0165, 5.0165, 5.0165,\n",
      "        5.0164, 5.0164, 5.0164, 5.0167, 5.0167, 5.0168, 5.0168, 5.0168, 5.0167,\n",
      "        5.0167, 5.0166, 5.0166, 5.0166, 5.0167, 5.0166, 5.0167, 5.0167, 5.0166,\n",
      "        5.0166, 5.0168, 5.0167, 5.0167, 5.0168, 5.0169, 5.0169, 5.0168, 5.0166,\n",
      "        5.0166, 5.0166, 5.0166, 5.0165, 5.0166, 5.0165, 5.0167, 5.0169, 5.0165,\n",
      "        5.0165, 5.0164, 5.0166, 5.0164, 5.0167, 5.0164, 5.0166, 5.0165, 5.0165,\n",
      "        5.0167, 5.0163, 5.0163, 5.0167, 5.0164, 5.0167, 5.0164, 5.0164, 5.0163,\n",
      "        5.0163, 5.0164, 5.0164], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.598045  [248124/5599865]\n",
      "average delta from current occupancy tensor([4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5079, 4.5079, 4.5078,\n",
      "        4.5079, 4.5079, 4.5079, 4.5079, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5079,\n",
      "        4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078, 4.5078,\n",
      "        4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5078,\n",
      "        4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5078, 4.5078, 4.5077, 4.5077,\n",
      "        4.5077, 4.5077, 4.5077, 4.5077, 4.5076, 4.5076, 4.5077, 4.5077, 4.5077,\n",
      "        4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077,\n",
      "        4.5077, 4.5078, 4.5077, 4.5078, 4.5077, 4.5076, 4.5077, 4.5077, 4.5077,\n",
      "        4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077, 4.5076, 4.5077,\n",
      "        4.5077, 4.5077, 4.5077, 4.5076, 4.5077, 4.5077, 4.5077, 4.5077, 4.5077,\n",
      "        4.5077, 4.5077, 4.5077, 4.5076, 4.5076, 4.5076, 4.5076, 4.5076, 4.5075,\n",
      "        4.5076, 4.5076, 4.5076], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.017256  [260524/5599865]\n",
      "average delta from current occupancy tensor([5.7015, 5.7015, 5.7015, 5.7016, 5.7016, 5.7015, 5.7015, 5.7015, 5.7014,\n",
      "        5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7014, 5.7014, 5.7015,\n",
      "        5.7016, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015,\n",
      "        5.7014, 5.7014, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015,\n",
      "        5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7014,\n",
      "        5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015, 5.7015,\n",
      "        5.7015, 5.7015, 5.7014, 5.7014, 5.7014, 5.7014, 5.7014, 5.7015, 5.7014,\n",
      "        5.7014, 5.7014, 5.7014, 5.7014, 5.7014, 5.7014, 5.7015, 5.7014, 5.7015,\n",
      "        5.7015, 5.7015, 5.7014, 5.7014, 5.7013, 5.7013, 5.7014, 5.7014, 5.7014,\n",
      "        5.7014, 5.7014, 5.7014, 5.7014, 5.7014, 5.7016, 5.7016, 5.7016, 5.7016,\n",
      "        5.7016, 5.7016, 5.7016, 5.7016, 5.7016, 5.7015, 5.7015, 5.7013, 5.7016,\n",
      "        5.7016, 5.7016, 5.7016, 5.7013, 5.7013, 5.7014, 5.7013, 5.7013, 5.7014,\n",
      "        5.7014, 5.7014, 5.7016, 5.7014, 5.7014, 5.7014, 5.7015, 5.7014, 5.7014,\n",
      "        5.7015, 5.7015, 5.7016], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.280700  [272924/5599865]\n",
      "average delta from current occupancy tensor([4.2416, 4.2416, 4.2417, 4.2417, 4.2417, 4.2416, 4.2417, 4.2417, 4.2417,\n",
      "        4.2417, 4.2417, 4.2417, 4.2417, 4.2417, 4.2417, 4.2417, 4.2418, 4.2417,\n",
      "        4.2418, 4.2417, 4.2417, 4.2418, 4.2418, 4.2417, 4.2417, 4.2417, 4.2417,\n",
      "        4.2418, 4.2417, 4.2417, 4.2417, 4.2418, 4.2417, 4.2416, 4.2416, 4.2418,\n",
      "        4.2417, 4.2417, 4.2417, 4.2416, 4.2416, 4.2416, 4.2416, 4.2416, 4.2416,\n",
      "        4.2416, 4.2416, 4.2416, 4.2417, 4.2417, 4.2417, 4.2417, 4.2417, 4.2417,\n",
      "        4.2416, 4.2417, 4.2417, 4.2417, 4.2418, 4.2418, 4.2418, 4.2418, 4.2418,\n",
      "        4.2417, 4.2417, 4.2417, 4.2418, 4.2417, 4.2417, 4.2417, 4.2417, 4.2417,\n",
      "        4.2416, 4.2417, 4.2416, 4.2416, 4.2416, 4.2417, 4.2417, 4.2417, 4.2417,\n",
      "        4.2416, 4.2418, 4.2418, 4.2417, 4.2418, 4.2417, 4.2418, 4.2418, 4.2417,\n",
      "        4.2417, 4.2418, 4.2416, 4.2418, 4.2417, 4.2417, 4.2416, 4.2416, 4.2416,\n",
      "        4.2416, 4.2416, 4.2416, 4.2416, 4.2416, 4.2416, 4.2416, 4.2416, 4.2416,\n",
      "        4.2417, 4.2416, 4.2415, 4.2417, 4.2416, 4.2417, 4.2417, 4.2418, 4.2417,\n",
      "        4.2417, 4.2417, 4.2416], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.678276  [285324/5599865]\n",
      "average delta from current occupancy tensor([4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985,\n",
      "        4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985,\n",
      "        4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7986,\n",
      "        4.7985, 4.7986, 4.7986, 4.7986, 4.7986, 4.7986, 4.7986, 4.7985, 4.7986,\n",
      "        4.7985, 4.7985, 4.7985, 4.7985, 4.7986, 4.7985, 4.7985, 4.7985, 4.7986,\n",
      "        4.7985, 4.7986, 4.7985, 4.7986, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985,\n",
      "        4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7986, 4.7986, 4.7986,\n",
      "        4.7986, 4.7986, 4.7986, 4.7985, 4.7986, 4.7986, 4.7986, 4.7986, 4.7986,\n",
      "        4.7985, 4.7986, 4.7986, 4.7986, 4.7986, 4.7985, 4.7986, 4.7985, 4.7985,\n",
      "        4.7986, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985,\n",
      "        4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7986, 4.7985, 4.7985,\n",
      "        4.7986, 4.7985, 4.7986, 4.7985, 4.7985, 4.7986, 4.7986, 4.7986, 4.7986,\n",
      "        4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7985, 4.7986, 4.7985,\n",
      "        4.7986, 4.7986, 4.7985], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.376492  [297724/5599865]\n",
      "average delta from current occupancy tensor([4.6373, 4.6372, 4.6373, 4.6373, 4.6371, 4.6373, 4.6372, 4.6372, 4.6372,\n",
      "        4.6372, 4.6373, 4.6373, 4.6373, 4.6374, 4.6373, 4.6372, 4.6372, 4.6373,\n",
      "        4.6373, 4.6373, 4.6372, 4.6372, 4.6372, 4.6372, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6372, 4.6373, 4.6373, 4.6372, 4.6373, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6372, 4.6372, 4.6372, 4.6372, 4.6373, 4.6373, 4.6373, 4.6372,\n",
      "        4.6373, 4.6372, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6374, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6373, 4.6373, 4.6373, 4.6372, 4.6372, 4.6373, 4.6372, 4.6373,\n",
      "        4.6372, 4.6372, 4.6373, 4.6372, 4.6373, 4.6373, 4.6372, 4.6373, 4.6373,\n",
      "        4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373,\n",
      "        4.6373, 4.6373, 4.6374, 4.6373, 4.6373, 4.6373, 4.6374, 4.6373, 4.6373,\n",
      "        4.6373, 4.6373, 4.6373], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.960676  [310124/5599865]\n",
      "average delta from current occupancy tensor([4.9762, 4.9762, 4.9763, 4.9763, 4.9760, 4.9762, 4.9760, 4.9760, 4.9761,\n",
      "        4.9760, 4.9762, 4.9761, 4.9761, 4.9762, 4.9760, 4.9760, 4.9760, 4.9761,\n",
      "        4.9761, 4.9762, 4.9761, 4.9760, 4.9761, 4.9763, 4.9764, 4.9764, 4.9763,\n",
      "        4.9765, 4.9763, 4.9763, 4.9763, 4.9763, 4.9766, 4.9766, 4.9766, 4.9766,\n",
      "        4.9765, 4.9765, 4.9765, 4.9764, 4.9764, 4.9766, 4.9766, 4.9765, 4.9763,\n",
      "        4.9765, 4.9765, 4.9766, 4.9765, 4.9767, 4.9766, 4.9765, 4.9767, 4.9765,\n",
      "        4.9766, 4.9765, 4.9766, 4.9767, 4.9767, 4.9768, 4.9767, 4.9769, 4.9769,\n",
      "        4.9768, 4.9768, 4.9767, 4.9767, 4.9766, 4.9767, 4.9766, 4.9766, 4.9766,\n",
      "        4.9768, 4.9765, 4.9765, 4.9766, 4.9766, 4.9764, 4.9763, 4.9765, 4.9764,\n",
      "        4.9766, 4.9764, 4.9764, 4.9767, 4.9765, 4.9763, 4.9767, 4.9763, 4.9765,\n",
      "        4.9766, 4.9765, 4.9766, 4.9765, 4.9766, 4.9766, 4.9763, 4.9765, 4.9764,\n",
      "        4.9763, 4.9764, 4.9763, 4.9762, 4.9763, 4.9761, 4.9762, 4.9763, 4.9764,\n",
      "        4.9764, 4.9765, 4.9765, 4.9764, 4.9764, 4.9765, 4.9765, 4.9765, 4.9765,\n",
      "        4.9766, 4.9765, 4.9766], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.017081  [322524/5599865]\n",
      "average delta from current occupancy tensor([4.9173, 4.9174, 4.9176, 4.9176, 4.9176, 4.9179, 4.9176, 4.9179, 4.9177,\n",
      "        4.9177, 4.9179, 4.9179, 4.9176, 4.9175, 4.9177, 4.9176, 4.9174, 4.9176,\n",
      "        4.9180, 4.9176, 4.9175, 4.9174, 4.9179, 4.9174, 4.9172, 4.9175, 4.9176,\n",
      "        4.9173, 4.9175, 4.9174, 4.9174, 4.9175, 4.9170, 4.9170, 4.9174, 4.9171,\n",
      "        4.9172, 4.9172, 4.9172, 4.9170, 4.9172, 4.9168, 4.9169, 4.9169, 4.9169,\n",
      "        4.9169, 4.9168, 4.9167, 4.9168, 4.9173, 4.9168, 4.9168, 4.9171, 4.9168,\n",
      "        4.9171, 4.9171, 4.9173, 4.9169, 4.9169, 4.9169, 4.9169, 4.9170, 4.9171,\n",
      "        4.9177, 4.9171, 4.9173, 4.9170, 4.9169, 4.9171, 4.9171, 4.9170, 4.9171,\n",
      "        4.9174, 4.9173, 4.9171, 4.9172, 4.9177, 4.9172, 4.9171, 4.9170, 4.9171,\n",
      "        4.9173, 4.9170, 4.9169, 4.9173, 4.9175, 4.9170, 4.9173, 4.9171, 4.9174,\n",
      "        4.9173, 4.9176, 4.9174, 4.9172, 4.9170, 4.9170, 4.9171, 4.9167, 4.9171,\n",
      "        4.9168, 4.9169, 4.9174, 4.9172, 4.9172, 4.9175, 4.9177, 4.9177, 4.9170,\n",
      "        4.9168, 4.9175, 4.9176, 4.9170, 4.9170, 4.9170, 4.9176, 4.9171, 4.9172,\n",
      "        4.9170, 4.9172, 4.9177], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.046819  [334924/5599865]\n",
      "average delta from current occupancy tensor([5.1211, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1211,\n",
      "        5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210,\n",
      "        5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1211, 5.1211, 5.1211,\n",
      "        5.1211, 5.1211, 5.1211, 5.1211, 5.1210, 5.1211, 5.1211, 5.1211, 5.1211,\n",
      "        5.1210, 5.1210, 5.1211, 5.1211, 5.1211, 5.1211, 5.1211, 5.1211, 5.1211,\n",
      "        5.1212, 5.1212, 5.1211, 5.1212, 5.1212, 5.1211, 5.1212, 5.1211, 5.1211,\n",
      "        5.1211, 5.1211, 5.1212, 5.1212, 5.1211, 5.1211, 5.1210, 5.1211, 5.1211,\n",
      "        5.1210, 5.1211, 5.1211, 5.1212, 5.1211, 5.1211, 5.1211, 5.1211, 5.1210,\n",
      "        5.1210, 5.1211, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210,\n",
      "        5.1210, 5.1211, 5.1210, 5.1211, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210,\n",
      "        5.1211, 5.1212, 5.1211, 5.1212, 5.1211, 5.1210, 5.1211, 5.1211, 5.1211,\n",
      "        5.1211, 5.1211, 5.1212, 5.1212, 5.1210, 5.1211, 5.1211, 5.1210, 5.1210,\n",
      "        5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210, 5.1210,\n",
      "        5.1210, 5.1210, 5.1210], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.205570  [347324/5599865]\n",
      "average delta from current occupancy tensor([5.1938, 5.1937, 5.1938, 5.1937, 5.1937, 5.1938, 5.1937, 5.1938, 5.1937,\n",
      "        5.1937, 5.1937, 5.1937, 5.1938, 5.1938, 5.1939, 5.1939, 5.1939, 5.1938,\n",
      "        5.1938, 5.1939, 5.1939, 5.1939, 5.1940, 5.1940, 5.1940, 5.1939, 5.1939,\n",
      "        5.1939, 5.1939, 5.1940, 5.1939, 5.1939, 5.1940, 5.1940, 5.1941, 5.1940,\n",
      "        5.1940, 5.1940, 5.1941, 5.1940, 5.1939, 5.1940, 5.1940, 5.1940, 5.1940,\n",
      "        5.1939, 5.1940, 5.1939, 5.1939, 5.1939, 5.1939, 5.1939, 5.1939, 5.1939,\n",
      "        5.1939, 5.1939, 5.1939, 5.1939, 5.1939, 5.1940, 5.1940, 5.1940, 5.1940,\n",
      "        5.1939, 5.1939, 5.1939, 5.1939, 5.1940, 5.1939, 5.1939, 5.1939, 5.1940,\n",
      "        5.1940, 5.1941, 5.1941, 5.1941, 5.1940, 5.1940, 5.1941, 5.1941, 5.1941,\n",
      "        5.1940, 5.1939, 5.1939, 5.1939, 5.1939, 5.1940, 5.1939, 5.1939, 5.1938,\n",
      "        5.1939, 5.1939, 5.1939, 5.1941, 5.1940, 5.1941, 5.1941, 5.1940, 5.1940,\n",
      "        5.1940, 5.1940, 5.1939, 5.1939, 5.1939, 5.1939, 5.1940, 5.1941, 5.1941,\n",
      "        5.1940, 5.1940, 5.1940, 5.1940, 5.1940, 5.1941, 5.1940, 5.1941, 5.1940,\n",
      "        5.1939, 5.1940, 5.1939], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.342203  [359724/5599865]\n",
      "average delta from current occupancy tensor([5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2901, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2901, 5.2902, 5.2902, 5.2901, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2901, 5.2901, 5.2901, 5.2901, 5.2901, 5.2901, 5.2901, 5.2902,\n",
      "        5.2901, 5.2902, 5.2901, 5.2901, 5.2901, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2901, 5.2901, 5.2901, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2902, 5.2902, 5.2901, 5.2901, 5.2901, 5.2902, 5.2901,\n",
      "        5.2901, 5.2901, 5.2901, 5.2901, 5.2901, 5.2901, 5.2901, 5.2902, 5.2902,\n",
      "        5.2902, 5.2902, 5.2901], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.644133  [372124/5599865]\n",
      "average delta from current occupancy tensor([4.7172, 4.7170, 4.7172, 4.7172, 4.7170, 4.7172, 4.7173, 4.7171, 4.7170,\n",
      "        4.7171, 4.7173, 4.7170, 4.7171, 4.7171, 4.7171, 4.7171, 4.7171, 4.7171,\n",
      "        4.7171, 4.7170, 4.7170, 4.7170, 4.7170, 4.7170, 4.7171, 4.7171, 4.7171,\n",
      "        4.7171, 4.7172, 4.7171, 4.7170, 4.7170, 4.7171, 4.7171, 4.7173, 4.7172,\n",
      "        4.7172, 4.7171, 4.7172, 4.7171, 4.7171, 4.7171, 4.7171, 4.7170, 4.7171,\n",
      "        4.7172, 4.7171, 4.7172, 4.7173, 4.7171, 4.7173, 4.7172, 4.7169, 4.7172,\n",
      "        4.7171, 4.7173, 4.7172, 4.7171, 4.7173, 4.7171, 4.7171, 4.7172, 4.7170,\n",
      "        4.7172, 4.7171, 4.7171, 4.7171, 4.7171, 4.7171, 4.7171, 4.7171, 4.7170,\n",
      "        4.7170, 4.7170, 4.7171, 4.7171, 4.7171, 4.7172, 4.7171, 4.7171, 4.7171,\n",
      "        4.7171, 4.7170, 4.7170, 4.7171, 4.7171, 4.7172, 4.7172, 4.7172, 4.7172,\n",
      "        4.7173, 4.7172, 4.7173, 4.7174, 4.7172, 4.7174, 4.7172, 4.7171, 4.7173,\n",
      "        4.7171, 4.7171, 4.7172, 4.7172, 4.7172, 4.7173, 4.7173, 4.7173, 4.7173,\n",
      "        4.7175, 4.7174, 4.7174, 4.7175, 4.7174, 4.7174, 4.7175, 4.7174, 4.7174,\n",
      "        4.7173, 4.7173, 4.7171], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.452192  [384524/5599865]\n",
      "average delta from current occupancy tensor([5.4201, 5.4201, 5.4201, 5.4201, 5.4202, 5.4201, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4200, 5.4200, 5.4200, 5.4201, 5.4200, 5.4201, 5.4200, 5.4201,\n",
      "        5.4200, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200, 5.4201, 5.4201, 5.4200,\n",
      "        5.4201, 5.4201, 5.4200, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4200, 5.4200,\n",
      "        5.4201, 5.4200, 5.4200, 5.4201, 5.4200, 5.4200, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4201, 5.4201, 5.4201, 5.4201, 5.4200, 5.4201, 5.4201, 5.4201,\n",
      "        5.4201, 5.4201, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200,\n",
      "        5.4200, 5.4199, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200, 5.4200,\n",
      "        5.4199, 5.4200, 5.4200, 5.4200, 5.4200, 5.4199, 5.4199, 5.4200, 5.4199,\n",
      "        5.4199, 5.4200, 5.4200, 5.4200, 5.4199, 5.4200, 5.4200, 5.4200, 5.4200,\n",
      "        5.4200, 5.4200, 5.4200, 5.4200, 5.4201, 5.4201, 5.4201, 5.4202, 5.4202,\n",
      "        5.4202, 5.4201, 5.4202], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.376778  [396924/5599865]\n",
      "average delta from current occupancy tensor([4.4355, 4.4356, 4.4356, 4.4356, 4.4355, 4.4356, 4.4356, 4.4355, 4.4356,\n",
      "        4.4356, 4.4356, 4.4356, 4.4355, 4.4356, 4.4356, 4.4356, 4.4356, 4.4356,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4356, 4.4356, 4.4356,\n",
      "        4.4356, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4356, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4356, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355, 4.4355,\n",
      "        4.4355, 4.4355, 4.4355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.125642  [409324/5599865]\n",
      "average delta from current occupancy tensor([4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9034, 4.9033, 4.9033, 4.9033, 4.9034, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9034, 4.9033, 4.9034, 4.9034, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033, 4.9033,\n",
      "        4.9033, 4.9033, 4.9033], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.993592  [421724/5599865]\n",
      "average delta from current occupancy tensor([4.9917, 4.9918, 4.9918, 4.9917, 4.9921, 4.9919, 4.9919, 4.9920, 4.9919,\n",
      "        4.9918, 4.9919, 4.9921, 4.9919, 4.9918, 4.9919, 4.9919, 4.9919, 4.9921,\n",
      "        4.9921, 4.9921, 4.9922, 4.9923, 4.9921, 4.9922, 4.9919, 4.9919, 4.9921,\n",
      "        4.9921, 4.9922, 4.9919, 4.9919, 4.9919, 4.9919, 4.9921, 4.9922, 4.9921,\n",
      "        4.9919, 4.9920, 4.9921, 4.9919, 4.9921, 4.9922, 4.9921, 4.9922, 4.9921,\n",
      "        4.9922, 4.9920, 4.9921, 4.9917, 4.9917, 4.9917, 4.9918, 4.9918, 4.9918,\n",
      "        4.9916, 4.9917, 4.9918, 4.9919, 4.9922, 4.9922, 4.9921, 4.9922, 4.9921,\n",
      "        4.9919, 4.9919, 4.9918, 4.9916, 4.9917, 4.9917, 4.9918, 4.9917, 4.9919,\n",
      "        4.9920, 4.9918, 4.9917, 4.9918, 4.9919, 4.9921, 4.9919, 4.9918, 4.9919,\n",
      "        4.9918, 4.9917, 4.9917, 4.9917, 4.9917, 4.9919, 4.9918, 4.9917, 4.9919,\n",
      "        4.9921, 4.9918, 4.9921, 4.9922, 4.9922, 4.9923, 4.9921, 4.9922, 4.9923,\n",
      "        4.9922, 4.9922, 4.9922, 4.9921, 4.9922, 4.9920, 4.9922, 4.9922, 4.9919,\n",
      "        4.9920, 4.9919, 4.9919, 4.9921, 4.9921, 4.9920, 4.9921, 4.9923, 4.9921,\n",
      "        4.9921, 4.9921, 4.9923], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.933531  [434124/5599865]\n",
      "average delta from current occupancy tensor([5.1772, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1772, 5.1772, 5.1771,\n",
      "        5.1772, 5.1772, 5.1772, 5.1774, 5.1773, 5.1773, 5.1774, 5.1773, 5.1772,\n",
      "        5.1771, 5.1772, 5.1772, 5.1772, 5.1773, 5.1771, 5.1772, 5.1773, 5.1772,\n",
      "        5.1772, 5.1772, 5.1772, 5.1772, 5.1772, 5.1772, 5.1772, 5.1772, 5.1771,\n",
      "        5.1772, 5.1772, 5.1772, 5.1772, 5.1772, 5.1772, 5.1773, 5.1773, 5.1773,\n",
      "        5.1774, 5.1773, 5.1773, 5.1773, 5.1772, 5.1772, 5.1772, 5.1772, 5.1773,\n",
      "        5.1773, 5.1773, 5.1774, 5.1774, 5.1773, 5.1773, 5.1774, 5.1773, 5.1773,\n",
      "        5.1773, 5.1772, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1774,\n",
      "        5.1774, 5.1774, 5.1773, 5.1774, 5.1774, 5.1774, 5.1772, 5.1773, 5.1773,\n",
      "        5.1773, 5.1773, 5.1774, 5.1774, 5.1773, 5.1773, 5.1773, 5.1773, 5.1773,\n",
      "        5.1774, 5.1773, 5.1773, 5.1773, 5.1772, 5.1773, 5.1773, 5.1772, 5.1774,\n",
      "        5.1774, 5.1773, 5.1774, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1773,\n",
      "        5.1773, 5.1772, 5.1773, 5.1773, 5.1773, 5.1773, 5.1774, 5.1774, 5.1774,\n",
      "        5.1773, 5.1773, 5.1773], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.304129  [446524/5599865]\n",
      "average delta from current occupancy tensor([5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0971, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0971, 5.0971, 5.0971, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0971, 5.0972,\n",
      "        5.0972, 5.0972, 5.0971, 5.0972, 5.0972, 5.0971, 5.0971, 5.0971, 5.0972,\n",
      "        5.0972, 5.0971, 5.0971, 5.0972, 5.0971, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972, 5.0971, 5.0972, 5.0972, 5.0972, 5.0971, 5.0972,\n",
      "        5.0972, 5.0971, 5.0972, 5.0971, 5.0972, 5.0972, 5.0971, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0973, 5.0972, 5.0973, 5.0972, 5.0972, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0973, 5.0972, 5.0972, 5.0973, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972, 5.0973, 5.0972, 5.0972, 5.0973, 5.0972, 5.0973,\n",
      "        5.0973, 5.0973, 5.0972, 5.0972, 5.0972, 5.0973, 5.0972, 5.0972, 5.0972,\n",
      "        5.0972, 5.0972, 5.0972], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.901051  [458924/5599865]\n",
      "average delta from current occupancy tensor([4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145,\n",
      "        4.8145, 4.8145, 4.8145, 4.8145, 4.8146, 4.8146, 4.8145, 4.8145, 4.8146,\n",
      "        4.8146, 4.8145, 4.8146, 4.8147, 4.8148, 4.8145, 4.8146, 4.8147, 4.8145,\n",
      "        4.8145, 4.8147, 4.8145, 4.8145, 4.8147, 4.8145, 4.8146, 4.8145, 4.8145,\n",
      "        4.8145, 4.8147, 4.8147, 4.8145, 4.8149, 4.8147, 4.8147, 4.8147, 4.8145,\n",
      "        4.8145, 4.8146, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145,\n",
      "        4.8144, 4.8145, 4.8145, 4.8146, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145,\n",
      "        4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8144,\n",
      "        4.8145, 4.8145, 4.8144, 4.8144, 4.8144, 4.8144, 4.8145, 4.8144, 4.8145,\n",
      "        4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145, 4.8145,\n",
      "        4.8145, 4.8145, 4.8145, 4.8144, 4.8145, 4.8144, 4.8144, 4.8146, 4.8146,\n",
      "        4.8145, 4.8145, 4.8147, 4.8145, 4.8145, 4.8146, 4.8145, 4.8145, 4.8145,\n",
      "        4.8145, 4.8145, 4.8146, 4.8146, 4.8147, 4.8146, 4.8147, 4.8148, 4.8146,\n",
      "        4.8150, 4.8149, 4.8151], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 6.014697  [471324/5599865]\n",
      "average delta from current occupancy tensor([5.8951, 5.8950, 5.8949, 5.8950, 5.8950, 5.8957, 5.8949, 5.8956, 5.8958,\n",
      "        5.8954, 5.8957, 5.8955, 5.8954, 5.8955, 5.8951, 5.8955, 5.8951, 5.8956,\n",
      "        5.8953, 5.8951, 5.8950, 5.8954, 5.8955, 5.8956, 5.8952, 5.8951, 5.8950,\n",
      "        5.8950, 5.8950, 5.8950, 5.8953, 5.8956, 5.8956, 5.8955, 5.8958, 5.8955,\n",
      "        5.8953, 5.8951, 5.8957, 5.8952, 5.8956, 5.8951, 5.8951, 5.8952, 5.8952,\n",
      "        5.8953, 5.8952, 5.8953, 5.8952, 5.8954, 5.8952, 5.8950, 5.8951, 5.8950,\n",
      "        5.8951, 5.8952, 5.8951, 5.8949, 5.8951, 5.8951, 5.8954, 5.8951, 5.8951,\n",
      "        5.8952, 5.8951, 5.8950, 5.8950, 5.8950, 5.8951, 5.8950, 5.8951, 5.8950,\n",
      "        5.8954, 5.8950, 5.8952, 5.8953, 5.8954, 5.8959, 5.8954, 5.8954, 5.8958,\n",
      "        5.8951, 5.8952, 5.8951, 5.8956, 5.8956, 5.8955, 5.8956, 5.8954, 5.8956,\n",
      "        5.8958, 5.8953, 5.8955, 5.8953, 5.8951, 5.8955, 5.8950, 5.8956, 5.8960,\n",
      "        5.8958, 5.8958, 5.8960, 5.8960, 5.8953, 5.8957, 5.8955, 5.8954, 5.8958,\n",
      "        5.8956, 5.8957, 5.8957, 5.8955, 5.8956, 5.8958, 5.8959, 5.8959, 5.8957,\n",
      "        5.8960, 5.8958, 5.8961], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.956225  [483724/5599865]\n",
      "average delta from current occupancy tensor([4.8469, 4.8469, 4.8470, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8468, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8468, 4.8469, 4.8469, 4.8468,\n",
      "        4.8468, 4.8468, 4.8469, 4.8469, 4.8468, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8468, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8468,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8468, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8470, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469, 4.8469,\n",
      "        4.8469, 4.8470, 4.8470, 4.8469, 4.8470, 4.8469, 4.8470, 4.8469, 4.8469,\n",
      "        4.8469, 4.8469, 4.8469], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.188186  [496124/5599865]\n",
      "average delta from current occupancy tensor([5.2663, 5.2664, 5.2664, 5.2664, 5.2666, 5.2664, 5.2664, 5.2664, 5.2664,\n",
      "        5.2664, 5.2664, 5.2663, 5.2664, 5.2663, 5.2663, 5.2664, 5.2665, 5.2666,\n",
      "        5.2665, 5.2666, 5.2667, 5.2664, 5.2664, 5.2663, 5.2665, 5.2665, 5.2663,\n",
      "        5.2663, 5.2663, 5.2664, 5.2664, 5.2664, 5.2664, 5.2663, 5.2663, 5.2664,\n",
      "        5.2664, 5.2663, 5.2663, 5.2663, 5.2664, 5.2665, 5.2663, 5.2664, 5.2664,\n",
      "        5.2664, 5.2665, 5.2664, 5.2664, 5.2664, 5.2664, 5.2663, 5.2663, 5.2664,\n",
      "        5.2664, 5.2663, 5.2664, 5.2663, 5.2665, 5.2663, 5.2663, 5.2664, 5.2664,\n",
      "        5.2665, 5.2664, 5.2665, 5.2664, 5.2664, 5.2664, 5.2664, 5.2663, 5.2663,\n",
      "        5.2664, 5.2665, 5.2664, 5.2664, 5.2663, 5.2665, 5.2664, 5.2664, 5.2664,\n",
      "        5.2665, 5.2664, 5.2665, 5.2665, 5.2664, 5.2664, 5.2664, 5.2664, 5.2665,\n",
      "        5.2664, 5.2664, 5.2664, 5.2664, 5.2665, 5.2664, 5.2664, 5.2664, 5.2665,\n",
      "        5.2664, 5.2664, 5.2664, 5.2664, 5.2664, 5.2663, 5.2664, 5.2664, 5.2664,\n",
      "        5.2664, 5.2664, 5.2663, 5.2664, 5.2664, 5.2664, 5.2662, 5.2663, 5.2664,\n",
      "        5.2663, 5.2663, 5.2664], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.897912  [508524/5599865]\n",
      "average delta from current occupancy tensor([4.7503, 4.7502, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7502, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7502,\n",
      "        4.7502, 4.7503, 4.7502, 4.7502, 4.7502, 4.7503, 4.7503, 4.7502, 4.7502,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7502, 4.7502, 4.7503, 4.7502, 4.7502, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7502, 4.7503, 4.7502, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7502, 4.7502, 4.7503, 4.7502, 4.7503, 4.7502, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7502, 4.7502, 4.7503, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503, 4.7503, 4.7503, 4.7504, 4.7503, 4.7503, 4.7503,\n",
      "        4.7503, 4.7503, 4.7503], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.888195  [520924/5599865]\n",
      "average delta from current occupancy tensor([5.6376, 5.6377, 5.6377, 5.6376, 5.6379, 5.6376, 5.6377, 5.6376, 5.6376,\n",
      "        5.6377, 5.6376, 5.6376, 5.6380, 5.6378, 5.6379, 5.6379, 5.6382, 5.6378,\n",
      "        5.6378, 5.6376, 5.6377, 5.6378, 5.6376, 5.6377, 5.6377, 5.6377, 5.6379,\n",
      "        5.6377, 5.6375, 5.6376, 5.6381, 5.6376, 5.6376, 5.6377, 5.6382, 5.6380,\n",
      "        5.6380, 5.6376, 5.6379, 5.6379, 5.6380, 5.6380, 5.6381, 5.6381, 5.6381,\n",
      "        5.6380, 5.6380, 5.6381, 5.6381, 5.6382, 5.6383, 5.6380, 5.6378, 5.6376,\n",
      "        5.6379, 5.6380, 5.6383, 5.6384, 5.6384, 5.6382, 5.6383, 5.6382, 5.6387,\n",
      "        5.6387, 5.6388, 5.6387, 5.6385, 5.6386, 5.6386, 5.6382, 5.6380, 5.6385,\n",
      "        5.6388, 5.6387, 5.6384, 5.6382, 5.6384, 5.6387, 5.6386, 5.6385, 5.6386,\n",
      "        5.6386, 5.6385, 5.6387, 5.6388, 5.6387, 5.6388, 5.6385, 5.6386, 5.6386,\n",
      "        5.6383, 5.6383, 5.6383, 5.6382, 5.6382, 5.6386, 5.6381, 5.6382, 5.6380,\n",
      "        5.6381, 5.6383, 5.6381, 5.6389, 5.6387, 5.6381, 5.6380, 5.6378, 5.6375,\n",
      "        5.6382, 5.6380, 5.6380, 5.6378, 5.6378, 5.6378, 5.6378, 5.6377, 5.6376,\n",
      "        5.6379, 5.6376, 5.6376], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.438009  [533324/5599865]\n",
      "average delta from current occupancy tensor([5.4034, 5.4033, 5.4034, 5.4032, 5.4033, 5.4033, 5.4033, 5.4035, 5.4033,\n",
      "        5.4034, 5.4032, 5.4032, 5.4033, 5.4032, 5.4033, 5.4033, 5.4034, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4033, 5.4032, 5.4032, 5.4033, 5.4034, 5.4032,\n",
      "        5.4034, 5.4033, 5.4033, 5.4032, 5.4032, 5.4033, 5.4034, 5.4032, 5.4034,\n",
      "        5.4034, 5.4034, 5.4033, 5.4032, 5.4032, 5.4035, 5.4032, 5.4032, 5.4032,\n",
      "        5.4033, 5.4032, 5.4034, 5.4035, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4033, 5.4034, 5.4034, 5.4032,\n",
      "        5.4032, 5.4033, 5.4032, 5.4032, 5.4033, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032, 5.4032,\n",
      "        5.4032, 5.4032, 5.4032], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.779369  [545724/5599865]\n",
      "average delta from current occupancy tensor([5.7022, 5.7022, 5.7022, 5.7023, 5.7023, 5.7022, 5.7023, 5.7021, 5.7021,\n",
      "        5.7020, 5.7021, 5.7021, 5.7021, 5.7021, 5.7020, 5.7020, 5.7019, 5.7019,\n",
      "        5.7018, 5.7019, 5.7018, 5.7018, 5.7019, 5.7019, 5.7019, 5.7018, 5.7019,\n",
      "        5.7021, 5.7020, 5.7019, 5.7021, 5.7021, 5.7021, 5.7022, 5.7020, 5.7021,\n",
      "        5.7020, 5.7020, 5.7020, 5.7021, 5.7022, 5.7022, 5.7020, 5.7021, 5.7020,\n",
      "        5.7021, 5.7021, 5.7021, 5.7022, 5.7022, 5.7022, 5.7023, 5.7023, 5.7021,\n",
      "        5.7022, 5.7021, 5.7020, 5.7019, 5.7019, 5.7020, 5.7020, 5.7020, 5.7020,\n",
      "        5.7020, 5.7021, 5.7021, 5.7021, 5.7020, 5.7021, 5.7020, 5.7021, 5.7020,\n",
      "        5.7019, 5.7020, 5.7021, 5.7021, 5.7021, 5.7022, 5.7021, 5.7021, 5.7022,\n",
      "        5.7021, 5.7021, 5.7022, 5.7023, 5.7021, 5.7022, 5.7021, 5.7021, 5.7021,\n",
      "        5.7022, 5.7021, 5.7023, 5.7021, 5.7023, 5.7024, 5.7024, 5.7022, 5.7021,\n",
      "        5.7019, 5.7020, 5.7021, 5.7021, 5.7021, 5.7021, 5.7022, 5.7022, 5.7021,\n",
      "        5.7020, 5.7017, 5.7017, 5.7018, 5.7018, 5.7017, 5.7019, 5.7020, 5.7018,\n",
      "        5.7017, 5.7017, 5.7017], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.256629  [558124/5599865]\n",
      "average delta from current occupancy tensor([5.3634, 5.3633, 5.3633, 5.3634, 5.3635, 5.3633, 5.3633, 5.3634, 5.3635,\n",
      "        5.3633, 5.3635, 5.3635, 5.3635, 5.3633, 5.3635, 5.3634, 5.3634, 5.3634,\n",
      "        5.3635, 5.3635, 5.3634, 5.3635, 5.3634, 5.3635, 5.3634, 5.3635, 5.3634,\n",
      "        5.3634, 5.3634, 5.3634, 5.3635, 5.3633, 5.3634, 5.3633, 5.3634, 5.3634,\n",
      "        5.3634, 5.3634, 5.3634, 5.3633, 5.3634, 5.3634, 5.3634, 5.3634, 5.3634,\n",
      "        5.3634, 5.3635, 5.3634, 5.3634, 5.3634, 5.3635, 5.3634, 5.3634, 5.3634,\n",
      "        5.3634, 5.3634, 5.3634, 5.3634, 5.3633, 5.3633, 5.3635, 5.3634, 5.3633,\n",
      "        5.3634, 5.3634, 5.3633, 5.3634, 5.3634, 5.3635, 5.3634, 5.3634, 5.3633,\n",
      "        5.3634, 5.3633, 5.3634, 5.3634, 5.3634, 5.3635, 5.3634, 5.3633, 5.3632,\n",
      "        5.3634, 5.3635, 5.3635, 5.3635, 5.3633, 5.3635, 5.3634, 5.3634, 5.3632,\n",
      "        5.3634, 5.3632, 5.3634, 5.3633, 5.3633, 5.3635, 5.3635, 5.3633, 5.3634,\n",
      "        5.3635, 5.3633, 5.3635, 5.3635, 5.3635, 5.3635, 5.3635, 5.3634, 5.3635,\n",
      "        5.3634, 5.3633, 5.3634, 5.3635, 5.3634, 5.3636, 5.3636, 5.3636, 5.3634,\n",
      "        5.3637, 5.3635, 5.3635], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.123467  [570524/5599865]\n",
      "average delta from current occupancy tensor([5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1936, 5.1936, 5.1936, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1936, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1936, 5.1936, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1935, 5.1936, 5.1935, 5.1935,\n",
      "        5.1935, 5.1935, 5.1935], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.122432  [582924/5599865]\n",
      "average delta from current occupancy tensor([5.2260, 5.2260, 5.2260, 5.2260, 5.2261, 5.2260, 5.2261, 5.2260, 5.2261,\n",
      "        5.2259, 5.2260, 5.2261, 5.2260, 5.2260, 5.2261, 5.2262, 5.2261, 5.2261,\n",
      "        5.2262, 5.2261, 5.2262, 5.2261, 5.2262, 5.2260, 5.2260, 5.2258, 5.2259,\n",
      "        5.2258, 5.2258, 5.2258, 5.2258, 5.2259, 5.2259, 5.2259, 5.2261, 5.2259,\n",
      "        5.2260, 5.2258, 5.2258, 5.2260, 5.2259, 5.2259, 5.2260, 5.2261, 5.2259,\n",
      "        5.2258, 5.2258, 5.2259, 5.2259, 5.2259, 5.2258, 5.2260, 5.2259, 5.2260,\n",
      "        5.2260, 5.2261, 5.2259, 5.2260, 5.2260, 5.2259, 5.2262, 5.2258, 5.2260,\n",
      "        5.2259, 5.2261, 5.2260, 5.2258, 5.2259, 5.2258, 5.2258, 5.2258, 5.2259,\n",
      "        5.2257, 5.2258, 5.2258, 5.2258, 5.2257, 5.2257, 5.2258, 5.2258, 5.2258,\n",
      "        5.2258, 5.2258, 5.2258, 5.2258, 5.2258, 5.2258, 5.2257, 5.2257, 5.2257,\n",
      "        5.2257, 5.2258, 5.2258, 5.2257, 5.2257, 5.2258, 5.2257, 5.2257, 5.2258,\n",
      "        5.2257, 5.2257, 5.2257, 5.2257, 5.2258, 5.2258, 5.2257, 5.2257, 5.2258,\n",
      "        5.2257, 5.2257, 5.2257, 5.2257, 5.2257, 5.2257, 5.2257, 5.2257, 5.2258,\n",
      "        5.2257, 5.2257, 5.2257], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.056409  [595324/5599865]\n",
      "average delta from current occupancy tensor([5.0557, 5.0557, 5.0557, 5.0558, 5.0557, 5.0557, 5.0556, 5.0556, 5.0557,\n",
      "        5.0557, 5.0556, 5.0556, 5.0556, 5.0557, 5.0557, 5.0557, 5.0557, 5.0556,\n",
      "        5.0557, 5.0557, 5.0557, 5.0557, 5.0557, 5.0559, 5.0558, 5.0556, 5.0557,\n",
      "        5.0558, 5.0556, 5.0558, 5.0557, 5.0556, 5.0556, 5.0557, 5.0556, 5.0557,\n",
      "        5.0557, 5.0556, 5.0557, 5.0556, 5.0556, 5.0556, 5.0557, 5.0557, 5.0556,\n",
      "        5.0556, 5.0557, 5.0558, 5.0556, 5.0556, 5.0557, 5.0557, 5.0557, 5.0556,\n",
      "        5.0556, 5.0556, 5.0556, 5.0556, 5.0557, 5.0556, 5.0556, 5.0556, 5.0557,\n",
      "        5.0556, 5.0557, 5.0558, 5.0558, 5.0558, 5.0557, 5.0557, 5.0558, 5.0557,\n",
      "        5.0557, 5.0558, 5.0558, 5.0558, 5.0557, 5.0558, 5.0558, 5.0558, 5.0558,\n",
      "        5.0558, 5.0558, 5.0558, 5.0559, 5.0559, 5.0558, 5.0558, 5.0558, 5.0557,\n",
      "        5.0559, 5.0559, 5.0559, 5.0557, 5.0557, 5.0558, 5.0557, 5.0558, 5.0558,\n",
      "        5.0558, 5.0558, 5.0558, 5.0557, 5.0558, 5.0557, 5.0557, 5.0557, 5.0557,\n",
      "        5.0557, 5.0557, 5.0558, 5.0558, 5.0558, 5.0558, 5.0557, 5.0558, 5.0558,\n",
      "        5.0558, 5.0557, 5.0558], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.533304  [607724/5599865]\n",
      "average delta from current occupancy tensor([4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5727, 4.5727, 4.5726, 4.5727, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5727, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5727, 4.5726, 4.5727, 4.5727, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5727, 4.5727,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726, 4.5726, 4.5726, 4.5727, 4.5726, 4.5726, 4.5726,\n",
      "        4.5726, 4.5726, 4.5726], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.378233  [620124/5599865]\n",
      "average delta from current occupancy tensor([5.2499, 5.2500, 5.2500, 5.2500, 5.2500, 5.2500, 5.2501, 5.2500, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2497, 5.2497, 5.2499, 5.2497, 5.2497, 5.2497,\n",
      "        5.2499, 5.2498, 5.2498, 5.2497, 5.2497, 5.2497, 5.2497, 5.2498, 5.2498,\n",
      "        5.2498, 5.2498, 5.2498, 5.2498, 5.2499, 5.2498, 5.2498, 5.2498, 5.2498,\n",
      "        5.2497, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498,\n",
      "        5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2497, 5.2497, 5.2497, 5.2497,\n",
      "        5.2497, 5.2497, 5.2497, 5.2497, 5.2497, 5.2498, 5.2497, 5.2498, 5.2497,\n",
      "        5.2497, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2498, 5.2497, 5.2499,\n",
      "        5.2497, 5.2497, 5.2497, 5.2496, 5.2497, 5.2497, 5.2498, 5.2498, 5.2498,\n",
      "        5.2498, 5.2500, 5.2498, 5.2498, 5.2499, 5.2499, 5.2499, 5.2499, 5.2499,\n",
      "        5.2498, 5.2499, 5.2499, 5.2498, 5.2499, 5.2501, 5.2499, 5.2499, 5.2499,\n",
      "        5.2498, 5.2499, 5.2500, 5.2498, 5.2500, 5.2500, 5.2499, 5.2499, 5.2499,\n",
      "        5.2499, 5.2499, 5.2499, 5.2498, 5.2499, 5.2499, 5.2498, 5.2499, 5.2499,\n",
      "        5.2498, 5.2497, 5.2497], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.809676  [632524/5599865]\n",
      "average delta from current occupancy tensor([5.9248, 5.9248, 5.9247, 5.9247, 5.9245, 5.9248, 5.9251, 5.9248, 5.9244,\n",
      "        5.9245, 5.9246, 5.9249, 5.9243, 5.9243, 5.9246, 5.9242, 5.9243, 5.9243,\n",
      "        5.9247, 5.9249, 5.9250, 5.9249, 5.9246, 5.9245, 5.9244, 5.9248, 5.9245,\n",
      "        5.9243, 5.9244, 5.9244, 5.9242, 5.9243, 5.9244, 5.9243, 5.9241, 5.9243,\n",
      "        5.9241, 5.9240, 5.9241, 5.9242, 5.9240, 5.9242, 5.9238, 5.9240, 5.9243,\n",
      "        5.9241, 5.9240, 5.9242, 5.9241, 5.9238, 5.9240, 5.9240, 5.9238, 5.9236,\n",
      "        5.9238, 5.9236, 5.9233, 5.9235, 5.9236, 5.9237, 5.9235, 5.9237, 5.9235,\n",
      "        5.9236, 5.9237, 5.9237, 5.9233, 5.9235, 5.9235, 5.9237, 5.9236, 5.9237,\n",
      "        5.9233, 5.9233, 5.9230, 5.9226, 5.9226, 5.9228, 5.9231, 5.9233, 5.9232,\n",
      "        5.9234, 5.9234, 5.9233, 5.9231, 5.9234, 5.9232, 5.9233, 5.9232, 5.9236,\n",
      "        5.9230, 5.9233, 5.9228, 5.9225, 5.9228, 5.9221, 5.9230, 5.9226, 5.9229,\n",
      "        5.9219, 5.9223, 5.9227, 5.9220, 5.9227, 5.9218, 5.9225, 5.9226, 5.9226,\n",
      "        5.9226, 5.9227, 5.9221, 5.9224, 5.9224, 5.9230, 5.9222, 5.9229, 5.9232,\n",
      "        5.9229, 5.9233, 5.9233], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.411449  [644924/5599865]\n",
      "average delta from current occupancy tensor([5.2263, 5.2263, 5.2264, 5.2264, 5.2264, 5.2263, 5.2263, 5.2262, 5.2264,\n",
      "        5.2264, 5.2264, 5.2264, 5.2264, 5.2264, 5.2263, 5.2265, 5.2264, 5.2264,\n",
      "        5.2264, 5.2263, 5.2264, 5.2264, 5.2264, 5.2265, 5.2266, 5.2265, 5.2265,\n",
      "        5.2265, 5.2266, 5.2265, 5.2265, 5.2266, 5.2266, 5.2266, 5.2266, 5.2266,\n",
      "        5.2266, 5.2265, 5.2266, 5.2266, 5.2267, 5.2266, 5.2267, 5.2266, 5.2266,\n",
      "        5.2266, 5.2266, 5.2266, 5.2266, 5.2266, 5.2265, 5.2265, 5.2265, 5.2265,\n",
      "        5.2265, 5.2265, 5.2265, 5.2264, 5.2264, 5.2265, 5.2264, 5.2265, 5.2265,\n",
      "        5.2265, 5.2266, 5.2265, 5.2265, 5.2265, 5.2264, 5.2265, 5.2265, 5.2264,\n",
      "        5.2264, 5.2265, 5.2265, 5.2265, 5.2263, 5.2264, 5.2265, 5.2266, 5.2266,\n",
      "        5.2266, 5.2266, 5.2266, 5.2266, 5.2265, 5.2265, 5.2265, 5.2266, 5.2265,\n",
      "        5.2266, 5.2266, 5.2265, 5.2264, 5.2265, 5.2264, 5.2265, 5.2265, 5.2267,\n",
      "        5.2265, 5.2265, 5.2265, 5.2265, 5.2265, 5.2265, 5.2265, 5.2265, 5.2265,\n",
      "        5.2265, 5.2265, 5.2265, 5.2265, 5.2266, 5.2267, 5.2265, 5.2267, 5.2267,\n",
      "        5.2266, 5.2266, 5.2266], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.473693  [657324/5599865]\n",
      "average delta from current occupancy tensor([4.5160, 4.5160, 4.5162, 4.5162, 4.5161, 4.5161, 4.5160, 4.5160, 4.5162,\n",
      "        4.5161, 4.5159, 4.5160, 4.5159, 4.5158, 4.5161, 4.5159, 4.5158, 4.5158,\n",
      "        4.5160, 4.5157, 4.5160, 4.5158, 4.5158, 4.5159, 4.5160, 4.5159, 4.5160,\n",
      "        4.5160, 4.5159, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160, 4.5160,\n",
      "        4.5159, 4.5160, 4.5162, 4.5160, 4.5161, 4.5161, 4.5161, 4.5158, 4.5158,\n",
      "        4.5158, 4.5159, 4.5159, 4.5158, 4.5159, 4.5158, 4.5157, 4.5157, 4.5157,\n",
      "        4.5156, 4.5156, 4.5158, 4.5156, 4.5158, 4.5157, 4.5158, 4.5160, 4.5159,\n",
      "        4.5158, 4.5159, 4.5158, 4.5158, 4.5157, 4.5159, 4.5158, 4.5158, 4.5158,\n",
      "        4.5159, 4.5158, 4.5159, 4.5159, 4.5160, 4.5159, 4.5159, 4.5159, 4.5161,\n",
      "        4.5159, 4.5159, 4.5158, 4.5158, 4.5161, 4.5160, 4.5160, 4.5159, 4.5157,\n",
      "        4.5157, 4.5159, 4.5157, 4.5157, 4.5156, 4.5159, 4.5159, 4.5157, 4.5160,\n",
      "        4.5160, 4.5158, 4.5159, 4.5159, 4.5159, 4.5159, 4.5159, 4.5160, 4.5159,\n",
      "        4.5160, 4.5160, 4.5159, 4.5161, 4.5160, 4.5161, 4.5160, 4.5158, 4.5161,\n",
      "        4.5162, 4.5160, 4.5161], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.608800  [669724/5599865]\n",
      "average delta from current occupancy tensor([5.5876, 5.5877, 5.5876, 5.5875, 5.5875, 5.5877, 5.5877, 5.5877, 5.5877,\n",
      "        5.5877, 5.5876, 5.5875, 5.5874, 5.5875, 5.5874, 5.5875, 5.5874, 5.5874,\n",
      "        5.5875, 5.5874, 5.5874, 5.5875, 5.5873, 5.5874, 5.5873, 5.5873, 5.5873,\n",
      "        5.5874, 5.5874, 5.5874, 5.5873, 5.5873, 5.5875, 5.5874, 5.5876, 5.5876,\n",
      "        5.5875, 5.5875, 5.5874, 5.5873, 5.5873, 5.5873, 5.5875, 5.5874, 5.5874,\n",
      "        5.5875, 5.5874, 5.5875, 5.5872, 5.5874, 5.5875, 5.5874, 5.5875, 5.5875,\n",
      "        5.5872, 5.5872, 5.5872, 5.5871, 5.5872, 5.5872, 5.5873, 5.5873, 5.5872,\n",
      "        5.5872, 5.5872, 5.5872, 5.5871, 5.5871, 5.5872, 5.5873, 5.5872, 5.5873,\n",
      "        5.5874, 5.5873, 5.5872, 5.5873, 5.5873, 5.5873, 5.5874, 5.5874, 5.5875,\n",
      "        5.5875, 5.5875, 5.5875, 5.5876, 5.5877, 5.5877, 5.5877, 5.5876, 5.5876,\n",
      "        5.5876, 5.5877, 5.5875, 5.5875, 5.5874, 5.5876, 5.5875, 5.5875, 5.5875,\n",
      "        5.5875, 5.5874, 5.5875, 5.5875, 5.5876, 5.5875, 5.5875, 5.5875, 5.5875,\n",
      "        5.5875, 5.5877, 5.5875, 5.5876, 5.5875, 5.5875, 5.5875, 5.5876, 5.5875,\n",
      "        5.5874, 5.5874, 5.5874], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.482504  [682124/5599865]\n",
      "average delta from current occupancy tensor([5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7177,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7177, 5.7177, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7177, 5.7178, 5.7178, 5.7178, 5.7178,\n",
      "        5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7178, 5.7177,\n",
      "        5.7178, 5.7178, 5.7178], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.395200  [694524/5599865]\n",
      "average delta from current occupancy tensor([5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5485, 5.5484,\n",
      "        5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484,\n",
      "        5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5484, 5.5486, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484, 5.5484,\n",
      "        5.5484, 5.5484, 5.5484, 5.5485, 5.5484, 5.5485, 5.5485, 5.5485, 5.5485,\n",
      "        5.5486, 5.5486, 5.5485, 5.5485, 5.5486, 5.5486, 5.5487, 5.5486, 5.5486,\n",
      "        5.5487, 5.5485, 5.5485, 5.5485, 5.5486, 5.5484, 5.5486, 5.5486, 5.5486,\n",
      "        5.5486, 5.5486, 5.5486, 5.5485, 5.5486, 5.5486, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5485, 5.5484, 5.5484,\n",
      "        5.5485, 5.5484, 5.5485, 5.5485, 5.5485, 5.5484, 5.5484, 5.5485, 5.5484,\n",
      "        5.5484, 5.5485, 5.5484, 5.5485, 5.5484, 5.5484, 5.5485, 5.5485, 5.5485,\n",
      "        5.5485, 5.5484, 5.5484, 5.5484, 5.5485, 5.5485, 5.5485, 5.5485, 5.5484,\n",
      "        5.5485, 5.5485, 5.5484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.310270  [706924/5599865]\n",
      "average delta from current occupancy tensor([5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548, 5.3548,\n",
      "        5.3548, 5.3548, 5.3548], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.277099  [719324/5599865]\n",
      "average delta from current occupancy tensor([5.1374, 5.1374, 5.1374, 5.1375, 5.1374, 5.1374, 5.1375, 5.1374, 5.1374,\n",
      "        5.1374, 5.1374, 5.1374, 5.1375, 5.1375, 5.1374, 5.1375, 5.1374, 5.1375,\n",
      "        5.1374, 5.1375, 5.1374, 5.1375, 5.1374, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1374, 5.1375,\n",
      "        5.1375, 5.1375, 5.1374, 5.1375, 5.1375, 5.1374, 5.1375, 5.1374, 5.1374,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1376,\n",
      "        5.1375, 5.1376, 5.1375, 5.1375, 5.1376, 5.1376, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1374, 5.1374, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375, 5.1375,\n",
      "        5.1375, 5.1375, 5.1375], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.306527  [731724/5599865]\n",
      "average delta from current occupancy tensor([5.4517, 5.4518, 5.4516, 5.4516, 5.4517, 5.4518, 5.4516, 5.4516, 5.4516,\n",
      "        5.4516, 5.4516, 5.4516, 5.4517, 5.4518, 5.4518, 5.4516, 5.4518, 5.4518,\n",
      "        5.4517, 5.4517, 5.4518, 5.4517, 5.4518, 5.4516, 5.4517, 5.4517, 5.4516,\n",
      "        5.4516, 5.4517, 5.4517, 5.4516, 5.4517, 5.4516, 5.4516, 5.4517, 5.4517,\n",
      "        5.4516, 5.4516, 5.4517, 5.4516, 5.4517, 5.4517, 5.4516, 5.4516, 5.4517,\n",
      "        5.4516, 5.4516, 5.4516, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517,\n",
      "        5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4516, 5.4516, 5.4516, 5.4517,\n",
      "        5.4516, 5.4516, 5.4516, 5.4516, 5.4516, 5.4517, 5.4516, 5.4517, 5.4517,\n",
      "        5.4516, 5.4516, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4516, 5.4516,\n",
      "        5.4516, 5.4517, 5.4516, 5.4516, 5.4516, 5.4517, 5.4516, 5.4516, 5.4517,\n",
      "        5.4517, 5.4517, 5.4516, 5.4516, 5.4516, 5.4517, 5.4516, 5.4517, 5.4516,\n",
      "        5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517, 5.4517,\n",
      "        5.4516, 5.4517, 5.4516, 5.4516, 5.4516, 5.4517, 5.4516, 5.4517, 5.4516,\n",
      "        5.4516, 5.4517, 5.4516], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.675326  [744124/5599865]\n",
      "average delta from current occupancy tensor([4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661, 4.7661,\n",
      "        4.7661, 4.7661, 4.7661], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.724810  [756524/5599865]\n",
      "average delta from current occupancy tensor([4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677, 4.9677,\n",
      "        4.9677, 4.9677, 4.9677], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.151112  [768924/5599865]\n",
      "average delta from current occupancy tensor([5.2599, 5.2598, 5.2597, 5.2596, 5.2595, 5.2597, 5.2597, 5.2598, 5.2598,\n",
      "        5.2597, 5.2598, 5.2598, 5.2598, 5.2598, 5.2597, 5.2597, 5.2598, 5.2597,\n",
      "        5.2598, 5.2599, 5.2601, 5.2597, 5.2598, 5.2597, 5.2598, 5.2597, 5.2599,\n",
      "        5.2600, 5.2601, 5.2599, 5.2601, 5.2600, 5.2603, 5.2603, 5.2601, 5.2601,\n",
      "        5.2601, 5.2602, 5.2599, 5.2599, 5.2598, 5.2600, 5.2600, 5.2600, 5.2601,\n",
      "        5.2598, 5.2599, 5.2596, 5.2598, 5.2596, 5.2598, 5.2598, 5.2599, 5.2599,\n",
      "        5.2599, 5.2600, 5.2597, 5.2592, 5.2594, 5.2592, 5.2596, 5.2594, 5.2596,\n",
      "        5.2597, 5.2596, 5.2597, 5.2598, 5.2598, 5.2600, 5.2602, 5.2603, 5.2599,\n",
      "        5.2601, 5.2600, 5.2600, 5.2599, 5.2602, 5.2599, 5.2598, 5.2599, 5.2599,\n",
      "        5.2598, 5.2598, 5.2601, 5.2599, 5.2601, 5.2602, 5.2602, 5.2597, 5.2601,\n",
      "        5.2602, 5.2599, 5.2598, 5.2598, 5.2597, 5.2597, 5.2595, 5.2595, 5.2593,\n",
      "        5.2595, 5.2592, 5.2595, 5.2599, 5.2599, 5.2594, 5.2598, 5.2599, 5.2600,\n",
      "        5.2598, 5.2596, 5.2594, 5.2593, 5.2593, 5.2595, 5.2596, 5.2600, 5.2596,\n",
      "        5.2600, 5.2598, 5.2602], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.007077  [781324/5599865]\n",
      "average delta from current occupancy tensor([4.9956, 4.9954, 4.9955, 4.9956, 4.9955, 4.9955, 4.9958, 4.9958, 4.9959,\n",
      "        4.9957, 4.9957, 4.9955, 4.9954, 4.9956, 4.9957, 4.9955, 4.9952, 4.9954,\n",
      "        4.9955, 4.9956, 4.9958, 4.9955, 4.9957, 4.9956, 4.9955, 4.9957, 4.9958,\n",
      "        4.9959, 4.9957, 4.9957, 4.9956, 4.9953, 4.9956, 4.9955, 4.9955, 4.9955,\n",
      "        4.9952, 4.9956, 4.9954, 4.9953, 4.9952, 4.9954, 4.9954, 4.9954, 4.9956,\n",
      "        4.9955, 4.9955, 4.9955, 4.9955, 4.9951, 4.9954, 4.9958, 4.9956, 4.9957,\n",
      "        4.9957, 4.9958, 4.9957, 4.9952, 4.9956, 4.9954, 4.9956, 4.9953, 4.9954,\n",
      "        4.9957, 4.9957, 4.9959, 4.9958, 4.9957, 4.9957, 4.9959, 4.9958, 4.9955,\n",
      "        4.9957, 4.9956, 4.9952, 4.9955, 4.9955, 4.9955, 4.9952, 4.9953, 4.9952,\n",
      "        4.9952, 4.9952, 4.9954, 4.9958, 4.9956, 4.9958, 4.9957, 4.9958, 4.9960,\n",
      "        4.9958, 4.9954, 4.9954, 4.9954, 4.9955, 4.9952, 4.9949, 4.9951, 4.9950,\n",
      "        4.9951, 4.9948, 4.9950, 4.9953, 4.9951, 4.9952, 4.9950, 4.9950, 4.9952,\n",
      "        4.9952, 4.9951, 4.9951, 4.9952, 4.9954, 4.9956, 4.9953, 4.9955, 4.9956,\n",
      "        4.9953, 4.9953, 4.9957], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 4.674374  [793724/5599865]\n",
      "average delta from current occupancy tensor([4.6371, 4.6370, 4.6370, 4.6371, 4.6371, 4.6371, 4.6372, 4.6372, 4.6372,\n",
      "        4.6371, 4.6372, 4.6371, 4.6371, 4.6373, 4.6373, 4.6372, 4.6372, 4.6372,\n",
      "        4.6372, 4.6372, 4.6372, 4.6370, 4.6373, 4.6373, 4.6372, 4.6371, 4.6372,\n",
      "        4.6372, 4.6372, 4.6371, 4.6371, 4.6371, 4.6373, 4.6372, 4.6373, 4.6373,\n",
      "        4.6372, 4.6373, 4.6373, 4.6373, 4.6373, 4.6373, 4.6372, 4.6371, 4.6371,\n",
      "        4.6372, 4.6372, 4.6372, 4.6371, 4.6371, 4.6371, 4.6370, 4.6371, 4.6371,\n",
      "        4.6371, 4.6371, 4.6371, 4.6372, 4.6371, 4.6372, 4.6371, 4.6371, 4.6373,\n",
      "        4.6372, 4.6372, 4.6372, 4.6373, 4.6372, 4.6373, 4.6371, 4.6372, 4.6372,\n",
      "        4.6372, 4.6372, 4.6372, 4.6372, 4.6372, 4.6371, 4.6371, 4.6371, 4.6371,\n",
      "        4.6372, 4.6372, 4.6372, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6370,\n",
      "        4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6371, 4.6372, 4.6373, 4.6373,\n",
      "        4.6373, 4.6372, 4.6372, 4.6371, 4.6372, 4.6371, 4.6372, 4.6371, 4.6372,\n",
      "        4.6371, 4.6371, 4.6371, 4.6372, 4.6370, 4.6371, 4.6371, 4.6371, 4.6371,\n",
      "        4.6371, 4.6371, 4.6370], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "loss: 5.361670  [806124/5599865]\n",
      "average delta from current occupancy tensor([5.4042, 5.4040, 5.4040, 5.4044, 5.4045, 5.4040, 5.4039, 5.4043, 5.4040,\n",
      "        5.4040, 5.4041, 5.4044, 5.4040, 5.4039, 5.4040, 5.4043, 5.4039, 5.4039,\n",
      "        5.4039, 5.4038, 5.4041, 5.4043, 5.4041, 5.4041, 5.4040, 5.4044, 5.4042,\n",
      "        5.4041, 5.4044, 5.4043, 5.4040, 5.4043, 5.4039, 5.4039, 5.4037, 5.4038,\n",
      "        5.4040, 5.4042, 5.4040, 5.4042, 5.4040, 5.4040, 5.4037, 5.4037, 5.4038,\n",
      "        5.4037, 5.4039, 5.4038, 5.4038, 5.4037, 5.4037, 5.4036, 5.4036, 5.4035,\n",
      "        5.4035, 5.4037, 5.4037, 5.4040, 5.4038, 5.4040, 5.4035, 5.4037, 5.4035,\n",
      "        5.4035, 5.4036, 5.4037, 5.4037, 5.4038, 5.4040, 5.4038, 5.4041, 5.4041,\n",
      "        5.4042, 5.4042, 5.4043, 5.4042, 5.4044, 5.4043, 5.4043, 5.4043, 5.4041,\n",
      "        5.4042, 5.4044, 5.4044, 5.4042, 5.4050, 5.4049, 5.4041, 5.4045, 5.4042,\n",
      "        5.4051, 5.4049, 5.4047, 5.4045, 5.4052, 5.4050, 5.4049, 5.4051, 5.4048,\n",
      "        5.4049, 5.4048, 5.4048, 5.4049, 5.4047, 5.4049, 5.4048, 5.4050, 5.4052,\n",
      "        5.4051, 5.4051, 5.4051, 5.4049, 5.4050, 5.4050, 5.4052, 5.4052, 5.4052,\n",
      "        5.4051, 5.4048, 5.4050], dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[357], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     test_loop(validation_dataloader, model, loss_fn)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[356], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set the model to training mode - important for batch normalization and dropout layers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Unnecessary in this situation but added for best practices\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction and loss\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rraag\\development\\bikeshare-availibility-predictions\\prediction-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\rraag\\development\\bikeshare-availibility-predictions\\prediction-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\rraag\\development\\bikeshare-availibility-predictions\\prediction-model\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[350], line 99\u001b[0m, in \u001b[0;36mBikeShareDatasetOptimized.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     97\u001b[0m neighbour_diffs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_nearest_differences[current_station]\n\u001b[0;32m     98\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[indices[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m neighbour_diffs[\u001b[38;5;28;01mNone\u001b[39;00m, :]]\n\u001b[1;32m---> 99\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFLAT_NUM_FEATURES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m y_indices \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhorizon \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m NUM_STATIONS\n\u001b[0;32m    102\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[y_indices, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# index 0 is NumBikes\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "class WeightedL1Loss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(WeightedL1Loss, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Ensure the weights are on the same device as predictions and targets\n",
    "        weights = self.weights.to(predictions.device)\n",
    "        \n",
    "        # Calculate the L1 loss (element-wise absolute difference)\n",
    "        loss = torch.abs(predictions - targets)\n",
    "        \n",
    "        # Apply the weights to the loss components\n",
    "        weighted_loss = loss * weights\n",
    "        \n",
    "        # Return the mean of the weighted loss\n",
    "        return torch.mean(weighted_loss)\n",
    "\n",
    "\n",
    "# weights = torch.linspace(1, 0.1, steps=horizon)\n",
    "\n",
    "\n",
    "# loss_fn = nn.L1Loss(reduction=\"mean\")\n",
    "loss_fn = nn.L1Loss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(validation_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
